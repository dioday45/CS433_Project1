{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.path.abspath(os.curdir)\n",
    "os.chdir(\"..\")\n",
    "ML_FOLDER_PATH = os.path.abspath(os.curdir)\n",
    "sys.path.append(ML_FOLDER_PATH)\n",
    "import numpy as np\n",
    "from src.nn import NN\n",
    "import src.helpers as hlp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining data path and models architectures\n",
    "\n",
    "TRAIN_DATA_PATH = 'data/train.csv'\n",
    "\n",
    "nn_architecture0 = [\n",
    "    {\"input_dim\": 36, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 64, \"output_dim\": 32, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 32, \"output_dim\": 16, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 16, \"output_dim\": 2, \"activation\": \"softmax\"},\n",
    "]\n",
    "nn_architecture1 = [\n",
    "    {\"input_dim\": 44, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 64, \"output_dim\": 32, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 32, \"output_dim\": 16, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 16, \"output_dim\": 2, \"activation\": \"softmax\"},\n",
    "]\n",
    "nn_architecture2 = [\n",
    "    {\"input_dim\": 58, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 64, \"output_dim\": 32, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 32, \"output_dim\": 16, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 16, \"output_dim\": 2, \"activation\": \"softmax\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 0: train_data0.shape=(99913, 36)\n",
      "dataset 1: train_data1.shape=(77544, 44)\n",
      "dataset 2: train_data2.shape=(72543, 58)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Loading, splitting along PRI_jet_num, preprocessing (polynomial expension, arcsinh transform, standardization),\n",
    "and train/val split.\n",
    "'''\n",
    "\n",
    "train_data_raw0, train_data_raw1, train_data_raw2 = hlp.load_split_data(TRAIN_DATA_PATH, one_hot=True)\n",
    "train_data0, train_data1, train_data2 = hlp.process_data(\n",
    "    train_data_raw0, train_data_raw1, train_data_raw2,\n",
    ")\n",
    "\n",
    "#delete unused variables to save memory\n",
    "del train_data_raw0\n",
    "del train_data_raw1\n",
    "del train_data_raw2\n",
    "\n",
    "train_data0, val_data0 = hlp.split_val_train(train_data0,seed=42)\n",
    "train_data1, val_data1 = hlp.split_val_train(train_data1,seed=42)\n",
    "train_data2, val_data2 = hlp.split_val_train(train_data2,seed=42)\n",
    "\n",
    "train_y0, train_data0 = (\n",
    "    train_data0[:, 1].astype(\"int32\"),\n",
    "    np.delete(train_data0, [0, 1], axis=1),\n",
    ")\n",
    "train_y1, train_data1 = (\n",
    "    train_data1[:, 1].astype(\"int32\"),\n",
    "    np.delete(train_data1, [0, 1], axis=1),\n",
    ")\n",
    "train_y2, train_data2 = (\n",
    "    train_data2[:, 1].astype(\"int32\"),\n",
    "    np.delete(train_data2, [0, 1], axis=1),\n",
    ")\n",
    "\n",
    "val_y0, val_data0 = (\n",
    "    val_data0[:, 1].astype(\"int32\"),\n",
    "    np.delete(val_data0, [0, 1], axis=1),\n",
    ")\n",
    "val_y1, val_data1 = (\n",
    "    val_data1[:, 1].astype(\"int32\"),\n",
    "    np.delete(val_data1, [0, 1], axis=1),\n",
    ")\n",
    "val_y2, val_data2 = (\n",
    "    val_data2[:, 1].astype(\"int32\"),\n",
    "    np.delete(val_data2, [0, 1], axis=1),\n",
    ")\n",
    "\n",
    "print(f'dataset 0: {train_data0.shape=},{val_data0.shape=}\\n\\\n",
    "dataset 1: {train_data1.shape=}, {val_data1.shape=}\\n\\\n",
    "dataset 2: {train_data2.shape=}, {val_data2.shape=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----model0 training-----\n",
      "\n",
      "epoch 1 lr 0.4990009993336666\n",
      "train_loss 0.6929624541941615 train_acc 0.5336462005538195\n",
      "epoch 2 lr 0.4980039946719958\n",
      "train_loss 0.6811384132532663 train_acc 0.7456990024577129\n",
      "epoch 3 lr 0.4970089820269677\n",
      "train_loss 0.6704707353220151 train_acc 0.7456990024577129\n",
      "epoch 4 lr 0.49601595741853033\n",
      "train_loss 0.6608444418824361 train_acc 0.7456990024577129\n",
      "epoch 5 lr 0.49502491687458405\n",
      "train_loss 0.6521553002614495 train_acc 0.7456990024577129\n",
      "epoch 6 lr 0.4940358564309653\n",
      "train_loss 0.6443092251912536 train_acc 0.7456990024577129\n",
      "epoch 7 lr 0.493048772131431\n",
      "train_loss 0.6372216362025216 train_acc 0.7456990024577129\n",
      "epoch 8 lr 0.49206366002764257\n",
      "train_loss 0.6308165179999368 train_acc 0.7456990024577129\n",
      "epoch 9 lr 0.4910805161791504\n",
      "train_loss 0.6250253930177418 train_acc 0.7456990024577129\n",
      "epoch 10 lr 0.4900993366533777\n",
      "train_loss 0.6197866787458517 train_acc 0.7456990024577129\n",
      "epoch 11 lr 0.4891201175256051\n",
      "train_loss 0.615045268431374 train_acc 0.7456990024577129\n",
      "epoch 12 lr 0.4881428548789547\n",
      "train_loss 0.6107517445325753 train_acc 0.7456990024577129\n",
      "epoch 13 lr 0.4871675448043747\n",
      "train_loss 0.6068615972151948 train_acc 0.7456990024577129\n",
      "epoch 14 lr 0.4861941834006235\n",
      "train_loss 0.6033350541313939 train_acc 0.7456990024577129\n",
      "epoch 15 lr 0.48522276677425413\n",
      "train_loss 0.6001362345546073 train_acc 0.7456990024577129\n",
      "epoch 16 lr 0.4842532910395988\n",
      "train_loss 0.5972329998767325 train_acc 0.7456990024577129\n",
      "epoch 17 lr 0.48328575231875337\n",
      "train_loss 0.594596399989245 train_acc 0.7456990024577129\n",
      "epoch 18 lr 0.48232014674156154\n",
      "train_loss 0.5922006605648493 train_acc 0.7456990024577129\n",
      "epoch 19 lr 0.4813564704455998\n",
      "train_loss 0.5900224767047484 train_acc 0.7456990024577129\n",
      "epoch 20 lr 0.48039471957616164\n",
      "train_loss 0.5880409759427171 train_acc 0.7456990024577129\n",
      "epoch 21 lr 0.4794348902862423\n",
      "train_loss 0.5862374546303168 train_acc 0.7456990024577129\n",
      "epoch 22 lr 0.47847697873652334\n",
      "train_loss 0.5845950067396276 train_acc 0.7456990024577129\n",
      "epoch 23 lr 0.47752098109535734\n",
      "train_loss 0.5830984310060137 train_acc 0.7456990024577129\n",
      "epoch 24 lr 0.47656689353875237\n",
      "train_loss 0.5817340746294535 train_acc 0.7456990024577129\n",
      "epoch 25 lr 0.475614712250357\n",
      "train_loss 0.5804895404251202 train_acc 0.7456990024577129\n",
      "epoch 26 lr 0.47466443342144476\n",
      "train_loss 0.5793537985167162 train_acc 0.7456990024577129\n",
      "epoch 27 lr 0.47371605325089916\n",
      "train_loss 0.5783168138488107 train_acc 0.7456990024577129\n",
      "epoch 28 lr 0.47276956794519814\n",
      "train_loss 0.577369538268979 train_acc 0.7456990024577129\n",
      "epoch 29 lr 0.47182497371839927\n",
      "train_loss 0.5765037827803945 train_acc 0.7456990024577129\n",
      "epoch 30 lr 0.47088226679212436\n",
      "train_loss 0.5757121588866547 train_acc 0.7456990024577129\n",
      "epoch 31 lr 0.46994144339554444\n",
      "train_loss 0.5749879824327039 train_acc 0.7456990024577129\n",
      "epoch 32 lr 0.46900249976536473\n",
      "train_loss 0.5743251994157235 train_acc 0.7456990024577129\n",
      "epoch 33 lr 0.4680654321458094\n",
      "train_loss 0.5737183355412889 train_acc 0.7456990024577129\n",
      "epoch 34 lr 0.46713023678860677\n",
      "train_loss 0.5731624464579563 train_acc 0.7456990024577129\n",
      "epoch 35 lr 0.46619690995297414\n",
      "train_loss 0.5726530153389521 train_acc 0.7456990024577129\n",
      "epoch 36 lr 0.46526544790560287\n",
      "train_loss 0.5721859640242236 train_acc 0.7456990024577129\n",
      "epoch 37 lr 0.4643358469206436\n",
      "train_loss 0.5717575666545458 train_acc 0.7456990024577129\n",
      "epoch 38 lr 0.4634081032796911\n",
      "train_loss 0.5713644556393428 train_acc 0.7456990024577129\n",
      "epoch 39 lr 0.46248221327176964\n",
      "train_loss 0.5710035720833262 train_acc 0.7456990024577129\n",
      "epoch 40 lr 0.4615581731933179\n",
      "train_loss 0.5706721233411495 train_acc 0.7456990024577129\n",
      "epoch 41 lr 0.4606359793481743\n",
      "train_loss 0.5703675673660031 train_acc 0.7456990024577129\n",
      "epoch 42 lr 0.45971562804756233\n",
      "train_loss 0.5700876035687292 train_acc 0.7456990024577129\n",
      "epoch 43 lr 0.45879711561007547\n",
      "train_loss 0.5698301317502661 train_acc 0.7456990024577129\n",
      "epoch 44 lr 0.4578804383616628\n",
      "train_loss 0.5695932295821147 train_acc 0.7456990024577129\n",
      "epoch 45 lr 0.4569655926356141\n",
      "train_loss 0.5693751472408618 train_acc 0.7456990024577129\n",
      "epoch 46 lr 0.45605257477254524\n",
      "train_loss 0.5691742914686702 train_acc 0.7456990024577129\n",
      "epoch 47 lr 0.4551413811203835\n",
      "train_loss 0.5689892092043082 train_acc 0.7456990024577129\n",
      "epoch 48 lr 0.4542320080343531\n",
      "train_loss 0.5688185798476588 train_acc 0.7456990024577129\n",
      "epoch 49 lr 0.45332445187696047\n",
      "train_loss 0.568661189079459 train_acc 0.7456990024577129\n",
      "\n",
      "val loss = 0.576498546543411, \n",
      "val acc = 0.7372898318654924\n",
      "\n",
      "epoch 50 lr 0.45241870901797976\n",
      "train_loss 0.5685159289487159 train_acc 0.7456990024577129\n",
      "epoch 51 lr 0.4515147758344384\n",
      "train_loss 0.5683817895048381 train_acc 0.7456990024577129\n",
      "epoch 52 lr 0.4506126487106024\n",
      "train_loss 0.5682578405737515 train_acc 0.7456990024577129\n",
      "epoch 53 lr 0.449712324037962\n",
      "train_loss 0.5681432363667195 train_acc 0.7456990024577129\n",
      "epoch 54 lr 0.44881379821521744\n",
      "train_loss 0.5680372043662625 train_acc 0.7456990024577129\n",
      "epoch 55 lr 0.4479170676482641\n",
      "train_loss 0.5679390362626846 train_acc 0.7456990024577129\n",
      "epoch 56 lr 0.4470221287501786\n",
      "train_loss 0.5678480838058597 train_acc 0.7456990024577129\n",
      "epoch 57 lr 0.44612897794120415\n",
      "train_loss 0.5677637525474418 train_acc 0.7456990024577129\n",
      "epoch 58 lr 0.44523761164873626\n",
      "train_loss 0.567685498947113 train_acc 0.7456990024577129\n",
      "epoch 59 lr 0.4443480263073087\n",
      "train_loss 0.5676128242177311 train_acc 0.7456990024577129\n",
      "epoch 60 lr 0.44346021835857874\n",
      "train_loss 0.5675452727108558 train_acc 0.7456990024577129\n",
      "epoch 61 lr 0.44257418425131356\n",
      "train_loss 0.5674824262018764 train_acc 0.7456990024577129\n",
      "epoch 62 lr 0.44168992044137545\n",
      "train_loss 0.5674238971245728 train_acc 0.7456990024577129\n",
      "epoch 63 lr 0.44080742339170803\n",
      "train_loss 0.5673693299355931 train_acc 0.7456990024577129\n",
      "epoch 64 lr 0.4399266895723219\n",
      "train_loss 0.5673184041695739 train_acc 0.7456990024577129\n",
      "epoch 65 lr 0.43904771546028065\n",
      "train_loss 0.5672708213968589 train_acc 0.7456990024577129\n",
      "epoch 66 lr 0.4381704975396867\n",
      "train_loss 0.5672263093578015 train_acc 0.7456990024577129\n",
      "epoch 67 lr 0.437295032301667\n",
      "train_loss 0.5671846186305646 train_acc 0.7456990024577129\n",
      "epoch 68 lr 0.43642131624435965\n",
      "train_loss 0.5671455195574387 train_acc 0.7456990024577129\n",
      "epoch 69 lr 0.4355493458728992\n",
      "train_loss 0.5671087979714695 train_acc 0.7456990024577129\n",
      "epoch 70 lr 0.4346791176994029\n",
      "train_loss 0.5670742610015613 train_acc 0.7456990024577129\n",
      "epoch 71 lr 0.433810628242957\n",
      "train_loss 0.5670417298770547 train_acc 0.7456990024577129\n",
      "epoch 72 lr 0.4329438740296025\n",
      "train_loss 0.5670110379631312 train_acc 0.7456990024577129\n",
      "epoch 73 lr 0.43207885159232134\n",
      "train_loss 0.5669820360942318 train_acc 0.7456990024577129\n",
      "epoch 74 lr 0.4312155574710227\n",
      "train_loss 0.5669545855802942 train_acc 0.7456990024577129\n",
      "epoch 75 lr 0.4303539882125289\n",
      "train_loss 0.5669285584265051 train_acc 0.7456990024577129\n",
      "epoch 76 lr 0.4294941403705617\n",
      "train_loss 0.5669038369090454 train_acc 0.7456990024577129\n",
      "epoch 77 lr 0.4286360105057287\n",
      "train_loss 0.5668803134868899 train_acc 0.7456990024577129\n",
      "epoch 78 lr 0.42777959518550923\n",
      "train_loss 0.5668578880908093 train_acc 0.7456990024577129\n",
      "epoch 79 lr 0.42692489098424086\n",
      "train_loss 0.566836467202359 train_acc 0.7456990024577129\n",
      "epoch 80 lr 0.4260718944831057\n",
      "train_loss 0.5668159652780298 train_acc 0.7456990024577129\n",
      "epoch 81 lr 0.4252206022701165\n",
      "train_loss 0.5667963058574985 train_acc 0.7456990024577129\n",
      "epoch 82 lr 0.4243710109401033\n",
      "train_loss 0.5667774177459521 train_acc 0.7456990024577129\n",
      "epoch 83 lr 0.4235231170946998\n",
      "train_loss 0.5667592301707484 train_acc 0.7456990024577129\n",
      "epoch 84 lr 0.4226769173423293\n",
      "train_loss 0.5667416837082146 train_acc 0.7456990024577129\n",
      "epoch 85 lr 0.4218324082981918\n",
      "train_loss 0.5667247223029065 train_acc 0.7456990024577129\n",
      "epoch 86 lr 0.42098958658424995\n",
      "train_loss 0.5667082938679552 train_acc 0.7456990024577129\n",
      "epoch 87 lr 0.4201484488292157\n",
      "train_loss 0.5666923503215413 train_acc 0.7456990024577129\n",
      "epoch 88 lr 0.419308991668537\n",
      "train_loss 0.5666768482897828 train_acc 0.7456990024577129\n",
      "epoch 89 lr 0.41847121174438406\n",
      "train_loss 0.5666617452680309 train_acc 0.7456990024577129\n",
      "epoch 90 lr 0.417635105705636\n",
      "train_loss 0.5666470027516101 train_acc 0.7456990024577129\n",
      "epoch 91 lr 0.41680067020786765\n",
      "train_loss 0.566632586176347 train_acc 0.7456990024577129\n",
      "epoch 92 lr 0.4159679019133359\n",
      "train_loss 0.5666184622571092 train_acc 0.7456990024577129\n",
      "epoch 93 lr 0.4151367974909663\n",
      "train_loss 0.5666045998658169 train_acc 0.7456990024577129\n",
      "epoch 94 lr 0.4143073536163403\n",
      "train_loss 0.566590969483303 train_acc 0.7456990024577129\n",
      "epoch 95 lr 0.41347956697168115\n",
      "train_loss 0.5665775471175094 train_acc 0.7456990024577129\n",
      "epoch 96 lr 0.4126534342458412\n",
      "train_loss 0.5665643071200095 train_acc 0.7456990024577129\n",
      "epoch 97 lr 0.41182895213428844\n",
      "train_loss 0.5665512281402166 train_acc 0.7456990024577129\n",
      "epoch 98 lr 0.41100611733909326\n",
      "train_loss 0.566538289216479 train_acc 0.7456990024577129\n",
      "epoch 99 lr 0.41018492656891553\n",
      "train_loss 0.5665254702300675 train_acc 0.7456990024577129\n",
      "\n",
      "val loss = 0.5754236741918397, \n",
      "val acc = 0.7372898318654924\n",
      "\n",
      "epoch 100 lr 0.4093653765389909\n",
      "train_loss 0.5665127528904216 train_acc 0.7456990024577129\n",
      "epoch 101 lr 0.4085474639711183\n",
      "train_loss 0.5665001208317556 train_acc 0.7456990024577129\n",
      "epoch 102 lr 0.40773118559364635\n",
      "train_loss 0.566487557672927 train_acc 0.7456990024577129\n",
      "epoch 103 lr 0.40691653814146034\n",
      "train_loss 0.566475049917545 train_acc 0.7456990024577129\n",
      "epoch 104 lr 0.40610351835596953\n",
      "train_loss 0.5664625827114881 train_acc 0.7456990024577129\n",
      "epoch 105 lr 0.40529212298509354\n",
      "train_loss 0.5664501421311079 train_acc 0.7456990024577129\n",
      "epoch 106 lr 0.4044823487832499\n",
      "train_loss 0.5664377168613535 train_acc 0.7456990024577129\n",
      "epoch 107 lr 0.40367419251134073\n",
      "train_loss 0.5664252962680486 train_acc 0.7456990024577129\n",
      "epoch 108 lr 0.4028676509367398\n",
      "train_loss 0.5664128685795893 train_acc 0.7456990024577129\n",
      "epoch 109 lr 0.4020627208332798\n",
      "train_loss 0.5664004232089981 train_acc 0.7456990024577129\n",
      "epoch 110 lr 0.40125939898123925\n",
      "train_loss 0.5663879487264775 train_acc 0.7456990024577129\n",
      "epoch 111 lr 0.4004576821673296\n",
      "train_loss 0.5663754371390856 train_acc 0.7456990024577129\n",
      "epoch 112 lr 0.39965756718468254\n",
      "train_loss 0.566362877571571 train_acc 0.7456990024577129\n",
      "epoch 113 lr 0.3988590508328371\n",
      "train_loss 0.5663502639580174 train_acc 0.7456990024577129\n",
      "epoch 114 lr 0.3980621299177268\n",
      "train_loss 0.566337589133008 train_acc 0.7456990024577129\n",
      "epoch 115 lr 0.39726680125166697\n",
      "train_loss 0.5663248456771477 train_acc 0.7456990024577129\n",
      "epoch 116 lr 0.39647306165334184\n",
      "train_loss 0.5663120220894903 train_acc 0.7456990024577129\n",
      "epoch 117 lr 0.3956809079477919\n",
      "train_loss 0.5662991132528051 train_acc 0.7456990024577129\n",
      "epoch 118 lr 0.39489033696640136\n",
      "train_loss 0.5662861137788715 train_acc 0.7456990024577129\n",
      "epoch 119 lr 0.3941013455468852\n",
      "train_loss 0.5662730149090418 train_acc 0.7456990024577129\n",
      "epoch 120 lr 0.3933139305332767\n",
      "train_loss 0.5662598097630456 train_acc 0.7456990024577129\n",
      "epoch 121 lr 0.3925280887759147\n",
      "train_loss 0.5662464951497338 train_acc 0.7456990024577129\n",
      "epoch 122 lr 0.39174381713143125\n",
      "train_loss 0.5662330662161791 train_acc 0.7456990024577129\n",
      "epoch 123 lr 0.3909611124627386\n",
      "train_loss 0.5662195170307643 train_acc 0.7456990024577129\n",
      "epoch 124 lr 0.39017997163901713\n",
      "train_loss 0.5662058392796357 train_acc 0.7456990024577129\n",
      "epoch 125 lr 0.38940039153570244\n",
      "train_loss 0.5661920254855395 train_acc 0.7456990024577129\n",
      "epoch 126 lr 0.38862236903447306\n",
      "train_loss 0.566178072200363 train_acc 0.7456990024577129\n",
      "epoch 127 lr 0.387845901023238\n",
      "train_loss 0.5661639728274914 train_acc 0.7456990024577129\n",
      "epoch 128 lr 0.38707098439612414\n",
      "train_loss 0.56614972182011 train_acc 0.7456990024577129\n",
      "epoch 129 lr 0.386297616053464\n",
      "train_loss 0.5661353157515101 train_acc 0.7456990024577129\n",
      "epoch 130 lr 0.3855257929017831\n",
      "train_loss 0.5661207499449082 train_acc 0.7456990024577129\n",
      "epoch 131 lr 0.3847555118537879\n",
      "train_loss 0.5661060168099045 train_acc 0.7456990024577129\n",
      "epoch 132 lr 0.3839867698283531\n",
      "train_loss 0.5660911106569091 train_acc 0.7456990024577129\n",
      "epoch 133 lr 0.3832195637505096\n",
      "train_loss 0.5660760272033384 train_acc 0.7456990024577129\n",
      "epoch 134 lr 0.38245389055143203\n",
      "train_loss 0.5660607615043586 train_acc 0.7456990024577129\n",
      "epoch 135 lr 0.3816897471684266\n",
      "train_loss 0.5660453084554808 train_acc 0.7456990024577129\n",
      "epoch 136 lr 0.3809271305449188\n",
      "train_loss 0.5660296647638058 train_acc 0.7456990024577129\n",
      "epoch 137 lr 0.38016603763044104\n",
      "train_loss 0.566013821500387 train_acc 0.7456990024577129\n",
      "epoch 138 lr 0.3794064653806207\n",
      "train_loss 0.5659977741762676 train_acc 0.7456990024577129\n",
      "epoch 139 lr 0.37864841075716776\n",
      "train_loss 0.5659815178919626 train_acc 0.7456990024577129\n",
      "epoch 140 lr 0.37789187072786273\n",
      "train_loss 0.5659650448731898 train_acc 0.7456990024577129\n",
      "epoch 141 lr 0.3771368422665445\n",
      "train_loss 0.5659483490374895 train_acc 0.7456990024577129\n",
      "epoch 142 lr 0.3763833223530981\n",
      "train_loss 0.5659314250233669 train_acc 0.7456990024577129\n",
      "epoch 143 lr 0.375631307973443\n",
      "train_loss 0.5659142700329031 train_acc 0.7456990024577129\n",
      "epoch 144 lr 0.3748807961195207\n",
      "train_loss 0.5658968777889679 train_acc 0.7456990024577129\n",
      "epoch 145 lr 0.37413178378928263\n",
      "train_loss 0.5658792443531833 train_acc 0.7456990024577129\n",
      "epoch 146 lr 0.37338426798667856\n",
      "train_loss 0.5658613651092022 train_acc 0.7456990024577129\n",
      "epoch 147 lr 0.37263824572164433\n",
      "train_loss 0.5658432300967838 train_acc 0.7456990024577129\n",
      "epoch 148 lr 0.3718937140100898\n",
      "train_loss 0.5658248311590447 train_acc 0.7456990024577129\n",
      "epoch 149 lr 0.3711506698738872\n",
      "train_loss 0.5658061613315906 train_acc 0.7456990024577129\n",
      "\n",
      "val loss = 0.5748145548078588, \n",
      "val acc = 0.7372898318654924\n",
      "\n",
      "epoch 150 lr 0.37040911034085894\n",
      "train_loss 0.5657872131123342 train_acc 0.7456990024577129\n",
      "epoch 151 lr 0.36966903244476595\n",
      "train_loss 0.5657679833529545 train_acc 0.7456990024577129\n",
      "epoch 152 lr 0.3689304332252956\n",
      "train_loss 0.5657484695737066 train_acc 0.7456990024577129\n",
      "epoch 153 lr 0.3681933097280501\n",
      "train_loss 0.5657286635896627 train_acc 0.7456990024577129\n",
      "epoch 154 lr 0.3674576590045344\n",
      "train_loss 0.5657085556811746 train_acc 0.7456990024577129\n",
      "epoch 155 lr 0.3667234781121447\n",
      "train_loss 0.5656881388146965 train_acc 0.7456990024577129\n",
      "epoch 156 lr 0.3659907641141563\n",
      "train_loss 0.5656674057762462 train_acc 0.7456990024577129\n",
      "epoch 157 lr 0.36525951407971247\n",
      "train_loss 0.565646350849774 train_acc 0.7456990024577129\n",
      "epoch 158 lr 0.36452972508381193\n",
      "train_loss 0.5656249694340335 train_acc 0.7456990024577129\n",
      "epoch 159 lr 0.36380139420729773\n",
      "train_loss 0.5656032514137395 train_acc 0.7456990024577129\n",
      "epoch 160 lr 0.36307451853684547\n",
      "train_loss 0.5655811866531653 train_acc 0.7456990024577129\n",
      "epoch 161 lr 0.36234909516495145\n",
      "train_loss 0.5655587683720767 train_acc 0.7456990024577129\n",
      "epoch 162 lr 0.36162512118992124\n",
      "train_loss 0.5655359859785692 train_acc 0.7456990024577129\n",
      "epoch 163 lr 0.3609025937158579\n",
      "train_loss 0.5655128336349777 train_acc 0.7456990024577129\n",
      "epoch 164 lr 0.3601815098526507\n",
      "train_loss 0.565489303705304 train_acc 0.7456990024577129\n",
      "epoch 165 lr 0.3594618667159631\n",
      "train_loss 0.5654653921714051 train_acc 0.7456990024577129\n",
      "epoch 166 lr 0.3587436614272217\n",
      "train_loss 0.565441089001544 train_acc 0.7456990024577129\n",
      "epoch 167 lr 0.35802689111360425\n",
      "train_loss 0.565416380584475 train_acc 0.7456990024577129\n",
      "epoch 168 lr 0.3573115529080287\n",
      "train_loss 0.5653912549040302 train_acc 0.7456990024577129\n",
      "epoch 169 lr 0.3565976439491412\n",
      "train_loss 0.5653656991410688 train_acc 0.7456990024577129\n",
      "epoch 170 lr 0.3558851613813049\n",
      "train_loss 0.5653397093867746 train_acc 0.7456990024577129\n",
      "epoch 171 lr 0.35517410235458863\n",
      "train_loss 0.5653132768755783 train_acc 0.7456990024577129\n",
      "epoch 172 lr 0.3544644640247554\n",
      "train_loss 0.5652863836917208 train_acc 0.7456990024577129\n",
      "epoch 173 lr 0.35375624355325086\n",
      "train_loss 0.5652590236880904 train_acc 0.7456990024577129\n",
      "epoch 174 lr 0.3530494381071922\n",
      "train_loss 0.5652311821334035 train_acc 0.7456990024577129\n",
      "epoch 175 lr 0.3523440448593567\n",
      "train_loss 0.5652028513301359 train_acc 0.7456990024577129\n",
      "epoch 176 lr 0.35164006098817047\n",
      "train_loss 0.565174017242453 train_acc 0.7456990024577129\n",
      "epoch 177 lr 0.350937483677697\n",
      "train_loss 0.5651446650814606 train_acc 0.7456990024577129\n",
      "epoch 178 lr 0.3502363101176262\n",
      "train_loss 0.5651147840635565 train_acc 0.7456990024577129\n",
      "epoch 179 lr 0.3495365375032628\n",
      "train_loss 0.5650843547545114 train_acc 0.7456990024577129\n",
      "epoch 180 lr 0.3488381630355155\n",
      "train_loss 0.5650533676230592 train_acc 0.7456990024577129\n",
      "epoch 181 lr 0.3481411839208855\n",
      "train_loss 0.5650218147435779 train_acc 0.7456990024577129\n",
      "epoch 182 lr 0.3474455973714553\n",
      "train_loss 0.5649896788299996 train_acc 0.7456990024577129\n",
      "epoch 183 lr 0.34675140060487786\n",
      "train_loss 0.5649569444023266 train_acc 0.7456990024577129\n",
      "epoch 184 lr 0.3460585908443652\n",
      "train_loss 0.5649235969941842 train_acc 0.7456990024577129\n",
      "epoch 185 lr 0.34536716531867734\n",
      "train_loss 0.5648896154362734 train_acc 0.7456990024577129\n",
      "epoch 186 lr 0.3446771212621112\n",
      "train_loss 0.5648549918471216 train_acc 0.7456990024577129\n",
      "epoch 187 lr 0.3439884559144897\n",
      "train_loss 0.5648197041927278 train_acc 0.7456990024577129\n",
      "epoch 188 lr 0.3433011665211505\n",
      "train_loss 0.5647837425308533 train_acc 0.7456990024577129\n",
      "epoch 189 lr 0.3426152503329351\n",
      "train_loss 0.5647470870507711 train_acc 0.7456990024577129\n",
      "epoch 190 lr 0.3419307046061779\n",
      "train_loss 0.5647097186207741 train_acc 0.7456990024577129\n",
      "epoch 191 lr 0.34124752660269503\n",
      "train_loss 0.5646716286201978 train_acc 0.7456990024577129\n",
      "epoch 192 lr 0.34056571358977356\n",
      "train_loss 0.5646327870542533 train_acc 0.7456990024577129\n",
      "epoch 193 lr 0.3398852628401605\n",
      "train_loss 0.5645931795479925 train_acc 0.7456990024577129\n",
      "epoch 194 lr 0.339206171632052\n",
      "train_loss 0.5645527848570998 train_acc 0.7456990024577129\n",
      "epoch 195 lr 0.3385284372490823\n",
      "train_loss 0.5645115829632151 train_acc 0.7456990024577129\n",
      "epoch 196 lr 0.337852056980313\n",
      "train_loss 0.5644695559424497 train_acc 0.7456990024577129\n",
      "epoch 197 lr 0.3371770281202221\n",
      "train_loss 0.5644266910646815 train_acc 0.7456990024577129\n",
      "epoch 198 lr 0.3365033479686932\n",
      "train_loss 0.5643829596692383 train_acc 0.7456990024577129\n",
      "epoch 199 lr 0.3358310138310049\n",
      "train_loss 0.564338333994398 train_acc 0.7456990024577129\n",
      "\n",
      "val loss = 0.5733224952019508, \n",
      "val acc = 0.7372898318654924\n",
      "\n",
      "epoch 200 lr 0.3351600230178196\n",
      "train_loss 0.5642927932389488 train_acc 0.7456990024577129\n",
      "epoch 201 lr 0.33449037284517336\n",
      "train_loss 0.5642463143909785 train_acc 0.7456990024577129\n",
      "epoch 202 lr 0.33382206063446446\n",
      "train_loss 0.5641988731743613 train_acc 0.7456990024577129\n",
      "epoch 203 lr 0.3331550837124432\n",
      "train_loss 0.5641504464073129 train_acc 0.7456990024577129\n",
      "epoch 204 lr 0.33248943941120096\n",
      "train_loss 0.5641010059005851 train_acc 0.7456990024577129\n",
      "epoch 205 lr 0.3318251250681597\n",
      "train_loss 0.5640505173902753 train_acc 0.7456990024577129\n",
      "epoch 206 lr 0.33116213802606115\n",
      "train_loss 0.5639989623604615 train_acc 0.7456990024577129\n",
      "epoch 207 lr 0.33050047563295626\n",
      "train_loss 0.5639463028203383 train_acc 0.7456990024577129\n",
      "epoch 208 lr 0.3298401352421945\n",
      "train_loss 0.5638925112884992 train_acc 0.7456990024577129\n",
      "epoch 209 lr 0.3291811142124136\n",
      "train_loss 0.5638375601098278 train_acc 0.7456990024577129\n",
      "epoch 210 lr 0.3285234099075284\n",
      "train_loss 0.5637814116120751 train_acc 0.7456990024577129\n",
      "epoch 211 lr 0.3278670196967209\n",
      "train_loss 0.5637240391403711 train_acc 0.7456990024577129\n",
      "epoch 212 lr 0.3272119409544293\n",
      "train_loss 0.5636654201384018 train_acc 0.7456990024577129\n",
      "epoch 213 lr 0.3265581710603378\n",
      "train_loss 0.5636055045904816 train_acc 0.7456990024577129\n",
      "epoch 214 lr 0.325905707399366\n",
      "train_loss 0.5635442449387799 train_acc 0.7456990024577129\n",
      "epoch 215 lr 0.32525454736165826\n",
      "train_loss 0.5634816152977304 train_acc 0.7456990024577129\n",
      "epoch 216 lr 0.3246046883425737\n",
      "train_loss 0.5634175755282032 train_acc 0.7456990024577129\n",
      "epoch 217 lr 0.3239561277426753\n",
      "train_loss 0.5633520886651431 train_acc 0.7456990024577129\n",
      "epoch 218 lr 0.3233088629677198\n",
      "train_loss 0.563285112935004 train_acc 0.7456990024577129\n",
      "epoch 219 lr 0.3226628914286473\n",
      "train_loss 0.563216616891376 train_acc 0.7456990024577129\n",
      "epoch 220 lr 0.32201821054157065\n",
      "train_loss 0.5631465478076718 train_acc 0.7456990024577129\n",
      "epoch 221 lr 0.3213748177277656\n",
      "train_loss 0.5630748659791581 train_acc 0.7456990024577129\n",
      "epoch 222 lr 0.3207327104136599\n",
      "train_loss 0.5630015192785535 train_acc 0.7456990024577129\n",
      "epoch 223 lr 0.32009188603082356\n",
      "train_loss 0.5629264711641818 train_acc 0.7456990024577129\n",
      "epoch 224 lr 0.31945234201595807\n",
      "train_loss 0.5628496652954562 train_acc 0.7456990024577129\n",
      "epoch 225 lr 0.3188140758108866\n",
      "train_loss 0.5627710218341814 train_acc 0.7456990024577129\n",
      "epoch 226 lr 0.31817708486254354\n",
      "train_loss 0.5626905112586217 train_acc 0.7456990024577129\n",
      "epoch 227 lr 0.31754136662296406\n",
      "train_loss 0.5626080579918104 train_acc 0.7456990024577129\n",
      "epoch 228 lr 0.3169069185492745\n",
      "train_loss 0.5625236271173922 train_acc 0.7456990024577129\n",
      "epoch 229 lr 0.3162737381036817\n",
      "train_loss 0.5624371509743038 train_acc 0.7456990024577129\n",
      "epoch 230 lr 0.315641822753463\n",
      "train_loss 0.5623485772810465 train_acc 0.7456990024577129\n",
      "epoch 231 lr 0.31501116997095613\n",
      "train_loss 0.5622578484311241 train_acc 0.7456990024577129\n",
      "epoch 232 lr 0.3143817772335492\n",
      "train_loss 0.562164905343159 train_acc 0.7456990024577129\n",
      "epoch 233 lr 0.31375364202367034\n",
      "train_loss 0.5620696702869691 train_acc 0.7456990024577129\n",
      "epoch 234 lr 0.31312676182877797\n",
      "train_loss 0.561972079720272 train_acc 0.7456990024577129\n",
      "epoch 235 lr 0.3125011341413504\n",
      "train_loss 0.5618720733439772 train_acc 0.7456990024577129\n",
      "epoch 236 lr 0.311876756458876\n",
      "train_loss 0.5617695571405178 train_acc 0.7456990024577129\n",
      "epoch 237 lr 0.3112536262838434\n",
      "train_loss 0.5616644415098696 train_acc 0.7456990024577129\n",
      "epoch 238 lr 0.3106317411237308\n",
      "train_loss 0.5615566368583637 train_acc 0.7456990024577129\n",
      "epoch 239 lr 0.310011098490997\n",
      "train_loss 0.5614460798685402 train_acc 0.7456990024577129\n",
      "epoch 240 lr 0.3093916959030704\n",
      "train_loss 0.5613326829185359 train_acc 0.7456990024577129\n",
      "epoch 241 lr 0.30877353088234\n",
      "train_loss 0.5612163658830606 train_acc 0.7456990024577129\n",
      "epoch 242 lr 0.30815660095614483\n",
      "train_loss 0.5610970600873235 train_acc 0.7456990024577129\n",
      "epoch 243 lr 0.30754090365676434\n",
      "train_loss 0.5609746721187276 train_acc 0.7456990024577129\n",
      "epoch 244 lr 0.3069264365214085\n",
      "train_loss 0.5608491158808121 train_acc 0.7456990024577129\n",
      "epoch 245 lr 0.30631319709220806\n",
      "train_loss 0.5607202727659787 train_acc 0.7456990024577129\n",
      "epoch 246 lr 0.30570118291620435\n",
      "train_loss 0.5605880153199437 train_acc 0.7456990024577129\n",
      "epoch 247 lr 0.3050903915453399\n",
      "train_loss 0.5604522343896753 train_acc 0.7456990024577129\n",
      "epoch 248 lr 0.3044808205364484\n",
      "train_loss 0.5603128210927536 train_acc 0.7456990024577129\n",
      "epoch 249 lr 0.3038724674512451\n",
      "train_loss 0.5601696668383851 train_acc 0.7456990024577129\n",
      "\n",
      "val loss = 0.5690069489189518, \n",
      "val acc = 0.7372898318654924\n",
      "\n",
      "epoch 250 lr 0.3032653298563167\n",
      "train_loss 0.560022671012004 train_acc 0.7456990024577129\n",
      "epoch 251 lr 0.3026594053231121\n",
      "train_loss 0.5598717076738 train_acc 0.7456990024577129\n",
      "epoch 252 lr 0.30205469142793234\n",
      "train_loss 0.5597166628896536 train_acc 0.7456990024577129\n",
      "epoch 253 lr 0.30145118575192104\n",
      "train_loss 0.5595574083955069 train_acc 0.7456990024577129\n",
      "epoch 254 lr 0.3008488858810547\n",
      "train_loss 0.5593938006548715 train_acc 0.7456990024577129\n",
      "epoch 255 lr 0.30024778940613295\n",
      "train_loss 0.5592256867684532 train_acc 0.7456990024577129\n",
      "epoch 256 lr 0.2996478939227692\n",
      "train_loss 0.5590529431271695 train_acc 0.7456990024577129\n",
      "epoch 257 lr 0.29904919703138066\n",
      "train_loss 0.5588754144341135 train_acc 0.7456990024577129\n",
      "epoch 258 lr 0.298451696337179\n",
      "train_loss 0.5586929014332098 train_acc 0.7456990024577129\n",
      "epoch 259 lr 0.2978553894501606\n",
      "train_loss 0.5585052162169178 train_acc 0.7456990024577129\n",
      "epoch 260 lr 0.29726027398509713\n",
      "train_loss 0.5583122526994081 train_acc 0.7456990024577129\n",
      "epoch 261 lr 0.296666347561526\n",
      "train_loss 0.5581138559801192 train_acc 0.7456990024577129\n",
      "epoch 262 lr 0.29607360780374065\n",
      "train_loss 0.5579098239831599 train_acc 0.7456990024577129\n",
      "epoch 263 lr 0.29548205234078123\n",
      "train_loss 0.55769998029505 train_acc 0.7456990024577129\n",
      "epoch 264 lr 0.2948916788064252\n",
      "train_loss 0.5574841250866416 train_acc 0.7456990024577129\n",
      "epoch 265 lr 0.2943024848391776\n",
      "train_loss 0.557262035470316 train_acc 0.7456990024577129\n",
      "epoch 266 lr 0.2937144680822617\n",
      "train_loss 0.5570335347048047 train_acc 0.7456990024577129\n",
      "epoch 267 lr 0.29312762618360977\n",
      "train_loss 0.5567984494176744 train_acc 0.7456990024577129\n",
      "epoch 268 lr 0.29254195679585343\n",
      "train_loss 0.5565565273723445 train_acc 0.7456990024577129\n",
      "epoch 269 lr 0.2919574575763143\n",
      "train_loss 0.5563075379128802 train_acc 0.7456990024577129\n",
      "epoch 270 lr 0.2913741261869948\n",
      "train_loss 0.5560512795803793 train_acc 0.7456990024577129\n",
      "epoch 271 lr 0.29079196029456855\n",
      "train_loss 0.5557875219389172 train_acc 0.7456990024577129\n",
      "epoch 272 lr 0.29021095757037113\n",
      "train_loss 0.5555159294367128 train_acc 0.7456990024577129\n",
      "epoch 273 lr 0.289631115690391\n",
      "train_loss 0.5552362589029676 train_acc 0.7456990024577129\n",
      "epoch 274 lr 0.2890524323352598\n",
      "train_loss 0.5549482541003733 train_acc 0.7456990024577129\n",
      "epoch 275 lr 0.2884749051902433\n",
      "train_loss 0.5546515997757027 train_acc 0.7456990024577129\n",
      "epoch 276 lr 0.28789853194523224\n",
      "train_loss 0.5543460228615438 train_acc 0.7456990024577129\n",
      "epoch 277 lr 0.2873233102947328\n",
      "train_loss 0.5540312175626109 train_acc 0.7456990024577129\n",
      "epoch 278 lr 0.28674923793785767\n",
      "train_loss 0.5537068972161868 train_acc 0.7456990024577129\n",
      "epoch 279 lr 0.2861763125783166\n",
      "train_loss 0.5533727728740317 train_acc 0.7456990024577129\n",
      "epoch 280 lr 0.2856045319244074\n",
      "train_loss 0.5530285000186627 train_acc 0.7456990024577129\n",
      "epoch 281 lr 0.2850338936890067\n",
      "train_loss 0.5526737915852453 train_acc 0.7456990024577129\n",
      "epoch 282 lr 0.28446439558956094\n",
      "train_loss 0.5523082984753764 train_acc 0.7456990024577129\n",
      "epoch 283 lr 0.28389603534807667\n",
      "train_loss 0.5519315728727796 train_acc 0.7456990024577129\n",
      "epoch 284 lr 0.2833288106911124\n",
      "train_loss 0.5515433399535317 train_acc 0.7456990024577129\n",
      "epoch 285 lr 0.2827627193497686\n",
      "train_loss 0.5511431578805563 train_acc 0.7456990024577129\n",
      "epoch 286 lr 0.2821977590596792\n",
      "train_loss 0.5507306541954204 train_acc 0.7456990024577129\n",
      "epoch 287 lr 0.28163392756100236\n",
      "train_loss 0.5503053713152969 train_acc 0.7456990024577129\n",
      "epoch 288 lr 0.2810712225984112\n",
      "train_loss 0.5498669108964768 train_acc 0.7456990024577129\n",
      "epoch 289 lr 0.2805096419210853\n",
      "train_loss 0.5494148445396894 train_acc 0.7456990024577129\n",
      "epoch 290 lr 0.279949183282701\n",
      "train_loss 0.5489488251021857 train_acc 0.7456990024577129\n",
      "epoch 291 lr 0.2793898444414232\n",
      "train_loss 0.5484685101985082 train_acc 0.7456990024577129\n",
      "epoch 292 lr 0.2788316231598956\n",
      "train_loss 0.5479733460451495 train_acc 0.7456990024577129\n",
      "epoch 293 lr 0.27827451720523244\n",
      "train_loss 0.5474629198096772 train_acc 0.7456990024577129\n",
      "epoch 294 lr 0.2777185243490092\n",
      "train_loss 0.5469367815455238 train_acc 0.7456990024577129\n",
      "epoch 295 lr 0.27716364236725355\n",
      "train_loss 0.5463944861438766 train_acc 0.7456990024577129\n",
      "epoch 296 lr 0.27660986904043694\n",
      "train_loss 0.5458355207618788 train_acc 0.7456990024577129\n",
      "epoch 297 lr 0.2760572021534653\n",
      "train_loss 0.5452594618029587 train_acc 0.7456990024577129\n",
      "epoch 298 lr 0.2755056394956704\n",
      "train_loss 0.544665904651137 train_acc 0.7456990024577129\n",
      "epoch 299 lr 0.2749551788608008\n",
      "train_loss 0.5440543514161266 train_acc 0.7456990024577129\n",
      "\n",
      "val loss = 0.5522224259771131, \n",
      "val acc = 0.7372898318654924\n",
      "\n",
      "epoch 300 lr 0.27440581804701325\n",
      "train_loss 0.5434243648669776 train_acc 0.7456990024577129\n",
      "epoch 301 lr 0.27385755485686375\n",
      "train_loss 0.5427754748285113 train_acc 0.7456990024577129\n",
      "epoch 302 lr 0.2733103870972988\n",
      "train_loss 0.5421071024987041 train_acc 0.7456990024577129\n",
      "epoch 303 lr 0.2727643125796467\n",
      "train_loss 0.5414187472624473 train_acc 0.7456990024577129\n",
      "epoch 304 lr 0.27221932911960856\n",
      "train_loss 0.5407100629975456 train_acc 0.7456990024577129\n",
      "epoch 305 lr 0.2716754345372499\n",
      "train_loss 0.5399807044097288 train_acc 0.7456990024577129\n",
      "epoch 306 lr 0.2711326266569916\n",
      "train_loss 0.5392302361381586 train_acc 0.7456990024577129\n",
      "epoch 307 lr 0.27059090330760144\n",
      "train_loss 0.538458283936355 train_acc 0.7456990024577129\n",
      "epoch 308 lr 0.27005026232218526\n",
      "train_loss 0.5376645038052027 train_acc 0.7456990024577129\n",
      "epoch 309 lr 0.2695107015381785\n",
      "train_loss 0.5368485047550855 train_acc 0.7456990024577129\n",
      "epoch 310 lr 0.26897221879733724\n",
      "train_loss 0.5360099162506006 train_acc 0.7456990024577129\n",
      "epoch 311 lr 0.26843481194572977\n",
      "train_loss 0.5351483530921478 train_acc 0.7456990024577129\n",
      "epoch 312 lr 0.267898478833728\n",
      "train_loss 0.5342636078067629 train_acc 0.7456990024577129\n",
      "epoch 313 lr 0.26736321731599877\n",
      "train_loss 0.5333552757574781 train_acc 0.7456990024577129\n",
      "epoch 314 lr 0.26682902525149527\n",
      "train_loss 0.5324231511419075 train_acc 0.7456990024577129\n",
      "epoch 315 lr 0.2662959005034486\n",
      "train_loss 0.5314669439736267 train_acc 0.7456990024577129\n",
      "epoch 316 lr 0.26576384093935895\n",
      "train_loss 0.53048646929218 train_acc 0.7456990024577129\n",
      "epoch 317 lr 0.26523284443098744\n",
      "train_loss 0.5294818062209814 train_acc 0.7456990024577129\n",
      "epoch 318 lr 0.2647029088543473\n",
      "train_loss 0.5284527918029158 train_acc 0.7456990024577129\n",
      "epoch 319 lr 0.2641740320896955\n",
      "train_loss 0.5273992933853927 train_acc 0.7456990024577129\n",
      "epoch 320 lr 0.2636462120215243\n",
      "train_loss 0.5263213507282399 train_acc 0.7456990024577129\n",
      "epoch 321 lr 0.2631194465385527\n",
      "train_loss 0.5252192517474453 train_acc 0.7456990024577129\n",
      "epoch 322 lr 0.26259373353371807\n",
      "train_loss 0.5240930521414524 train_acc 0.7456990024577129\n",
      "epoch 323 lr 0.2620690709041677\n",
      "train_loss 0.5229431357144375 train_acc 0.7456990024577129\n",
      "epoch 324 lr 0.2615454565512504\n",
      "train_loss 0.521769841575898 train_acc 0.7456990024577129\n",
      "epoch 325 lr 0.261022888380508\n",
      "train_loss 0.5205735451871709 train_acc 0.7456990024577129\n",
      "epoch 326 lr 0.2605013643016672\n",
      "train_loss 0.5193546567689479 train_acc 0.7456990024577129\n",
      "epoch 327 lr 0.2599808822286309\n",
      "train_loss 0.5181137583433403 train_acc 0.7456990024577129\n",
      "epoch 328 lr 0.2594614400794702\n",
      "train_loss 0.5168514023131805 train_acc 0.7456990024577129\n",
      "epoch 329 lr 0.2589430357764157\n",
      "train_loss 0.5155684321917031 train_acc 0.7456990024577129\n",
      "epoch 330 lr 0.2584256672458496\n",
      "train_loss 0.5142655306908096 train_acc 0.7456990024577129\n",
      "epoch 331 lr 0.25790933241829705\n",
      "train_loss 0.512943229633016 train_acc 0.7456990024577129\n",
      "epoch 332 lr 0.2573940292284181\n",
      "train_loss 0.5116025376277668 train_acc 0.7456990024577129\n",
      "epoch 333 lr 0.2568797556149992\n",
      "train_loss 0.5102444562973605 train_acc 0.7456990024577129\n",
      "epoch 334 lr 0.25636650952094525\n",
      "train_loss 0.508869969453944 train_acc 0.7456990024577129\n",
      "epoch 335 lr 0.2558542888932712\n",
      "train_loss 0.5074800857046415 train_acc 0.7456990024577129\n",
      "epoch 336 lr 0.25534309168309394\n",
      "train_loss 0.5060760608536949 train_acc 0.7456990024577129\n",
      "epoch 337 lr 0.2548329158456238\n",
      "train_loss 0.504659117480103 train_acc 0.7456990024577129\n",
      "epoch 338 lr 0.25432375934015683\n",
      "train_loss 0.5032306360512498 train_acc 0.7456990024577129\n",
      "epoch 339 lr 0.25381562013006637\n",
      "train_loss 0.5017917284073703 train_acc 0.7456990024577129\n",
      "epoch 340 lr 0.2533084961827948\n",
      "train_loss 0.5003437705357333 train_acc 0.7456990024577129\n",
      "epoch 341 lr 0.25280238546984574\n",
      "train_loss 0.4988881100010633 train_acc 0.7456990024577129\n",
      "epoch 342 lr 0.2522972859667756\n",
      "train_loss 0.49742614873418634 train_acc 0.7456990024577129\n",
      "epoch 343 lr 0.2517931956531857\n",
      "train_loss 0.49595922540335274 train_acc 0.7456990024577129\n",
      "epoch 344 lr 0.2512901125127142\n",
      "train_loss 0.49448874219792044 train_acc 0.7456990024577129\n",
      "epoch 345 lr 0.2507880345330278\n",
      "train_loss 0.49301578811868696 train_acc 0.7456990024577129\n",
      "epoch 346 lr 0.2502869597058139\n",
      "train_loss 0.49154192542774006 train_acc 0.7456990024577129\n",
      "epoch 347 lr 0.24978688602677251\n",
      "train_loss 0.49006873350288893 train_acc 0.7456990024577129\n",
      "epoch 348 lr 0.2492878114956083\n",
      "train_loss 0.4885971543528711 train_acc 0.7456990024577129\n",
      "epoch 349 lr 0.24878973411602245\n",
      "train_loss 0.4871286122927659 train_acc 0.7456990024577129\n",
      "\n",
      "val loss = 0.4932568788891903, \n",
      "val acc = 0.7372898318654924\n",
      "\n",
      "epoch 350 lr 0.2482926518957048\n",
      "train_loss 0.48566422328533565 train_acc 0.7456990024577129\n",
      "epoch 351 lr 0.24779656284632576\n",
      "train_loss 0.4842051455631177 train_acc 0.7456990024577129\n",
      "epoch 352 lr 0.2473014649835285\n",
      "train_loss 0.48275281855176755 train_acc 0.7456990024577129\n",
      "epoch 353 lr 0.24680735632692094\n",
      "train_loss 0.48130844899313907 train_acc 0.7456990024577129\n",
      "epoch 354 lr 0.24631423490006774\n",
      "train_loss 0.479872883000311 train_acc 0.7456990024577129\n",
      "epoch 355 lr 0.24582209873048258\n",
      "train_loss 0.47844693181090975 train_acc 0.7456990024577129\n",
      "epoch 356 lr 0.2453309458496201\n",
      "train_loss 0.4770314201038318 train_acc 0.7456990024577129\n",
      "epoch 357 lr 0.2448407742928681\n",
      "train_loss 0.47562727849525566 train_acc 0.7456990024577129\n",
      "epoch 358 lr 0.24435158209953975\n",
      "train_loss 0.47423563285774517 train_acc 0.7456990024577129\n",
      "epoch 359 lr 0.2438633673128656\n",
      "train_loss 0.47285728184100867 train_acc 0.7456990024577129\n",
      "epoch 360 lr 0.24337612797998584\n",
      "train_loss 0.47149276532815554 train_acc 0.7456990024577129\n",
      "epoch 361 lr 0.24288986215194253\n",
      "train_loss 0.4701426126080848 train_acc 0.7456990024577129\n",
      "epoch 362 lr 0.24240456788367165\n",
      "train_loss 0.46880754371490413 train_acc 0.7456990024577129\n",
      "epoch 363 lr 0.24192024323399552\n",
      "train_loss 0.46748785500751716 train_acc 0.7456990024577129\n",
      "epoch 364 lr 0.24143688626561488\n",
      "train_loss 0.46618439360981123 train_acc 0.7456990024577129\n",
      "epoch 365 lr 0.24095449504510122\n",
      "train_loss 0.46489740949024305 train_acc 0.7456990024577129\n",
      "epoch 366 lr 0.24047306764288903\n",
      "train_loss 0.46362730129456897 train_acc 0.7456990024577129\n",
      "epoch 367 lr 0.23999260213326803\n",
      "train_loss 0.4623741898274153 train_acc 0.7456990024577129\n",
      "epoch 368 lr 0.23951309659437556\n",
      "train_loss 0.4611381412510011 train_acc 0.7456990024577129\n",
      "epoch 369 lr 0.2390345491081888\n",
      "train_loss 0.4599196682913738 train_acc 0.7456990024577129\n",
      "epoch 370 lr 0.23855695776051722\n",
      "train_loss 0.45871876344307677 train_acc 0.7456990024577129\n",
      "epoch 371 lr 0.2380803206409947\n",
      "train_loss 0.45753547900262276 train_acc 0.7456990024577129\n",
      "epoch 372 lr 0.23760463584307223\n",
      "train_loss 0.45636923610330565 train_acc 0.7456990024577129\n",
      "epoch 373 lr 0.23712990146400992\n",
      "train_loss 0.4552203896663888 train_acc 0.7456990024577129\n",
      "epoch 374 lr 0.23665611560486965\n",
      "train_loss 0.4540888049630372 train_acc 0.7456990024577129\n",
      "epoch 375 lr 0.23618327637050734\n",
      "train_loss 0.45297469273957125 train_acc 0.7456990024577129\n",
      "epoch 376 lr 0.23571138186956545\n",
      "train_loss 0.45187770754085227 train_acc 0.7456990024577129\n",
      "epoch 377 lr 0.23524043021446528\n",
      "train_loss 0.450798053851107 train_acc 0.7456990024577129\n",
      "epoch 378 lr 0.23477041952139963\n",
      "train_loss 0.4497358504836217 train_acc 0.7456990024577129\n",
      "epoch 379 lr 0.23430134791032511\n",
      "train_loss 0.4486907047535026 train_acc 0.7456990024577129\n",
      "epoch 380 lr 0.23383321350495462\n",
      "train_loss 0.4476623419428218 train_acc 0.7456990024577129\n",
      "epoch 381 lr 0.23336601443274993\n",
      "train_loss 0.4466504234081894 train_acc 0.7456990024577129\n",
      "epoch 382 lr 0.23289974882491413\n",
      "train_loss 0.4456547133465147 train_acc 0.7456990024577129\n",
      "epoch 383 lr 0.23243441481638413\n",
      "train_loss 0.4446748350538621 train_acc 0.7456990024577129\n",
      "epoch 384 lr 0.23197001054582334\n",
      "train_loss 0.44371068805243025 train_acc 0.7456990024577129\n",
      "epoch 385 lr 0.23150653415561404\n",
      "train_loss 0.4427621834205782 train_acc 0.7456990024577129\n",
      "epoch 386 lr 0.23104398379185\n",
      "train_loss 0.44182918054890596 train_acc 0.7456990024577129\n",
      "epoch 387 lr 0.2305823576043292\n",
      "train_loss 0.4409113763413484 train_acc 0.7456990024577129\n",
      "epoch 388 lr 0.23012165374654628\n",
      "train_loss 0.44000861385628626 train_acc 0.7456990024577129\n",
      "epoch 389 lr 0.22966187037568517\n",
      "train_loss 0.4391205078511687 train_acc 0.7456990024577129\n",
      "epoch 390 lr 0.22920300565261176\n",
      "train_loss 0.4382471775521751 train_acc 0.7456990024577129\n",
      "epoch 391 lr 0.2287450577418666\n",
      "train_loss 0.437388276740185 train_acc 0.7456990024577129\n",
      "epoch 392 lr 0.22828802481165736\n",
      "train_loss 0.4365429808404372 train_acc 0.7456990024577129\n",
      "epoch 393 lr 0.22783190503385176\n",
      "train_loss 0.4357111282313253 train_acc 0.7456990024577129\n",
      "epoch 394 lr 0.22737669658397008\n",
      "train_loss 0.43489268999092845 train_acc 0.7456990024577129\n",
      "epoch 395 lr 0.2269223976411779\n",
      "train_loss 0.4340873773343388 train_acc 0.7456990024577129\n",
      "epoch 396 lr 0.22646900638827885\n",
      "train_loss 0.4332946512888783 train_acc 0.7456990024577129\n",
      "epoch 397 lr 0.2260165210117073\n",
      "train_loss 0.4325147720238018 train_acc 0.7456990024577129\n",
      "epoch 398 lr 0.2255649397015212\n",
      "train_loss 0.43174757550755116 train_acc 0.7456990024577129\n",
      "epoch 399 lr 0.22511426065139462\n",
      "train_loss 0.43099264052012687 train_acc 0.7456990024577129\n",
      "\n",
      "val loss = 0.43551665390403554, \n",
      "val acc = 0.7372898318654924\n",
      "\n",
      "epoch 400 lr 0.22466448205861078\n",
      "train_loss 0.4302498047829069 train_acc 0.7456990024577129\n",
      "epoch 401 lr 0.22421560212405475\n",
      "train_loss 0.42951853395295914 train_acc 0.7456990024577129\n",
      "epoch 402 lr 0.22376761905220618\n",
      "train_loss 0.4287986770870443 train_acc 0.7456990024577129\n",
      "epoch 403 lr 0.22332053105113217\n",
      "train_loss 0.4280899971433817 train_acc 0.7456990024577129\n",
      "epoch 404 lr 0.2228743363324801\n",
      "train_loss 0.4273922975849956 train_acc 0.7456990024577129\n",
      "epoch 405 lr 0.22242903311147055\n",
      "train_loss 0.42670555221530426 train_acc 0.7456990024577129\n",
      "epoch 406 lr 0.22198461960689\n",
      "train_loss 0.42602961374903986 train_acc 0.7456990024577129\n",
      "epoch 407 lr 0.2215410940410839\n",
      "train_loss 0.42536424633354925 train_acc 0.7456990024577129\n",
      "epoch 408 lr 0.22109845463994934\n",
      "train_loss 0.42470891323842735 train_acc 0.7456990024577129\n",
      "epoch 409 lr 0.2206566996329281\n",
      "train_loss 0.42406352609850456 train_acc 0.7456990024577129\n",
      "epoch 410 lr 0.22021582725299965\n",
      "train_loss 0.42342794773082865 train_acc 0.7456990024577129\n",
      "epoch 411 lr 0.21977583573667378\n",
      "train_loss 0.4228021065496282 train_acc 0.7456990024577129\n",
      "epoch 412 lr 0.21933672332398393\n",
      "train_loss 0.42218584370827056 train_acc 0.7457101233304789\n",
      "epoch 413 lr 0.21889848825847982\n",
      "train_loss 0.4215788083641632 train_acc 0.7460993538772923\n",
      "epoch 414 lr 0.2184611287872206\n",
      "train_loss 0.4209808813597321 train_acc 0.7471447159173051\n",
      "epoch 415 lr 0.2180246431607678\n",
      "train_loss 0.42039227050928424 train_acc 0.7499582967271271\n",
      "epoch 416 lr 0.21758902963317836\n",
      "train_loss 0.4198125141303579 train_acc 0.7536504264854705\n",
      "epoch 417 lr 0.21715428646199755\n",
      "train_loss 0.4192413480504236 train_acc 0.7603007083995952\n",
      "epoch 418 lr 0.21672041190825214\n",
      "train_loss 0.4186783383904186 train_acc 0.7714549437839882\n",
      "epoch 419 lr 0.21628740423644333\n",
      "train_loss 0.418123115746225 train_acc 0.7863235506722568\n",
      "epoch 420 lr 0.21585526171453984\n",
      "train_loss 0.41757614694221895 train_acc 0.8006583556677528\n",
      "epoch 421 lr 0.21542398261397103\n",
      "train_loss 0.4170373636495231 train_acc 0.8102000645010621\n",
      "epoch 422 lr 0.2149935652096199\n",
      "train_loss 0.4165066836802358 train_acc 0.8156048086653841\n",
      "epoch 423 lr 0.21456400777981627\n",
      "train_loss 0.41598358636735444 train_acc 0.8171617308526373\n",
      "epoch 424 lr 0.21413530860632982\n",
      "train_loss 0.4154681554365354 train_acc 0.8182182137654163\n",
      "epoch 425 lr 0.21370746597436333\n",
      "train_loss 0.4149599713458255 train_acc 0.8190745209684056\n",
      "epoch 426 lr 0.21328047817254567\n",
      "train_loss 0.4144590652733646 train_acc 0.8196972898433069\n",
      "epoch 427 lr 0.2128543434929251\n",
      "train_loss 0.4139654499485786 train_acc 0.8203089378454421\n",
      "epoch 428 lr 0.21242906023096228\n",
      "train_loss 0.41347875658232386 train_acc 0.8207537727560859\n",
      "epoch 429 lr 0.21200462668552364\n",
      "train_loss 0.41299853768311784 train_acc 0.8211430033028992\n",
      "epoch 430 lr 0.2115810411588744\n",
      "train_loss 0.4125249950577168 train_acc 0.8215989590863091\n",
      "epoch 431 lr 0.2111583019566719\n",
      "train_loss 0.41205844931277746 train_acc 0.8221994862156782\n",
      "epoch 432 lr 0.2107364073879588\n",
      "train_loss 0.4115988632569429 train_acc 0.822533112398661\n",
      "epoch 433 lr 0.2103153557651562\n",
      "train_loss 0.4111456990332011 train_acc 0.8226999254901525\n",
      "epoch 434 lr 0.20989514540405713\n",
      "train_loss 0.41069867399566196 train_acc 0.8228000133450473\n",
      "epoch 435 lr 0.2094757746238195\n",
      "train_loss 0.4102577159907985 train_acc 0.8231336395280302\n",
      "epoch 436 lr 0.20905724174695967\n",
      "train_loss 0.40982283436977085 train_acc 0.8232226065101589\n",
      "epoch 437 lr 0.20863954509934557\n",
      "train_loss 0.4093936255136801 train_acc 0.8234895074565451\n",
      "epoch 438 lr 0.20822268301019004\n",
      "train_loss 0.40897017159122245 train_acc 0.8233782987288842\n",
      "epoch 439 lr 0.2078066538120442\n",
      "train_loss 0.4085522415401895 train_acc 0.8235228700748435\n",
      "epoch 440 lr 0.2073914558407907\n",
      "train_loss 0.40813994217641264 train_acc 0.823700804039101\n",
      "epoch 441 lr 0.20697708743563706\n",
      "train_loss 0.4077332451230824 train_acc 0.8238564962578263\n",
      "epoch 442 lr 0.20656354693910914\n",
      "train_loss 0.40733196066444444 train_acc 0.8239454632399551\n",
      "epoch 443 lr 0.20615083269704437\n",
      "train_loss 0.4069359726517635 train_acc 0.8240121884765517\n",
      "epoch 444 lr 0.20573894305858528\n",
      "train_loss 0.4065451454932388 train_acc 0.8242234850591075\n",
      "epoch 445 lr 0.20532787637617275\n",
      "train_loss 0.4061594580458663 train_acc 0.8242790894229379\n",
      "epoch 446 lr 0.20491763100553947\n",
      "train_loss 0.4057789152880666 train_acc 0.8246127156059208\n",
      "epoch 447 lr 0.20450820530570346\n",
      "train_loss 0.40540346164174823 train_acc 0.8249685835344358\n",
      "epoch 448 lr 0.20409959763896135\n",
      "train_loss 0.4050326615893414 train_acc 0.8251353966259272\n",
      "epoch 449 lr 0.2036918063708819\n",
      "train_loss 0.4046663277203199 train_acc 0.8252354844808221\n",
      "\n",
      "val loss = 0.4078163045811744, \n",
      "val acc = 0.8204563650920736\n",
      "\n",
      "epoch 450 lr 0.20328482987029955\n",
      "train_loss 0.40430511866189867 train_acc 0.8252910888446525\n",
      "epoch 451 lr 0.20287866650930772\n",
      "train_loss 0.40394851364659734 train_acc 0.8253911766995474\n",
      "epoch 452 lr 0.20247331466325244\n",
      "train_loss 0.40359612111145343 train_acc 0.825457901936144\n",
      "epoch 453 lr 0.20206877271072576\n",
      "train_loss 0.40324813363810375 train_acc 0.8255246271727406\n",
      "epoch 454 lr 0.20166503903355937\n",
      "train_loss 0.40290459211658514 train_acc 0.8257581655008285\n",
      "epoch 455 lr 0.20126211201681798\n",
      "train_loss 0.4025651908647371 train_acc 0.8258026489918929\n",
      "epoch 456 lr 0.200859990048793\n",
      "train_loss 0.40222980585886947 train_acc 0.8259805829561504\n",
      "epoch 457 lr 0.20045867152099606\n",
      "train_loss 0.4018986612781472 train_acc 0.8260806708110453\n",
      "epoch 458 lr 0.20005815482815245\n",
      "train_loss 0.4015716022371702 train_acc 0.8261251543021096\n",
      "epoch 459 lr 0.1996584383681949\n",
      "train_loss 0.40124846032744066 train_acc 0.8263920552484959\n",
      "epoch 460 lr 0.19925952054225707\n",
      "train_loss 0.40092936125630485 train_acc 0.826525505721689\n",
      "epoch 461 lr 0.19886139975466707\n",
      "train_loss 0.4006140424509154 train_acc 0.8265588683399874\n",
      "epoch 462 lr 0.19846407441294123\n",
      "train_loss 0.4003022152100141 train_acc 0.8266700770676483\n",
      "epoch 463 lr 0.19806754292777767\n",
      "train_loss 0.39999390222001074 train_acc 0.826747923177011\n",
      "epoch 464 lr 0.1976718037130499\n",
      "train_loss 0.39968898008159764 train_acc 0.8267701649225431\n",
      "epoch 465 lr 0.19727685518580054\n",
      "train_loss 0.39938769935559054 train_acc 0.8269480988868007\n",
      "epoch 466 lr 0.196882695766235\n",
      "train_loss 0.3990897720548779 train_acc 0.8270481867416954\n",
      "epoch 467 lr 0.19648932387771498\n",
      "train_loss 0.3987949417449084 train_acc 0.8270815493599938\n",
      "epoch 468 lr 0.19609673794675248\n",
      "train_loss 0.3985033949205785 train_acc 0.8271482745965903\n",
      "epoch 469 lr 0.19570493640300324\n",
      "train_loss 0.39821535858409507 train_acc 0.8271816372148886\n",
      "epoch 470 lr 0.19531391767926054\n",
      "train_loss 0.3979304251974658 train_acc 0.8271705163421226\n",
      "epoch 471 lr 0.19492368021144899\n",
      "train_loss 0.39764863558763486 train_acc 0.8272483624514851\n",
      "epoch 472 lr 0.19453422243861818\n",
      "train_loss 0.3973697763123259 train_acc 0.8273039668153157\n",
      "epoch 473 lr 0.1941455428029365\n",
      "train_loss 0.3970938972772274 train_acc 0.8273595711791462\n",
      "epoch 474 lr 0.19375763974968488\n",
      "train_loss 0.3968211689922891 train_acc 0.827448538161275\n",
      "epoch 475 lr 0.19337051172725062\n",
      "train_loss 0.39655133994531444 train_acc 0.8274930216523393\n",
      "epoch 476 lr 0.19298415718712106\n",
      "train_loss 0.3962842436271802 train_acc 0.827570867761702\n",
      "epoch 477 lr 0.1925985745838776\n",
      "train_loss 0.3960199641433765 train_acc 0.8276598347438306\n",
      "epoch 478 lr 0.19221376237518928\n",
      "train_loss 0.3957585274089867 train_acc 0.8277265599804272\n",
      "epoch 479 lr 0.19182971902180673\n",
      "train_loss 0.3954998231275068 train_acc 0.8278044060897899\n",
      "epoch 480 lr 0.19144644298755603\n",
      "train_loss 0.39524378348588884 train_acc 0.8280157026723457\n",
      "epoch 481 lr 0.19106393273933253\n",
      "train_loss 0.3949903897300936 train_acc 0.8280601861634102\n",
      "epoch 482 lr 0.19068218674709478\n",
      "train_loss 0.3947396258163672 train_acc 0.828171394891071\n",
      "epoch 483 lr 0.19030120348385823\n",
      "train_loss 0.3944911420778508 train_acc 0.8281602740183049\n",
      "epoch 484 lr 0.18992098142568936\n",
      "train_loss 0.394245178215166 train_acc 0.8282158783821354\n",
      "epoch 485 lr 0.18954151905169941\n",
      "train_loss 0.39400153162329127 train_acc 0.8282492410004337\n",
      "epoch 486 lr 0.1891628148440384\n",
      "train_loss 0.39376029440990234 train_acc 0.8283270871097964\n",
      "epoch 487 lr 0.18878486728788899\n",
      "train_loss 0.39352107970602096 train_acc 0.8284939002012878\n",
      "epoch 488 lr 0.18840767487146046\n",
      "train_loss 0.39328391124177137 train_acc 0.8287051967838436\n",
      "epoch 489 lr 0.18803123608598257\n",
      "train_loss 0.3930491318958483 train_acc 0.828760801147674\n",
      "epoch 490 lr 0.18765554942569979\n",
      "train_loss 0.39281666601694837 train_acc 0.8288831307481012\n",
      "epoch 491 lr 0.1872806133878649\n",
      "train_loss 0.3925858830626285 train_acc 0.8290277020940603\n",
      "epoch 492 lr 0.18690642647273326\n",
      "train_loss 0.3923572490595381 train_acc 0.8291722734400195\n",
      "epoch 493 lr 0.1865329871835567\n",
      "train_loss 0.3921307918819219 train_acc 0.8292278778038501\n",
      "epoch 494 lr 0.18616029402657763\n",
      "train_loss 0.39190631749285115 train_acc 0.8292501195493822\n",
      "epoch 495 lr 0.18578834551102286\n",
      "train_loss 0.3916833227975225 train_acc 0.8292834821676806\n",
      "epoch 496 lr 0.18541714014909785\n",
      "train_loss 0.39146226290983155 train_acc 0.8293946908953415\n",
      "epoch 497 lr 0.18504667645598066\n",
      "train_loss 0.39124312594126426 train_acc 0.8294280535136398\n",
      "epoch 498 lr 0.184676952949816\n",
      "train_loss 0.3910256585574847 train_acc 0.8296059874778973\n",
      "epoch 499 lr 0.18430796815170944\n",
      "train_loss 0.3908101172500821 train_acc 0.8297171962055582\n",
      "\n",
      "val loss = 0.39291904629496605, \n",
      "val acc = 0.8264611689351481\n",
      "\n",
      "epoch 500 lr 0.1839397205857212\n",
      "train_loss 0.39059621235252384 train_acc 0.8297616796966226\n",
      "epoch 501 lr 0.18357220877886052\n",
      "train_loss 0.390383758522789 train_acc 0.8298172840604531\n",
      "epoch 502 lr 0.18320543126107974\n",
      "train_loss 0.39017261606806314 train_acc 0.8299173719153479\n",
      "epoch 503 lr 0.1828393865652683\n",
      "train_loss 0.38996303486061956 train_acc 0.8298617675515174\n",
      "epoch 504 lr 0.18247407322724687\n",
      "train_loss 0.38975542054802575 train_acc 0.8298951301698158\n",
      "epoch 505 lr 0.18210948978576166\n",
      "train_loss 0.3895493899869239 train_acc 0.8300285806430089\n",
      "epoch 506 lr 0.18174563478247843\n",
      "train_loss 0.3893451506105808 train_acc 0.830162031116202\n",
      "epoch 507 lr 0.18138250676197665\n",
      "train_loss 0.3891426587272953 train_acc 0.8302176354800325\n",
      "epoch 508 lr 0.18102010427174375\n",
      "train_loss 0.3889414482040401 train_acc 0.8302287563527986\n",
      "epoch 509 lr 0.1806584258621693\n",
      "train_loss 0.38874201926302965 train_acc 0.8304511738081205\n",
      "epoch 510 lr 0.18029747008653915\n",
      "train_loss 0.3885439720567856 train_acc 0.8304956572991848\n",
      "epoch 511 lr 0.17993723550102977\n",
      "train_loss 0.38834716717842566 train_acc 0.8305512616630153\n",
      "epoch 512 lr 0.17957772066470232\n",
      "train_loss 0.3881517034747712 train_acc 0.8305957451540797\n",
      "epoch 513 lr 0.17921892413949694\n",
      "train_loss 0.387957583453301 train_acc 0.8306068660268457\n",
      "epoch 514 lr 0.1788608444902271\n",
      "train_loss 0.38776476388489417 train_acc 0.8307736791183372\n",
      "epoch 515 lr 0.1785034802845737\n",
      "train_loss 0.38757324213662964 train_acc 0.830751437372805\n",
      "epoch 516 lr 0.17814683009307944\n",
      "train_loss 0.3873830264754233 train_acc 0.830862646100466\n",
      "epoch 517 lr 0.17779089248914307\n",
      "train_loss 0.38719346251879033 train_acc 0.8309404922098286\n",
      "epoch 518 lr 0.1774356660490137\n",
      "train_loss 0.3870052739299089 train_acc 0.830984975700893\n",
      "epoch 519 lr 0.17708114935178515\n",
      "train_loss 0.3868181968842947 train_acc 0.8310628218102557\n",
      "epoch 520 lr 0.17672734097939005\n",
      "train_loss 0.38663267922724986 train_acc 0.8311184261740862\n",
      "epoch 521 lr 0.17637423951659456\n",
      "train_loss 0.38644827826931366 train_acc 0.8312629975200454\n",
      "epoch 522 lr 0.1760218435509923\n",
      "train_loss 0.38626455298500795 train_acc 0.8313074810111097\n",
      "epoch 523 lr 0.1756701516729989\n",
      "train_loss 0.3860814707373062 train_acc 0.8313964479932385\n",
      "epoch 524 lr 0.17531916247584645\n",
      "train_loss 0.3858993739660505 train_acc 0.8315076567208994\n",
      "epoch 525 lr 0.17496887455557766\n",
      "train_loss 0.3857183294672943 train_acc 0.8316299863213265\n",
      "epoch 526 lr 0.1746192865110404\n",
      "train_loss 0.38553844305286583 train_acc 0.8316188654485605\n",
      "epoch 527 lr 0.17427039694388197\n",
      "train_loss 0.3853590481642979 train_acc 0.8317523159217536\n",
      "epoch 528 lr 0.1739222044585437\n",
      "train_loss 0.38518059904610535 train_acc 0.8319080081404788\n",
      "epoch 529 lr 0.17357470766225516\n",
      "train_loss 0.38500282619103854 train_acc 0.8319413707587772\n",
      "epoch 530 lr 0.1732279051650287\n",
      "train_loss 0.3848258146056108 train_acc 0.8319080081404788\n",
      "epoch 531 lr 0.17288179557965389\n",
      "train_loss 0.38464932648798633 train_acc 0.8319747333770754\n",
      "epoch 532 lr 0.17253637752169187\n",
      "train_loss 0.3844735204733978 train_acc 0.8319858542498415\n",
      "epoch 533 lr 0.17219164960947\n",
      "train_loss 0.38429867945606494 train_acc 0.8321860299596312\n",
      "epoch 534 lr 0.17184761046407618\n",
      "train_loss 0.3841247186774202 train_acc 0.8322527551962278\n",
      "epoch 535 lr 0.17150425870935332\n",
      "train_loss 0.38395145460090874 train_acc 0.8323417221783566\n",
      "epoch 536 lr 0.17116159297189398\n",
      "train_loss 0.38377944191930213 train_acc 0.8324974143970819\n",
      "epoch 537 lr 0.17081961188103473\n",
      "train_loss 0.383608627539334 train_acc 0.8324974143970819\n",
      "epoch 538 lr 0.17047831406885078\n",
      "train_loss 0.3834390552793374 train_acc 0.8325641396336785\n",
      "epoch 539 lr 0.1701376981701504\n",
      "train_loss 0.3832704504943132 train_acc 0.8326419857430412\n",
      "epoch 540 lr 0.16979776282246956\n",
      "train_loss 0.38310260684996583 train_acc 0.8326864692341055\n",
      "epoch 541 lr 0.1694585066660664\n",
      "train_loss 0.3829355665915512 train_acc 0.8327754362162343\n",
      "epoch 542 lr 0.16911992834391587\n",
      "train_loss 0.3827694782475838 train_acc 0.8328866449438952\n",
      "epoch 543 lr 0.16878202650170418\n",
      "train_loss 0.38260428080242675 train_acc 0.8329422493077256\n",
      "epoch 544 lr 0.16844479978782353\n",
      "train_loss 0.3824398017080643 train_acc 0.8331201832719832\n",
      "epoch 545 lr 0.16810824685336664\n",
      "train_loss 0.3822761370171215 train_acc 0.8331757876358137\n",
      "epoch 546 lr 0.16777236635212134\n",
      "train_loss 0.3821130088207937 train_acc 0.833220271126878\n",
      "epoch 547 lr 0.1674371569405651\n",
      "train_loss 0.3819503382994506 train_acc 0.8333870842183695\n",
      "epoch 548 lr 0.16710261727785988\n",
      "train_loss 0.38178857850299774 train_acc 0.8333759633456034\n",
      "epoch 549 lr 0.1667687460258466\n",
      "train_loss 0.38162775341084115 train_acc 0.8334982929460304\n",
      "\n",
      "val loss = 0.38304128987095143, \n",
      "val acc = 0.8295636509207366\n",
      "\n",
      "epoch 550 lr 0.16643554184903978\n",
      "train_loss 0.3814678180023135 train_acc 0.8336095016736913\n",
      "epoch 551 lr 0.16610300341462225\n",
      "train_loss 0.3813083919960711 train_acc 0.8336651060375219\n",
      "epoch 552 lr 0.16577112939243985\n",
      "train_loss 0.38114954973736975 train_acc 0.8336539851647558\n",
      "epoch 553 lr 0.16543991845499603\n",
      "train_loss 0.380991033202861 train_acc 0.8337651938924167\n",
      "epoch 554 lr 0.16510936927744665\n",
      "train_loss 0.3808332713464151 train_acc 0.8338875234928437\n",
      "epoch 555 lr 0.1647794805375945\n",
      "train_loss 0.38067601154117275 train_acc 0.8339653696022064\n",
      "epoch 556 lr 0.16445025091588422\n",
      "train_loss 0.38051925889911165 train_acc 0.8341099409481656\n",
      "epoch 557 lr 0.16412167909539688\n",
      "train_loss 0.38036336327425885 train_acc 0.8342322705485926\n",
      "epoch 558 lr 0.16379376376184474\n",
      "train_loss 0.38020834904966505 train_acc 0.8344213253856163\n",
      "epoch 559 lr 0.16346650360356604\n",
      "train_loss 0.3800541472025033 train_acc 0.8343990836400841\n",
      "epoch 560 lr 0.16313989731151973\n",
      "train_loss 0.37990062096366667 train_acc 0.8344880506222129\n",
      "epoch 561 lr 0.16281394357928017\n",
      "train_loss 0.3797472912224112 train_acc 0.8345325341132772\n",
      "epoch 562 lr 0.162488641103032\n",
      "train_loss 0.3795943842608714 train_acc 0.8346103802226399\n",
      "epoch 563 lr 0.16216398858156494\n",
      "train_loss 0.3794423052943885 train_acc 0.8347104680775347\n",
      "epoch 564 lr 0.1618399847162684\n",
      "train_loss 0.3792911595355865 train_acc 0.8348327976779618\n",
      "epoch 565 lr 0.1615166282111265\n",
      "train_loss 0.3791405124737318 train_acc 0.8348772811690262\n",
      "epoch 566 lr 0.16119391777271277\n",
      "train_loss 0.37899029339969154 train_acc 0.8349551272783888\n",
      "epoch 567 lr 0.1608718521101851\n",
      "train_loss 0.37884094216210096 train_acc 0.8350996986243481\n",
      "epoch 568 lr 0.16055042993528035\n",
      "train_loss 0.3786923642246613 train_acc 0.8351886656064768\n",
      "epoch 569 lr 0.1602296499623094\n",
      "train_loss 0.37854453448003583 train_acc 0.8353109952069039\n",
      "epoch 570 lr 0.15990951090815195\n",
      "train_loss 0.3783974277440691 train_acc 0.8353554786979682\n",
      "epoch 571 lr 0.15959001149225135\n",
      "train_loss 0.3782512798922487 train_acc 0.8353554786979682\n",
      "epoch 572 lr 0.1592711504366095\n",
      "train_loss 0.3781058826672674 train_acc 0.8354666874256291\n",
      "epoch 573 lr 0.15895292646578177\n",
      "train_loss 0.3779610355292141 train_acc 0.8356112587715884\n",
      "epoch 574 lr 0.15863533830687182\n",
      "train_loss 0.37781654679289367 train_acc 0.8357002257537172\n",
      "epoch 575 lr 0.1583183846895266\n",
      "train_loss 0.3776728182416246 train_acc 0.8357558301175476\n",
      "epoch 576 lr 0.15800206434593128\n",
      "train_loss 0.37752991790346363 train_acc 0.8357780718630798\n",
      "epoch 577 lr 0.15768637601080396\n",
      "train_loss 0.37738781127670085 train_acc 0.8358670388452085\n",
      "epoch 578 lr 0.15737131842139096\n",
      "train_loss 0.3772463582701835 train_acc 0.8359337640818051\n",
      "epoch 579 lr 0.15705689031746148\n",
      "train_loss 0.37710575468215046 train_acc 0.8360338519367\n",
      "epoch 580 lr 0.15674309044130266\n",
      "train_loss 0.3769659660953045 train_acc 0.8360116101911678\n",
      "epoch 581 lr 0.1564299175377146\n",
      "train_loss 0.37682700064684327 train_acc 0.8361116980460627\n",
      "epoch 582 lr 0.15611737035400527\n",
      "train_loss 0.3766888778282569 train_acc 0.8361005771732966\n",
      "epoch 583 lr 0.15580544763998552\n",
      "train_loss 0.3765512901591319 train_acc 0.8362117859009575\n",
      "epoch 584 lr 0.15549414814796406\n",
      "train_loss 0.3764145262187527 train_acc 0.8361895441554253\n",
      "epoch 585 lr 0.15518347063274252\n",
      "train_loss 0.376278706377297 train_acc 0.8363229946286185\n",
      "epoch 586 lr 0.1548734138516104\n",
      "train_loss 0.3761436574701457 train_acc 0.836500928592876\n",
      "epoch 587 lr 0.15456397656434023\n",
      "train_loss 0.3760093613268822 train_acc 0.8366010164477709\n",
      "epoch 588 lr 0.15425515753318236\n",
      "train_loss 0.37587581207617765 train_acc 0.8365898955750047\n",
      "epoch 589 lr 0.1539469555228603\n",
      "train_loss 0.3757430565643388 train_acc 0.8367011043026656\n",
      "epoch 590 lr 0.15363936930056563\n",
      "train_loss 0.37561091912320793 train_acc 0.8367789504120283\n",
      "epoch 591 lr 0.153332397635953\n",
      "train_loss 0.37547931613536956 train_acc 0.8368901591396893\n",
      "epoch 592 lr 0.15302603930113534\n",
      "train_loss 0.37534833832374576 train_acc 0.8369568843762859\n",
      "epoch 593 lr 0.15272029307067891\n",
      "train_loss 0.3752176959899684 train_acc 0.8370569722311807\n",
      "epoch 594 lr 0.15241515772159842\n",
      "train_loss 0.37508764392309213 train_acc 0.8369902469945841\n",
      "epoch 595 lr 0.15211063203335204\n",
      "train_loss 0.37495821895270576 train_acc 0.8370792139767129\n",
      "epoch 596 lr 0.15180671478783658\n",
      "train_loss 0.37482933279369385 train_acc 0.8371793018316077\n",
      "epoch 597 lr 0.1515034047693827\n",
      "train_loss 0.37470116436966855 train_acc 0.8372793896865026\n",
      "epoch 598 lr 0.1512007007647499\n",
      "train_loss 0.3745738885844278 train_acc 0.8372793896865026\n",
      "epoch 599 lr 0.15089860156312174\n",
      "train_loss 0.3744472208595887 train_acc 0.8373349940503331\n",
      "\n",
      "val loss = 0.37537641033470215, \n",
      "val acc = 0.8332666132906325\n",
      "\n",
      "epoch 600 lr 0.15059710595610104\n",
      "train_loss 0.3743210687083057 train_acc 0.8373683566686314\n",
      "epoch 601 lr 0.15029621273770497\n",
      "train_loss 0.37419567042264895 train_acc 0.8373794775413974\n",
      "epoch 602 lr 0.14999592070436024\n",
      "train_loss 0.3740707579924811 train_acc 0.8374128401596957\n",
      "epoch 603 lr 0.14969622865489834\n",
      "train_loss 0.37394654709943975 train_acc 0.8374128401596957\n",
      "epoch 604 lr 0.14939713539055063\n",
      "train_loss 0.3738230525305212 train_acc 0.8374906862690584\n",
      "epoch 605 lr 0.1490986397149437\n",
      "train_loss 0.37370009248709996 train_acc 0.8376241367422516\n",
      "epoch 606 lr 0.14880074043409441\n",
      "train_loss 0.3735776498198285 train_acc 0.8376018949967193\n",
      "epoch 607 lr 0.14850343635640526\n",
      "train_loss 0.3734560712973226 train_acc 0.8376241367422516\n",
      "epoch 608 lr 0.14820672629265955\n",
      "train_loss 0.37333502123992224 train_acc 0.8377242245971463\n",
      "epoch 609 lr 0.1479106090560166\n",
      "train_loss 0.37321454689327993 train_acc 0.8378465541975735\n",
      "epoch 610 lr 0.1476150834620071\n",
      "train_loss 0.3730945697602286 train_acc 0.8378687959431056\n",
      "epoch 611 lr 0.14732014832852827\n",
      "train_loss 0.3729753056284971 train_acc 0.8379355211797022\n",
      "epoch 612 lr 0.14702580247583918\n",
      "train_loss 0.3728568152625175 train_acc 0.8379466420524683\n",
      "epoch 613 lr 0.14673204472655602\n",
      "train_loss 0.3727390225754652 train_acc 0.8380133672890648\n",
      "epoch 614 lr 0.14643887390564742\n",
      "train_loss 0.37262202190296273 train_acc 0.8380912133984275\n",
      "epoch 615 lr 0.14614628884042968\n",
      "train_loss 0.3725059302320566 train_acc 0.8381023342711936\n",
      "epoch 616 lr 0.1458542883605622\n",
      "train_loss 0.3723904292515924 train_acc 0.8381690595077902\n",
      "epoch 617 lr 0.1455628712980426\n",
      "train_loss 0.372275452830549 train_acc 0.8382469056171529\n",
      "epoch 618 lr 0.14527203648720227\n",
      "train_loss 0.3721612785852661 train_acc 0.8383025099809833\n",
      "epoch 619 lr 0.1449817827647016\n",
      "train_loss 0.3720478601846078 train_acc 0.8383692352175799\n",
      "epoch 620 lr 0.1446921089695253\n",
      "train_loss 0.3719352010566641 train_acc 0.8384582021997087\n",
      "epoch 621 lr 0.1444030139429778\n",
      "train_loss 0.37182307481255894 train_acc 0.8384804439452408\n",
      "epoch 622 lr 0.1441144965286786\n",
      "train_loss 0.37171159578584695 train_acc 0.8384137187086442\n",
      "epoch 623 lr 0.1438265555725577\n",
      "train_loss 0.3716008925920899 train_acc 0.8384804439452408\n",
      "epoch 624 lr 0.14353918992285084\n",
      "train_loss 0.37149059669961854 train_acc 0.8385360483090712\n",
      "epoch 625 lr 0.14325239843009505\n",
      "train_loss 0.37138082015812657 train_acc 0.8385582900546035\n",
      "epoch 626 lr 0.14296617994712396\n",
      "train_loss 0.3712714457893429 train_acc 0.8385694109273696\n",
      "epoch 627 lr 0.14268053332906333\n",
      "train_loss 0.3711627803790097 train_acc 0.8386806196550305\n",
      "epoch 628 lr 0.1423954574333262\n",
      "train_loss 0.3710547846381222 train_acc 0.8388696744920542\n",
      "epoch 629 lr 0.14211095111960875\n",
      "train_loss 0.3709474564918515 train_acc 0.8388807953648202\n",
      "epoch 630 lr 0.1418270132498852\n",
      "train_loss 0.3708407205244762 train_acc 0.8389586414741829\n",
      "epoch 631 lr 0.14154364268840375\n",
      "train_loss 0.37073481281164855 train_acc 0.8390253667107794\n",
      "epoch 632 lr 0.1412608383016818\n",
      "train_loss 0.37062945434002953 train_acc 0.8390809710746099\n",
      "epoch 633 lr 0.14097859895850137\n",
      "train_loss 0.3705246686216281 train_acc 0.8391143336929082\n",
      "epoch 634 lr 0.14069692352990476\n",
      "train_loss 0.3704204961283613 train_acc 0.8391921798022709\n",
      "epoch 635 lr 0.1404158108891899\n",
      "train_loss 0.370316755572432 train_acc 0.8392811467843997\n",
      "epoch 636 lr 0.14013525991190579\n",
      "train_loss 0.3702135710342013 train_acc 0.8393145094026979\n",
      "epoch 637 lr 0.13985526947584817\n",
      "train_loss 0.37011085992520276 train_acc 0.8392811467843997\n",
      "epoch 638 lr 0.13957583846105492\n",
      "train_loss 0.37000855945771766 train_acc 0.8393589928937623\n",
      "epoch 639 lr 0.13929696574980163\n",
      "train_loss 0.3699067546680187 train_acc 0.8393701137665284\n",
      "epoch 640 lr 0.13901865022659707\n",
      "train_loss 0.36980535856801816 train_acc 0.8395369268580198\n",
      "epoch 641 lr 0.13874089077817878\n",
      "train_loss 0.3697044607658071 train_acc 0.8395702894763181\n",
      "epoch 642 lr 0.13846368629350858\n",
      "train_loss 0.3696040862336255 train_acc 0.8396592564584469\n",
      "epoch 643 lr 0.13818703566376817\n",
      "train_loss 0.3695044376225604 train_acc 0.8396814982039791\n",
      "epoch 644 lr 0.13791093778235466\n",
      "train_loss 0.3694052667682091 train_acc 0.8397482234405756\n",
      "epoch 645 lr 0.13763539154487617\n",
      "train_loss 0.36930658902919744 train_acc 0.8398483112954704\n",
      "epoch 646 lr 0.13736039584914736\n",
      "train_loss 0.3692085977515997 train_acc 0.8398816739137688\n",
      "epoch 647 lr 0.1370859495951851\n",
      "train_loss 0.369111244563878 train_acc 0.8398705530410027\n",
      "epoch 648 lr 0.13681205168520402\n",
      "train_loss 0.3690142659083088 train_acc 0.8398483112954704\n",
      "epoch 649 lr 0.1365387010236121\n",
      "train_loss 0.3689179570390748 train_acc 0.8398483112954704\n",
      "\n",
      "val loss = 0.3695982836296144, \n",
      "val acc = 0.8371697357886309\n",
      "\n",
      "epoch 650 lr 0.1362658965170063\n",
      "train_loss 0.3688221787385422 train_acc 0.8398816739137688\n",
      "epoch 651 lr 0.13599363707416826\n",
      "train_loss 0.36872684661836713 train_acc 0.8399039156593009\n",
      "epoch 652 lr 0.13572192160605984\n",
      "train_loss 0.36863201561386305 train_acc 0.8400040035141958\n",
      "epoch 653 lr 0.13545074902581883\n",
      "train_loss 0.3685378237589763 train_acc 0.840037366132494\n",
      "epoch 654 lr 0.1351801182487545\n",
      "train_loss 0.36844407034101234 train_acc 0.8400040035141958\n",
      "epoch 655 lr 0.1349100281923434\n",
      "train_loss 0.36835083164835136 train_acc 0.840026245259728\n",
      "epoch 656 lr 0.13464047777622498\n",
      "train_loss 0.3682582232345293 train_acc 0.840037366132494\n",
      "epoch 657 lr 0.13437146592219718\n",
      "train_loss 0.3681662240110024 train_acc 0.840037366132494\n",
      "epoch 658 lr 0.1341029915542122\n",
      "train_loss 0.36807476941633266 train_acc 0.8401374539873889\n",
      "epoch 659 lr 0.13383505359837228\n",
      "train_loss 0.36798371495821913 train_acc 0.8401708166056873\n",
      "epoch 660 lr 0.13356765098292517\n",
      "train_loss 0.3678931333020728 train_acc 0.8402264209695177\n",
      "epoch 661 lr 0.1333007826382601\n",
      "train_loss 0.36780306906246873 train_acc 0.8402820253333482\n",
      "epoch 662 lr 0.1330344474969033\n",
      "train_loss 0.36771349365911393 train_acc 0.8403042670788804\n",
      "epoch 663 lr 0.1327686444935139\n",
      "train_loss 0.3676244447769794 train_acc 0.8402709044605821\n",
      "epoch 664 lr 0.13250337256487946\n",
      "train_loss 0.3675358489105216 train_acc 0.8403042670788804\n",
      "epoch 665 lr 0.13223863064991195\n",
      "train_loss 0.36744774878256786 train_acc 0.8403265088244125\n",
      "epoch 666 lr 0.13197441768964338\n",
      "train_loss 0.36736002835669135 train_acc 0.8403932340610091\n",
      "epoch 667 lr 0.13171073262722155\n",
      "train_loss 0.3672729052880584 train_acc 0.8404377175520735\n",
      "epoch 668 lr 0.1314475744079058\n",
      "train_loss 0.36718618490125504 train_acc 0.8404710801703718\n",
      "epoch 669 lr 0.13118494197906297\n",
      "train_loss 0.36709987500662444 train_acc 0.8404822010431379\n",
      "epoch 670 lr 0.13092283429016296\n",
      "train_loss 0.3670139905072 train_acc 0.8405378054069683\n",
      "epoch 671 lr 0.1306612502927747\n",
      "train_loss 0.3669284331050023 train_acc 0.8405489262797344\n",
      "epoch 672 lr 0.13040018894056182\n",
      "train_loss 0.36684321269417175 train_acc 0.8406045306435649\n",
      "epoch 673 lr 0.13013964918927856\n",
      "train_loss 0.3667583576093905 train_acc 0.8406378932618632\n",
      "epoch 674 lr 0.12987962999676558\n",
      "train_loss 0.3666739464807783 train_acc 0.8406490141346293\n",
      "epoch 675 lr 0.12962013032294575\n",
      "train_loss 0.36658989354850674 train_acc 0.8407491019895241\n",
      "epoch 676 lr 0.12936114912982002\n",
      "train_loss 0.3665061693580131 train_acc 0.8407935854805885\n",
      "epoch 677 lr 0.12910268538146333\n",
      "train_loss 0.3664228575716112 train_acc 0.840860310717185\n",
      "epoch 678 lr 0.12884473804402027\n",
      "train_loss 0.36633985580789724 train_acc 0.8409159150810156\n",
      "epoch 679 lr 0.1285873060857012\n",
      "train_loss 0.3662573189111306 train_acc 0.8409603985720799\n",
      "epoch 680 lr 0.12833038847677794\n",
      "train_loss 0.36617529242277946 train_acc 0.8409826403176122\n",
      "epoch 681 lr 0.12807398418957966\n",
      "train_loss 0.3660936498074383 train_acc 0.8409492776993138\n",
      "epoch 682 lr 0.12781809219848891\n",
      "train_loss 0.3660124485308098 train_acc 0.8409937611903783\n",
      "epoch 683 lr 0.1275627114799374\n",
      "train_loss 0.36593161330799173 train_acc 0.8410716072997408\n",
      "epoch 684 lr 0.12730784101240186\n",
      "train_loss 0.36585111563841083 train_acc 0.8410716072997408\n",
      "epoch 685 lr 0.12705347977640014\n",
      "train_loss 0.3657710051016555 train_acc 0.8411494534091035\n",
      "epoch 686 lr 0.12679962675448692\n",
      "train_loss 0.36569138352929514 train_acc 0.8412829038822967\n",
      "epoch 687 lr 0.12654628093124978\n",
      "train_loss 0.3656122227257309 train_acc 0.8412940247550628\n",
      "epoch 688 lr 0.12629344129330514\n",
      "train_loss 0.3655335230764051 train_acc 0.8413051456278289\n",
      "epoch 689 lr 0.126041106829294\n",
      "train_loss 0.36545516403920486 train_acc 0.8413273873733611\n",
      "epoch 690 lr 0.12578927652987826\n",
      "train_loss 0.3653772004927864 train_acc 0.841316266500595\n",
      "epoch 691 lr 0.12553794938773635\n",
      "train_loss 0.3652994457518589 train_acc 0.8413829917371916\n",
      "epoch 692 lr 0.1252871243975594\n",
      "train_loss 0.36522198430816694 train_acc 0.8413718708644254\n",
      "epoch 693 lr 0.12503680055604707\n",
      "train_loss 0.36514481290977496 train_acc 0.8413829917371916\n",
      "epoch 694 lr 0.12478697686190368\n",
      "train_loss 0.36506798203889007 train_acc 0.8414052334827237\n",
      "epoch 695 lr 0.12453765231583412\n",
      "train_loss 0.3649914060679105 train_acc 0.8414052334827237\n",
      "epoch 696 lr 0.12428882592053987\n",
      "train_loss 0.3649150304692274 train_acc 0.8414608378465542\n",
      "epoch 697 lr 0.12404049668071501\n",
      "train_loss 0.36483888550808696 train_acc 0.8415053213376186\n",
      "epoch 698 lr 0.12379266360304228\n",
      "train_loss 0.36476309992177985 train_acc 0.8414608378465542\n",
      "epoch 699 lr 0.123545325696189\n",
      "train_loss 0.36468757372753324 train_acc 0.8414830795920863\n",
      "\n",
      "val loss = 0.3652182536486512, \n",
      "val acc = 0.838470776621297\n",
      "\n",
      "epoch 700 lr 0.12329848197080326\n",
      "train_loss 0.364612310953959 train_acc 0.8415498048286829\n",
      "epoch 701 lr 0.12305213143950978\n",
      "train_loss 0.3645373600860058 train_acc 0.841560925701449\n",
      "epoch 702 lr 0.12280627311690613\n",
      "train_loss 0.3644628831777076 train_acc 0.8416498926835778\n",
      "epoch 703 lr 0.1225609060195587\n",
      "train_loss 0.3643887579728594 train_acc 0.8416387718108117\n",
      "epoch 704 lr 0.12231602916599875\n",
      "train_loss 0.36431499585773514 train_acc 0.8416165300652795\n",
      "epoch 705 lr 0.12207164157671856\n",
      "train_loss 0.364241489131657 train_acc 0.8416054091925135\n",
      "epoch 706 lr 0.12182774227416744\n",
      "train_loss 0.3641682218943263 train_acc 0.8415942883197474\n",
      "epoch 707 lr 0.12158433028274784\n",
      "train_loss 0.3640953397703471 train_acc 0.8416498926835778\n",
      "epoch 708 lr 0.1213414046288115\n",
      "train_loss 0.36402272286733606 train_acc 0.8416610135563439\n",
      "epoch 709 lr 0.12109896434065545\n",
      "train_loss 0.3639504186939709 train_acc 0.84167213442911\n",
      "epoch 710 lr 0.12085700844851824\n",
      "train_loss 0.3638782948471669 train_acc 0.8417388596657066\n",
      "epoch 711 lr 0.12061553598457596\n",
      "train_loss 0.36380637646254693 train_acc 0.8417499805384726\n",
      "epoch 712 lr 0.12037454598293844\n",
      "train_loss 0.3637347814861773 train_acc 0.8417277387929405\n",
      "epoch 713 lr 0.12013403747964535\n",
      "train_loss 0.3636635665015367 train_acc 0.8417388596657066\n",
      "epoch 714 lr 0.11989400951266237\n",
      "train_loss 0.3635927275141059 train_acc 0.841783343156771\n",
      "epoch 715 lr 0.11965446112187728\n",
      "train_loss 0.3635223598791191 train_acc 0.8417722222840048\n",
      "epoch 716 lr 0.11941539134909622\n",
      "train_loss 0.3634522802424914 train_acc 0.841905672757198\n",
      "epoch 717 lr 0.11917679923803978\n",
      "train_loss 0.3633824390732274 train_acc 0.8419279145027302\n",
      "epoch 718 lr 0.1189386838343392\n",
      "train_loss 0.3633129819362179 train_acc 0.8419167936299641\n",
      "epoch 719 lr 0.11870104418553254\n",
      "train_loss 0.36324385512302737 train_acc 0.8419390353754963\n",
      "epoch 720 lr 0.11846387934106088\n",
      "train_loss 0.36317494541665907 train_acc 0.8419167936299641\n",
      "epoch 721 lr 0.11822718835226455\n",
      "train_loss 0.3631061573619621 train_acc 0.8419835188665606\n",
      "epoch 722 lr 0.11799097027237926\n",
      "train_loss 0.36303753451364246 train_acc 0.8421169693397538\n",
      "epoch 723 lr 0.11775522415653238\n",
      "train_loss 0.3629691425764379 train_acc 0.8421503319580521\n",
      "epoch 724 lr 0.11751994906173914\n",
      "train_loss 0.3629010430922063 train_acc 0.8422170571946487\n",
      "epoch 725 lr 0.11728514404689884\n",
      "train_loss 0.36283322389603867 train_acc 0.8422059363218826\n",
      "epoch 726 lr 0.1170508081727911\n",
      "train_loss 0.3627656659924041 train_acc 0.8421836945763503\n",
      "epoch 727 lr 0.11681694050207211\n",
      "train_loss 0.3626984335429719 train_acc 0.8422059363218826\n",
      "epoch 728 lr 0.1165835400992709\n",
      "train_loss 0.3626316205379499 train_acc 0.8422281780674147\n",
      "epoch 729 lr 0.11635060603078552\n",
      "train_loss 0.3625651839262035 train_acc 0.842261540685713\n",
      "epoch 730 lr 0.11611813736487941\n",
      "train_loss 0.36249904005503364 train_acc 0.8422949033040112\n",
      "epoch 731 lr 0.11588613317167758\n",
      "train_loss 0.3624330767811983 train_acc 0.8423171450495435\n",
      "epoch 732 lr 0.11565459252316296\n",
      "train_loss 0.3623673011125197 train_acc 0.8423393867950757\n",
      "epoch 733 lr 0.11542351449317262\n",
      "train_loss 0.36230195496622714 train_acc 0.8423393867950757\n",
      "epoch 734 lr 0.11519289815739416\n",
      "train_loss 0.36223703402617574 train_acc 0.8423505076678418\n",
      "epoch 735 lr 0.11496274259336192\n",
      "train_loss 0.3621724637011469 train_acc 0.84238387028614\n",
      "epoch 736 lr 0.11473304688045334\n",
      "train_loss 0.36210814164913674 train_acc 0.8424172329044384\n",
      "epoch 737 lr 0.11450381009988526\n",
      "train_loss 0.36204407111347847 train_acc 0.8424839581410349\n",
      "epoch 738 lr 0.11427503133471024\n",
      "train_loss 0.3619802156113121 train_acc 0.8425506833776315\n",
      "epoch 739 lr 0.11404670966981294\n",
      "train_loss 0.3619166026094237 train_acc 0.8425840459959297\n",
      "epoch 740 lr 0.11381884419190637\n",
      "train_loss 0.361853325653951 train_acc 0.8425951668686958\n",
      "epoch 741 lr 0.11359143398952833\n",
      "train_loss 0.3617904406641944 train_acc 0.8426730129780585\n",
      "epoch 742 lr 0.1133644781530377\n",
      "train_loss 0.3617277712687033 train_acc 0.8426841338508246\n",
      "epoch 743 lr 0.11313797577461085\n",
      "train_loss 0.36166530437136307 train_acc 0.8426730129780585\n",
      "epoch 744 lr 0.11291192594823793\n",
      "train_loss 0.36160311327602396 train_acc 0.8427174964691229\n",
      "epoch 745 lr 0.11268632776971936\n",
      "train_loss 0.36154116381858714 train_acc 0.8426952547235907\n",
      "epoch 746 lr 0.11246118033666212\n",
      "train_loss 0.3614795588905108 train_acc 0.8427174964691229\n",
      "epoch 747 lr 0.11223648274847618\n",
      "train_loss 0.3614181800069862 train_acc 0.8427063755963567\n",
      "epoch 748 lr 0.11201223410637087\n",
      "train_loss 0.36135716451734723 train_acc 0.8427397382146551\n",
      "epoch 749 lr 0.11178843351335134\n",
      "train_loss 0.3612964837400984 train_acc 0.8427731008329534\n",
      "\n",
      "val loss = 0.36164230802763625, \n",
      "val acc = 0.8398718975180144\n",
      "\n",
      "epoch 750 lr 0.11156508007421491\n",
      "train_loss 0.36123584231988465 train_acc 0.8428064634512517\n",
      "epoch 751 lr 0.11134217289554754\n",
      "train_loss 0.3611754294230745 train_acc 0.8428175843240178\n",
      "epoch 752 lr 0.1111197110857202\n",
      "train_loss 0.3611153039785812 train_acc 0.8428287051967839\n",
      "epoch 753 lr 0.11089769375488537\n",
      "train_loss 0.3610554817886792 train_acc 0.8428287051967839\n",
      "epoch 754 lr 0.11067612001497341\n",
      "train_loss 0.36099593052588463 train_acc 0.8427953425784855\n",
      "epoch 755 lr 0.1104549889796891\n",
      "train_loss 0.36093654298170935 train_acc 0.8428175843240178\n",
      "epoch 756 lr 0.11023429976450796\n",
      "train_loss 0.3608773817199122 train_acc 0.8427619799601873\n",
      "epoch 757 lr 0.11001405148667287\n",
      "train_loss 0.36081840782654945 train_acc 0.8427508590874212\n",
      "epoch 758 lr 0.10979424326519041\n",
      "train_loss 0.36075959710638905 train_acc 0.8427953425784855\n",
      "epoch 759 lr 0.1095748742208274\n",
      "train_loss 0.3607010295245224 train_acc 0.8428064634512517\n",
      "epoch 760 lr 0.10935594347610737\n",
      "train_loss 0.36064269762509493 train_acc 0.8428287051967839\n",
      "epoch 761 lr 0.10913745015530707\n",
      "train_loss 0.36058453242123484 train_acc 0.8428731886878482\n",
      "epoch 762 lr 0.10891939338445289\n",
      "train_loss 0.3605265630727729 train_acc 0.842850946942316\n",
      "epoch 763 lr 0.10870177229131747\n",
      "train_loss 0.3604686926822347 train_acc 0.8428843095606143\n",
      "epoch 764 lr 0.10848458600541616\n",
      "train_loss 0.3604109062855495 train_acc 0.8429287930516787\n",
      "epoch 765 lr 0.10826783365800352\n",
      "train_loss 0.36035326529346584 train_acc 0.842962155669977\n",
      "epoch 766 lr 0.10805151438206988\n",
      "train_loss 0.3602958125832997 train_acc 0.8430400017793397\n",
      "epoch 767 lr 0.10783562731233781\n",
      "train_loss 0.3602386784991077 train_acc 0.8430956061431701\n",
      "epoch 768 lr 0.10762017158525879\n",
      "train_loss 0.3601817925109031 train_acc 0.8430733643976379\n",
      "epoch 769 lr 0.1074051463390096\n",
      "train_loss 0.3601251307663986 train_acc 0.8431067270159363\n",
      "epoch 770 lr 0.10719055071348897\n",
      "train_loss 0.3600686620428231 train_acc 0.8431178478887023\n",
      "epoch 771 lr 0.10697638385031412\n",
      "train_loss 0.3600124750303205 train_acc 0.8431956939980649\n",
      "epoch 772 lr 0.1067626448928173\n",
      "train_loss 0.35995643962347657 train_acc 0.8432290566163633\n",
      "epoch 773 lr 0.1065493329860424\n",
      "train_loss 0.3599004882947528 train_acc 0.8432290566163633\n",
      "epoch 774 lr 0.10633644727674152\n",
      "train_loss 0.35984476518196673 train_acc 0.8432179357435972\n",
      "epoch 775 lr 0.10612398691337152\n",
      "train_loss 0.35978930240631224 train_acc 0.8432512983618955\n",
      "epoch 776 lr 0.10591195104609068\n",
      "train_loss 0.35973401661282584 train_acc 0.8432290566163633\n",
      "epoch 777 lr 0.10570033882675522\n",
      "train_loss 0.359678798324302 train_acc 0.8432401774891294\n",
      "epoch 778 lr 0.10548914940891603\n",
      "train_loss 0.3596237177093665 train_acc 0.8431845731252988\n",
      "epoch 779 lr 0.10527838194781511\n",
      "train_loss 0.359568792950689 train_acc 0.8431845731252988\n",
      "epoch 780 lr 0.10506803560038236\n",
      "train_loss 0.35951404665693026 train_acc 0.8432179357435972\n",
      "epoch 781 lr 0.1048581095252321\n",
      "train_loss 0.35945947662890065 train_acc 0.8432512983618955\n",
      "epoch 782 lr 0.10464860288265976\n",
      "train_loss 0.3594050258947852 train_acc 0.8433180235984921\n",
      "epoch 783 lr 0.10443951483463847\n",
      "train_loss 0.35935076689088047 train_acc 0.8433180235984921\n",
      "epoch 784 lr 0.10423084454481576\n",
      "train_loss 0.35929665162716407 train_acc 0.8433625070895564\n",
      "epoch 785 lr 0.10402259117851023\n",
      "train_loss 0.3592426950330066 train_acc 0.843306902725726\n",
      "epoch 786 lr 0.1038147539027081\n",
      "train_loss 0.3591889391002871 train_acc 0.8433625070895564\n",
      "epoch 787 lr 0.10360733188606\n",
      "train_loss 0.3591353751645539 train_acc 0.8433625070895564\n",
      "epoch 788 lr 0.10340032429887758\n",
      "train_loss 0.3590819737640889 train_acc 0.8433625070895564\n",
      "epoch 789 lr 0.10319373031313023\n",
      "train_loss 0.35902883535361013 train_acc 0.8433402653440242\n",
      "epoch 790 lr 0.10298754910244173\n",
      "train_loss 0.35897601436481896 train_acc 0.8433625070895564\n",
      "epoch 791 lr 0.10278177984208695\n",
      "train_loss 0.35892346562903904 train_acc 0.8433736279623225\n",
      "epoch 792 lr 0.10257642170898858\n",
      "train_loss 0.3588711674944294 train_acc 0.8433736279623225\n",
      "epoch 793 lr 0.10237147388171382\n",
      "train_loss 0.35881909055823846 train_acc 0.8433736279623225\n",
      "epoch 794 lr 0.10216693554047107\n",
      "train_loss 0.35876728502606037 train_acc 0.843429232326153\n",
      "epoch 795 lr 0.10196280586710671\n",
      "train_loss 0.35871565049243553 train_acc 0.8434625949444512\n",
      "epoch 796 lr 0.10175908404510177\n",
      "train_loss 0.3586642109672034 train_acc 0.8434403531989191\n",
      "epoch 797 lr 0.10155576925956869\n",
      "train_loss 0.35861291899860614 train_acc 0.843429232326153\n",
      "epoch 798 lr 0.10135286069724805\n",
      "train_loss 0.35856188234508546 train_acc 0.8434625949444512\n",
      "epoch 799 lr 0.10115035754650535\n",
      "train_loss 0.3585110640668206 train_acc 0.8434848366899834\n",
      "\n",
      "val loss = 0.35873261140856166, \n",
      "val acc = 0.8410728582866293\n",
      "\n",
      "epoch 800 lr 0.10094825899732769\n",
      "train_loss 0.3584603461560112 train_acc 0.8434959575627495\n",
      "epoch 801 lr 0.10074656424132063\n",
      "train_loss 0.35840969270058104 train_acc 0.8435404410538139\n",
      "epoch 802 lr 0.10054527247170485\n",
      "train_loss 0.35835924265103103 train_acc 0.8435404410538139\n",
      "epoch 803 lr 0.10034438288331303\n",
      "train_loss 0.3583090890726575 train_acc 0.8435181993082818\n",
      "epoch 804 lr 0.10014389467258653\n",
      "train_loss 0.35825915535152697 train_acc 0.8435070784355156\n",
      "epoch 805 lr 0.09994380703757223\n",
      "train_loss 0.35820941281833635 train_acc 0.8435960454176443\n",
      "epoch 806 lr 0.09974411917791937\n",
      "train_loss 0.358159955670557 train_acc 0.8435626827993461\n",
      "epoch 807 lr 0.0995448302948762\n",
      "train_loss 0.3581107599299899 train_acc 0.8436405289087088\n",
      "epoch 808 lr 0.09934593959128692\n",
      "train_loss 0.35806174151062675 train_acc 0.8436961332725392\n",
      "epoch 809 lr 0.09914744627158849\n",
      "train_loss 0.35801283783144605 train_acc 0.8437739793819019\n",
      "epoch 810 lr 0.09894934954180733\n",
      "train_loss 0.35796417521322715 train_acc 0.8437962211274341\n",
      "epoch 811 lr 0.09875164860955626\n",
      "train_loss 0.35791581608430545 train_acc 0.8438184628729662\n",
      "epoch 812 lr 0.09855434268403132\n",
      "train_loss 0.3578676353790471 train_acc 0.8438295837457324\n",
      "epoch 813 lr 0.09835743097600853\n",
      "train_loss 0.3578196574116097 train_acc 0.8438518254912646\n",
      "epoch 814 lr 0.09816091269784077\n",
      "train_loss 0.35777198865845455 train_acc 0.8438740672367967\n",
      "epoch 815 lr 0.09796478706345468\n",
      "train_loss 0.35772445894612664 train_acc 0.8438851881095628\n",
      "epoch 816 lr 0.09776905328834747\n",
      "train_loss 0.3576771043350084 train_acc 0.8439185507278611\n",
      "epoch 817 lr 0.09757371058958376\n",
      "train_loss 0.3576299805675638 train_acc 0.8438740672367967\n",
      "epoch 818 lr 0.09737875818579252\n",
      "train_loss 0.3575830324337418 train_acc 0.8438851881095628\n",
      "epoch 819 lr 0.09718419529716385\n",
      "train_loss 0.35753633591573963 train_acc 0.8439852759644577\n",
      "epoch 820 lr 0.09699002114544596\n",
      "train_loss 0.35748978766634887 train_acc 0.8440520012010543\n",
      "epoch 821 lr 0.09679623495394196\n",
      "train_loss 0.35744341133206237 train_acc 0.8440742429465864\n",
      "epoch 822 lr 0.09660283594750685\n",
      "train_loss 0.35739724885584156 train_acc 0.8440742429465864\n",
      "epoch 823 lr 0.09640982335254432\n",
      "train_loss 0.3573512392828755 train_acc 0.8441076055648847\n",
      "epoch 824 lr 0.09621719639700377\n",
      "train_loss 0.35730538610529233 train_acc 0.8441187264376508\n",
      "epoch 825 lr 0.09602495431037707\n",
      "train_loss 0.3572596901600889 train_acc 0.8441743308014813\n",
      "epoch 826 lr 0.09583309632369566\n",
      "train_loss 0.35721418555172396 train_acc 0.8441743308014813\n",
      "epoch 827 lr 0.0956416216695273\n",
      "train_loss 0.3571688307334328 train_acc 0.8441965725470135\n",
      "epoch 828 lr 0.09545052958197317\n",
      "train_loss 0.3571236809184861 train_acc 0.8441965725470135\n",
      "epoch 829 lr 0.09525981929666462\n",
      "train_loss 0.3570786111275347 train_acc 0.8442410560380779\n",
      "epoch 830 lr 0.09506949005076028\n",
      "train_loss 0.3570337140593083 train_acc 0.8441965725470135\n",
      "epoch 831 lr 0.09487954108294289\n",
      "train_loss 0.35698900019251234 train_acc 0.8441854516742474\n",
      "epoch 832 lr 0.09468997163341634\n",
      "train_loss 0.35694451117426496 train_acc 0.844252176910844\n",
      "epoch 833 lr 0.09450078094390259\n",
      "train_loss 0.35690024667182735 train_acc 0.8442855395291422\n",
      "epoch 834 lr 0.0943119682576386\n",
      "train_loss 0.35685606211923626 train_acc 0.8442744186563762\n",
      "epoch 835 lr 0.0941235328193734\n",
      "train_loss 0.3568119563793776 train_acc 0.8443077812746744\n",
      "epoch 836 lr 0.09393547387536497\n",
      "train_loss 0.3567679595639208 train_acc 0.8442966604019083\n",
      "epoch 837 lr 0.09374779067337728\n",
      "train_loss 0.3567241659937238 train_acc 0.8442966604019083\n",
      "epoch 838 lr 0.0935604824626773\n",
      "train_loss 0.35668045680460136 train_acc 0.8442299351653118\n",
      "epoch 839 lr 0.09337354849403191\n",
      "train_loss 0.3566368913941979 train_acc 0.8442188142925456\n",
      "epoch 840 lr 0.09318698801970499\n",
      "train_loss 0.35659344878462507 train_acc 0.8441965725470135\n",
      "epoch 841 lr 0.09300080029345441\n",
      "train_loss 0.3565501914603162 train_acc 0.8441854516742474\n",
      "epoch 842 lr 0.09281498457052899\n",
      "train_loss 0.35650702512893656 train_acc 0.8441965725470135\n",
      "epoch 843 lr 0.09262954010766561\n",
      "train_loss 0.35646407730324636 train_acc 0.8442076934197796\n",
      "epoch 844 lr 0.09244446616308617\n",
      "train_loss 0.3564213515767261 train_acc 0.8442076934197796\n",
      "epoch 845 lr 0.09225976199649465\n",
      "train_loss 0.3563786723312311 train_acc 0.8442410560380779\n",
      "epoch 846 lr 0.09207542686907412\n",
      "train_loss 0.3563360590830192 train_acc 0.8442188142925456\n",
      "epoch 847 lr 0.09189146004348384\n",
      "train_loss 0.35629352848466356 train_acc 0.8442076934197796\n",
      "epoch 848 lr 0.09170786078385623\n",
      "train_loss 0.3562511922451395 train_acc 0.844252176910844\n",
      "epoch 849 lr 0.09152462835579406\n",
      "train_loss 0.3562090834628949 train_acc 0.8442744186563762\n",
      "\n",
      "val loss = 0.35639499343591613, \n",
      "val acc = 0.841773418734988\n",
      "\n",
      "epoch 850 lr 0.09134176202636733\n",
      "train_loss 0.3561671997428559 train_acc 0.8442855395291422\n",
      "epoch 851 lr 0.09115926106411051\n",
      "train_loss 0.3561254412531046 train_acc 0.8443189021474405\n",
      "epoch 852 lr 0.09097712473901948\n",
      "train_loss 0.3560837025605832 train_acc 0.8443077812746744\n",
      "epoch 853 lr 0.09079535232254872\n",
      "train_loss 0.3560420442168357 train_acc 0.8443411438929728\n",
      "epoch 854 lr 0.0906139430876083\n",
      "train_loss 0.35600046421810105 train_acc 0.8443633856385049\n",
      "epoch 855 lr 0.09043289630856105\n",
      "train_loss 0.35595895673220806 train_acc 0.8444078691295693\n",
      "epoch 856 lr 0.09025221126121961\n",
      "train_loss 0.3559176071782343 train_acc 0.8443856273840371\n",
      "epoch 857 lr 0.09007188722284357\n",
      "train_loss 0.35587635707051407 train_acc 0.8444412317478676\n",
      "epoch 858 lr 0.0898919234721365\n",
      "train_loss 0.35583522997945966 train_acc 0.8444523526206337\n",
      "epoch 859 lr 0.08971231928924317\n",
      "train_loss 0.3557942384071795 train_acc 0.8444523526206337\n",
      "epoch 860 lr 0.08953307395574663\n",
      "train_loss 0.3557533584098934 train_acc 0.8444523526206337\n",
      "epoch 861 lr 0.08935418675466528\n",
      "train_loss 0.35571258549848556 train_acc 0.8444523526206337\n",
      "epoch 862 lr 0.08917565697045009\n",
      "train_loss 0.35567187904925446 train_acc 0.8444745943661659\n",
      "epoch 863 lr 0.08899748388898167\n",
      "train_loss 0.35563132807726394 train_acc 0.8445413196027625\n",
      "epoch 864 lr 0.08881966679756749\n",
      "train_loss 0.35559088626883606 train_acc 0.8445301987299964\n",
      "epoch 865 lr 0.08864220498493891\n",
      "train_loss 0.35555057962399755 train_acc 0.8445190778572302\n",
      "epoch 866 lr 0.08846509774124847\n",
      "train_loss 0.35551032144416633 train_acc 0.8445635613482946\n",
      "epoch 867 lr 0.08828834435806693\n",
      "train_loss 0.3554701909212183 train_acc 0.844608044839359\n",
      "epoch 868 lr 0.08811194412838055\n",
      "train_loss 0.35543015955108415 train_acc 0.8446191657121251\n",
      "epoch 869 lr 0.08793589634658817\n",
      "train_loss 0.35539025358862125 train_acc 0.8446747700759556\n",
      "epoch 870 lr 0.08776020030849843\n",
      "train_loss 0.3553506021876501 train_acc 0.8446414074576573\n",
      "epoch 871 lr 0.08758485531132694\n",
      "train_loss 0.3553111065286768 train_acc 0.8446414074576573\n",
      "epoch 872 lr 0.08740986065369347\n",
      "train_loss 0.35527168343802223 train_acc 0.8446747700759556\n",
      "epoch 873 lr 0.08723521563561916\n",
      "train_loss 0.3552324034999002 train_acc 0.844730374439786\n",
      "epoch 874 lr 0.0870609195585237\n",
      "train_loss 0.3551933089540245 train_acc 0.8447081326942538\n",
      "epoch 875 lr 0.08688697172522256\n",
      "train_loss 0.35515422361594956 train_acc 0.8446747700759556\n",
      "epoch 876 lr 0.08671337143992418\n",
      "train_loss 0.3551152961158465 train_acc 0.8447192535670199\n",
      "epoch 877 lr 0.08654011800822715\n",
      "train_loss 0.35507652919595317 train_acc 0.8447192535670199\n",
      "epoch 878 lr 0.08636721073711758\n",
      "train_loss 0.35503798294253924 train_acc 0.8447414953125522\n",
      "epoch 879 lr 0.08619464893496608\n",
      "train_loss 0.3549994884075501 train_acc 0.8447637370580843\n",
      "epoch 880 lr 0.08602243191152525\n",
      "train_loss 0.3549611514411832 train_acc 0.8447526161853183\n",
      "epoch 881 lr 0.08585055897792677\n",
      "train_loss 0.35492293809181913 train_acc 0.8447526161853183\n",
      "epoch 882 lr 0.08567902944667868\n",
      "train_loss 0.35488477127557183 train_acc 0.8447748579308504\n",
      "epoch 883 lr 0.08550784263166261\n",
      "train_loss 0.3548466450000038 train_acc 0.8447414953125522\n",
      "epoch 884 lr 0.08533699784813108\n",
      "train_loss 0.3548086276606781 train_acc 0.8447192535670199\n",
      "epoch 885 lr 0.08516649441270471\n",
      "train_loss 0.35477073173051227 train_acc 0.8447637370580843\n",
      "epoch 886 lr 0.08499633164336956\n",
      "train_loss 0.35473304299224173 train_acc 0.8447859788036165\n",
      "epoch 887 lr 0.0848265088594743\n",
      "train_loss 0.3546956272437233 train_acc 0.8447859788036165\n",
      "epoch 888 lr 0.08465702538172759\n",
      "train_loss 0.354658334453797 train_acc 0.8447859788036165\n",
      "epoch 889 lr 0.08448788053219529\n",
      "train_loss 0.35462108386115476 train_acc 0.8447970996763826\n",
      "epoch 890 lr 0.08431907363429776\n",
      "train_loss 0.35458396885386373 train_acc 0.844841583167447\n",
      "epoch 891 lr 0.08415060401280719\n",
      "train_loss 0.3545469683279715 train_acc 0.8448860666585114\n",
      "epoch 892 lr 0.08398247099384487\n",
      "train_loss 0.3545100578883224 train_acc 0.8448971875312774\n",
      "epoch 893 lr 0.0838146739048785\n",
      "train_loss 0.3544732870740141 train_acc 0.844952791895108\n",
      "epoch 894 lr 0.0836472120747195\n",
      "train_loss 0.3544367253797669 train_acc 0.8449305501495757\n",
      "epoch 895 lr 0.08348008483352035\n",
      "train_loss 0.35440030177291376 train_acc 0.8449972753861723\n",
      "epoch 896 lr 0.08331329151277182\n",
      "train_loss 0.3543640118997108 train_acc 0.8450306380044705\n",
      "epoch 897 lr 0.08314683144530044\n",
      "train_loss 0.35432782276218144 train_acc 0.8450417588772366\n",
      "epoch 898 lr 0.08298070396526569\n",
      "train_loss 0.3542916717473357 train_acc 0.8450973632410672\n",
      "epoch 899 lr 0.08281490840815746\n",
      "train_loss 0.35425557268723884 train_acc 0.8451752093504298\n",
      "\n",
      "val loss = 0.3545308173879436, \n",
      "val acc = 0.8430744595676541\n",
      "\n",
      "epoch 900 lr 0.08264944411079327\n",
      "train_loss 0.3542195913558768 train_acc 0.8451752093504298\n",
      "epoch 901 lr 0.08248431041131572\n",
      "train_loss 0.3541836352495593 train_acc 0.8451863302231959\n",
      "epoch 902 lr 0.0823195066491898\n",
      "train_loss 0.3541478069919961 train_acc 0.845197451095962\n",
      "epoch 903 lr 0.08215503216520023\n",
      "train_loss 0.3541121200660217 train_acc 0.845197451095962\n",
      "epoch 904 lr 0.08199088630144886\n",
      "train_loss 0.3540764656983713 train_acc 0.845197451095962\n",
      "epoch 905 lr 0.08182706840135202\n",
      "train_loss 0.35404082382880836 train_acc 0.8452308137142603\n",
      "epoch 906 lr 0.0816635778096379\n",
      "train_loss 0.3540053028218457 train_acc 0.8452530554597925\n",
      "epoch 907 lr 0.08150041387234389\n",
      "train_loss 0.3539698580281154 train_acc 0.8452975389508569\n",
      "epoch 908 lr 0.08133757593681404\n",
      "train_loss 0.3539344835405428 train_acc 0.8453309015691551\n",
      "epoch 909 lr 0.08117506335169639\n",
      "train_loss 0.35389913611064816 train_acc 0.8452864180780908\n",
      "epoch 910 lr 0.08101287546694037\n",
      "train_loss 0.35386378661788165 train_acc 0.8453309015691551\n",
      "epoch 911 lr 0.08085101163379425\n",
      "train_loss 0.3538285294962692 train_acc 0.845319780696389\n",
      "epoch 912 lr 0.08068947120480247\n",
      "train_loss 0.3537933705041482 train_acc 0.845319780696389\n",
      "epoch 913 lr 0.08052825353380308\n",
      "train_loss 0.35375835962109553 train_acc 0.845319780696389\n",
      "epoch 914 lr 0.08036735797592519\n",
      "train_loss 0.35372343438341214 train_acc 0.8452975389508569\n",
      "epoch 915 lr 0.08020678388758637\n",
      "train_loss 0.35368869201269215 train_acc 0.8453420224419212\n",
      "epoch 916 lr 0.08004653062649005\n",
      "train_loss 0.35365409939098397 train_acc 0.8453309015691551\n",
      "epoch 917 lr 0.07988659755162296\n",
      "train_loss 0.3536195693614358 train_acc 0.8453753850602195\n",
      "epoch 918 lr 0.07972698402325258\n",
      "train_loss 0.353585110247728 train_acc 0.8454087476785178\n",
      "epoch 919 lr 0.07956768940292461\n",
      "train_loss 0.35355068982105625 train_acc 0.84543098942405\n",
      "epoch 920 lr 0.07940871305346034\n",
      "train_loss 0.3535164775691287 train_acc 0.8454754729151144\n",
      "epoch 921 lr 0.07925005433895416\n",
      "train_loss 0.35348237413107136 train_acc 0.8454977146606466\n",
      "epoch 922 lr 0.07909171262477101\n",
      "train_loss 0.35344864921062136 train_acc 0.8455644398972432\n",
      "epoch 923 lr 0.0789336872775438\n",
      "train_loss 0.3534149815536445 train_acc 0.8455978025155414\n",
      "epoch 924 lr 0.07877597766517096\n",
      "train_loss 0.35338145753359695 train_acc 0.8456089233883075\n",
      "epoch 925 lr 0.0786185831568138\n",
      "train_loss 0.3533480866607688 train_acc 0.845664527752138\n",
      "epoch 926 lr 0.0784615031228941\n",
      "train_loss 0.35331492282645544 train_acc 0.8457312529887345\n",
      "epoch 927 lr 0.0783047369350915\n",
      "train_loss 0.353281912563293 train_acc 0.8457090112432024\n",
      "epoch 928 lr 0.07814828396634106\n",
      "train_loss 0.3532489639032261 train_acc 0.8457090112432024\n",
      "epoch 929 lr 0.07799214359083068\n",
      "train_loss 0.35321605711659343 train_acc 0.8457312529887345\n",
      "epoch 930 lr 0.07783631518399864\n",
      "train_loss 0.3531832759908917 train_acc 0.8457312529887345\n",
      "epoch 931 lr 0.07768079812253113\n",
      "train_loss 0.35315068687269807 train_acc 0.8456978903704363\n",
      "epoch 932 lr 0.07752559178435968\n",
      "train_loss 0.3531182087840619 train_acc 0.8457312529887345\n",
      "epoch 933 lr 0.07737069554865875\n",
      "train_loss 0.3530858183588422 train_acc 0.8457534947342668\n",
      "epoch 934 lr 0.07721610879584316\n",
      "train_loss 0.3530535309172194 train_acc 0.8457312529887345\n",
      "epoch 935 lr 0.0770618309075657\n",
      "train_loss 0.3530213952736233 train_acc 0.8457312529887345\n",
      "epoch 936 lr 0.07690786126671463\n",
      "train_loss 0.3529892937440874 train_acc 0.8457534947342668\n",
      "epoch 937 lr 0.07675419925741117\n",
      "train_loss 0.3529571646616271 train_acc 0.845786857352565\n",
      "epoch 938 lr 0.0766008442650071\n",
      "train_loss 0.3529250389612559 train_acc 0.8458090990980972\n",
      "epoch 939 lr 0.0764477956760822\n",
      "train_loss 0.3528930286797146 train_acc 0.8458424617163955\n",
      "epoch 940 lr 0.07629505287844195\n",
      "train_loss 0.3528612025311783 train_acc 0.8458090990980972\n",
      "epoch 941 lr 0.07614261526111492\n",
      "train_loss 0.35282943664275407 train_acc 0.8458090990980972\n",
      "epoch 942 lr 0.07599048221435047\n",
      "train_loss 0.3527977761523046 train_acc 0.8457979782253311\n",
      "epoch 943 lr 0.0758386531296162\n",
      "train_loss 0.3527661853858847 train_acc 0.8457979782253311\n",
      "epoch 944 lr 0.07568712739959556\n",
      "train_loss 0.3527345912267339 train_acc 0.8457423738615006\n",
      "epoch 945 lr 0.07553590441818543\n",
      "train_loss 0.35270302344129645 train_acc 0.8457534947342668\n",
      "epoch 946 lr 0.0753849835804937\n",
      "train_loss 0.35267159764285005 train_acc 0.8457090112432024\n",
      "epoch 947 lr 0.0752343642828368\n",
      "train_loss 0.35264032358730957 train_acc 0.8457312529887345\n",
      "epoch 948 lr 0.07508404592273733\n",
      "train_loss 0.3526091118054266 train_acc 0.8457090112432024\n",
      "epoch 949 lr 0.07493402789892167\n",
      "train_loss 0.35257791364355195 train_acc 0.8457201321159684\n",
      "\n",
      "val loss = 0.3530796010371913, \n",
      "val acc = 0.8433746997598078\n",
      "\n",
      "epoch 950 lr 0.07478430961131753\n",
      "train_loss 0.35254680227755336 train_acc 0.8457201321159684\n",
      "epoch 951 lr 0.07463489046105154\n",
      "train_loss 0.35251572346399584 train_acc 0.8457312529887345\n",
      "epoch 952 lr 0.07448576985044691\n",
      "train_loss 0.35248479048505704 train_acc 0.8457090112432024\n",
      "epoch 953 lr 0.07433694718302099\n",
      "train_loss 0.35245395652729045 train_acc 0.8457201321159684\n",
      "epoch 954 lr 0.07418842186348293\n",
      "train_loss 0.35242326882653535 train_acc 0.8457090112432024\n",
      "epoch 955 lr 0.07404019329773123\n",
      "train_loss 0.3523927975683727 train_acc 0.8457534947342668\n",
      "epoch 956 lr 0.07389226089285145\n",
      "train_loss 0.3523624456675623 train_acc 0.8457423738615006\n",
      "epoch 957 lr 0.07374462405711375\n",
      "train_loss 0.35233216989972527 train_acc 0.8457646156070329\n",
      "epoch 958 lr 0.07359728219997062\n",
      "train_loss 0.3523020100317852 train_acc 0.845786857352565\n",
      "epoch 959 lr 0.0734502347320544\n",
      "train_loss 0.3522719254600429 train_acc 0.845775736479799\n",
      "epoch 960 lr 0.07330348106517506\n",
      "train_loss 0.35224186637411137 train_acc 0.8457646156070329\n",
      "epoch 961 lr 0.07315702061231773\n",
      "train_loss 0.3522118508798454 train_acc 0.8458090990980972\n",
      "epoch 962 lr 0.07301085278764037\n",
      "train_loss 0.3521818178249002 train_acc 0.8458090990980972\n",
      "epoch 963 lr 0.07286497700647152\n",
      "train_loss 0.35215188192867225 train_acc 0.8458313408436294\n",
      "epoch 964 lr 0.07271939268530785\n",
      "train_loss 0.3521220923858171 train_acc 0.8458424617163955\n",
      "epoch 965 lr 0.07257409924181187\n",
      "train_loss 0.3520924205811728 train_acc 0.8458202199708633\n",
      "epoch 966 lr 0.07242909609480962\n",
      "train_loss 0.35206289643487465 train_acc 0.8458758243346938\n",
      "epoch 967 lr 0.07228438266428833\n",
      "train_loss 0.35203350272589884 train_acc 0.8458758243346938\n",
      "epoch 968 lr 0.07213995837139407\n",
      "train_loss 0.3520041652133406 train_acc 0.8458535825891615\n",
      "epoch 969 lr 0.07199582263842949\n",
      "train_loss 0.3519749104127901 train_acc 0.8458647034619277\n",
      "epoch 970 lr 0.07185197488885146\n",
      "train_loss 0.3519457650626537 train_acc 0.8458090990980972\n",
      "epoch 971 lr 0.07170841454726878\n",
      "train_loss 0.3519166372993058 train_acc 0.8458424617163955\n",
      "epoch 972 lr 0.07156514103943991\n",
      "train_loss 0.35188756167418195 train_acc 0.8458647034619277\n",
      "epoch 973 lr 0.07142215379227061\n",
      "train_loss 0.35185862053440853 train_acc 0.8458647034619277\n",
      "epoch 974 lr 0.07127945223381171\n",
      "train_loss 0.3518297659477993 train_acc 0.8459091869529921\n",
      "epoch 975 lr 0.0711370357932568\n",
      "train_loss 0.35180096391738436 train_acc 0.8459647913168226\n",
      "epoch 976 lr 0.07099490390093989\n",
      "train_loss 0.35177220782612906 train_acc 0.8459981539351208\n",
      "epoch 977 lr 0.07085305598833325\n",
      "train_loss 0.35174358732421446 train_acc 0.8460092748078869\n",
      "epoch 978 lr 0.07071149148804504\n",
      "train_loss 0.3517150312635966 train_acc 0.8460760000444835\n",
      "epoch 979 lr 0.07057020983381705\n",
      "train_loss 0.3516865911198977 train_acc 0.8460648791717174\n",
      "epoch 980 lr 0.0704292104605225\n",
      "train_loss 0.35165825933392475 train_acc 0.8460426374261852\n",
      "epoch 981 lr 0.0702884928041637\n",
      "train_loss 0.3516299707023596 train_acc 0.8460426374261852\n",
      "epoch 982 lr 0.07014805630186983\n",
      "train_loss 0.35160177119539815 train_acc 0.8460871209172496\n",
      "epoch 983 lr 0.0700079003918947\n",
      "train_loss 0.3515736266901937 train_acc 0.8460982417900157\n",
      "epoch 984 lr 0.06986802451361449\n",
      "train_loss 0.351545448181383 train_acc 0.8460982417900157\n",
      "epoch 985 lr 0.06972842810752547\n",
      "train_loss 0.3515172679748818 train_acc 0.8460982417900157\n",
      "epoch 986 lr 0.06958911061524187\n",
      "train_loss 0.35148910039708603 train_acc 0.8460982417900157\n",
      "epoch 987 lr 0.0694500714794935\n",
      "train_loss 0.3514609826964427 train_acc 0.8461204835355479\n",
      "epoch 988 lr 0.06931131014412366\n",
      "train_loss 0.3514329588169597 train_acc 0.8461316044083139\n",
      "epoch 989 lr 0.06917282605408681\n",
      "train_loss 0.3514049788136521 train_acc 0.8461316044083139\n",
      "epoch 990 lr 0.06903461865544641\n",
      "train_loss 0.35137705423989785 train_acc 0.8461204835355479\n",
      "epoch 991 lr 0.06889668739537268\n",
      "train_loss 0.35134920172050443 train_acc 0.8461538461538461\n",
      "epoch 992 lr 0.06875903172214039\n",
      "train_loss 0.3513213201884714 train_acc 0.8461316044083139\n",
      "epoch 993 lr 0.06862165108512666\n",
      "train_loss 0.3512934748659975 train_acc 0.8461538461538461\n",
      "epoch 994 lr 0.06848454493480877\n",
      "train_loss 0.3512657393938574 train_acc 0.8461649670266123\n",
      "epoch 995 lr 0.06834771272276194\n",
      "train_loss 0.3512380455161869 train_acc 0.8461204835355479\n",
      "epoch 996 lr 0.06821115390165712\n",
      "train_loss 0.3512104272877791 train_acc 0.8462094505176766\n",
      "epoch 997 lr 0.06807486792525885\n",
      "train_loss 0.3511828471180404 train_acc 0.8461983296449105\n",
      "epoch 998 lr 0.06793885424842305\n",
      "train_loss 0.35115527331352825 train_acc 0.8462316922632088\n",
      "epoch 999 lr 0.06780311232709485\n",
      "train_loss 0.35112780730035814 train_acc 0.8462205713904427\n",
      "\n",
      "val loss = 0.3519212947442862, \n",
      "val acc = 0.844275420336269\n",
      "\n",
      "epoch 1000 lr 0.06766764161830634\n",
      "train_loss 0.35110046065940226 train_acc 0.8461872087721445\n",
      "epoch 1001 lr 0.06753244158017455\n",
      "train_loss 0.35107310300422373 train_acc 0.8461649670266123\n",
      "epoch 1002 lr 0.0673975116718991\n",
      "train_loss 0.3510457917493144 train_acc 0.8461538461538461\n",
      "epoch 1003 lr 0.06726285135376021\n",
      "train_loss 0.35101846847674584 train_acc 0.8461649670266123\n",
      "epoch 1004 lr 0.06712846008711641\n",
      "train_loss 0.35099113869743975 train_acc 0.8461983296449105\n",
      "epoch 1005 lr 0.06699433733440249\n",
      "train_loss 0.35096383842055373 train_acc 0.8462428131359749\n",
      "epoch 1006 lr 0.0668604825591272\n",
      "train_loss 0.3509365958279208 train_acc 0.8462984174998054\n",
      "epoch 1007 lr 0.06672689522587133\n",
      "train_loss 0.3509095045855706 train_acc 0.8462984174998054\n",
      "epoch 1008 lr 0.0665935748002853\n",
      "train_loss 0.3508826013787033 train_acc 0.8462872966270393\n",
      "epoch 1009 lr 0.06646052074908729\n",
      "train_loss 0.3508557874478717 train_acc 0.8463429009908697\n",
      "epoch 1010 lr 0.06632773254006086\n",
      "train_loss 0.3508290278756044 train_acc 0.846365142736402\n",
      "epoch 1011 lr 0.06619520964205305\n",
      "train_loss 0.35080237060937625 train_acc 0.8463429009908697\n",
      "epoch 1012 lr 0.06606295152497205\n",
      "train_loss 0.35077588974009494 train_acc 0.8463317801181036\n",
      "epoch 1013 lr 0.06593095765978525\n",
      "train_loss 0.35074948089053753 train_acc 0.8463206592453376\n",
      "epoch 1014 lr 0.06579922751851698\n",
      "train_loss 0.35072311870429834 train_acc 0.8463429009908697\n",
      "epoch 1015 lr 0.06566776057424654\n",
      "train_loss 0.35069678479290883 train_acc 0.8463095383725715\n",
      "epoch 1016 lr 0.06553655630110594\n",
      "train_loss 0.3506704554705591 train_acc 0.8462872966270393\n",
      "epoch 1017 lr 0.06540561417427794\n",
      "train_loss 0.35064416230134016 train_acc 0.8462872966270393\n",
      "epoch 1018 lr 0.06527493366999382\n",
      "train_loss 0.3506178747445712 train_acc 0.8462984174998054\n",
      "epoch 1019 lr 0.06514451426553144\n",
      "train_loss 0.3505915908012795 train_acc 0.846265054881507\n",
      "epoch 1020 lr 0.06501435543921295\n",
      "train_loss 0.3505653935740912 train_acc 0.846265054881507\n",
      "epoch 1021 lr 0.06488445667040295\n",
      "train_loss 0.35053931897113133 train_acc 0.846265054881507\n",
      "epoch 1022 lr 0.06475481743950609\n",
      "train_loss 0.3505132626777972 train_acc 0.8462872966270393\n",
      "epoch 1023 lr 0.06462543722796536\n",
      "train_loss 0.3504873381211534 train_acc 0.8463206592453376\n",
      "epoch 1024 lr 0.0644963155182597\n",
      "train_loss 0.3504616163570111 train_acc 0.8463095383725715\n",
      "epoch 1025 lr 0.06436745179390212\n",
      "train_loss 0.35043613503447074 train_acc 0.8463206592453376\n",
      "epoch 1026 lr 0.06423884553943751\n",
      "train_loss 0.3504108141776677 train_acc 0.8463206592453376\n",
      "epoch 1027 lr 0.06411049624044075\n",
      "train_loss 0.3503856039162727 train_acc 0.8463095383725715\n",
      "epoch 1028 lr 0.0639824033835144\n",
      "train_loss 0.3503605260766932 train_acc 0.8463206592453376\n",
      "epoch 1029 lr 0.06385456645628691\n",
      "train_loss 0.35033558089116534 train_acc 0.8463095383725715\n",
      "epoch 1030 lr 0.06372698494741037\n",
      "train_loss 0.35031060032457917 train_acc 0.8463095383725715\n",
      "epoch 1031 lr 0.06359965834655862\n",
      "train_loss 0.35028569198572296 train_acc 0.8462872966270393\n",
      "epoch 1032 lr 0.06347258614442501\n",
      "train_loss 0.3502608970817546 train_acc 0.8462761757542732\n",
      "epoch 1033 lr 0.06334576783272065\n",
      "train_loss 0.3502361446866069 train_acc 0.8462316922632088\n",
      "epoch 1034 lr 0.06321920290417204\n",
      "train_loss 0.3502114483759893 train_acc 0.8462761757542732\n",
      "epoch 1035 lr 0.06309289085251939\n",
      "train_loss 0.35018679848002876 train_acc 0.846253934008741\n",
      "epoch 1036 lr 0.06296683117251423\n",
      "train_loss 0.3501622015696992 train_acc 0.8462872966270393\n",
      "epoch 1037 lr 0.06284102335991774\n",
      "train_loss 0.35013762310216223 train_acc 0.8463206592453376\n",
      "epoch 1038 lr 0.06271546691149846\n",
      "train_loss 0.3501131930785906 train_acc 0.8463206592453376\n",
      "epoch 1039 lr 0.06259016132503047\n",
      "train_loss 0.35008887834686586 train_acc 0.8463429009908697\n",
      "epoch 1040 lr 0.062465106099291214\n",
      "train_loss 0.35006465461483643 train_acc 0.8463317801181036\n",
      "epoch 1041 lr 0.06234030073405966\n",
      "train_loss 0.35004048819771655 train_acc 0.8463095383725715\n",
      "epoch 1042 lr 0.06221574473011414\n",
      "train_loss 0.35001641756668983 train_acc 0.8463095383725715\n",
      "epoch 1043 lr 0.06209143758923052\n",
      "train_loss 0.3499924136576042 train_acc 0.8463429009908697\n",
      "epoch 1044 lr 0.06196737881418002\n",
      "train_loss 0.34996843780550063 train_acc 0.8463429009908697\n",
      "epoch 1045 lr 0.06184356790872742\n",
      "train_loss 0.3499444559683631 train_acc 0.8463540218636358\n",
      "epoch 1046 lr 0.06172000437762889\n",
      "train_loss 0.3499205427234397 train_acc 0.846365142736402\n",
      "epoch 1047 lr 0.06159668772663019\n",
      "train_loss 0.3498966390142866 train_acc 0.8463540218636358\n",
      "epoch 1048 lr 0.061473617462464505\n",
      "train_loss 0.3498727928821773 train_acc 0.8463985053547003\n",
      "epoch 1049 lr 0.06135079309285066\n",
      "train_loss 0.34984900426004123 train_acc 0.8463873844819342\n",
      "\n",
      "val loss = 0.35086457712804525, \n",
      "val acc = 0.8449759807846277\n",
      "\n",
      "epoch 1050 lr 0.06122821412649095\n",
      "train_loss 0.34982526053233 train_acc 0.8463985053547003\n",
      "epoch 1051 lr 0.06110588007306942\n",
      "train_loss 0.34980156389702904 train_acc 0.8464096262274663\n",
      "epoch 1052 lr 0.06098379044324963\n",
      "train_loss 0.34977790209501797 train_acc 0.8464318679729985\n",
      "epoch 1053 lr 0.06086194474867295\n",
      "train_loss 0.34975435722101944 train_acc 0.8464096262274663\n",
      "epoch 1054 lr 0.06074034250195639\n",
      "train_loss 0.3497308447306431 train_acc 0.8464429888457646\n",
      "epoch 1055 lr 0.06061898321669085\n",
      "train_loss 0.3497073707416055 train_acc 0.8464652305912969\n",
      "epoch 1056 lr 0.06049786640743897\n",
      "train_loss 0.3496839883228904 train_acc 0.8464652305912969\n",
      "epoch 1057 lr 0.06037699158973341\n",
      "train_loss 0.3496606822021855 train_acc 0.8465097140823612\n",
      "epoch 1058 lr 0.06025635828007469\n",
      "train_loss 0.3496373800963593 train_acc 0.8464985932095951\n",
      "epoch 1059 lr 0.060135965995929457\n",
      "train_loss 0.3496141202768101 train_acc 0.8464763514640629\n",
      "epoch 1060 lr 0.06001581425572836\n",
      "train_loss 0.349590871360675 train_acc 0.846487472336829\n",
      "epoch 1061 lr 0.05989590257886434\n",
      "train_loss 0.3495676614255153 train_acc 0.8464985932095951\n",
      "epoch 1062 lr 0.05977623048569047\n",
      "train_loss 0.349544409367828 train_acc 0.8465319558278934\n",
      "epoch 1063 lr 0.05965679749751827\n",
      "train_loss 0.3495211208396384 train_acc 0.8465208349551273\n",
      "epoch 1064 lr 0.05953760313661557\n",
      "train_loss 0.34949787445771496 train_acc 0.8465541975734255\n",
      "epoch 1065 lr 0.05941864692620483\n",
      "train_loss 0.3494747340922677 train_acc 0.8465541975734255\n",
      "epoch 1066 lr 0.05929992839046099\n",
      "train_loss 0.34945173624141634 train_acc 0.8465430767006594\n",
      "epoch 1067 lr 0.059181447054509805\n",
      "train_loss 0.3494288785468065 train_acc 0.8465430767006594\n",
      "epoch 1068 lr 0.05906320244442573\n",
      "train_loss 0.3494061728211874 train_acc 0.8465541975734255\n",
      "epoch 1069 lr 0.0589451940872302\n",
      "train_loss 0.34938351736541995 train_acc 0.8465764393189578\n",
      "epoch 1070 lr 0.05882742151088959\n",
      "train_loss 0.34936086898219937 train_acc 0.8465875601917239\n",
      "epoch 1071 lr 0.05870988424431349\n",
      "train_loss 0.34933825296820464 train_acc 0.846609801937256\n",
      "epoch 1072 lr 0.058592581817352614\n",
      "train_loss 0.34931570430093584 train_acc 0.84659868106449\n",
      "epoch 1073 lr 0.05847551376079716\n",
      "train_loss 0.34929324366743225 train_acc 0.8466209228100221\n",
      "epoch 1074 lr 0.05835867960637469\n",
      "train_loss 0.3492708886928492 train_acc 0.8466209228100221\n",
      "epoch 1075 lr 0.05824207888674848\n",
      "train_loss 0.3492485302257243 train_acc 0.8466431645555543\n",
      "epoch 1076 lr 0.05812571113551546\n",
      "train_loss 0.34922615849976046 train_acc 0.8466320436827882\n",
      "epoch 1077 lr 0.05800957588720449\n",
      "train_loss 0.3492038327822287 train_acc 0.8466320436827882\n",
      "epoch 1078 lr 0.0578936726772744\n",
      "train_loss 0.349181518065116 train_acc 0.8466987689193848\n",
      "epoch 1079 lr 0.05777800104211224\n",
      "train_loss 0.3491592359858604 train_acc 0.8467432524104491\n",
      "epoch 1080 lr 0.05766256051903125\n",
      "train_loss 0.3491370040486979 train_acc 0.8467654941559813\n",
      "epoch 1081 lr 0.05754735064626926\n",
      "train_loss 0.3491149477171582 train_acc 0.8467766150287475\n",
      "epoch 1082 lr 0.05743237096298654\n",
      "train_loss 0.3490929670921063 train_acc 0.8467654941559813\n",
      "epoch 1083 lr 0.05731762100926429\n",
      "train_loss 0.34907106924127523 train_acc 0.846721010664917\n",
      "epoch 1084 lr 0.05720310032610247\n",
      "train_loss 0.34904928143618097 train_acc 0.8466987689193848\n",
      "epoch 1085 lr 0.05708880845541825\n",
      "train_loss 0.3490275930539002 train_acc 0.846721010664917\n",
      "epoch 1086 lr 0.05697474494004394\n",
      "train_loss 0.34900596592101096 train_acc 0.846721010664917\n",
      "epoch 1087 lr 0.05686090932372539\n",
      "train_loss 0.3489843449451298 train_acc 0.8466987689193848\n",
      "epoch 1088 lr 0.056747301151119915\n",
      "train_loss 0.3489627558427931 train_acc 0.8467321315376831\n",
      "epoch 1089 lr 0.05663391996779474\n",
      "train_loss 0.3489411903448804 train_acc 0.8467543732832152\n",
      "epoch 1090 lr 0.056520765320224924\n",
      "train_loss 0.3489197003158481 train_acc 0.8467543732832152\n",
      "epoch 1091 lr 0.05640783675579177\n",
      "train_loss 0.348898182181624 train_acc 0.8467432524104491\n",
      "epoch 1092 lr 0.05629513382278083\n",
      "train_loss 0.348876631436928 train_acc 0.8467321315376831\n",
      "epoch 1093 lr 0.05618265607038026\n",
      "train_loss 0.3488551135726088 train_acc 0.8466987689193848\n",
      "epoch 1094 lr 0.05607040304867886\n",
      "train_loss 0.34883363557628483 train_acc 0.8466876480466187\n",
      "epoch 1095 lr 0.05595837430866444\n",
      "train_loss 0.34881222471634027 train_acc 0.8466987689193848\n",
      "epoch 1096 lr 0.05584656940222184\n",
      "train_loss 0.34879085647455266 train_acc 0.8467321315376831\n",
      "epoch 1097 lr 0.05573498788213133\n",
      "train_loss 0.34876956994774155 train_acc 0.8467432524104491\n",
      "epoch 1098 lr 0.05562362930206665\n",
      "train_loss 0.348748349259767 train_acc 0.8467432524104491\n",
      "epoch 1099 lr 0.055512493216593364\n",
      "train_loss 0.34872723795512967 train_acc 0.8467543732832152\n",
      "\n",
      "val loss = 0.3499837723537061, \n",
      "val acc = 0.8459767814251401\n",
      "\n",
      "epoch 1100 lr 0.05540157918116693\n",
      "train_loss 0.3487061716710639 train_acc 0.8468210985198118\n",
      "epoch 1101 lr 0.05529088675213112\n",
      "train_loss 0.34868521923604173 train_acc 0.8468878237564084\n",
      "epoch 1102 lr 0.05518041548671601\n",
      "train_loss 0.34866440046616237 train_acc 0.8468878237564084\n",
      "epoch 1103 lr 0.05507016494303645\n",
      "train_loss 0.3486437230272845 train_acc 0.8469211863747067\n",
      "epoch 1104 lr 0.05496013468009006\n",
      "train_loss 0.34862305662516097 train_acc 0.8469434281202389\n",
      "epoch 1105 lr 0.054850324257755705\n",
      "train_loss 0.34860244863341905 train_acc 0.8469545489930049\n",
      "epoch 1106 lr 0.05474073323679148\n",
      "train_loss 0.34858197051508627 train_acc 0.8469434281202389\n",
      "epoch 1107 lr 0.054631361178833215\n",
      "train_loss 0.3485615001886912 train_acc 0.846965669865771\n",
      "epoch 1108 lr 0.054522207646392484\n",
      "train_loss 0.34854101410691635 train_acc 0.8469434281202389\n",
      "epoch 1109 lr 0.054413272202855065\n",
      "train_loss 0.3485205532324447 train_acc 0.8469434281202389\n",
      "epoch 1110 lr 0.05430455441247898\n",
      "train_loss 0.3485001140037442 train_acc 0.8469323072474728\n",
      "epoch 1111 lr 0.05419605384039297\n",
      "train_loss 0.3484797328803187 train_acc 0.8469545489930049\n",
      "epoch 1112 lr 0.05408777005259457\n",
      "train_loss 0.34845937353113343 train_acc 0.8469323072474728\n",
      "epoch 1113 lr 0.05397970261594851\n",
      "train_loss 0.34843905296924016 train_acc 0.8469323072474728\n",
      "epoch 1114 lr 0.05387185109818487\n",
      "train_loss 0.34841875268129463 train_acc 0.8469434281202389\n",
      "epoch 1115 lr 0.053764215067897476\n",
      "train_loss 0.348398512532009 train_acc 0.846965669865771\n",
      "epoch 1116 lr 0.053656794094542014\n",
      "train_loss 0.34837832509176053 train_acc 0.8469545489930049\n",
      "epoch 1117 lr 0.05354958774843449\n",
      "train_loss 0.34835812665545174 train_acc 0.846965669865771\n",
      "epoch 1118 lr 0.05344259560074934\n",
      "train_loss 0.34833794717662914 train_acc 0.8469545489930049\n",
      "epoch 1119 lr 0.05333581722351788\n",
      "train_loss 0.3483178357675225 train_acc 0.8469211863747067\n",
      "epoch 1120 lr 0.053229252189626396\n",
      "train_loss 0.34829782351060956 train_acc 0.8469323072474728\n",
      "epoch 1121 lr 0.05312290007281467\n",
      "train_loss 0.34827780737074443 train_acc 0.8469434281202389\n",
      "epoch 1122 lr 0.05301676044767405\n",
      "train_loss 0.3482577563777453 train_acc 0.8469767907385372\n",
      "epoch 1123 lr 0.05291083288964592\n",
      "train_loss 0.3482377009636807 train_acc 0.8469990324840694\n",
      "epoch 1124 lr 0.052805116975019877\n",
      "train_loss 0.3482177194556761 train_acc 0.8470212742296015\n",
      "epoch 1125 lr 0.052699612280932166\n",
      "train_loss 0.3481978064430895 train_acc 0.8470435159751337\n",
      "epoch 1126 lr 0.052594318385363846\n",
      "train_loss 0.3481778938517809 train_acc 0.8470546368478998\n",
      "epoch 1127 lr 0.05248923486713917\n",
      "train_loss 0.34815800025058896 train_acc 0.847065757720666\n",
      "epoch 1128 lr 0.05238436130592397\n",
      "train_loss 0.3481380487084006 train_acc 0.8470546368478998\n",
      "epoch 1129 lr 0.052279697282223814\n",
      "train_loss 0.348118069513513 train_acc 0.8470435159751337\n",
      "epoch 1130 lr 0.05217524237738252\n",
      "train_loss 0.348098095701384 train_acc 0.847065757720666\n",
      "epoch 1131 lr 0.052070996173580276\n",
      "train_loss 0.3480781412416509 train_acc 0.8470768785934321\n",
      "epoch 1132 lr 0.05196695825383218\n",
      "train_loss 0.3480582115504768 train_acc 0.847065757720666\n",
      "epoch 1133 lr 0.051863128201986367\n",
      "train_loss 0.34803832948998337 train_acc 0.8470879994661981\n",
      "epoch 1134 lr 0.05175950560272253\n",
      "train_loss 0.34801847279561954 train_acc 0.8471324829572625\n",
      "epoch 1135 lr 0.0516560900415501\n",
      "train_loss 0.34799867440045773 train_acc 0.8471324829572625\n",
      "epoch 1136 lr 0.05155288110480673\n",
      "train_loss 0.3479789598976209 train_acc 0.8471658455755607\n",
      "epoch 1137 lr 0.0514498783796565\n",
      "train_loss 0.347959281580028 train_acc 0.8471436038300286\n",
      "epoch 1138 lr 0.0513470814540884\n",
      "train_loss 0.3479396563567716 train_acc 0.8471658455755607\n",
      "epoch 1139 lr 0.05124448991691456\n",
      "train_loss 0.3479200286145389 train_acc 0.847188087321093\n",
      "epoch 1140 lr 0.05114210335776874\n",
      "train_loss 0.34790042331430804 train_acc 0.847188087321093\n",
      "epoch 1141 lr 0.051039921367104515\n",
      "train_loss 0.34788092073104415 train_acc 0.8472214499393912\n",
      "epoch 1142 lr 0.05093794353619384\n",
      "train_loss 0.34786148827339985 train_acc 0.8472436916849234\n",
      "epoch 1143 lr 0.0508361694571252\n",
      "train_loss 0.34784214825921594 train_acc 0.8472436916849234\n",
      "epoch 1144 lr 0.05073459872280219\n",
      "train_loss 0.34782284004025915 train_acc 0.8472659334304556\n",
      "epoch 1145 lr 0.0506332309269417\n",
      "train_loss 0.3478035828635931 train_acc 0.8472992960487539\n",
      "epoch 1146 lr 0.05053206566407245\n",
      "train_loss 0.3477844594883203 train_acc 0.8473215377942861\n",
      "epoch 1147 lr 0.05043110252953321\n",
      "train_loss 0.3477654219159929 train_acc 0.8473437795398183\n",
      "epoch 1148 lr 0.05033034111947135\n",
      "train_loss 0.3477464081377458 train_acc 0.8473326586670522\n",
      "epoch 1149 lr 0.05022978103084105\n",
      "train_loss 0.34772739663710944 train_acc 0.8473660212853504\n",
      "\n",
      "val loss = 0.3492289492283602, \n",
      "val acc = 0.8457766212970377\n",
      "\n",
      "epoch 1150 lr 0.050129421861401874\n",
      "train_loss 0.3477084005160208 train_acc 0.8473660212853504\n",
      "epoch 1151 lr 0.050029263209716957\n",
      "train_loss 0.3476894339382429 train_acc 0.8473882630308827\n",
      "epoch 1152 lr 0.04992930467515161\n",
      "train_loss 0.3476704464592074 train_acc 0.8473882630308827\n",
      "epoch 1153 lr 0.04982954585787151\n",
      "train_loss 0.34765149078614854 train_acc 0.8473771421581165\n",
      "epoch 1154 lr 0.04972998635884131\n",
      "train_loss 0.34763259658483425 train_acc 0.8473549004125844\n",
      "epoch 1155 lr 0.04963062577982282\n",
      "train_loss 0.3476137064572696 train_acc 0.8473771421581165\n",
      "epoch 1156 lr 0.04953146372337366\n",
      "train_loss 0.34759488245314013 train_acc 0.8473882630308827\n",
      "epoch 1157 lr 0.0494324997928454\n",
      "train_loss 0.3475760630374651 train_acc 0.847432746521947\n",
      "epoch 1158 lr 0.049333733592382245\n",
      "train_loss 0.3475572672682715 train_acc 0.8474105047764149\n",
      "epoch 1159 lr 0.049235164726919224\n",
      "train_loss 0.34753845603505995 train_acc 0.8473771421581165\n",
      "epoch 1160 lr 0.04913679280218077\n",
      "train_loss 0.3475196592094349 train_acc 0.8474438673947131\n",
      "epoch 1161 lr 0.04903861742467903\n",
      "train_loss 0.34750082997282344 train_acc 0.8474438673947131\n",
      "epoch 1162 lr 0.048940638201712384\n",
      "train_loss 0.3474820331948576 train_acc 0.8474883508857776\n",
      "epoch 1163 lr 0.04884285474136378\n",
      "train_loss 0.34746329194506864 train_acc 0.8474772300130115\n",
      "epoch 1164 lr 0.048745266652499286\n",
      "train_loss 0.3474445304265516 train_acc 0.8474661091402453\n",
      "epoch 1165 lr 0.04864787354476638\n",
      "train_loss 0.34742583234227964 train_acc 0.8474549882674792\n",
      "epoch 1166 lr 0.04855067502859253\n",
      "train_loss 0.34740718639323437 train_acc 0.8474438673947131\n",
      "epoch 1167 lr 0.048453670715183514\n",
      "train_loss 0.3473885834512209 train_acc 0.8474549882674792\n",
      "epoch 1168 lr 0.04835686021652198\n",
      "train_loss 0.3473700293971774 train_acc 0.8474549882674792\n",
      "epoch 1169 lr 0.048260243145365776\n",
      "train_loss 0.3473514448471453 train_acc 0.8474772300130115\n",
      "epoch 1170 lr 0.04816381911524652\n",
      "train_loss 0.34733285686218557 train_acc 0.8474772300130115\n",
      "epoch 1171 lr 0.04806758774046792\n",
      "train_loss 0.34731429726621155 train_acc 0.8474883508857776\n",
      "epoch 1172 lr 0.04797154863610439\n",
      "train_loss 0.34729580352617817 train_acc 0.8475105926313097\n",
      "epoch 1173 lr 0.04787570141799934\n",
      "train_loss 0.34727730101436777 train_acc 0.8474883508857776\n",
      "epoch 1174 lr 0.047780045702763826\n",
      "train_loss 0.3472588807084384 train_acc 0.8474549882674792\n",
      "epoch 1175 lr 0.04768458110777481\n",
      "train_loss 0.3472405074168571 train_acc 0.8474883508857776\n",
      "epoch 1176 lr 0.047589307251173815\n",
      "train_loss 0.3472221043884315 train_acc 0.8474994717585436\n",
      "epoch 1177 lr 0.04749422375186527\n",
      "train_loss 0.3472037026927526 train_acc 0.8474994717585436\n",
      "epoch 1178 lr 0.04739933022951507\n",
      "train_loss 0.3471852309986538 train_acc 0.8474883508857776\n",
      "epoch 1179 lr 0.047304626304548965\n",
      "train_loss 0.34716683828024947 train_acc 0.8474661091402453\n",
      "epoch 1180 lr 0.04721011159815118\n",
      "train_loss 0.34714851613459036 train_acc 0.8475105926313097\n",
      "epoch 1181 lr 0.04711578573226271\n",
      "train_loss 0.34713021819432305 train_acc 0.8474772300130115\n",
      "epoch 1182 lr 0.04702164832958001\n",
      "train_loss 0.3471119096152041 train_acc 0.8474549882674792\n",
      "epoch 1183 lr 0.0469276990135533\n",
      "train_loss 0.3470936362714186 train_acc 0.847421625649181\n",
      "epoch 1184 lr 0.046833937408385234\n",
      "train_loss 0.34707550452936914 train_acc 0.8474105047764149\n",
      "epoch 1185 lr 0.04674036313902923\n",
      "train_loss 0.3470575234647392 train_acc 0.8473326586670522\n",
      "epoch 1186 lr 0.046646975831188126\n",
      "train_loss 0.3470396405143336 train_acc 0.8473326586670522\n",
      "epoch 1187 lr 0.04655377511131252\n",
      "train_loss 0.347021772781841 train_acc 0.8473326586670522\n",
      "epoch 1188 lr 0.04646076060659945\n",
      "train_loss 0.3470039502176612 train_acc 0.8472992960487539\n",
      "epoch 1189 lr 0.04636793194499073\n",
      "train_loss 0.3469862190901632 train_acc 0.8473326586670522\n",
      "epoch 1190 lr 0.046275288755171645\n",
      "train_loss 0.34696863384330495 train_acc 0.8473437795398183\n",
      "epoch 1191 lr 0.04618283066656925\n",
      "train_loss 0.346951070164387 train_acc 0.847421625649181\n",
      "epoch 1192 lr 0.04609055730935113\n",
      "train_loss 0.3469335846639059 train_acc 0.8474105047764149\n",
      "epoch 1193 lr 0.045998468314423675\n",
      "train_loss 0.3469161724698547 train_acc 0.8474105047764149\n",
      "epoch 1194 lr 0.04590656331343083\n",
      "train_loss 0.34689878421550485 train_acc 0.8474105047764149\n",
      "epoch 1195 lr 0.045814841938752425\n",
      "train_loss 0.34688141141540957 train_acc 0.8473882630308827\n",
      "epoch 1196 lr 0.045723303823502884\n",
      "train_loss 0.34686408231462396 train_acc 0.8473993839036488\n",
      "epoch 1197 lr 0.045631948601529575\n",
      "train_loss 0.34684681017529917 train_acc 0.8474105047764149\n",
      "epoch 1198 lr 0.04554077590741154\n",
      "train_loss 0.3468295618143649 train_acc 0.8474549882674792\n",
      "epoch 1199 lr 0.04544978537645784\n",
      "train_loss 0.3468124057017497 train_acc 0.8474661091402453\n",
      "\n",
      "val loss = 0.34854877225583747, \n",
      "val acc = 0.847177742193755\n",
      "\n",
      "epoch 1200 lr 0.04535897664470626\n",
      "train_loss 0.3467952668346059 train_acc 0.8474661091402453\n",
      "epoch 1201 lr 0.04526834934892172\n",
      "train_loss 0.34677808591255405 train_acc 0.8474772300130115\n",
      "epoch 1202 lr 0.04517790312659495\n",
      "train_loss 0.34676092256783153 train_acc 0.8474661091402453\n",
      "epoch 1203 lr 0.04508763761594091\n",
      "train_loss 0.34674380434928864 train_acc 0.8474661091402453\n",
      "epoch 1204 lr 0.04499755245589746\n",
      "train_loss 0.3467267302703442 train_acc 0.8474549882674792\n",
      "epoch 1205 lr 0.04490764728612382\n",
      "train_loss 0.3467096681919296 train_acc 0.8474438673947131\n",
      "epoch 1206 lr 0.044817921746999216\n",
      "train_loss 0.34669263803849776 train_acc 0.8474883508857776\n",
      "epoch 1207 lr 0.044728375479621336\n",
      "train_loss 0.3466755782559779 train_acc 0.8475105926313097\n",
      "epoch 1208 lr 0.04463900812580504\n",
      "train_loss 0.34665858059625826 train_acc 0.8475328343768419\n",
      "epoch 1209 lr 0.04454981932808074\n",
      "train_loss 0.34664166386991563 train_acc 0.8475550761223741\n",
      "epoch 1210 lr 0.04446080872969317\n",
      "train_loss 0.34662480324823514 train_acc 0.8475773178679062\n",
      "epoch 1211 lr 0.044371975974599784\n",
      "train_loss 0.34660796356791573 train_acc 0.8475884387406724\n",
      "epoch 1212 lr 0.04428332070746948\n",
      "train_loss 0.3465911414568639 train_acc 0.8475995596134385\n",
      "epoch 1213 lr 0.04419484257368103\n",
      "train_loss 0.3465743579207192 train_acc 0.8476440431045028\n",
      "epoch 1214 lr 0.04410654121932182\n",
      "train_loss 0.3465576362215047 train_acc 0.8476774057228011\n",
      "epoch 1215 lr 0.044018416291186274\n",
      "train_loss 0.3465409487697127 train_acc 0.8476996474683333\n",
      "epoch 1216 lr 0.0439304674367746\n",
      "train_loss 0.3465243742847217 train_acc 0.8476774057228011\n",
      "epoch 1217 lr 0.04384269430429123\n",
      "train_loss 0.3465079293548122 train_acc 0.8477330100866316\n",
      "epoch 1218 lr 0.04375509654264356\n",
      "train_loss 0.34649157606223374 train_acc 0.8477552518321638\n",
      "epoch 1219 lr 0.043667673801440376\n",
      "train_loss 0.34647527200490014 train_acc 0.8477441309593977\n",
      "epoch 1220 lr 0.04358042573099065\n",
      "train_loss 0.3464590041679785 train_acc 0.8477330100866316\n",
      "epoch 1221 lr 0.04349335198230193\n",
      "train_loss 0.3464427323348317 train_acc 0.8477552518321638\n",
      "epoch 1222 lr 0.043406452207079144\n",
      "train_loss 0.34642640528145363 train_acc 0.8477441309593977\n",
      "epoch 1223 lr 0.043319726057723044\n",
      "train_loss 0.3464100477700938 train_acc 0.8477552518321638\n",
      "epoch 1224 lr 0.04323317318732896\n",
      "train_loss 0.34639370734877695 train_acc 0.8477330100866316\n",
      "epoch 1225 lr 0.04314679324968525\n",
      "train_loss 0.3463774533995565 train_acc 0.8477107683410994\n",
      "epoch 1226 lr 0.04306058589927208\n",
      "train_loss 0.3463612568753415 train_acc 0.8476551639772689\n",
      "epoch 1227 lr 0.042974550791259905\n",
      "train_loss 0.3463450734528593 train_acc 0.8476440431045028\n",
      "epoch 1228 lr 0.04288868758150821\n",
      "train_loss 0.3463289502553325 train_acc 0.847666284850035\n",
      "epoch 1229 lr 0.042802995926564016\n",
      "train_loss 0.3463128716393407 train_acc 0.8476885265955673\n",
      "epoch 1230 lr 0.04271747548366061\n",
      "train_loss 0.346296896015142 train_acc 0.8476996474683333\n",
      "epoch 1231 lr 0.042632125910716086\n",
      "train_loss 0.3462809398463059 train_acc 0.8477330100866316\n",
      "epoch 1232 lr 0.04254694686633206\n",
      "train_loss 0.3462650170947579 train_acc 0.8477330100866316\n",
      "epoch 1233 lr 0.042461938009792206\n",
      "train_loss 0.34624915443055454 train_acc 0.8477552518321638\n",
      "epoch 1234 lr 0.04237709900106103\n",
      "train_loss 0.3462333344212068 train_acc 0.8477774935776959\n",
      "epoch 1235 lr 0.042292429500782346\n",
      "train_loss 0.34621749501943094 train_acc 0.847788614450462\n",
      "epoch 1236 lr 0.04220792917027807\n",
      "train_loss 0.3462016495553538 train_acc 0.8477774935776959\n",
      "epoch 1237 lr 0.042123597671546734\n",
      "train_loss 0.346185837902302 train_acc 0.8477663727049299\n",
      "epoch 1238 lr 0.04203943466726227\n",
      "train_loss 0.3461700387326079 train_acc 0.8477441309593977\n",
      "epoch 1239 lr 0.0419554398207725\n",
      "train_loss 0.3461542049772798 train_acc 0.8477441309593977\n",
      "epoch 1240 lr 0.04187161279609798\n",
      "train_loss 0.34613841751780794 train_acc 0.8477330100866316\n",
      "epoch 1241 lr 0.04178795325793045\n",
      "train_loss 0.3461226616646143 train_acc 0.8477441309593977\n",
      "epoch 1242 lr 0.041704460871631696\n",
      "train_loss 0.34610690077874434 train_acc 0.8477774935776959\n",
      "epoch 1243 lr 0.041621135303232006\n",
      "train_loss 0.34609118077512097 train_acc 0.847788614450462\n",
      "epoch 1244 lr 0.04153797621942905\n",
      "train_loss 0.3460755419492849 train_acc 0.8478108561959943\n",
      "epoch 1245 lr 0.04145498328758633\n",
      "train_loss 0.3460599490906392 train_acc 0.8478219770687604\n",
      "epoch 1246 lr 0.04137215617573206\n",
      "train_loss 0.3460443717506679 train_acc 0.8477997353232282\n",
      "epoch 1247 lr 0.041289494552557635\n",
      "train_loss 0.34602887829258966 train_acc 0.8478330979415265\n",
      "epoch 1248 lr 0.041206998087416485\n",
      "train_loss 0.3460134360557542 train_acc 0.8478442188142925\n",
      "epoch 1249 lr 0.04112466645032262\n",
      "train_loss 0.34599802877851016 train_acc 0.8478442188142925\n",
      "\n",
      "val loss = 0.3479442369868268, \n",
      "val acc = 0.8474779823859088\n",
      "\n",
      "epoch 1250 lr 0.0410424993119494\n",
      "train_loss 0.3459826445893817 train_acc 0.8478330979415265\n",
      "epoch 1251 lr 0.040960496343628146\n",
      "train_loss 0.3459672216011816 train_acc 0.8478330979415265\n",
      "epoch 1252 lr 0.040878657217346875\n",
      "train_loss 0.3459517516218534 train_acc 0.8478330979415265\n",
      "epoch 1253 lr 0.04079698160574899\n",
      "train_loss 0.3459363391583494 train_acc 0.8478108561959943\n",
      "epoch 1254 lr 0.040715469182131904\n",
      "train_loss 0.3459210051282627 train_acc 0.8478553396870586\n",
      "epoch 1255 lr 0.04063411962044585\n",
      "train_loss 0.34590577407899836 train_acc 0.8478775814325908\n",
      "epoch 1256 lr 0.04055293259529245\n",
      "train_loss 0.34589059652165505 train_acc 0.8478553396870586\n",
      "epoch 1257 lr 0.040471907781923507\n",
      "train_loss 0.3458754597178431 train_acc 0.8478775814325908\n",
      "epoch 1258 lr 0.04039104485623964\n",
      "train_loss 0.34586033671888433 train_acc 0.847888702305357\n",
      "epoch 1259 lr 0.040310343494789076\n",
      "train_loss 0.34584520317040474 train_acc 0.8478998231781231\n",
      "epoch 1260 lr 0.04022980337476621\n",
      "train_loss 0.34583007426809503 train_acc 0.847888702305357\n",
      "epoch 1261 lr 0.04014942417401051\n",
      "train_loss 0.34581496174566756 train_acc 0.8478998231781231\n",
      "epoch 1262 lr 0.04006920557100502\n",
      "train_loss 0.3457998707126825 train_acc 0.847888702305357\n",
      "epoch 1263 lr 0.039989147244875255\n",
      "train_loss 0.345784848053667 train_acc 0.8479109440508891\n",
      "epoch 1264 lr 0.03990924887538777\n",
      "train_loss 0.34576982894677416 train_acc 0.8479220649236552\n",
      "epoch 1265 lr 0.03982951014294902\n",
      "train_loss 0.3457548188954337 train_acc 0.8479220649236552\n",
      "epoch 1266 lr 0.03974993072860393\n",
      "train_loss 0.3457398158120762 train_acc 0.8479331857964213\n",
      "epoch 1267 lr 0.03967051031403477\n",
      "train_loss 0.34572485270893233 train_acc 0.8479443066691874\n",
      "epoch 1268 lr 0.03959124858155974\n",
      "train_loss 0.3457099201998924 train_acc 0.8479220649236552\n",
      "epoch 1269 lr 0.03951214521413184\n",
      "train_loss 0.34569496796994287 train_acc 0.847888702305357\n",
      "epoch 1270 lr 0.03943319989533747\n",
      "train_loss 0.3456800362807876 train_acc 0.8479109440508891\n",
      "epoch 1271 lr 0.03935441230939527\n",
      "train_loss 0.3456651570027032 train_acc 0.8479331857964213\n",
      "epoch 1272 lr 0.03927578214115477\n",
      "train_loss 0.34565030818004383 train_acc 0.8479220649236552\n",
      "epoch 1273 lr 0.03919730907609521\n",
      "train_loss 0.34563546837755205 train_acc 0.8479554275419535\n",
      "epoch 1274 lr 0.03911899280032421\n",
      "train_loss 0.3456206160381723 train_acc 0.8479776692874856\n",
      "epoch 1275 lr 0.039040833000576584\n",
      "train_loss 0.3456057724831179 train_acc 0.8479665484147196\n",
      "epoch 1276 lr 0.03896282936421299\n",
      "train_loss 0.3455909622488682 train_acc 0.8479554275419535\n",
      "epoch 1277 lr 0.03888498157921883\n",
      "train_loss 0.3455762133872361 train_acc 0.8479776692874856\n",
      "epoch 1278 lr 0.03880728933420281\n",
      "train_loss 0.3455615186435424 train_acc 0.8480221527785501\n",
      "epoch 1279 lr 0.03872975231839589\n",
      "train_loss 0.34554680372169233 train_acc 0.848011031905784\n",
      "epoch 1280 lr 0.03865237022164987\n",
      "train_loss 0.34553215077590527 train_acc 0.848011031905784\n",
      "epoch 1281 lr 0.03857514273443629\n",
      "train_loss 0.3455175874974598 train_acc 0.8480221527785501\n",
      "epoch 1282 lr 0.03849806954784506\n",
      "train_loss 0.34550300608222884 train_acc 0.848011031905784\n",
      "epoch 1283 lr 0.038421150353583365\n",
      "train_loss 0.3454884406130817 train_acc 0.848011031905784\n",
      "epoch 1284 lr 0.0383443848439743\n",
      "train_loss 0.345473912914189 train_acc 0.8480332736513162\n",
      "epoch 1285 lr 0.03826777271195576\n",
      "train_loss 0.34545934538567225 train_acc 0.8480332736513162\n",
      "epoch 1286 lr 0.03819131365107906\n",
      "train_loss 0.3454448424502929 train_acc 0.8480666362696144\n",
      "epoch 1287 lr 0.038115007355507914\n",
      "train_loss 0.34543041981512673 train_acc 0.8480443945240822\n",
      "epoch 1288 lr 0.03803885352001699\n",
      "train_loss 0.34541602230386464 train_acc 0.8480555153968483\n",
      "epoch 1289 lr 0.03796285183999089\n",
      "train_loss 0.3454016648044393 train_acc 0.8480777571423805\n",
      "epoch 1290 lr 0.03788700201142274\n",
      "train_loss 0.34538732869003247 train_acc 0.8480777571423805\n",
      "epoch 1291 lr 0.03781130373091317\n",
      "train_loss 0.34537305050218225 train_acc 0.8480777571423805\n",
      "epoch 1292 lr 0.03773575669566892\n",
      "train_loss 0.3453588030456711 train_acc 0.8480999988879128\n",
      "epoch 1293 lr 0.03766036060350179\n",
      "train_loss 0.34534456049523327 train_acc 0.8481222406334449\n",
      "epoch 1294 lr 0.03758511515282727\n",
      "train_loss 0.3453303464519031 train_acc 0.8481222406334449\n",
      "epoch 1295 lr 0.03751002004266348\n",
      "train_loss 0.34531615622737216 train_acc 0.8481222406334449\n",
      "epoch 1296 lr 0.03743507497262987\n",
      "train_loss 0.34530196334530544 train_acc 0.8481444823789771\n",
      "epoch 1297 lr 0.03736027964294608\n",
      "train_loss 0.3452877774270008 train_acc 0.848133361506211\n",
      "epoch 1298 lr 0.037285633754430655\n",
      "train_loss 0.3452736319611027 train_acc 0.848133361506211\n",
      "epoch 1299 lr 0.03721113700849998\n",
      "train_loss 0.3452594786582762 train_acc 0.8481222406334449\n",
      "\n",
      "val loss = 0.34741545036291516, \n",
      "val acc = 0.8472778222578062\n",
      "\n",
      "epoch 1300 lr 0.03713678910716693\n",
      "train_loss 0.34524534679277463 train_acc 0.8481444823789771\n",
      "epoch 1301 lr 0.03706258975303985\n",
      "train_loss 0.3452312224773168 train_acc 0.848133361506211\n",
      "epoch 1302 lr 0.03698853864932118\n",
      "train_loss 0.34521708784052774 train_acc 0.8481667241245093\n",
      "epoch 1303 lr 0.03691463549980645\n",
      "train_loss 0.3452029888718384 train_acc 0.8481778449972753\n",
      "epoch 1304 lr 0.03684088000888291\n",
      "train_loss 0.34518898259061565 train_acc 0.8481778449972753\n",
      "epoch 1305 lr 0.03676727188152855\n",
      "train_loss 0.3451750140931185 train_acc 0.8482334493611059\n",
      "epoch 1306 lr 0.03669381082331072\n",
      "train_loss 0.3451611054595653 train_acc 0.8482334493611059\n",
      "epoch 1307 lr 0.03662049654038512\n",
      "train_loss 0.34514721662169906 train_acc 0.848255691106638\n",
      "epoch 1308 lr 0.0365473287394945\n",
      "train_loss 0.3451333020533338 train_acc 0.848244570233872\n",
      "epoch 1309 lr 0.03647430712796758\n",
      "train_loss 0.345119399303811 train_acc 0.8483224163432346\n",
      "epoch 1310 lr 0.036401431413717794\n",
      "train_loss 0.34510553823661005 train_acc 0.8483224163432346\n",
      "epoch 1311 lr 0.036328701305242204\n",
      "train_loss 0.3450917077854657 train_acc 0.8483335372160007\n",
      "epoch 1312 lr 0.036256116511620265\n",
      "train_loss 0.34507791187406817 train_acc 0.8483335372160007\n",
      "epoch 1313 lr 0.03618367674251273\n",
      "train_loss 0.3450641528582266 train_acc 0.848366899834299\n",
      "epoch 1314 lr 0.03611138170816039\n",
      "train_loss 0.34505042731929464 train_acc 0.8484002624525973\n",
      "epoch 1315 lr 0.03603923111938305\n",
      "train_loss 0.3450367174666738 train_acc 0.8484336250708956\n",
      "epoch 1316 lr 0.03596722468757822\n",
      "train_loss 0.34502303278618424 train_acc 0.8484558668164277\n",
      "epoch 1317 lr 0.035895362124720116\n",
      "train_loss 0.34500935961108414 train_acc 0.8484558668164277\n",
      "epoch 1318 lr 0.035823643143358355\n",
      "train_loss 0.3449957017961328 train_acc 0.848489229434726\n",
      "epoch 1319 lr 0.03575206745661695\n",
      "train_loss 0.3449820894314112 train_acc 0.8484781085619599\n",
      "epoch 1320 lr 0.03568063477819302\n",
      "train_loss 0.3449685108978486 train_acc 0.8485225920530243\n",
      "epoch 1321 lr 0.035609344822355796\n",
      "train_loss 0.344954939875466 train_acc 0.8485337129257904\n",
      "epoch 1322 lr 0.035538197303945335\n",
      "train_loss 0.3449413939730475 train_acc 0.8485559546713226\n",
      "epoch 1323 lr 0.03546719193837148\n",
      "train_loss 0.34492791518728577 train_acc 0.8485337129257904\n",
      "epoch 1324 lr 0.03539632844161265\n",
      "train_loss 0.34491443556477047 train_acc 0.8485337129257904\n",
      "epoch 1325 lr 0.0353256065302148\n",
      "train_loss 0.3449010119835951 train_acc 0.8485448337985565\n",
      "epoch 1326 lr 0.03525502592129015\n",
      "train_loss 0.34488759883796566 train_acc 0.8485225920530243\n",
      "epoch 1327 lr 0.03518458633251621\n",
      "train_loss 0.34487417750166455 train_acc 0.8485337129257904\n",
      "epoch 1328 lr 0.03511428748213451\n",
      "train_loss 0.3448607484458993 train_acc 0.8485337129257904\n",
      "epoch 1329 lr 0.035044129088949556\n",
      "train_loss 0.3448472914706157 train_acc 0.8485448337985565\n",
      "epoch 1330 lr 0.03497411087232768\n",
      "train_loss 0.344833835056617 train_acc 0.8485448337985565\n",
      "epoch 1331 lr 0.034904232552195935\n",
      "train_loss 0.3448203704564449 train_acc 0.8485114711802583\n",
      "epoch 1332 lr 0.03483449384904092\n",
      "train_loss 0.3448069420773935 train_acc 0.8485225920530243\n",
      "epoch 1333 lr 0.034764894483907766\n",
      "train_loss 0.3447934755811767 train_acc 0.8485225920530243\n",
      "epoch 1334 lr 0.03469543417839889\n",
      "train_loss 0.3447799887803455 train_acc 0.8485225920530243\n",
      "epoch 1335 lr 0.034626112654673\n",
      "train_loss 0.34476650214212307 train_acc 0.8485337129257904\n",
      "epoch 1336 lr 0.03455692963544388\n",
      "train_loss 0.34475301728389635 train_acc 0.8485225920530243\n",
      "epoch 1337 lr 0.03448788484397939\n",
      "train_loss 0.34473954267246315 train_acc 0.8485003503074922\n",
      "epoch 1338 lr 0.034418978004100244\n",
      "train_loss 0.3447260774694632 train_acc 0.848489229434726\n",
      "epoch 1339 lr 0.03435020884017903\n",
      "train_loss 0.3447126618609981 train_acc 0.8485003503074922\n",
      "epoch 1340 lr 0.034281577077138956\n",
      "train_loss 0.3446993034602935 train_acc 0.8484781085619599\n",
      "epoch 1341 lr 0.034213082440452916\n",
      "train_loss 0.3446859577473783 train_acc 0.848489229434726\n",
      "epoch 1342 lr 0.03414472465614224\n",
      "train_loss 0.34467266451666456 train_acc 0.8484669876891938\n",
      "epoch 1343 lr 0.03407650345077572\n",
      "train_loss 0.3446594108495346 train_acc 0.8484447459436617\n",
      "epoch 1344 lr 0.03400841855146844\n",
      "train_loss 0.34464619450498335 train_acc 0.8484336250708956\n",
      "epoch 1345 lr 0.03394046968588072\n",
      "train_loss 0.3446329966277169 train_acc 0.8484336250708956\n",
      "epoch 1346 lr 0.03387265658221698\n",
      "train_loss 0.3446198131996471 train_acc 0.8484225041981295\n",
      "epoch 1347 lr 0.03380497896922475\n",
      "train_loss 0.34460667845256554 train_acc 0.8484336250708956\n",
      "epoch 1348 lr 0.03373743657619345\n",
      "train_loss 0.3445935417329152 train_acc 0.8484336250708956\n",
      "epoch 1349 lr 0.03367002913295346\n",
      "train_loss 0.34458044254870834 train_acc 0.8484336250708956\n",
      "\n",
      "val loss = 0.34690329941874054, \n",
      "val acc = 0.8476781425140112\n",
      "\n",
      "epoch 1350 lr 0.03360275636987487\n",
      "train_loss 0.3445673643330787 train_acc 0.8484225041981295\n",
      "epoch 1351 lr 0.033535618017866586\n",
      "train_loss 0.344554324729537 train_acc 0.8484225041981295\n",
      "epoch 1352 lr 0.033468613808375076\n",
      "train_loss 0.3445413265324693 train_acc 0.8484002624525973\n",
      "epoch 1353 lr 0.033401743473383434\n",
      "train_loss 0.34452834333657456 train_acc 0.8484113833253634\n",
      "epoch 1354 lr 0.033335006745410206\n",
      "train_loss 0.3445153537696615 train_acc 0.8484336250708956\n",
      "epoch 1355 lr 0.03326840335750843\n",
      "train_loss 0.34450239296640633 train_acc 0.8484447459436617\n",
      "epoch 1356 lr 0.033201933043264416\n",
      "train_loss 0.34448944348131044 train_acc 0.8484447459436617\n",
      "epoch 1357 lr 0.03313559553679686\n",
      "train_loss 0.34447650531843127 train_acc 0.8484336250708956\n",
      "epoch 1358 lr 0.03306939057275562\n",
      "train_loss 0.34446359953325495 train_acc 0.8484336250708956\n",
      "epoch 1359 lr 0.03300331788632078\n",
      "train_loss 0.34445069527496996 train_acc 0.8484336250708956\n",
      "epoch 1360 lr 0.032937377213201474\n",
      "train_loss 0.34443781176433824 train_acc 0.8484781085619599\n",
      "epoch 1361 lr 0.03287156828963495\n",
      "train_loss 0.34442496900402825 train_acc 0.8485225920530243\n",
      "epoch 1362 lr 0.032805890852385396\n",
      "train_loss 0.3444121554596625 train_acc 0.8485337129257904\n",
      "epoch 1363 lr 0.032740344638743014\n",
      "train_loss 0.3443993753942468 train_acc 0.8485670755440887\n",
      "epoch 1364 lr 0.032674929386522826\n",
      "train_loss 0.3443866001415467 train_acc 0.8485670755440887\n",
      "epoch 1365 lr 0.03260964483406376\n",
      "train_loss 0.3443738542685287 train_acc 0.8485670755440887\n",
      "epoch 1366 lr 0.032544490720227505\n",
      "train_loss 0.34436117250156795 train_acc 0.8485781964168548\n",
      "epoch 1367 lr 0.032479466784397525\n",
      "train_loss 0.3443485315635939 train_acc 0.8486338007806853\n",
      "epoch 1368 lr 0.03241457276647798\n",
      "train_loss 0.3443358886802765 train_acc 0.8486338007806853\n",
      "epoch 1369 lr 0.032349808406892736\n",
      "train_loss 0.34432327479238256 train_acc 0.8486560425262174\n",
      "epoch 1370 lr 0.032285173446584235\n",
      "train_loss 0.34431070699020405 train_acc 0.8486671633989835\n",
      "epoch 1371 lr 0.03222066762701259\n",
      "train_loss 0.3442981956877408 train_acc 0.8486671633989835\n",
      "epoch 1372 lr 0.03215629069015439\n",
      "train_loss 0.34428571424991855 train_acc 0.8487005260172819\n",
      "epoch 1373 lr 0.03209204237850184\n",
      "train_loss 0.34427326314908335 train_acc 0.8487450095083462\n",
      "epoch 1374 lr 0.032027922435061584\n",
      "train_loss 0.3442607950111918 train_acc 0.848711646890048\n",
      "epoch 1375 lr 0.031963930603353785\n",
      "train_loss 0.34424834954856826 train_acc 0.8486782842717496\n",
      "epoch 1376 lr 0.03190006662741102\n",
      "train_loss 0.34423589961625184 train_acc 0.8486782842717496\n",
      "epoch 1377 lr 0.03183633025177728\n",
      "train_loss 0.34422346121498865 train_acc 0.8486894051445157\n",
      "epoch 1378 lr 0.03177272122150701\n",
      "train_loss 0.3442110243479484 train_acc 0.8486894051445157\n",
      "epoch 1379 lr 0.03170923928216398\n",
      "train_loss 0.3441986221095869 train_acc 0.8486782842717496\n",
      "epoch 1380 lr 0.031645884179820366\n",
      "train_loss 0.3441862578909881 train_acc 0.8486782842717496\n",
      "epoch 1381 lr 0.031582655661055656\n",
      "train_loss 0.34417393602986585 train_acc 0.8486782842717496\n",
      "epoch 1382 lr 0.031519553472955715\n",
      "train_loss 0.3441616349951073 train_acc 0.8486894051445157\n",
      "epoch 1383 lr 0.03145657736311167\n",
      "train_loss 0.3441493493928347 train_acc 0.8486782842717496\n",
      "epoch 1384 lr 0.031393727079619044\n",
      "train_loss 0.3441370983268644 train_acc 0.8486671633989835\n",
      "epoch 1385 lr 0.031331002371076576\n",
      "train_loss 0.34412486626505423 train_acc 0.8486560425262174\n",
      "epoch 1386 lr 0.031268402986585384\n",
      "train_loss 0.34411265421449144 train_acc 0.8486560425262174\n",
      "epoch 1387 lr 0.031205928675747813\n",
      "train_loss 0.34410042199089397 train_acc 0.8486560425262174\n",
      "epoch 1388 lr 0.031143579188666566\n",
      "train_loss 0.3440881982351487 train_acc 0.8486782842717496\n",
      "epoch 1389 lr 0.031081354275943586\n",
      "train_loss 0.3440759848931349 train_acc 0.8487005260172819\n",
      "epoch 1390 lr 0.031019253688679162\n",
      "train_loss 0.34406379432245565 train_acc 0.848711646890048\n",
      "epoch 1391 lr 0.03095727717847084\n",
      "train_loss 0.344051623496729 train_acc 0.8487672512538784\n",
      "epoch 1392 lr 0.030895424497412522\n",
      "train_loss 0.34403945810323777 train_acc 0.8487783721266445\n",
      "epoch 1393 lr 0.030833695398093375\n",
      "train_loss 0.3440273088234096 train_acc 0.8487783721266445\n",
      "epoch 1394 lr 0.030772089633596945\n",
      "train_loss 0.34401519775390077 train_acc 0.8487672512538784\n",
      "epoch 1395 lr 0.030710606957500067\n",
      "train_loss 0.34400309508858984 train_acc 0.8488006138721766\n",
      "epoch 1396 lr 0.030649247123871976\n",
      "train_loss 0.3439909883443859 train_acc 0.8488006138721766\n",
      "epoch 1397 lr 0.030588009887273237\n",
      "train_loss 0.34397884692699504 train_acc 0.8487894929994106\n",
      "epoch 1398 lr 0.03052689500275484\n",
      "train_loss 0.34396673180543524 train_acc 0.8487338886355801\n",
      "epoch 1399 lr 0.030465902225857145\n",
      "train_loss 0.3439546726140292 train_acc 0.8487338886355801\n",
      "\n",
      "val loss = 0.34642926581881545, \n",
      "val acc = 0.8482786228983187\n",
      "\n",
      "epoch 1400 lr 0.03040503131260899\n",
      "train_loss 0.3439426528194921 train_acc 0.8487450095083462\n",
      "epoch 1401 lr 0.03034428201952661\n",
      "train_loss 0.34393066833332053 train_acc 0.8487561303811123\n",
      "epoch 1402 lr 0.03028365410361278\n",
      "train_loss 0.3439186686806856 train_acc 0.8488006138721766\n",
      "epoch 1403 lr 0.03022314732235573\n",
      "train_loss 0.3439066938710608 train_acc 0.8487783721266445\n",
      "epoch 1404 lr 0.030162761433728282\n",
      "train_loss 0.3438947107650414 train_acc 0.8487672512538784\n",
      "epoch 1405 lr 0.03010249619618677\n",
      "train_loss 0.34388271464060344 train_acc 0.8487783721266445\n",
      "epoch 1406 lr 0.030042351368670197\n",
      "train_loss 0.3438707413574184 train_acc 0.8488006138721766\n",
      "epoch 1407 lr 0.02998232671059914\n",
      "train_loss 0.34385878148415566 train_acc 0.8488006138721766\n",
      "epoch 1408 lr 0.02992242198187491\n",
      "train_loss 0.34384681157285907 train_acc 0.8488006138721766\n",
      "epoch 1409 lr 0.029862636942878495\n",
      "train_loss 0.3438348282860424 train_acc 0.8488117347449428\n",
      "epoch 1410 lr 0.029802971354469684\n",
      "train_loss 0.34382281895032385 train_acc 0.8488117347449428\n",
      "epoch 1411 lr 0.029743424977986013\n",
      "train_loss 0.34381080028354116 train_acc 0.8488450973632411\n",
      "epoch 1412 lr 0.029683997575241924\n",
      "train_loss 0.34379876109587276 train_acc 0.8488562182360072\n",
      "epoch 1413 lr 0.0296246889085277\n",
      "train_loss 0.3437867552070099 train_acc 0.8488895808543054\n",
      "epoch 1414 lr 0.029565498740608626\n",
      "train_loss 0.3437747811249571 train_acc 0.8488673391087732\n",
      "epoch 1415 lr 0.02950642683472392\n",
      "train_loss 0.3437628361040173 train_acc 0.8488562182360072\n",
      "epoch 1416 lr 0.02944747295458591\n",
      "train_loss 0.34375092521090306 train_acc 0.8488673391087732\n",
      "epoch 1417 lr 0.029388636864378967\n",
      "train_loss 0.3437390378353441 train_acc 0.8489340643453698\n",
      "epoch 1418 lr 0.02932991832875868\n",
      "train_loss 0.3437272057849941 train_acc 0.8489340643453698\n",
      "epoch 1419 lr 0.0292713171128508\n",
      "train_loss 0.3437154224936197 train_acc 0.8489340643453698\n",
      "epoch 1420 lr 0.029212832982250414\n",
      "train_loss 0.34370369230733333 train_acc 0.848956306090902\n",
      "epoch 1421 lr 0.029154465703020896\n",
      "train_loss 0.3436919776030859 train_acc 0.8489785478364342\n",
      "epoch 1422 lr 0.029096215041693074\n",
      "train_loss 0.3436802590814687 train_acc 0.8489896687092003\n",
      "epoch 1423 lr 0.0290380807652642\n",
      "train_loss 0.34366853671799685 train_acc 0.8490230313274986\n",
      "epoch 1424 lr 0.028980062641197117\n",
      "train_loss 0.3436567898019962 train_acc 0.8490341522002647\n",
      "epoch 1425 lr 0.028922160437419228\n",
      "train_loss 0.3436450440050117 train_acc 0.8490341522002647\n",
      "epoch 1426 lr 0.028864373922321666\n",
      "train_loss 0.3436332881387253 train_acc 0.8490230313274986\n",
      "epoch 1427 lr 0.02880670286475826\n",
      "train_loss 0.343621556996208 train_acc 0.8490341522002647\n",
      "epoch 1428 lr 0.028749147034044742\n",
      "train_loss 0.3436098639565289 train_acc 0.8490341522002647\n",
      "epoch 1429 lr 0.028691706199957676\n",
      "train_loss 0.3435982337070483 train_acc 0.8490452730730308\n",
      "epoch 1430 lr 0.02863438013273368\n",
      "train_loss 0.34358665443592834 train_acc 0.8490341522002647\n",
      "epoch 1431 lr 0.02857716860306838\n",
      "train_loss 0.3435751513693436 train_acc 0.8490230313274986\n",
      "epoch 1432 lr 0.028520071382115608\n",
      "train_loss 0.3435636468051606 train_acc 0.8490119104547325\n",
      "epoch 1433 lr 0.028463088241486377\n",
      "train_loss 0.3435521293415856 train_acc 0.8490230313274986\n",
      "epoch 1434 lr 0.028406218953248078\n",
      "train_loss 0.34354062373898525 train_acc 0.8490119104547325\n",
      "epoch 1435 lr 0.02834946328992345\n",
      "train_loss 0.3435291286003103 train_acc 0.8490230313274986\n",
      "epoch 1436 lr 0.0282928210244898\n",
      "train_loss 0.34351763644263555 train_acc 0.8490007895819663\n",
      "epoch 1437 lr 0.028236291930377955\n",
      "train_loss 0.3435061067967309 train_acc 0.8490007895819663\n",
      "epoch 1438 lr 0.028179875781471495\n",
      "train_loss 0.3434945742780499 train_acc 0.8490119104547325\n",
      "epoch 1439 lr 0.02812357235210572\n",
      "train_loss 0.34348309993059767 train_acc 0.8490230313274986\n",
      "epoch 1440 lr 0.028067381417066863\n",
      "train_loss 0.3434716708246853 train_acc 0.8489785478364342\n",
      "epoch 1441 lr 0.028011302751591086\n",
      "train_loss 0.34346025573380307 train_acc 0.8490007895819663\n",
      "epoch 1442 lr 0.027955336131363678\n",
      "train_loss 0.34344885822128296 train_acc 0.8490007895819663\n",
      "epoch 1443 lr 0.027899481332518055\n",
      "train_loss 0.34343747376657396 train_acc 0.8489785478364342\n",
      "epoch 1444 lr 0.027843738131634974\n",
      "train_loss 0.34342610355061953 train_acc 0.8489674269636681\n",
      "epoch 1445 lr 0.02778810630574153\n",
      "train_loss 0.3434147564238367 train_acc 0.8489674269636681\n",
      "epoch 1446 lr 0.027732585632310375\n",
      "train_loss 0.3434034191811857 train_acc 0.8489785478364342\n",
      "epoch 1447 lr 0.027677175889258714\n",
      "train_loss 0.343392085913558 train_acc 0.848956306090902\n",
      "epoch 1448 lr 0.027621876854947523\n",
      "train_loss 0.3433807787230226 train_acc 0.8489451852181359\n",
      "epoch 1449 lr 0.02756668830818057\n",
      "train_loss 0.3433695093342605 train_acc 0.848956306090902\n",
      "\n",
      "val loss = 0.34600135207604404, \n",
      "val acc = 0.8487790232185749\n",
      "\n",
      "epoch 1450 lr 0.027511610028203615\n",
      "train_loss 0.3433582688523237 train_acc 0.8489451852181359\n",
      "epoch 1451 lr 0.027456641794703446\n",
      "train_loss 0.3433470379009946 train_acc 0.848956306090902\n",
      "epoch 1452 lr 0.027401783387807077\n",
      "train_loss 0.3433357910117329 train_acc 0.8489340643453698\n",
      "epoch 1453 lr 0.02734703458808078\n",
      "train_loss 0.3433245987048971 train_acc 0.8489451852181359\n",
      "epoch 1454 lr 0.027292395176529313\n",
      "train_loss 0.3433134586363805 train_acc 0.8489229434726038\n",
      "epoch 1455 lr 0.02723786493459493\n",
      "train_loss 0.34330235938380715 train_acc 0.8489229434726038\n",
      "epoch 1456 lr 0.02718344364415661\n",
      "train_loss 0.3432912448360225 train_acc 0.8489118225998377\n",
      "epoch 1457 lr 0.027129131087529103\n",
      "train_loss 0.343280165723728 train_acc 0.8489007017270715\n",
      "epoch 1458 lr 0.02707492704746213\n",
      "train_loss 0.3432691103682216 train_acc 0.8489229434726038\n",
      "epoch 1459 lr 0.027020831307139434\n",
      "train_loss 0.34325802765030683 train_acc 0.8489118225998377\n",
      "epoch 1460 lr 0.02696684365017801\n",
      "train_loss 0.34324694308186743 train_acc 0.8489340643453698\n",
      "epoch 1461 lr 0.026912963860627127\n",
      "train_loss 0.3432358979218059 train_acc 0.8489451852181359\n",
      "epoch 1462 lr 0.026859191722967583\n",
      "train_loss 0.34322489120960065 train_acc 0.8489451852181359\n",
      "epoch 1463 lr 0.02680552702211073\n",
      "train_loss 0.34321392639956266 train_acc 0.8489229434726038\n",
      "epoch 1464 lr 0.02675196954339772\n",
      "train_loss 0.3432029654315719 train_acc 0.8489674269636681\n",
      "epoch 1465 lr 0.02669851907259854\n",
      "train_loss 0.3431919896045246 train_acc 0.8489896687092003\n",
      "epoch 1466 lr 0.02664517539591126\n",
      "train_loss 0.3431810325398323 train_acc 0.8490119104547325\n",
      "epoch 1467 lr 0.02659193829996108\n",
      "train_loss 0.3431700850108048 train_acc 0.8490119104547325\n",
      "epoch 1468 lr 0.026538807571799567\n",
      "train_loss 0.3431591506019837 train_acc 0.8490007895819663\n",
      "epoch 1469 lr 0.026485782998903713\n",
      "train_loss 0.34314827418951627 train_acc 0.8489896687092003\n",
      "epoch 1470 lr 0.02643286436917518\n",
      "train_loss 0.3431374415848592 train_acc 0.8489785478364342\n",
      "epoch 1471 lr 0.02638005147093936\n",
      "train_loss 0.3431266465649876 train_acc 0.8489785478364342\n",
      "epoch 1472 lr 0.026327344092944606\n",
      "train_loss 0.3431158492257275 train_acc 0.848956306090902\n",
      "epoch 1473 lr 0.02627474202436132\n",
      "train_loss 0.3431050608944463 train_acc 0.8489451852181359\n",
      "epoch 1474 lr 0.02622224505478117\n",
      "train_loss 0.3430942596208175 train_acc 0.8489674269636681\n",
      "epoch 1475 lr 0.02616985297421619\n",
      "train_loss 0.34308349437646335 train_acc 0.8489785478364342\n",
      "epoch 1476 lr 0.026117565573098016\n",
      "train_loss 0.34307274073738525 train_acc 0.8489896687092003\n",
      "epoch 1477 lr 0.026065382642276945\n",
      "train_loss 0.34306203137538277 train_acc 0.8489896687092003\n",
      "epoch 1478 lr 0.026013303973021207\n",
      "train_loss 0.3430513307848284 train_acc 0.8490007895819663\n",
      "epoch 1479 lr 0.025961329357016033\n",
      "train_loss 0.3430406458075252 train_acc 0.8489896687092003\n",
      "epoch 1480 lr 0.025909458586362916\n",
      "train_loss 0.34303000115688154 train_acc 0.8490007895819663\n",
      "epoch 1481 lr 0.02585769145357868\n",
      "train_loss 0.34301935034922126 train_acc 0.8490230313274986\n",
      "epoch 1482 lr 0.025806027751594744\n",
      "train_loss 0.3430086882807795 train_acc 0.8490563939457969\n",
      "epoch 1483 lr 0.025754467273756212\n",
      "train_loss 0.3429980527643716 train_acc 0.849078635691329\n",
      "epoch 1484 lr 0.025703009813821127\n",
      "train_loss 0.34298747166268456 train_acc 0.8490675148185629\n",
      "epoch 1485 lr 0.025651655165959554\n",
      "train_loss 0.3429769343097825 train_acc 0.849078635691329\n",
      "epoch 1486 lr 0.02560040312475286\n",
      "train_loss 0.3429664104302014 train_acc 0.8490675148185629\n",
      "epoch 1487 lr 0.02554925348519279\n",
      "train_loss 0.3429558920304248 train_acc 0.8490897565640951\n",
      "epoch 1488 lr 0.025498206042680733\n",
      "train_loss 0.3429454041813389 train_acc 0.8491119983096274\n",
      "epoch 1489 lr 0.025447260593026835\n",
      "train_loss 0.34293492366524003 train_acc 0.8491231191823935\n",
      "epoch 1490 lr 0.02539641693244925\n",
      "train_loss 0.342924444104195 train_acc 0.8491231191823935\n",
      "epoch 1491 lr 0.025345674857573247\n",
      "train_loss 0.3429139936935326 train_acc 0.8491231191823935\n",
      "epoch 1492 lr 0.02529503416543048\n",
      "train_loss 0.34290354963679653 train_acc 0.8491231191823935\n",
      "epoch 1493 lr 0.025244494653458086\n",
      "train_loss 0.3428930996942772 train_acc 0.8491119983096274\n",
      "epoch 1494 lr 0.02519405611949798\n",
      "train_loss 0.34288266161775777 train_acc 0.8491342400551596\n",
      "epoch 1495 lr 0.025143718361795932\n",
      "train_loss 0.342872213106563 train_acc 0.8491342400551596\n",
      "epoch 1496 lr 0.025093481179000867\n",
      "train_loss 0.3428617596687245 train_acc 0.8491231191823935\n",
      "epoch 1497 lr 0.025043344370163964\n",
      "train_loss 0.3428513481243394 train_acc 0.8491008774368612\n",
      "epoch 1498 lr 0.024993307734737943\n",
      "train_loss 0.34284093804017046 train_acc 0.8490563939457969\n",
      "epoch 1499 lr 0.024943371072576177\n",
      "train_loss 0.34283052979618794 train_acc 0.8490563939457969\n",
      "\n",
      "val loss = 0.3456015798574541, \n",
      "val acc = 0.8489791833466773\n",
      "\n",
      "epoch 1500 lr 0.02489353418393197\n",
      "train_loss 0.34282015509120123 train_acc 0.8490563939457969\n",
      "epoch 1501 lr 0.02484379686945769\n",
      "train_loss 0.3428097899179808 train_acc 0.8490230313274986\n",
      "epoch 1502 lr 0.024794158930204\n",
      "train_loss 0.3427994285780543 train_acc 0.8490563939457969\n",
      "epoch 1503 lr 0.024744620167619105\n",
      "train_loss 0.3427890417433707 train_acc 0.8490675148185629\n",
      "epoch 1504 lr 0.024695180383547857\n",
      "train_loss 0.3427786807248443 train_acc 0.8491008774368612\n",
      "epoch 1505 lr 0.024645839380231085\n",
      "train_loss 0.34276836289002977 train_acc 0.8490897565640951\n",
      "epoch 1506 lr 0.02459659696030468\n",
      "train_loss 0.3427580707565604 train_acc 0.849078635691329\n",
      "epoch 1507 lr 0.024547452926798927\n",
      "train_loss 0.3427477992754359 train_acc 0.8490897565640951\n",
      "epoch 1508 lr 0.024498407083137597\n",
      "train_loss 0.3427375349191691 train_acc 0.8490897565640951\n",
      "epoch 1509 lr 0.024449459233137277\n",
      "train_loss 0.34272731117525623 train_acc 0.8490897565640951\n",
      "epoch 1510 lr 0.024400609181006477\n",
      "train_loss 0.3427171426774029 train_acc 0.849078635691329\n",
      "epoch 1511 lr 0.024351856731344948\n",
      "train_loss 0.3427070178299978 train_acc 0.8491119983096274\n",
      "epoch 1512 lr 0.024303201689142802\n",
      "train_loss 0.3426969098995055 train_acc 0.8491342400551596\n",
      "epoch 1513 lr 0.024254643859779827\n",
      "train_loss 0.34268677937542985 train_acc 0.8491342400551596\n",
      "epoch 1514 lr 0.024206183049024617\n",
      "train_loss 0.34267667786661593 train_acc 0.8491231191823935\n",
      "epoch 1515 lr 0.02415781906303389\n",
      "train_loss 0.3426666306004875 train_acc 0.8491231191823935\n",
      "epoch 1516 lr 0.02410955170835162\n",
      "train_loss 0.34265660691118544 train_acc 0.849078635691329\n",
      "epoch 1517 lr 0.024061380791908338\n",
      "train_loss 0.3426466145147056 train_acc 0.849078635691329\n",
      "epoch 1518 lr 0.024013306121020293\n",
      "train_loss 0.34263661966121867 train_acc 0.8490897565640951\n",
      "epoch 1519 lr 0.02396532750338876\n",
      "train_loss 0.34262662041886816 train_acc 0.8490897565640951\n",
      "epoch 1520 lr 0.023917444747099184\n",
      "train_loss 0.342616653123809 train_acc 0.8490897565640951\n",
      "epoch 1521 lr 0.023869657660620498\n",
      "train_loss 0.34260667623320884 train_acc 0.8490675148185629\n",
      "epoch 1522 lr 0.023821966052804268\n",
      "train_loss 0.3425966997388243 train_acc 0.8491008774368612\n",
      "epoch 1523 lr 0.023774369732884024\n",
      "train_loss 0.3425867338858628 train_acc 0.8491008774368612\n",
      "epoch 1524 lr 0.0237268685104744\n",
      "train_loss 0.3425767747176191 train_acc 0.8491119983096274\n",
      "epoch 1525 lr 0.023679462195570464\n",
      "train_loss 0.34256684589910663 train_acc 0.8490897565640951\n",
      "epoch 1526 lr 0.023632150598546876\n",
      "train_loss 0.3425569059402621 train_acc 0.8491008774368612\n",
      "epoch 1527 lr 0.0235849335301572\n",
      "train_loss 0.34254702080099736 train_acc 0.8491231191823935\n",
      "epoch 1528 lr 0.02353781080153308\n",
      "train_loss 0.34253720410934185 train_acc 0.8491342400551596\n",
      "epoch 1529 lr 0.023490782224183555\n",
      "train_loss 0.34252740223602235 train_acc 0.8491342400551596\n",
      "epoch 1530 lr 0.023443847609994243\n",
      "train_loss 0.3425176058322482 train_acc 0.8491008774368612\n",
      "epoch 1531 lr 0.02339700677122664\n",
      "train_loss 0.34250780500617034 train_acc 0.8491119983096274\n",
      "epoch 1532 lr 0.023350259520517308\n",
      "train_loss 0.3424979911260156 train_acc 0.8491342400551596\n",
      "epoch 1533 lr 0.0233036056708772\n",
      "train_loss 0.3424881533926992 train_acc 0.8491342400551596\n",
      "epoch 1534 lr 0.023257045035690836\n",
      "train_loss 0.3424783481987212 train_acc 0.8491453609279256\n",
      "epoch 1535 lr 0.023210577428715636\n",
      "train_loss 0.34246855005747445 train_acc 0.8491676026734578\n",
      "epoch 1536 lr 0.02316420266408109\n",
      "train_loss 0.34245878519131046 train_acc 0.8491676026734578\n",
      "epoch 1537 lr 0.023117920556288092\n",
      "train_loss 0.3424490489381734 train_acc 0.8491564818006917\n",
      "epoch 1538 lr 0.023071730920208137\n",
      "train_loss 0.342439307003411 train_acc 0.8491676026734578\n",
      "epoch 1539 lr 0.023025633571082633\n",
      "train_loss 0.34242953773360896 train_acc 0.8491676026734578\n",
      "epoch 1540 lr 0.022979628324522106\n",
      "train_loss 0.342419728327584 train_acc 0.8491342400551596\n",
      "epoch 1541 lr 0.022933714996505525\n",
      "train_loss 0.34240994194132185 train_acc 0.8491342400551596\n",
      "epoch 1542 lr 0.022887893403379496\n",
      "train_loss 0.34240021229531703 train_acc 0.8491453609279256\n",
      "epoch 1543 lr 0.022842163361857612\n",
      "train_loss 0.34239050193040543 train_acc 0.8491231191823935\n",
      "epoch 1544 lr 0.022796524689019618\n",
      "train_loss 0.3423807541095085 train_acc 0.8491342400551596\n",
      "epoch 1545 lr 0.02275097720231079\n",
      "train_loss 0.342371011394852 train_acc 0.8491119983096274\n",
      "epoch 1546 lr 0.02270552071954109\n",
      "train_loss 0.3423612833469664 train_acc 0.8490897565640951\n",
      "epoch 1547 lr 0.022660155058884555\n",
      "train_loss 0.34235156828611485 train_acc 0.8490897565640951\n",
      "epoch 1548 lr 0.02261488003887846\n",
      "train_loss 0.34234186967151764 train_acc 0.849078635691329\n",
      "epoch 1549 lr 0.022569695478422684\n",
      "train_loss 0.3423322210219884 train_acc 0.8490675148185629\n",
      "\n",
      "val loss = 0.3452251608011234, \n",
      "val acc = 0.849279423538831\n",
      "\n",
      "epoch 1550 lr 0.022524601196778904\n",
      "train_loss 0.3423225850789625 train_acc 0.849078635691329\n",
      "epoch 1551 lr 0.02247959701356995\n",
      "train_loss 0.3423129791551695 train_acc 0.8491119983096274\n",
      "epoch 1552 lr 0.02243468274877902\n",
      "train_loss 0.34230333330035956 train_acc 0.8491231191823935\n",
      "epoch 1553 lr 0.022389858222749002\n",
      "train_loss 0.34229367391122634 train_acc 0.8491342400551596\n",
      "epoch 1554 lr 0.022345123256181723\n",
      "train_loss 0.34228398211638633 train_acc 0.8491342400551596\n",
      "epoch 1555 lr 0.022300477670137268\n",
      "train_loss 0.34227428866448273 train_acc 0.8491231191823935\n",
      "epoch 1556 lr 0.02225592128603322\n",
      "train_loss 0.34226460197068087 train_acc 0.8491342400551596\n",
      "epoch 1557 lr 0.022211453925644\n",
      "train_loss 0.3422549162751863 train_acc 0.8491453609279256\n",
      "epoch 1558 lr 0.02216707541110009\n",
      "train_loss 0.3422451971618728 train_acc 0.8491564818006917\n",
      "epoch 1559 lr 0.022122785564887386\n",
      "train_loss 0.3422354649411108 train_acc 0.8491564818006917\n",
      "epoch 1560 lr 0.02207858420984643\n",
      "train_loss 0.34222574190216454 train_acc 0.8491453609279256\n",
      "epoch 1561 lr 0.022034471169171763\n",
      "train_loss 0.3422160539532666 train_acc 0.8491342400551596\n",
      "epoch 1562 lr 0.021990446266411143\n",
      "train_loss 0.34220635046051895 train_acc 0.8491564818006917\n",
      "epoch 1563 lr 0.021946509325464915\n",
      "train_loss 0.342196643180637 train_acc 0.8491676026734578\n",
      "epoch 1564 lr 0.021902660170585245\n",
      "train_loss 0.34218692791745264 train_acc 0.8492009652917561\n",
      "epoch 1565 lr 0.02185889862637547\n",
      "train_loss 0.34217720123330303 train_acc 0.8492009652917561\n",
      "epoch 1566 lr 0.021815224517789333\n",
      "train_loss 0.34216747789108637 train_acc 0.8491787235462239\n",
      "epoch 1567 lr 0.021771637670130368\n",
      "train_loss 0.3421577781860643 train_acc 0.8491564818006917\n",
      "epoch 1568 lr 0.021728137909051103\n",
      "train_loss 0.3421480926897589 train_acc 0.8491676026734578\n",
      "epoch 1569 lr 0.02168472506055245\n",
      "train_loss 0.3421384017488745 train_acc 0.8491676026734578\n",
      "epoch 1570 lr 0.021641398950982948\n",
      "train_loss 0.3421287231688958 train_acc 0.8491676026734578\n",
      "epoch 1571 lr 0.02159815940703811\n",
      "train_loss 0.3421190600588157 train_acc 0.8491453609279256\n",
      "epoch 1572 lr 0.021555006255759693\n",
      "train_loss 0.3421094244126162 train_acc 0.8491564818006917\n",
      "epoch 1573 lr 0.021511939324535045\n",
      "train_loss 0.3420998126314473 train_acc 0.8491564818006917\n",
      "epoch 1574 lr 0.021468958441096368\n",
      "train_loss 0.3420901980725745 train_acc 0.8491453609279256\n",
      "epoch 1575 lr 0.02142606343352009\n",
      "train_loss 0.34208059411461117 train_acc 0.8491342400551596\n",
      "epoch 1576 lr 0.021383254130226105\n",
      "train_loss 0.3420710051269534 train_acc 0.8491453609279256\n",
      "epoch 1577 lr 0.021340530359977163\n",
      "train_loss 0.34206144004062405 train_acc 0.8491342400551596\n",
      "epoch 1578 lr 0.021297891951878107\n",
      "train_loss 0.3420519011815909 train_acc 0.8491676026734578\n",
      "epoch 1579 lr 0.021255338735375263\n",
      "train_loss 0.34204239386938884 train_acc 0.8491676026734578\n",
      "epoch 1580 lr 0.02121287054025569\n",
      "train_loss 0.34203288327541065 train_acc 0.8491787235462239\n",
      "epoch 1581 lr 0.021170487196646572\n",
      "train_loss 0.34202338559186574 train_acc 0.8491787235462239\n",
      "epoch 1582 lr 0.021128188535014462\n",
      "train_loss 0.3420139035098608 train_acc 0.8491787235462239\n",
      "epoch 1583 lr 0.02108597438616467\n",
      "train_loss 0.34200441974949825 train_acc 0.84918984441899\n",
      "epoch 1584 lr 0.021043844581240527\n",
      "train_loss 0.34199495167666094 train_acc 0.8492009652917561\n",
      "epoch 1585 lr 0.021001798951722776\n",
      "train_loss 0.3419855197819809 train_acc 0.84918984441899\n",
      "epoch 1586 lr 0.020959837329428826\n",
      "train_loss 0.3419761109089917 train_acc 0.8491787235462239\n",
      "epoch 1587 lr 0.020917959546512148\n",
      "train_loss 0.341966723525611 train_acc 0.8492009652917561\n",
      "epoch 1588 lr 0.02087616543546154\n",
      "train_loss 0.34195732679124996 train_acc 0.84918984441899\n",
      "epoch 1589 lr 0.020834454829100516\n",
      "train_loss 0.3419479324460832 train_acc 0.84918984441899\n",
      "epoch 1590 lr 0.02079282756058658\n",
      "train_loss 0.341938559137694 train_acc 0.8492009652917561\n",
      "epoch 1591 lr 0.02075128346341062\n",
      "train_loss 0.34192922751853944 train_acc 0.8492120861645222\n",
      "epoch 1592 lr 0.020709822371396173\n",
      "train_loss 0.3419199007215935 train_acc 0.8492565696555866\n",
      "epoch 1593 lr 0.020668444118698833\n",
      "train_loss 0.34191060347232294 train_acc 0.8492454487828205\n",
      "epoch 1594 lr 0.020627148539805514\n",
      "train_loss 0.3419013105266326 train_acc 0.8492788114011187\n",
      "epoch 1595 lr 0.02058593546953387\n",
      "train_loss 0.3418920169922906 train_acc 0.8493232948921832\n",
      "epoch 1596 lr 0.02054480474303154\n",
      "train_loss 0.3418827282284923 train_acc 0.8493232948921832\n",
      "epoch 1597 lr 0.020503756195775585\n",
      "train_loss 0.341873419093671 train_acc 0.8493344157649493\n",
      "epoch 1598 lr 0.020462789663571745\n",
      "train_loss 0.34186409290560427 train_acc 0.8493455366377153\n",
      "epoch 1599 lr 0.02042190498255385\n",
      "train_loss 0.3418547727440816 train_acc 0.8493455366377153\n",
      "\n",
      "val loss = 0.34487162671065374, \n",
      "val acc = 0.8493795036028823\n",
      "\n",
      "epoch 1600 lr 0.020381101989183102\n",
      "train_loss 0.34184549214455034 train_acc 0.8493566575104814\n",
      "epoch 1601 lr 0.0203403805202475\n",
      "train_loss 0.3418362664389817 train_acc 0.8493900201287797\n",
      "epoch 1602 lr 0.02029974041286109\n",
      "train_loss 0.34182708354096664 train_acc 0.8493788992560136\n",
      "epoch 1603 lr 0.020259181504463403\n",
      "train_loss 0.3418179139356159 train_acc 0.8493788992560136\n",
      "epoch 1604 lr 0.02021870363281874\n",
      "train_loss 0.34180878729126507 train_acc 0.8493677783832475\n",
      "epoch 1605 lr 0.020178306636015574\n",
      "train_loss 0.34179968676436423 train_acc 0.849423382747078\n",
      "epoch 1606 lr 0.02013799035246585\n",
      "train_loss 0.3417906029949227 train_acc 0.8494345036198441\n",
      "epoch 1607 lr 0.020097754620904393\n",
      "train_loss 0.34178152604571593 train_acc 0.8494345036198441\n",
      "epoch 1608 lr 0.020057599280388208\n",
      "train_loss 0.34177242275600944 train_acc 0.8494345036198441\n",
      "epoch 1609 lr 0.020017524170295897\n",
      "train_loss 0.3417633090021528 train_acc 0.8494122618743118\n",
      "epoch 1610 lr 0.019977529130326948\n",
      "train_loss 0.34175420067348644 train_acc 0.8494122618743118\n",
      "epoch 1611 lr 0.019937614000501168\n",
      "train_loss 0.34174509904268696 train_acc 0.8494011410015458\n",
      "epoch 1612 lr 0.019897778621157963\n",
      "train_loss 0.3417360057927221 train_acc 0.8494011410015458\n",
      "epoch 1613 lr 0.019858022832955784\n",
      "train_loss 0.3417269336201944 train_acc 0.8494011410015458\n",
      "epoch 1614 lr 0.0198183464768714\n",
      "train_loss 0.3417178669206229 train_acc 0.8494011410015458\n",
      "epoch 1615 lr 0.019778749394199362\n",
      "train_loss 0.34170879066267734 train_acc 0.8494122618743118\n",
      "epoch 1616 lr 0.019739231426551263\n",
      "train_loss 0.34169971526436577 train_acc 0.8494345036198441\n",
      "epoch 1617 lr 0.019699792415855195\n",
      "train_loss 0.341690655469792 train_acc 0.849423382747078\n",
      "epoch 1618 lr 0.019660432204355052\n",
      "train_loss 0.34168158843659124 train_acc 0.8494345036198441\n",
      "epoch 1619 lr 0.019621150634609945\n",
      "train_loss 0.341672537178782 train_acc 0.849423382747078\n",
      "epoch 1620 lr 0.019581947549493533\n",
      "train_loss 0.34166348587266443 train_acc 0.8494345036198441\n",
      "epoch 1621 lr 0.019542822792193434\n",
      "train_loss 0.341654435541064 train_acc 0.8494345036198441\n",
      "epoch 1622 lr 0.019503776206210553\n",
      "train_loss 0.34164539186721476 train_acc 0.8494345036198441\n",
      "epoch 1623 lr 0.019464807635358513\n",
      "train_loss 0.34163635134130965 train_acc 0.8494678662381424\n",
      "epoch 1624 lr 0.019425916923762956\n",
      "train_loss 0.34162733531552897 train_acc 0.8494678662381424\n",
      "epoch 1625 lr 0.019387103915861004\n",
      "train_loss 0.3416182931401351 train_acc 0.8494456244926102\n",
      "epoch 1626 lr 0.019348368456400568\n",
      "train_loss 0.3416092384735066 train_acc 0.849423382747078\n",
      "epoch 1627 lr 0.019309710390439744\n",
      "train_loss 0.34160018832174455 train_acc 0.8494345036198441\n",
      "epoch 1628 lr 0.019271129563346236\n",
      "train_loss 0.3415911482704445 train_acc 0.849423382747078\n",
      "epoch 1629 lr 0.01923262582079667\n",
      "train_loss 0.3415821410520046 train_acc 0.8494345036198441\n",
      "epoch 1630 lr 0.019194199008776038\n",
      "train_loss 0.34157315256432 train_acc 0.8494345036198441\n",
      "epoch 1631 lr 0.019155848973577024\n",
      "train_loss 0.3415641946619061 train_acc 0.8494456244926102\n",
      "epoch 1632 lr 0.019117575561799455\n",
      "train_loss 0.3415552390439869 train_acc 0.8494678662381424\n",
      "epoch 1633 lr 0.019079378620349613\n",
      "train_loss 0.34154630257977403 train_acc 0.8494789871109084\n",
      "epoch 1634 lr 0.019041257996439704\n",
      "train_loss 0.3415373788225679 train_acc 0.8494678662381424\n",
      "epoch 1635 lr 0.019003213537587157\n",
      "train_loss 0.3415284674095613 train_acc 0.8494901079836745\n",
      "epoch 1636 lr 0.018965245091614107\n",
      "train_loss 0.3415195821931128 train_acc 0.8495012288564406\n",
      "epoch 1637 lr 0.018927352506646705\n",
      "train_loss 0.3415107140229154 train_acc 0.8495012288564406\n",
      "epoch 1638 lr 0.01888953563111457\n",
      "train_loss 0.34150185295690383 train_acc 0.8495012288564406\n",
      "epoch 1639 lr 0.01885179431375014\n",
      "train_loss 0.3414929830735375 train_acc 0.8494901079836745\n",
      "epoch 1640 lr 0.018814128403588107\n",
      "train_loss 0.3414841161458415 train_acc 0.8494789871109084\n",
      "epoch 1641 lr 0.018776537749964767\n",
      "train_loss 0.341475279392272 train_acc 0.8495012288564406\n",
      "epoch 1642 lr 0.018739022202517473\n",
      "train_loss 0.3414664321586107 train_acc 0.8495123497292068\n",
      "epoch 1643 lr 0.018701581611183963\n",
      "train_loss 0.3414575870600819 train_acc 0.8495123497292068\n",
      "epoch 1644 lr 0.01866421582620184\n",
      "train_loss 0.34144876683420344 train_acc 0.8495012288564406\n",
      "epoch 1645 lr 0.018626924698107904\n",
      "train_loss 0.3414399544318163 train_acc 0.8495123497292068\n",
      "epoch 1646 lr 0.0185897080777376\n",
      "train_loss 0.34143114694130183 train_acc 0.8495012288564406\n",
      "epoch 1647 lr 0.018552565816224387\n",
      "train_loss 0.3414223486736506 train_acc 0.8495012288564406\n",
      "epoch 1648 lr 0.018515497764999184\n",
      "train_loss 0.34141356034600406 train_acc 0.8495234706019729\n",
      "epoch 1649 lr 0.01847850377578972\n",
      "train_loss 0.34140478920527517 train_acc 0.8495123497292068\n",
      "\n",
      "val loss = 0.3445373928044794, \n",
      "val acc = 0.8499799839871898\n",
      "\n",
      "epoch 1650 lr 0.018441583700620004\n",
      "train_loss 0.34139601981725914 train_acc 0.8495123497292068\n",
      "epoch 1651 lr 0.018404737391809672\n",
      "train_loss 0.3413872762607314 train_acc 0.8494789871109084\n",
      "epoch 1652 lr 0.018367964701973456\n",
      "train_loss 0.3413785393604419 train_acc 0.8494901079836745\n",
      "epoch 1653 lr 0.01833126548402053\n",
      "train_loss 0.3413698365457547 train_acc 0.8494789871109084\n",
      "epoch 1654 lr 0.01829463959115399\n",
      "train_loss 0.34136114347184077 train_acc 0.8494567453653763\n",
      "epoch 1655 lr 0.018258086876870198\n",
      "train_loss 0.34135242189782494 train_acc 0.8494678662381424\n",
      "epoch 1656 lr 0.01822160719495827\n",
      "train_loss 0.34134371729610186 train_acc 0.8494901079836745\n",
      "epoch 1657 lr 0.018185200399499404\n",
      "train_loss 0.3413350155331826 train_acc 0.8495123497292068\n",
      "epoch 1658 lr 0.018148866344866392\n",
      "train_loss 0.34132632322200357 train_acc 0.8495234706019729\n",
      "epoch 1659 lr 0.01811260488572295\n",
      "train_loss 0.34131760984192844 train_acc 0.8495234706019729\n",
      "epoch 1660 lr 0.01807641587702321\n",
      "train_loss 0.3413088877258309 train_acc 0.849534591474739\n",
      "epoch 1661 lr 0.018040299174011072\n",
      "train_loss 0.3413001676143217 train_acc 0.849534591474739\n",
      "epoch 1662 lr 0.018004254632219694\n",
      "train_loss 0.3412914807828022 train_acc 0.8495679540930372\n",
      "epoch 1663 lr 0.01796828210747084\n",
      "train_loss 0.3412828211739376 train_acc 0.8495679540930372\n",
      "epoch 1664 lr 0.01793238145587438\n",
      "train_loss 0.3412741595985189 train_acc 0.8495901958385694\n",
      "epoch 1665 lr 0.01789655253382765\n",
      "train_loss 0.3412654818253294 train_acc 0.8496013167113355\n",
      "epoch 1666 lr 0.01786079519801492\n",
      "train_loss 0.34125683119052297 train_acc 0.8496124375841017\n",
      "epoch 1667 lr 0.017825109305406792\n",
      "train_loss 0.34124819748554025 train_acc 0.8496235584568677\n",
      "epoch 1668 lr 0.01778949471325966\n",
      "train_loss 0.3412395562219013 train_acc 0.8496346793296338\n",
      "epoch 1669 lr 0.017753951279115093\n",
      "train_loss 0.34123091823370005 train_acc 0.8496458002023999\n",
      "epoch 1670 lr 0.01771847886079932\n",
      "train_loss 0.34122230194121783 train_acc 0.8496458002023999\n",
      "epoch 1671 lr 0.01768307731642261\n",
      "train_loss 0.34121371935666106 train_acc 0.8496346793296338\n",
      "epoch 1672 lr 0.01764774650437875\n",
      "train_loss 0.3412051524624533 train_acc 0.8496235584568677\n",
      "epoch 1673 lr 0.017612486283344428\n",
      "train_loss 0.34119658752968424 train_acc 0.8496346793296338\n",
      "epoch 1674 lr 0.01757729651227873\n",
      "train_loss 0.341188030812621 train_acc 0.8495679540930372\n",
      "epoch 1675 lr 0.017542177050422512\n",
      "train_loss 0.3411794665093562 train_acc 0.8495901958385694\n",
      "epoch 1676 lr 0.017507127757297892\n",
      "train_loss 0.3411708814876999 train_acc 0.8495901958385694\n",
      "epoch 1677 lr 0.01747214849270764\n",
      "train_loss 0.341162304590362 train_acc 0.8495901958385694\n",
      "epoch 1678 lr 0.017437239116734657\n",
      "train_loss 0.3411537683176123 train_acc 0.8495790749658033\n",
      "epoch 1679 lr 0.017402399489741385\n",
      "train_loss 0.3411452498360512 train_acc 0.8496235584568677\n",
      "epoch 1680 lr 0.01736762947236928\n",
      "train_loss 0.3411367284704679 train_acc 0.8495901958385694\n",
      "epoch 1681 lr 0.01733292892553822\n",
      "train_loss 0.3411282011966928 train_acc 0.8495679540930372\n",
      "epoch 1682 lr 0.017298297710445977\n",
      "train_loss 0.3411196826310172 train_acc 0.8495901958385694\n",
      "epoch 1683 lr 0.017263735688567632\n",
      "train_loss 0.3411111699652661 train_acc 0.8496013167113355\n",
      "epoch 1684 lr 0.017229242721655068\n",
      "train_loss 0.3411026411287654 train_acc 0.8496013167113355\n",
      "epoch 1685 lr 0.017194818671736355\n",
      "train_loss 0.34109412935211764 train_acc 0.8496124375841017\n",
      "epoch 1686 lr 0.017160463401115263\n",
      "train_loss 0.3410856612543412 train_acc 0.8496458002023999\n",
      "epoch 1687 lr 0.01712617677237065\n",
      "train_loss 0.3410771877271009 train_acc 0.8496680419479321\n",
      "epoch 1688 lr 0.017091958648355967\n",
      "train_loss 0.34106875487334376 train_acc 0.8496680419479321\n",
      "epoch 1689 lr 0.01705780889219866\n",
      "train_loss 0.3410603670900872 train_acc 0.8496791628206982\n",
      "epoch 1690 lr 0.017023727367299672\n",
      "train_loss 0.3410519855472513 train_acc 0.8496680419479321\n",
      "epoch 1691 lr 0.016989713937332847\n",
      "train_loss 0.34104362074937267 train_acc 0.8496902836934642\n",
      "epoch 1692 lr 0.016955768466244428\n",
      "train_loss 0.3410352801949732 train_acc 0.8497125254389964\n",
      "epoch 1693 lr 0.016921890818252475\n",
      "train_loss 0.34102696072101896 train_acc 0.8496902836934642\n",
      "epoch 1694 lr 0.016888080857846367\n",
      "train_loss 0.34101865967252365 train_acc 0.8496902836934642\n",
      "epoch 1695 lr 0.016854338449786198\n",
      "train_loss 0.3410103641146509 train_acc 0.8497125254389964\n",
      "epoch 1696 lr 0.016820663459102308\n",
      "train_loss 0.34100206490184 train_acc 0.8497347671845287\n",
      "epoch 1697 lr 0.016787055751094678\n",
      "train_loss 0.34099377963878175 train_acc 0.8497236463117626\n",
      "epoch 1698 lr 0.01675351519133244\n",
      "train_loss 0.34098552240000474 train_acc 0.8497347671845287\n",
      "epoch 1699 lr 0.0167200416456533\n",
      "train_loss 0.3409773093031212 train_acc 0.8497347671845287\n",
      "\n",
      "val loss = 0.34425010199642897, \n",
      "val acc = 0.8496797437950361\n",
      "\n",
      "epoch 1700 lr 0.01668663498016304\n",
      "train_loss 0.34096911070178354 train_acc 0.8497125254389964\n",
      "epoch 1701 lr 0.016653295061234943\n",
      "train_loss 0.34096091524342376 train_acc 0.8497125254389964\n",
      "epoch 1702 lr 0.016620021755509303\n",
      "train_loss 0.34095273920045055 train_acc 0.8497125254389964\n",
      "epoch 1703 lr 0.016586814929892838\n",
      "train_loss 0.3409445793256249 train_acc 0.8497014045662303\n",
      "epoch 1704 lr 0.01655367445155822\n",
      "train_loss 0.340936411199826 train_acc 0.8497125254389964\n",
      "epoch 1705 lr 0.016520600187943466\n",
      "train_loss 0.34092823527632493 train_acc 0.8496902836934642\n",
      "epoch 1706 lr 0.0164875920067515\n",
      "train_loss 0.34092006996131863 train_acc 0.8496680419479321\n",
      "epoch 1707 lr 0.01645464977594954\n",
      "train_loss 0.34091192002844717 train_acc 0.8496791628206982\n",
      "epoch 1708 lr 0.016421773363768627\n",
      "train_loss 0.3409037729022824 train_acc 0.8496791628206982\n",
      "epoch 1709 lr 0.01638896263870306\n",
      "train_loss 0.3408956390969028 train_acc 0.8497014045662303\n",
      "epoch 1710 lr 0.016356217469509906\n",
      "train_loss 0.3408875308895486 train_acc 0.8497125254389964\n",
      "epoch 1711 lr 0.01632353772520843\n",
      "train_loss 0.34087938886614605 train_acc 0.8497236463117626\n",
      "epoch 1712 lr 0.01629092327507963\n",
      "train_loss 0.3408712483945629 train_acc 0.8497236463117626\n",
      "epoch 1713 lr 0.016258373988665645\n",
      "train_loss 0.3408630966610346 train_acc 0.8497458880572948\n",
      "epoch 1714 lr 0.016225889735769296\n",
      "train_loss 0.3408549591127718 train_acc 0.849779250675593\n",
      "epoch 1715 lr 0.01619347038645352\n",
      "train_loss 0.340846837994563 train_acc 0.849779250675593\n",
      "epoch 1716 lr 0.016161115811040884\n",
      "train_loss 0.34083869491776825 train_acc 0.8497903715483591\n",
      "epoch 1717 lr 0.016128825880113037\n",
      "train_loss 0.34083055082436864 train_acc 0.849779250675593\n",
      "epoch 1718 lr 0.01609660046451022\n",
      "train_loss 0.3408224139853231 train_acc 0.849779250675593\n",
      "epoch 1719 lr 0.01606443943533072\n",
      "train_loss 0.340814313661039 train_acc 0.849779250675593\n",
      "epoch 1720 lr 0.016032342663930384\n",
      "train_loss 0.34080621635770425 train_acc 0.849779250675593\n",
      "epoch 1721 lr 0.016000310021922075\n",
      "train_loss 0.3407981317227814 train_acc 0.8497903715483591\n",
      "epoch 1722 lr 0.015968341381175196\n",
      "train_loss 0.3407900703459008 train_acc 0.8497903715483591\n",
      "epoch 1723 lr 0.015936436613815122\n",
      "train_loss 0.34078202465033497 train_acc 0.849779250675593\n",
      "epoch 1724 lr 0.01590459559222276\n",
      "train_loss 0.3407739549578446 train_acc 0.849779250675593\n",
      "epoch 1725 lr 0.01587281818903397\n",
      "train_loss 0.34076589618915654 train_acc 0.849779250675593\n",
      "epoch 1726 lr 0.0158411042771391\n",
      "train_loss 0.34075785414260257 train_acc 0.8497681298028269\n",
      "epoch 1727 lr 0.015809453729682458\n",
      "train_loss 0.3407498125355667 train_acc 0.8497458880572948\n",
      "epoch 1728 lr 0.01577786642006182\n",
      "train_loss 0.3407417812002206 train_acc 0.8497347671845287\n",
      "epoch 1729 lr 0.015746342221927893\n",
      "train_loss 0.34073374440820775 train_acc 0.8497236463117626\n",
      "epoch 1730 lr 0.015714881009183855\n",
      "train_loss 0.3407256996727267 train_acc 0.8497570089300608\n",
      "epoch 1731 lr 0.0156834826559848\n",
      "train_loss 0.34071764471168375 train_acc 0.8497681298028269\n",
      "epoch 1732 lr 0.01565214703673729\n",
      "train_loss 0.34070959220240427 train_acc 0.8497458880572948\n",
      "epoch 1733 lr 0.015620874026098784\n",
      "train_loss 0.3407015499097335 train_acc 0.8497236463117626\n",
      "epoch 1734 lr 0.01558966349897722\n",
      "train_loss 0.34069351473671583 train_acc 0.8497347671845287\n",
      "epoch 1735 lr 0.015558515330530431\n",
      "train_loss 0.3406855133327987 train_acc 0.8497681298028269\n",
      "epoch 1736 lr 0.015527429396165715\n",
      "train_loss 0.3406775583782709 train_acc 0.849779250675593\n",
      "epoch 1737 lr 0.015496405571539282\n",
      "train_loss 0.3406696066774036 train_acc 0.8497903715483591\n",
      "epoch 1738 lr 0.015465443732555801\n",
      "train_loss 0.34066165558210787 train_acc 0.8497903715483591\n",
      "epoch 1739 lr 0.015434543755367867\n",
      "train_loss 0.3406536957071578 train_acc 0.8497903715483591\n",
      "epoch 1740 lr 0.01540370551637554\n",
      "train_loss 0.3406457194512087 train_acc 0.849779250675593\n",
      "epoch 1741 lr 0.015372928892225808\n",
      "train_loss 0.3406377557298665 train_acc 0.849779250675593\n",
      "epoch 1742 lr 0.015342213759812151\n",
      "train_loss 0.34062979837332263 train_acc 0.849779250675593\n",
      "epoch 1743 lr 0.015311559996273982\n",
      "train_loss 0.34062184691801556 train_acc 0.8497903715483591\n",
      "epoch 1744 lr 0.01528096747899622\n",
      "train_loss 0.34061388949778887 train_acc 0.8497347671845287\n",
      "epoch 1745 lr 0.015250436085608741\n",
      "train_loss 0.34060593824067315 train_acc 0.8497458880572948\n",
      "epoch 1746 lr 0.015219965693985947\n",
      "train_loss 0.34059800463760453 train_acc 0.8497681298028269\n",
      "epoch 1747 lr 0.015189556182246215\n",
      "train_loss 0.3405900956702926 train_acc 0.8497347671845287\n",
      "epoch 1748 lr 0.015159207428751471\n",
      "train_loss 0.3405821816132035 train_acc 0.8497236463117626\n",
      "epoch 1749 lr 0.015128919312106647\n",
      "train_loss 0.3405742685381935 train_acc 0.8497236463117626\n",
      "\n",
      "val loss = 0.3439885796250639, \n",
      "val acc = 0.8495796637309848\n",
      "\n",
      "epoch 1750 lr 0.01509869171115925\n",
      "train_loss 0.3405663747355542 train_acc 0.8497125254389964\n",
      "epoch 1751 lr 0.01506852450499883\n",
      "train_loss 0.3405585010549738 train_acc 0.8497236463117626\n",
      "epoch 1752 lr 0.015038417572956516\n",
      "train_loss 0.340550652190145 train_acc 0.8497347671845287\n",
      "epoch 1753 lr 0.01500837079460455\n",
      "train_loss 0.34054283944606895 train_acc 0.8497347671845287\n",
      "epoch 1754 lr 0.014978384049755768\n",
      "train_loss 0.34053503807011726 train_acc 0.8497236463117626\n",
      "epoch 1755 lr 0.01494845721846316\n",
      "train_loss 0.3405272449295741 train_acc 0.8497236463117626\n",
      "epoch 1756 lr 0.014918590181019353\n",
      "train_loss 0.3405194413007983 train_acc 0.8497236463117626\n",
      "epoch 1757 lr 0.014888782817956168\n",
      "train_loss 0.34051159415000215 train_acc 0.8497125254389964\n",
      "epoch 1758 lr 0.0148590350100441\n",
      "train_loss 0.34050374272645406 train_acc 0.8497014045662303\n",
      "epoch 1759 lr 0.01482934663829189\n",
      "train_loss 0.3404959071601795 train_acc 0.8497125254389964\n",
      "epoch 1760 lr 0.014799717583946\n",
      "train_loss 0.3404881039603837 train_acc 0.8497014045662303\n",
      "epoch 1761 lr 0.014770147728490184\n",
      "train_loss 0.3404803397317186 train_acc 0.8497125254389964\n",
      "epoch 1762 lr 0.01474063695364497\n",
      "train_loss 0.3404726066721993 train_acc 0.8497458880572948\n",
      "epoch 1763 lr 0.014711185141367232\n",
      "train_loss 0.34046488496795546 train_acc 0.8497347671845287\n",
      "epoch 1764 lr 0.014681792173849666\n",
      "train_loss 0.340457177348675 train_acc 0.8497125254389964\n",
      "epoch 1765 lr 0.01465245793352038\n",
      "train_loss 0.34044949689214493 train_acc 0.8497014045662303\n",
      "epoch 1766 lr 0.014623182303042357\n",
      "train_loss 0.3404418317742526 train_acc 0.8497236463117626\n",
      "epoch 1767 lr 0.01459396516531305\n",
      "train_loss 0.34043420792013473 train_acc 0.8497236463117626\n",
      "epoch 1768 lr 0.014564806403463856\n",
      "train_loss 0.3404266229778926 train_acc 0.8497125254389964\n",
      "epoch 1769 lr 0.014535705900859702\n",
      "train_loss 0.3404190554154652 train_acc 0.8497458880572948\n",
      "epoch 1770 lr 0.014506663541098527\n",
      "train_loss 0.34041149107139934 train_acc 0.8497570089300608\n",
      "epoch 1771 lr 0.014477679208010864\n",
      "train_loss 0.3404039199299856 train_acc 0.8497681298028269\n",
      "epoch 1772 lr 0.014448752785659331\n",
      "train_loss 0.34039636591185907 train_acc 0.8497681298028269\n",
      "epoch 1773 lr 0.014419884158338211\n",
      "train_loss 0.3403888267486226 train_acc 0.849779250675593\n",
      "epoch 1774 lr 0.014391073210572945\n",
      "train_loss 0.340381281328273 train_acc 0.8498014924211252\n",
      "epoch 1775 lr 0.014362319827119717\n",
      "train_loss 0.34037373628320966 train_acc 0.8498126132938914\n",
      "epoch 1776 lr 0.01433362389296494\n",
      "train_loss 0.3403662092357761 train_acc 0.8498348550394235\n",
      "epoch 1777 lr 0.014304985293324853\n",
      "train_loss 0.3403587060464346 train_acc 0.8498126132938914\n",
      "epoch 1778 lr 0.014276403913645005\n",
      "train_loss 0.3403511876118995 train_acc 0.8498126132938914\n",
      "epoch 1779 lr 0.014247879639599854\n",
      "train_loss 0.3403436780920491 train_acc 0.8498348550394235\n",
      "epoch 1780 lr 0.014219412357092252\n",
      "train_loss 0.3403361675730936 train_acc 0.8498570967849557\n",
      "epoch 1781 lr 0.014191001952253044\n",
      "train_loss 0.34032866976694526 train_acc 0.8498570967849557\n",
      "epoch 1782 lr 0.01416264831144056\n",
      "train_loss 0.340321186726888 train_acc 0.8498570967849557\n",
      "epoch 1783 lr 0.014134351321240213\n",
      "train_loss 0.34031372912775154 train_acc 0.8498570967849557\n",
      "epoch 1784 lr 0.01410611086846399\n",
      "train_loss 0.34030628641487226 train_acc 0.8498793385304879\n",
      "epoch 1785 lr 0.014077926840150053\n",
      "train_loss 0.3402988643747662 train_acc 0.8498682176577218\n",
      "epoch 1786 lr 0.014049799123562244\n",
      "train_loss 0.3402914546634588 train_acc 0.8498682176577218\n",
      "epoch 1787 lr 0.014021727606189666\n",
      "train_loss 0.34028403583184524 train_acc 0.8499238220215523\n",
      "epoch 1788 lr 0.013993712175746204\n",
      "train_loss 0.3402766066133228 train_acc 0.8499571846398505\n",
      "epoch 1789 lr 0.013965752720170107\n",
      "train_loss 0.34026917989718686 train_acc 0.8499349428943184\n",
      "epoch 1790 lr 0.013937849127623508\n",
      "train_loss 0.34026174624823813 train_acc 0.8499349428943184\n",
      "epoch 1791 lr 0.013910001286492009\n",
      "train_loss 0.34025430539144447 train_acc 0.8499349428943184\n",
      "epoch 1792 lr 0.013882209085384196\n",
      "train_loss 0.3402468688414374 train_acc 0.8499238220215523\n",
      "epoch 1793 lr 0.01385447241313124\n",
      "train_loss 0.3402394307476944 train_acc 0.8499127011487861\n",
      "epoch 1794 lr 0.013826791158786404\n",
      "train_loss 0.34023200811864224 train_acc 0.8499238220215523\n",
      "epoch 1795 lr 0.013799165211624644\n",
      "train_loss 0.3402245678685658 train_acc 0.8499238220215523\n",
      "epoch 1796 lr 0.013771594461142124\n",
      "train_loss 0.3402171359792949 train_acc 0.8499460637670845\n",
      "epoch 1797 lr 0.013744078797055815\n",
      "train_loss 0.34020969823635305 train_acc 0.8499127011487861\n",
      "epoch 1798 lr 0.013716618109303016\n",
      "train_loss 0.34020226778486484 train_acc 0.8499127011487861\n",
      "epoch 1799 lr 0.013689212288040948\n",
      "train_loss 0.34019482296931275 train_acc 0.8499127011487861\n",
      "\n",
      "val loss = 0.34376635573621905, \n",
      "val acc = 0.8493795036028823\n",
      "\n",
      "epoch 1800 lr 0.01366186122364628\n",
      "train_loss 0.340187375208891 train_acc 0.8499238220215523\n",
      "epoch 1801 lr 0.013634564806714726\n",
      "train_loss 0.34017993804364405 train_acc 0.8499460637670845\n",
      "epoch 1802 lr 0.013607322928060573\n",
      "train_loss 0.3401725202865798 train_acc 0.8499460637670845\n",
      "epoch 1803 lr 0.013580135478716282\n",
      "train_loss 0.34016511510467334 train_acc 0.8499571846398505\n",
      "epoch 1804 lr 0.013553002349932005\n",
      "train_loss 0.340157679540916 train_acc 0.8499794263853827\n",
      "epoch 1805 lr 0.013525923433175206\n",
      "train_loss 0.3401502391062297 train_acc 0.8499571846398505\n",
      "epoch 1806 lr 0.013498898620130168\n",
      "train_loss 0.3401428014443969 train_acc 0.8499571846398505\n",
      "epoch 1807 lr 0.013471927802697617\n",
      "train_loss 0.34013536424598656 train_acc 0.8499683055126166\n",
      "epoch 1808 lr 0.013445010872994231\n",
      "train_loss 0.34012794502798416 train_acc 0.8499571846398505\n",
      "epoch 1809 lr 0.013418147723352269\n",
      "train_loss 0.3401205166534479 train_acc 0.8499571846398505\n",
      "epoch 1810 lr 0.013391338246319088\n",
      "train_loss 0.3401131101842371 train_acc 0.8499460637670845\n",
      "epoch 1811 lr 0.01336458233465675\n",
      "train_loss 0.3401057327856649 train_acc 0.8499349428943184\n",
      "epoch 1812 lr 0.013337879881341566\n",
      "train_loss 0.340098376526144 train_acc 0.8499349428943184\n",
      "epoch 1813 lr 0.013311230779563697\n",
      "train_loss 0.34009101801225244 train_acc 0.8499349428943184\n",
      "epoch 1814 lr 0.013284634922726688\n",
      "train_loss 0.34008369725184673 train_acc 0.8499238220215523\n",
      "epoch 1815 lr 0.01325809220444709\n",
      "train_loss 0.3400763991100101 train_acc 0.8499238220215523\n",
      "epoch 1816 lr 0.013231602518553981\n",
      "train_loss 0.3400691087039654 train_acc 0.8499127011487861\n",
      "epoch 1817 lr 0.013205165759088594\n",
      "train_loss 0.3400617941140131 train_acc 0.8499127011487861\n",
      "epoch 1818 lr 0.013178781820303844\n",
      "train_loss 0.340054469886751 train_acc 0.8499238220215523\n",
      "epoch 1819 lr 0.013152450596663954\n",
      "train_loss 0.3400471489663181 train_acc 0.8499238220215523\n",
      "epoch 1820 lr 0.01312617198284398\n",
      "train_loss 0.34003982460288384 train_acc 0.8499127011487861\n",
      "epoch 1821 lr 0.013099945873729446\n",
      "train_loss 0.34003250322109957 train_acc 0.84990158027602\n",
      "epoch 1822 lr 0.013073772164415867\n",
      "train_loss 0.3400251833201195 train_acc 0.8499238220215523\n",
      "epoch 1823 lr 0.013047650750208382\n",
      "train_loss 0.34001786404977874 train_acc 0.8499238220215523\n",
      "epoch 1824 lr 0.01302158152662129\n",
      "train_loss 0.34001056820932035 train_acc 0.84990158027602\n",
      "epoch 1825 lr 0.012995564389377674\n",
      "train_loss 0.3400032960694869 train_acc 0.84990158027602\n",
      "epoch 1826 lr 0.012969599234408935\n",
      "train_loss 0.3399960068922184 train_acc 0.8498904594032539\n",
      "epoch 1827 lr 0.012943685957854433\n",
      "train_loss 0.3399887085101903 train_acc 0.8498904594032539\n",
      "epoch 1828 lr 0.012917824456061013\n",
      "train_loss 0.33998137634603687 train_acc 0.8498904594032539\n",
      "epoch 1829 lr 0.01289201462558265\n",
      "train_loss 0.3399740356121786 train_acc 0.8498904594032539\n",
      "epoch 1830 lr 0.012866256363179972\n",
      "train_loss 0.33996669875924623 train_acc 0.8498904594032539\n",
      "epoch 1831 lr 0.012840549565819906\n",
      "train_loss 0.3399593798294573 train_acc 0.8498570967849557\n",
      "epoch 1832 lr 0.01281489413067522\n",
      "train_loss 0.33995206631608144 train_acc 0.8498459759121896\n",
      "epoch 1833 lr 0.012789289955124147\n",
      "train_loss 0.3399447381646042 train_acc 0.8498348550394235\n",
      "epoch 1834 lr 0.012763736936749943\n",
      "train_loss 0.3399374252092798 train_acc 0.8498348550394235\n",
      "epoch 1835 lr 0.012738234973340508\n",
      "train_loss 0.3399301106447974 train_acc 0.8498459759121896\n",
      "epoch 1836 lr 0.012712783962887947\n",
      "train_loss 0.3399228065575749 train_acc 0.8498570967849557\n",
      "epoch 1837 lr 0.012687383803588193\n",
      "train_loss 0.3399155285940635 train_acc 0.8498793385304879\n",
      "epoch 1838 lr 0.012662034393840563\n",
      "train_loss 0.3399082664129017 train_acc 0.8498793385304879\n",
      "epoch 1839 lr 0.012636735632247398\n",
      "train_loss 0.33990101066183726 train_acc 0.8498682176577218\n",
      "epoch 1840 lr 0.012611487417613606\n",
      "train_loss 0.33989376177186376 train_acc 0.8498793385304879\n",
      "epoch 1841 lr 0.012586289648946303\n",
      "train_loss 0.33988651697970723 train_acc 0.8498682176577218\n",
      "epoch 1842 lr 0.012561142225454375\n",
      "train_loss 0.3398792714903218 train_acc 0.8498682176577218\n",
      "epoch 1843 lr 0.012536045046548101\n",
      "train_loss 0.33987204185453995 train_acc 0.8498682176577218\n",
      "epoch 1844 lr 0.012510998011838722\n",
      "train_loss 0.3398648155217816 train_acc 0.8498682176577218\n",
      "epoch 1845 lr 0.012486001021138077\n",
      "train_loss 0.33985761098822215 train_acc 0.8498793385304879\n",
      "epoch 1846 lr 0.01246105397445816\n",
      "train_loss 0.3398504065938758 train_acc 0.8498793385304879\n",
      "epoch 1847 lr 0.012436156772010761\n",
      "train_loss 0.33984319658432427 train_acc 0.8498793385304879\n",
      "epoch 1848 lr 0.012411309314207026\n",
      "train_loss 0.33983596817723444 train_acc 0.8498793385304879\n",
      "epoch 1849 lr 0.0123865115016571\n",
      "train_loss 0.339828742645354 train_acc 0.8498904594032539\n",
      "\n",
      "val loss = 0.3435612182182337, \n",
      "val acc = 0.8498799039231385\n",
      "\n",
      "epoch 1850 lr 0.012361763235169692\n",
      "train_loss 0.3398215415856835 train_acc 0.8498793385304879\n",
      "epoch 1851 lr 0.012337064415751714\n",
      "train_loss 0.33981437324554276 train_acc 0.8498682176577218\n",
      "epoch 1852 lr 0.01231241494460784\n",
      "train_loss 0.33980722016885745 train_acc 0.8498682176577218\n",
      "epoch 1853 lr 0.012287814723140169\n",
      "train_loss 0.3398000613762487 train_acc 0.8499127011487861\n",
      "epoch 1854 lr 0.012263263652947769\n",
      "train_loss 0.33979292770713604 train_acc 0.8499127011487861\n",
      "epoch 1855 lr 0.012238761635826335\n",
      "train_loss 0.3397858107174715 train_acc 0.84990158027602\n",
      "epoch 1856 lr 0.012214308573767757\n",
      "train_loss 0.3397787022224421 train_acc 0.8499238220215523\n",
      "epoch 1857 lr 0.012189904368959767\n",
      "train_loss 0.3397715663482193 train_acc 0.8499127011487861\n",
      "epoch 1858 lr 0.012165548923785501\n",
      "train_loss 0.3397644293897822 train_acc 0.8499238220215523\n",
      "epoch 1859 lr 0.012141242140823155\n",
      "train_loss 0.3397572828189321 train_acc 0.8499460637670845\n",
      "epoch 1860 lr 0.012116983922845556\n",
      "train_loss 0.3397501379135682 train_acc 0.8499571846398505\n",
      "epoch 1861 lr 0.01209277417281981\n",
      "train_loss 0.3397429988701423 train_acc 0.8499683055126166\n",
      "epoch 1862 lr 0.012068612793906872\n",
      "train_loss 0.3397358713469281 train_acc 0.8499571846398505\n",
      "epoch 1863 lr 0.012044499689461209\n",
      "train_loss 0.33972875005318004 train_acc 0.8499683055126166\n",
      "epoch 1864 lr 0.012020434763030358\n",
      "train_loss 0.3397216370190185 train_acc 0.8499571846398505\n",
      "epoch 1865 lr 0.011996417918354589\n",
      "train_loss 0.33971451233676825 train_acc 0.8499571846398505\n",
      "epoch 1866 lr 0.011972449059366484\n",
      "train_loss 0.33970739706076253 train_acc 0.8499683055126166\n",
      "epoch 1867 lr 0.011948528090190586\n",
      "train_loss 0.3397003106484531 train_acc 0.8499571846398505\n",
      "epoch 1868 lr 0.011924654915142973\n",
      "train_loss 0.33969321293401816 train_acc 0.8499683055126166\n",
      "epoch 1869 lr 0.011900829438730927\n",
      "train_loss 0.33968611206105614 train_acc 0.8499794263853827\n",
      "epoch 1870 lr 0.011877051565652498\n",
      "train_loss 0.3396790391645146 train_acc 0.8499683055126166\n",
      "epoch 1871 lr 0.011853321200796173\n",
      "train_loss 0.33967198042661 train_acc 0.8499905472581488\n",
      "epoch 1872 lr 0.011829638249240451\n",
      "train_loss 0.3396649142830314 train_acc 0.8500016681309149\n",
      "epoch 1873 lr 0.011806002616253503\n",
      "train_loss 0.33965783882742107 train_acc 0.8499905472581488\n",
      "epoch 1874 lr 0.011782414207292757\n",
      "train_loss 0.3396507497473366 train_acc 0.8499905472581488\n",
      "epoch 1875 lr 0.011758872928004555\n",
      "train_loss 0.3396436572068923 train_acc 0.8499905472581488\n",
      "epoch 1876 lr 0.011735378684223743\n",
      "train_loss 0.33963657533322267 train_acc 0.8499794263853827\n",
      "epoch 1877 lr 0.01171193138197331\n",
      "train_loss 0.3396294814489173 train_acc 0.8500016681309149\n",
      "epoch 1878 lr 0.011688530927464027\n",
      "train_loss 0.3396223975337402 train_acc 0.8500016681309149\n",
      "epoch 1879 lr 0.011665177227094032\n",
      "train_loss 0.3396153049108574 train_acc 0.8499683055126166\n",
      "epoch 1880 lr 0.011641870187448505\n",
      "train_loss 0.33960822746078145 train_acc 0.8499683055126166\n",
      "epoch 1881 lr 0.011618609715299244\n",
      "train_loss 0.3396011443750332 train_acc 0.8499905472581488\n",
      "epoch 1882 lr 0.011595395717604342\n",
      "train_loss 0.3395940504158582 train_acc 0.8499683055126166\n",
      "epoch 1883 lr 0.011572228101507766\n",
      "train_loss 0.3395869307289721 train_acc 0.8499460637670845\n",
      "epoch 1884 lr 0.01154910677433903\n",
      "train_loss 0.339579812785209 train_acc 0.8499571846398505\n",
      "epoch 1885 lr 0.011526031643612785\n",
      "train_loss 0.3395726861877901 train_acc 0.8499571846398505\n",
      "epoch 1886 lr 0.011503002617028489\n",
      "train_loss 0.3395655457795036 train_acc 0.8499238220215523\n",
      "epoch 1887 lr 0.011480019602469992\n",
      "train_loss 0.33955841371050577 train_acc 0.8499349428943184\n",
      "epoch 1888 lr 0.011457082508005216\n",
      "train_loss 0.33955129119643085 train_acc 0.8499238220215523\n",
      "epoch 1889 lr 0.011434191241885746\n",
      "train_loss 0.33954416634450024 train_acc 0.8499238220215523\n",
      "epoch 1890 lr 0.01141134571254649\n",
      "train_loss 0.33953705328905615 train_acc 0.8499349428943184\n",
      "epoch 1891 lr 0.011388545828605297\n",
      "train_loss 0.33952994980698614 train_acc 0.8499460637670845\n",
      "epoch 1892 lr 0.011365791498862608\n",
      "train_loss 0.33952284081551243 train_acc 0.8499571846398505\n",
      "epoch 1893 lr 0.011343082632301065\n",
      "train_loss 0.33951573274626073 train_acc 0.8499571846398505\n",
      "epoch 1894 lr 0.011320419138085179\n",
      "train_loss 0.3395086004103158 train_acc 0.8499683055126166\n",
      "epoch 1895 lr 0.011297800925560934\n",
      "train_loss 0.33950148745490216 train_acc 0.8499794263853827\n",
      "epoch 1896 lr 0.01127522790425546\n",
      "train_loss 0.339494402462997 train_acc 0.8499905472581488\n",
      "epoch 1897 lr 0.011252699983876631\n",
      "train_loss 0.33948731415845623 train_acc 0.8499794263853827\n",
      "epoch 1898 lr 0.011230217074312746\n",
      "train_loss 0.3394802128488016 train_acc 0.8499794263853827\n",
      "epoch 1899 lr 0.011207779085632127\n",
      "train_loss 0.33947311063333374 train_acc 0.8499571846398505\n",
      "\n",
      "val loss = 0.343361157029301, \n",
      "val acc = 0.8499799839871898\n",
      "\n",
      "epoch 1900 lr 0.0111853859280828\n",
      "train_loss 0.3394660041588952 train_acc 0.8499460637670845\n",
      "epoch 1901 lr 0.011163037512092095\n",
      "train_loss 0.3394588734823842 train_acc 0.8499460637670845\n",
      "epoch 1902 lr 0.011140733748266326\n",
      "train_loss 0.3394517447181016 train_acc 0.8499460637670845\n",
      "epoch 1903 lr 0.0111184745473904\n",
      "train_loss 0.33944462674066755 train_acc 0.8499349428943184\n",
      "epoch 1904 lr 0.011096259820427494\n",
      "train_loss 0.3394375268090982 train_acc 0.8499794263853827\n",
      "epoch 1905 lr 0.011074089478518657\n",
      "train_loss 0.33943043714065585 train_acc 0.8499794263853827\n",
      "epoch 1906 lr 0.011051963432982507\n",
      "train_loss 0.33942335270161783 train_acc 0.8499683055126166\n",
      "epoch 1907 lr 0.011029881595314818\n",
      "train_loss 0.339416304543622 train_acc 0.8499905472581488\n",
      "epoch 1908 lr 0.011007843877188223\n",
      "train_loss 0.3394092807884232 train_acc 0.8499905472581488\n",
      "epoch 1909 lr 0.010985850190451809\n",
      "train_loss 0.3394022844599418 train_acc 0.8500016681309149\n",
      "epoch 1910 lr 0.01096390044713081\n",
      "train_loss 0.3393953180296756 train_acc 0.8500016681309149\n",
      "epoch 1911 lr 0.010941994559426212\n",
      "train_loss 0.33938837725036824 train_acc 0.8500016681309149\n",
      "epoch 1912 lr 0.010920132439714446\n",
      "train_loss 0.33938146761358834 train_acc 0.8500016681309149\n",
      "epoch 1913 lr 0.010898314000546996\n",
      "train_loss 0.3393745443855586 train_acc 0.850012789003681\n",
      "epoch 1914 lr 0.010876539154650082\n",
      "train_loss 0.33936763799309727 train_acc 0.8500350307492132\n",
      "epoch 1915 lr 0.010854807814924285\n",
      "train_loss 0.3393607337479482 train_acc 0.8500461516219793\n",
      "epoch 1916 lr 0.010833119894444226\n",
      "train_loss 0.33935382144110177 train_acc 0.8500683933675115\n",
      "epoch 1917 lr 0.010811475306458183\n",
      "train_loss 0.33934689835530407 train_acc 0.8500461516219793\n",
      "epoch 1918 lr 0.010789873964387785\n",
      "train_loss 0.33933999044583607 train_acc 0.8500461516219793\n",
      "epoch 1919 lr 0.010768315781827627\n",
      "train_loss 0.33933309618214536 train_acc 0.8500461516219793\n",
      "epoch 1920 lr 0.010746800672544961\n",
      "train_loss 0.33932622473969554 train_acc 0.8500350307492132\n",
      "epoch 1921 lr 0.010725328550479307\n",
      "train_loss 0.33931936600739687 train_acc 0.8500795142402776\n",
      "epoch 1922 lr 0.010703899329742162\n",
      "train_loss 0.33931251893649833 train_acc 0.8500795142402776\n",
      "epoch 1923 lr 0.010682512924616602\n",
      "train_loss 0.33930568899127855 train_acc 0.8501017559858097\n",
      "epoch 1924 lr 0.010661169249556988\n",
      "train_loss 0.3392988810999029 train_acc 0.8500795142402776\n",
      "epoch 1925 lr 0.010639868219188582\n",
      "train_loss 0.33929207421622193 train_acc 0.8500683933675115\n",
      "epoch 1926 lr 0.010618609748307245\n",
      "train_loss 0.33928526714547474 train_acc 0.8500572724947454\n",
      "epoch 1927 lr 0.010597393751879056\n",
      "train_loss 0.3392784714051228 train_acc 0.8500683933675115\n",
      "epoch 1928 lr 0.010576220145040009\n",
      "train_loss 0.3392716990010009 train_acc 0.8500572724947454\n",
      "epoch 1929 lr 0.010555088843095637\n",
      "train_loss 0.33926494223441295 train_acc 0.8500683933675115\n",
      "epoch 1930 lr 0.010533999761520717\n",
      "train_loss 0.3392581868690176 train_acc 0.8500906351130437\n",
      "epoch 1931 lr 0.010512952815958883\n",
      "train_loss 0.3392514402593255 train_acc 0.8500906351130437\n",
      "epoch 1932 lr 0.010491947922222335\n",
      "train_loss 0.3392446672880786 train_acc 0.8501017559858097\n",
      "epoch 1933 lr 0.01047098499629146\n",
      "train_loss 0.33923788345508477 train_acc 0.8501128768585758\n",
      "epoch 1934 lr 0.010450063954314536\n",
      "train_loss 0.3392310912593412 train_acc 0.8501128768585758\n",
      "epoch 1935 lr 0.010429184712607358\n",
      "train_loss 0.3392242951800863 train_acc 0.8501017559858097\n",
      "epoch 1936 lr 0.010408347187652942\n",
      "train_loss 0.33921748641077715 train_acc 0.850123997731342\n",
      "epoch 1937 lr 0.010387551296101149\n",
      "train_loss 0.33921067307606384 train_acc 0.8501128768585758\n",
      "epoch 1938 lr 0.010366796954768396\n",
      "train_loss 0.33920388086886294 train_acc 0.8501351186041081\n",
      "epoch 1939 lr 0.010346084080637278\n",
      "train_loss 0.3391971033771538 train_acc 0.8501573603496403\n",
      "epoch 1940 lr 0.010325412590856283\n",
      "train_loss 0.3391903235830611 train_acc 0.8501351186041081\n",
      "epoch 1941 lr 0.010304782402739413\n",
      "train_loss 0.33918355058075356 train_acc 0.850123997731342\n",
      "epoch 1942 lr 0.0102841934337659\n",
      "train_loss 0.33917676992494167 train_acc 0.8501128768585758\n",
      "epoch 1943 lr 0.010263645601579828\n",
      "train_loss 0.33916997031667206 train_acc 0.850123997731342\n",
      "epoch 1944 lr 0.010243138823989853\n",
      "train_loss 0.3391631415020273 train_acc 0.8501351186041081\n",
      "epoch 1945 lr 0.010222673018968826\n",
      "train_loss 0.33915632610874985 train_acc 0.8501573603496403\n",
      "epoch 1946 lr 0.01020224810465351\n",
      "train_loss 0.33914951923613434 train_acc 0.8501573603496403\n",
      "epoch 1947 lr 0.010181863999344213\n",
      "train_loss 0.3391427276087356 train_acc 0.8501684812224063\n",
      "epoch 1948 lr 0.01016152062150449\n",
      "train_loss 0.33913592529830633 train_acc 0.8501796020951724\n",
      "epoch 1949 lr 0.0101412178897608\n",
      "train_loss 0.3391291340347665 train_acc 0.8501907229679385\n",
      "\n",
      "val loss = 0.34319263497316566, \n",
      "val acc = 0.8505804643714971\n",
      "\n",
      "epoch 1950 lr 0.010120955722902196\n",
      "train_loss 0.33912233291344285 train_acc 0.8502018438407046\n",
      "epoch 1951 lr 0.010100734039879971\n",
      "train_loss 0.339115530748098 train_acc 0.8502129647134707\n",
      "epoch 1952 lr 0.01008055275980738\n",
      "train_loss 0.3391087220668516 train_acc 0.8502129647134707\n",
      "epoch 1953 lr 0.010060411801959263\n",
      "train_loss 0.3391019109715803 train_acc 0.8502240855862369\n",
      "epoch 1954 lr 0.010040311085771771\n",
      "train_loss 0.3390950980736763 train_acc 0.8502352064590029\n",
      "epoch 1955 lr 0.010020250530842007\n",
      "train_loss 0.3390882722281044 train_acc 0.8502240855862369\n",
      "epoch 1956 lr 0.01000023005692773\n",
      "train_loss 0.3390814516327129 train_acc 0.8502240855862369\n",
      "epoch 1957 lr 0.00998024958394701\n",
      "train_loss 0.3390746482966935 train_acc 0.8502018438407046\n",
      "epoch 1958 lr 0.009960309031977938\n",
      "train_loss 0.33906786929104 train_acc 0.8502018438407046\n",
      "epoch 1959 lr 0.00994040832125827\n",
      "train_loss 0.33906111806403777 train_acc 0.8502240855862369\n",
      "epoch 1960 lr 0.009920547372185144\n",
      "train_loss 0.3390543860214416 train_acc 0.8502352064590029\n",
      "epoch 1961 lr 0.00990072610531473\n",
      "train_loss 0.3390476813730732 train_acc 0.8502129647134707\n",
      "epoch 1962 lr 0.009880944441361943\n",
      "train_loss 0.33904096149581914 train_acc 0.8502240855862369\n",
      "epoch 1963 lr 0.009861202301200092\n",
      "train_loss 0.3390342412482064 train_acc 0.850246327331769\n",
      "epoch 1964 lr 0.009841499605860598\n",
      "train_loss 0.3390275423430658 train_acc 0.8502685690773012\n",
      "epoch 1965 lr 0.009821836276532644\n",
      "train_loss 0.33902087596435654 train_acc 0.8502685690773012\n",
      "epoch 1966 lr 0.009802212234562898\n",
      "train_loss 0.33901422764117894 train_acc 0.8502685690773012\n",
      "epoch 1967 lr 0.009782627401455156\n",
      "train_loss 0.3390075811141064 train_acc 0.8502574482045351\n",
      "epoch 1968 lr 0.009763081698870066\n",
      "train_loss 0.3390009492421143 train_acc 0.850246327331769\n",
      "epoch 1969 lr 0.009743575048624786\n",
      "train_loss 0.33899433132151163 train_acc 0.850246327331769\n",
      "epoch 1970 lr 0.009724107372692695\n",
      "train_loss 0.3389877322787147 train_acc 0.8502685690773012\n",
      "epoch 1971 lr 0.009704678593203057\n",
      "train_loss 0.33898114834571785 train_acc 0.8502796899500673\n",
      "epoch 1972 lr 0.009685288632440735\n",
      "train_loss 0.3389746144189272 train_acc 0.8502796899500673\n",
      "epoch 1973 lr 0.009665937412845852\n",
      "train_loss 0.33896809179475856 train_acc 0.8502908108228334\n",
      "epoch 1974 lr 0.009646624857013513\n",
      "train_loss 0.3389615753338048 train_acc 0.8502908108228334\n",
      "epoch 1975 lr 0.00962735088769346\n",
      "train_loss 0.3389550724498262 train_acc 0.8502908108228334\n",
      "epoch 1976 lr 0.009608115427789799\n",
      "train_loss 0.3389485680694266 train_acc 0.8502796899500673\n",
      "epoch 1977 lr 0.009588918400360654\n",
      "train_loss 0.33894206036738017 train_acc 0.8502685690773012\n",
      "epoch 1978 lr 0.009569759728617901\n",
      "train_loss 0.33893555259855057 train_acc 0.8502685690773012\n",
      "epoch 1979 lr 0.009550639335926819\n",
      "train_loss 0.33892904111764044 train_acc 0.8502685690773012\n",
      "epoch 1980 lr 0.009531557145805818\n",
      "train_loss 0.3389225121854747 train_acc 0.8502685690773012\n",
      "epoch 1981 lr 0.009512513081926105\n",
      "train_loss 0.3389159589503376 train_acc 0.8502574482045351\n",
      "epoch 1982 lr 0.009493507068111407\n",
      "train_loss 0.3389094101081947 train_acc 0.8502574482045351\n",
      "epoch 1983 lr 0.009474539028337635\n",
      "train_loss 0.33890287123411655 train_acc 0.8502574482045351\n",
      "epoch 1984 lr 0.009455608886732613\n",
      "train_loss 0.33889633880645875 train_acc 0.8502908108228334\n",
      "epoch 1985 lr 0.009436716567575743\n",
      "train_loss 0.3388897986545551 train_acc 0.8503019316955994\n",
      "epoch 1986 lr 0.009417861995297728\n",
      "train_loss 0.3388832728613839 train_acc 0.8502908108228334\n",
      "epoch 1987 lr 0.009399045094480248\n",
      "train_loss 0.3388767517421819 train_acc 0.8502685690773012\n",
      "epoch 1988 lr 0.009380265789855681\n",
      "train_loss 0.3388702425784167 train_acc 0.8502574482045351\n",
      "epoch 1989 lr 0.009361524006306778\n",
      "train_loss 0.3388637225844958 train_acc 0.8502685690773012\n",
      "epoch 1990 lr 0.009342819668866386\n",
      "train_loss 0.33885721138167085 train_acc 0.8502240855862369\n",
      "epoch 1991 lr 0.009324152702717121\n",
      "train_loss 0.33885069355164454 train_acc 0.8502240855862369\n",
      "epoch 1992 lr 0.009305523033191106\n",
      "train_loss 0.33884418175441816 train_acc 0.8502240855862369\n",
      "epoch 1993 lr 0.009286930585769624\n",
      "train_loss 0.3388376807227161 train_acc 0.8502018438407046\n",
      "epoch 1994 lr 0.009268375286082873\n",
      "train_loss 0.3388311806000138 train_acc 0.8501907229679385\n",
      "epoch 1995 lr 0.009249857059909621\n",
      "train_loss 0.3388246894936889 train_acc 0.8502129647134707\n",
      "epoch 1996 lr 0.009231375833176944\n",
      "train_loss 0.338818203977854 train_acc 0.8502129647134707\n",
      "epoch 1997 lr 0.009212931531959906\n",
      "train_loss 0.3388117458768745 train_acc 0.8502129647134707\n",
      "epoch 1998 lr 0.009194524082481281\n",
      "train_loss 0.33880529636964785 train_acc 0.8502129647134707\n",
      "epoch 1999 lr 0.009176153411111243\n",
      "train_loss 0.33879884792677056 train_acc 0.8502574482045351\n",
      "\n",
      "val loss = 0.34303626857806235, \n",
      "val acc = 0.8507806244995997\n",
      "\n",
      "epoch 2000 lr 0.00915781944436709\n",
      "train_loss 0.33879240164614566 train_acc 0.850246327331769\n",
      "epoch 2001 lr 0.009139522108912923\n",
      "train_loss 0.3387859586727235 train_acc 0.8502685690773012\n",
      "epoch 2002 lr 0.009121261331559377\n",
      "train_loss 0.3387795121231367 train_acc 0.8502796899500673\n",
      "epoch 2003 lr 0.009103037039263313\n",
      "train_loss 0.3387730676615042 train_acc 0.8502685690773012\n",
      "epoch 2004 lr 0.00908484915912755\n",
      "train_loss 0.3387666222127923 train_acc 0.8502908108228334\n",
      "epoch 2005 lr 0.009066697618400538\n",
      "train_loss 0.3387601945581504 train_acc 0.8503019316955994\n",
      "epoch 2006 lr 0.009048582344476088\n",
      "train_loss 0.33875377504336796 train_acc 0.8503352943138978\n",
      "epoch 2007 lr 0.009030503264893072\n",
      "train_loss 0.33874735873559036 train_acc 0.8503241734411316\n",
      "epoch 2008 lr 0.009012460307335164\n",
      "train_loss 0.3387409451566213 train_acc 0.8503130525683655\n",
      "epoch 2009 lr 0.008994453399630502\n",
      "train_loss 0.33873452637913076 train_acc 0.8503130525683655\n",
      "epoch 2010 lr 0.008976482469751431\n",
      "train_loss 0.33872809971573825 train_acc 0.8503130525683655\n",
      "epoch 2011 lr 0.0089585474458142\n",
      "train_loss 0.3387216847734881 train_acc 0.8502908108228334\n",
      "epoch 2012 lr 0.008940648256078706\n",
      "train_loss 0.33871529479568535 train_acc 0.8503130525683655\n",
      "epoch 2013 lr 0.008922784828948156\n",
      "train_loss 0.33870891000800396 train_acc 0.8503464151866639\n",
      "epoch 2014 lr 0.00890495709296882\n",
      "train_loss 0.33870251076225416 train_acc 0.8503352943138978\n",
      "epoch 2015 lr 0.008887164976829722\n",
      "train_loss 0.3386961013777848 train_acc 0.8503352943138978\n",
      "epoch 2016 lr 0.008869408409362387\n",
      "train_loss 0.338689696449189 train_acc 0.850368656932196\n",
      "epoch 2017 lr 0.008851687319540516\n",
      "train_loss 0.33868329013421866 train_acc 0.85035753605943\n",
      "epoch 2018 lr 0.008834001636479724\n",
      "train_loss 0.33867690064532724 train_acc 0.85035753605943\n",
      "epoch 2019 lr 0.00881635128943725\n",
      "train_loss 0.33867052361585936 train_acc 0.8504020195504943\n",
      "epoch 2020 lr 0.008798736207811696\n",
      "train_loss 0.3386641480501159 train_acc 0.8504020195504943\n",
      "epoch 2021 lr 0.008781156321142706\n",
      "train_loss 0.33865775903360007 train_acc 0.8504020195504943\n",
      "epoch 2022 lr 0.008763611559110708\n",
      "train_loss 0.33865138431621056 train_acc 0.8503797778049621\n",
      "epoch 2023 lr 0.008746101851536623\n",
      "train_loss 0.33864502746602904 train_acc 0.8504020195504943\n",
      "epoch 2024 lr 0.008728627128381615\n",
      "train_loss 0.33863867222707794 train_acc 0.8503908986777282\n",
      "epoch 2025 lr 0.008711187319746757\n",
      "train_loss 0.3386323150246485 train_acc 0.8503908986777282\n",
      "epoch 2026 lr 0.008693782355872794\n",
      "train_loss 0.33862595789055683 train_acc 0.8503797778049621\n",
      "epoch 2027 lr 0.008676412167139838\n",
      "train_loss 0.33861963857094174 train_acc 0.8503908986777282\n",
      "epoch 2028 lr 0.008659076684067128\n",
      "train_loss 0.33861333763780826 train_acc 0.8503908986777282\n",
      "epoch 2029 lr 0.008641775837312697\n",
      "train_loss 0.33860705523862866 train_acc 0.8503797778049621\n",
      "epoch 2030 lr 0.00862450955767314\n",
      "train_loss 0.33860077279386913 train_acc 0.8504020195504943\n",
      "epoch 2031 lr 0.008607277776083305\n",
      "train_loss 0.3385944985456731 train_acc 0.8503908986777282\n",
      "epoch 2032 lr 0.008590080423616057\n",
      "train_loss 0.33858822471555 train_acc 0.8503797778049621\n",
      "epoch 2033 lr 0.008572917431481959\n",
      "train_loss 0.3385819441981788 train_acc 0.8503797778049621\n",
      "epoch 2034 lr 0.008555788731029015\n",
      "train_loss 0.3385756739448158 train_acc 0.8504020195504943\n",
      "epoch 2035 lr 0.008538694253742398\n",
      "train_loss 0.33856941256372947 train_acc 0.8504353821687926\n",
      "epoch 2036 lr 0.008521633931244187\n",
      "train_loss 0.33856314361948103 train_acc 0.8504465030415587\n",
      "epoch 2037 lr 0.008504607695293062\n",
      "train_loss 0.33855686971699245 train_acc 0.8504465030415587\n",
      "epoch 2038 lr 0.00848761547778406\n",
      "train_loss 0.3385505863028339 train_acc 0.8504576239143248\n",
      "epoch 2039 lr 0.008470657210748276\n",
      "train_loss 0.3385443255699641 train_acc 0.8504576239143248\n",
      "epoch 2040 lr 0.008453732826352638\n",
      "train_loss 0.33853809223850045 train_acc 0.8504687447870909\n",
      "epoch 2041 lr 0.008436842256899576\n",
      "train_loss 0.3385318543963925 train_acc 0.8504909865326231\n",
      "epoch 2042 lr 0.008419985434826792\n",
      "train_loss 0.33852562337277686 train_acc 0.8504909865326231\n",
      "epoch 2043 lr 0.008403162292706967\n",
      "train_loss 0.3385194074723167 train_acc 0.850479865659857\n",
      "epoch 2044 lr 0.008386372763247524\n",
      "train_loss 0.3385131961643841 train_acc 0.850479865659857\n",
      "epoch 2045 lr 0.008369616779290316\n",
      "train_loss 0.3385069811785311 train_acc 0.8505021074053892\n",
      "epoch 2046 lr 0.008352894273811385\n",
      "train_loss 0.3385007618251506 train_acc 0.850479865659857\n",
      "epoch 2047 lr 0.008336205179920677\n",
      "train_loss 0.3384945408072241 train_acc 0.8504687447870909\n",
      "epoch 2048 lr 0.008319549430861812\n",
      "train_loss 0.33848833790746063 train_acc 0.8504687447870909\n",
      "epoch 2049 lr 0.008302926960011765\n",
      "train_loss 0.33848215527561804 train_acc 0.8504576239143248\n",
      "\n",
      "val loss = 0.34289800695955047, \n",
      "val acc = 0.8505804643714971\n",
      "\n",
      "epoch 2050 lr 0.008286337700880626\n",
      "train_loss 0.33847598235268994 train_acc 0.850479865659857\n",
      "epoch 2051 lr 0.008269781587111332\n",
      "train_loss 0.3384697795603625 train_acc 0.8504909865326231\n",
      "epoch 2052 lr 0.008253258552479421\n",
      "train_loss 0.33846360258473585 train_acc 0.8504909865326231\n",
      "epoch 2053 lr 0.008236768530892724\n",
      "train_loss 0.33845743669856254 train_acc 0.8505021074053892\n",
      "epoch 2054 lr 0.008220311456391134\n",
      "train_loss 0.338451280383025 train_acc 0.8505021074053892\n",
      "epoch 2055 lr 0.008203887263146322\n",
      "train_loss 0.33844513494867573 train_acc 0.8504909865326231\n",
      "epoch 2056 lr 0.008187495885461507\n",
      "train_loss 0.33843898540481704 train_acc 0.850479865659857\n",
      "epoch 2057 lr 0.008171137257771152\n",
      "train_loss 0.3384328541221929 train_acc 0.8504909865326231\n",
      "epoch 2058 lr 0.008154811314640725\n",
      "train_loss 0.3384267339911264 train_acc 0.8505021074053892\n",
      "epoch 2059 lr 0.00813851799076642\n",
      "train_loss 0.33842062490663377 train_acc 0.8505021074053892\n",
      "epoch 2060 lr 0.008122257220974935\n",
      "train_loss 0.33841450576288773 train_acc 0.8505132282781552\n",
      "epoch 2061 lr 0.008106028940223166\n",
      "train_loss 0.3384083880174137 train_acc 0.8505354700236875\n",
      "epoch 2062 lr 0.008089833083597965\n",
      "train_loss 0.33840225159585285 train_acc 0.8505688326419858\n",
      "epoch 2063 lr 0.008073669586315878\n",
      "train_loss 0.33839611962208943 train_acc 0.8505577117692197\n",
      "epoch 2064 lr 0.008057538383722907\n",
      "train_loss 0.338389978587356 train_acc 0.8505465908964536\n",
      "epoch 2065 lr 0.008041439411294217\n",
      "train_loss 0.33838382524225946 train_acc 0.8505465908964536\n",
      "epoch 2066 lr 0.008025372604633893\n",
      "train_loss 0.33837766954169657 train_acc 0.8505577117692197\n",
      "epoch 2067 lr 0.008009337899474679\n",
      "train_loss 0.3383715372980828 train_acc 0.8505799535147518\n",
      "epoch 2068 lr 0.00799333523167775\n",
      "train_loss 0.33836543865335283 train_acc 0.850602195260284\n",
      "epoch 2069 lr 0.007977364537232407\n",
      "train_loss 0.3383593422764799 train_acc 0.8505910743875179\n",
      "epoch 2070 lr 0.007961425752255849\n",
      "train_loss 0.33835326022361334 train_acc 0.8505799535147518\n",
      "epoch 2071 lr 0.007945518812992908\n",
      "train_loss 0.3383472076136694 train_acc 0.8505910743875179\n",
      "epoch 2072 lr 0.007929643655815818\n",
      "train_loss 0.33834116243115275 train_acc 0.8505799535147518\n",
      "epoch 2073 lr 0.007913800217223927\n",
      "train_loss 0.33833511567228763 train_acc 0.8505910743875179\n",
      "epoch 2074 lr 0.007897988433843456\n",
      "train_loss 0.33832909453826265 train_acc 0.850602195260284\n",
      "epoch 2075 lr 0.007882208242427243\n",
      "train_loss 0.33832308017005064 train_acc 0.850602195260284\n",
      "epoch 2076 lr 0.007866459579854516\n",
      "train_loss 0.3383170788979496 train_acc 0.8506133161330501\n",
      "epoch 2077 lr 0.007850742383130598\n",
      "train_loss 0.3383111101650819 train_acc 0.8506355578785824\n",
      "epoch 2078 lr 0.00783505658938668\n",
      "train_loss 0.3383051529878693 train_acc 0.8506244370058162\n",
      "epoch 2079 lr 0.007819402135879559\n",
      "train_loss 0.33829919569845335 train_acc 0.8506244370058162\n",
      "epoch 2080 lr 0.007803778959991416\n",
      "train_loss 0.33829324528062393 train_acc 0.8506577996241145\n",
      "epoch 2081 lr 0.007788186999229517\n",
      "train_loss 0.3382872995248554 train_acc 0.8506466787513484\n",
      "epoch 2082 lr 0.007772626191225999\n",
      "train_loss 0.3382813451267088 train_acc 0.8506466787513484\n",
      "epoch 2083 lr 0.007757096473737602\n",
      "train_loss 0.33827538674611685 train_acc 0.8506466787513484\n",
      "epoch 2084 lr 0.0077415977846454495\n",
      "train_loss 0.338269400932799 train_acc 0.8506466787513484\n",
      "epoch 2085 lr 0.0077261300619547585\n",
      "train_loss 0.3382634122543984 train_acc 0.8506244370058162\n",
      "epoch 2086 lr 0.007710693243794617\n",
      "train_loss 0.33825742380358303 train_acc 0.8506355578785824\n",
      "epoch 2087 lr 0.007695287268417724\n",
      "train_loss 0.3382514446777985 train_acc 0.8506577996241145\n",
      "epoch 2088 lr 0.007679912074200172\n",
      "train_loss 0.33824544886707697 train_acc 0.8506689204968806\n",
      "epoch 2089 lr 0.007664567599641157\n",
      "train_loss 0.33823944661222316 train_acc 0.8506355578785824\n",
      "epoch 2090 lr 0.00764925378336276\n",
      "train_loss 0.33823343625937247 train_acc 0.8506689204968806\n",
      "epoch 2091 lr 0.007633970564109688\n",
      "train_loss 0.33822741638416715 train_acc 0.8506689204968806\n",
      "epoch 2092 lr 0.007618717880749058\n",
      "train_loss 0.33822139506131005 train_acc 0.8506800413696467\n",
      "epoch 2093 lr 0.00760349567227011\n",
      "train_loss 0.3382153681144105 train_acc 0.8506911622424128\n",
      "epoch 2094 lr 0.007588303877783989\n",
      "train_loss 0.3382093561426963 train_acc 0.8506800413696467\n",
      "epoch 2095 lr 0.00757314243652349\n",
      "train_loss 0.3382033712376177 train_acc 0.8507022831151789\n",
      "epoch 2096 lr 0.0075580112878428415\n",
      "train_loss 0.33819738701041324 train_acc 0.850724524860711\n",
      "epoch 2097 lr 0.007542910371217421\n",
      "train_loss 0.3381914065593999 train_acc 0.8507356457334772\n",
      "epoch 2098 lr 0.007527839626243543\n",
      "train_loss 0.3381854371183222 train_acc 0.8507578874790094\n",
      "epoch 2099 lr 0.0075127989926382\n",
      "train_loss 0.33817950063791474 train_acc 0.8507801292245415\n",
      "\n",
      "val loss = 0.34277677509623744, \n",
      "val acc = 0.850480384307446\n",
      "\n",
      "epoch 2100 lr 0.0074977884102388525\n",
      "train_loss 0.3381735710286901 train_acc 0.8507690083517755\n",
      "epoch 2101 lr 0.0074828078190031415\n",
      "train_loss 0.3381676147786865 train_acc 0.8507690083517755\n",
      "epoch 2102 lr 0.007467857159008684\n",
      "train_loss 0.33816163857483145 train_acc 0.8507801292245415\n",
      "epoch 2103 lr 0.007452936370452814\n",
      "train_loss 0.3381556605061375 train_acc 0.8507912500973076\n",
      "epoch 2104 lr 0.007438045393652368\n",
      "train_loss 0.33814969148526014 train_acc 0.8508023709700737\n",
      "epoch 2105 lr 0.007423184169043416\n",
      "train_loss 0.33814371588486614 train_acc 0.8507912500973076\n",
      "epoch 2106 lr 0.007408352637181036\n",
      "train_loss 0.3381377301276503 train_acc 0.8508023709700737\n",
      "epoch 2107 lr 0.007393550738739077\n",
      "train_loss 0.3381317626554697 train_acc 0.8508134918428398\n",
      "epoch 2108 lr 0.0073787784145099376\n",
      "train_loss 0.33812578003875193 train_acc 0.8508246127156059\n",
      "epoch 2109 lr 0.007364035605404294\n",
      "train_loss 0.3381197824784112 train_acc 0.8508246127156059\n",
      "epoch 2110 lr 0.007349322252450892\n",
      "train_loss 0.33811380184913653 train_acc 0.8508357335883721\n",
      "epoch 2111 lr 0.007334638296796291\n",
      "train_loss 0.33810780889648634 train_acc 0.8508468544611381\n",
      "epoch 2112 lr 0.007319983679704664\n",
      "train_loss 0.3381018084302364 train_acc 0.8508690962066703\n",
      "epoch 2113 lr 0.007305358342557515\n",
      "train_loss 0.33809582494552015 train_acc 0.8508690962066703\n",
      "epoch 2114 lr 0.007290762226853477\n",
      "train_loss 0.33808984247212837 train_acc 0.8508468544611381\n",
      "epoch 2115 lr 0.007276195274208062\n",
      "train_loss 0.3380838582102254 train_acc 0.8508357335883721\n",
      "epoch 2116 lr 0.00726165742635345\n",
      "train_loss 0.3380778692628103 train_acc 0.8508468544611381\n",
      "epoch 2117 lr 0.007247148625138227\n",
      "train_loss 0.3380718714537718 train_acc 0.8508802170794364\n",
      "epoch 2118 lr 0.007232668812527167\n",
      "train_loss 0.33806589071482246 train_acc 0.8508802170794364\n",
      "epoch 2119 lr 0.0072182179306009946\n",
      "train_loss 0.3380599390282678 train_acc 0.8508802170794364\n",
      "epoch 2120 lr 0.007203795921556175\n",
      "train_loss 0.33805401973132004 train_acc 0.8508468544611381\n",
      "epoch 2121 lr 0.007189402727704647\n",
      "train_loss 0.33804808552589866 train_acc 0.8508357335883721\n",
      "epoch 2122 lr 0.007175038291473615\n",
      "train_loss 0.33804216129371945 train_acc 0.8508357335883721\n",
      "epoch 2123 lr 0.00716070255540531\n",
      "train_loss 0.3380362470669904 train_acc 0.8508357335883721\n",
      "epoch 2124 lr 0.0071463954621567806\n",
      "train_loss 0.3380303456563493 train_acc 0.8508579753339042\n",
      "epoch 2125 lr 0.007132116954499628\n",
      "train_loss 0.33802445800361736 train_acc 0.8508690962066703\n",
      "epoch 2126 lr 0.007117866975319803\n",
      "train_loss 0.3380185700222885 train_acc 0.8508802170794364\n",
      "epoch 2127 lr 0.007103645467617369\n",
      "train_loss 0.33801268751107716 train_acc 0.8508802170794364\n",
      "epoch 2128 lr 0.007089452374506271\n",
      "train_loss 0.33800678068372497 train_acc 0.8508579753339042\n",
      "epoch 2129 lr 0.007075287639214131\n",
      "train_loss 0.3380008594930444 train_acc 0.8508579753339042\n",
      "epoch 2130 lr 0.007061151205081981\n",
      "train_loss 0.33799493452997587 train_acc 0.8508690962066703\n",
      "epoch 2131 lr 0.007047043015564066\n",
      "train_loss 0.3379890099298348 train_acc 0.8508579753339042\n",
      "epoch 2132 lr 0.007032963014227603\n",
      "train_loss 0.3379831103725845 train_acc 0.8508579753339042\n",
      "epoch 2133 lr 0.007018911144752581\n",
      "train_loss 0.3379772261251852 train_acc 0.8508468544611381\n",
      "epoch 2134 lr 0.007004887350931495\n",
      "train_loss 0.33797135420479524 train_acc 0.8508468544611381\n",
      "epoch 2135 lr 0.006990891576669154\n",
      "train_loss 0.337965481471613 train_acc 0.8508690962066703\n",
      "epoch 2136 lr 0.006976923765982434\n",
      "train_loss 0.3379595997066062 train_acc 0.8508690962066703\n",
      "epoch 2137 lr 0.006962983863000087\n",
      "train_loss 0.33795372435800086 train_acc 0.8508690962066703\n",
      "epoch 2138 lr 0.006949071811962477\n",
      "train_loss 0.3379478353855007 train_acc 0.8508579753339042\n",
      "epoch 2139 lr 0.006935187557221378\n",
      "train_loss 0.3379419481029208 train_acc 0.8508690962066703\n",
      "epoch 2140 lr 0.0069213310432397505\n",
      "train_loss 0.3379360795770904 train_acc 0.8508579753339042\n",
      "epoch 2141 lr 0.00690750221459153\n",
      "train_loss 0.3379302203506123 train_acc 0.8508690962066703\n",
      "epoch 2142 lr 0.0068937010159613775\n",
      "train_loss 0.33792436553517524 train_acc 0.8508579753339042\n",
      "epoch 2143 lr 0.006879927392144481\n",
      "train_loss 0.3379185131416287 train_acc 0.8508802170794364\n",
      "epoch 2144 lr 0.00686618128804632\n",
      "train_loss 0.3379126584523319 train_acc 0.8508802170794364\n",
      "epoch 2145 lr 0.0068524626486824725\n",
      "train_loss 0.33790680998468503 train_acc 0.8508690962066703\n",
      "epoch 2146 lr 0.006838771419178356\n",
      "train_loss 0.33790097136076863 train_acc 0.8508579753339042\n",
      "epoch 2147 lr 0.006825107544769034\n",
      "train_loss 0.3378951480987268 train_acc 0.8508690962066703\n",
      "epoch 2148 lr 0.006811470970798986\n",
      "train_loss 0.3378893382898808 train_acc 0.8508579753339042\n",
      "epoch 2149 lr 0.006797861642721909\n",
      "train_loss 0.33788351721166415 train_acc 0.8508690962066703\n",
      "\n",
      "val loss = 0.3426774406382516, \n",
      "val acc = 0.8506805444355484\n",
      "\n",
      "epoch 2150 lr 0.006784279506100467\n",
      "train_loss 0.33787771015287904 train_acc 0.8509024588249686\n",
      "epoch 2151 lr 0.006770724506606094\n",
      "train_loss 0.3378719168595263 train_acc 0.8508802170794364\n",
      "epoch 2152 lr 0.006757196590018771\n",
      "train_loss 0.3378661046287018 train_acc 0.8508802170794364\n",
      "epoch 2153 lr 0.006743695702226822\n",
      "train_loss 0.3378602982941529 train_acc 0.8509024588249686\n",
      "epoch 2154 lr 0.006730221789226674\n",
      "train_loss 0.33785448964152875 train_acc 0.8508913379522025\n",
      "epoch 2155 lr 0.006716774797122657\n",
      "train_loss 0.3378486663056549 train_acc 0.8509135796977346\n",
      "epoch 2156 lr 0.006703354672126778\n",
      "train_loss 0.33784284275450177 train_acc 0.8509358214432668\n",
      "epoch 2157 lr 0.00668996136055853\n",
      "train_loss 0.337837032057703 train_acc 0.8509135796977346\n",
      "epoch 2158 lr 0.006676594808844646\n",
      "train_loss 0.33783122729057424 train_acc 0.8509247005705007\n",
      "epoch 2159 lr 0.006663254963518899\n",
      "train_loss 0.337825428151104 train_acc 0.8509247005705007\n",
      "epoch 2160 lr 0.006649941771221884\n",
      "train_loss 0.33781963499379225 train_acc 0.8509247005705007\n",
      "epoch 2161 lr 0.006636655178700826\n",
      "train_loss 0.3378138647946022 train_acc 0.8509247005705007\n",
      "epoch 2162 lr 0.006623395132809333\n",
      "train_loss 0.3378080926071638 train_acc 0.8508913379522025\n",
      "epoch 2163 lr 0.006610161580507201\n",
      "train_loss 0.337802318038866 train_acc 0.8508802170794364\n",
      "epoch 2164 lr 0.006596954468860199\n",
      "train_loss 0.33779654451233354 train_acc 0.8509024588249686\n",
      "epoch 2165 lr 0.0065837737450398755\n",
      "train_loss 0.33779077670152263 train_acc 0.8508690962066703\n",
      "epoch 2166 lr 0.006570619356323309\n",
      "train_loss 0.33778501329890276 train_acc 0.8508802170794364\n",
      "epoch 2167 lr 0.00655749125009293\n",
      "train_loss 0.337779237077812 train_acc 0.8508802170794364\n",
      "epoch 2168 lr 0.006544389373836289\n",
      "train_loss 0.33777346056845603 train_acc 0.8508690962066703\n",
      "epoch 2169 lr 0.006531313675145874\n",
      "train_loss 0.33776770243865406 train_acc 0.8508802170794364\n",
      "epoch 2170 lr 0.006518264101718868\n",
      "train_loss 0.33776193592769066 train_acc 0.8508802170794364\n",
      "epoch 2171 lr 0.00650524060135696\n",
      "train_loss 0.3377561725314769 train_acc 0.8508913379522025\n",
      "epoch 2172 lr 0.0064922431219661255\n",
      "train_loss 0.3377503825103705 train_acc 0.8508913379522025\n",
      "epoch 2173 lr 0.006479271611556441\n",
      "train_loss 0.3377445611765793 train_acc 0.8508913379522025\n",
      "epoch 2174 lr 0.006466326018241842\n",
      "train_loss 0.33773874532551645 train_acc 0.8509024588249686\n",
      "epoch 2175 lr 0.006453406290239937\n",
      "train_loss 0.3377329539368199 train_acc 0.8509358214432668\n",
      "epoch 2176 lr 0.006440512375871792\n",
      "train_loss 0.33772716824227467 train_acc 0.8509247005705007\n",
      "epoch 2177 lr 0.0064276442235617435\n",
      "train_loss 0.3377213769551065 train_acc 0.8509358214432668\n",
      "epoch 2178 lr 0.00641480178183716\n",
      "train_loss 0.33771559223256464 train_acc 0.850946942316033\n",
      "epoch 2179 lr 0.006401984999328256\n",
      "train_loss 0.3377098019431433 train_acc 0.850946942316033\n",
      "epoch 2180 lr 0.00638919382476788\n",
      "train_loss 0.3377040227569444 train_acc 0.8509580631887991\n",
      "epoch 2181 lr 0.0063764282069913285\n",
      "train_loss 0.3376982395074846 train_acc 0.850946942316033\n",
      "epoch 2182 lr 0.006363688094936106\n",
      "train_loss 0.3376924585764306 train_acc 0.8509803049343313\n",
      "epoch 2183 lr 0.006350973437641749\n",
      "train_loss 0.33768667120533874 train_acc 0.8510025466798634\n",
      "epoch 2184 lr 0.006338284184249604\n",
      "train_loss 0.3376808724773259 train_acc 0.8510025466798634\n",
      "epoch 2185 lr 0.006325620284002653\n",
      "train_loss 0.3376750706776279 train_acc 0.8509914258070973\n",
      "epoch 2186 lr 0.006312981686245271\n",
      "train_loss 0.33766927052931167 train_acc 0.8510025466798634\n",
      "epoch 2187 lr 0.006300368340423053\n",
      "train_loss 0.3376634595461428 train_acc 0.8510136675526295\n",
      "epoch 2188 lr 0.006287780196082591\n",
      "train_loss 0.33765765552636284 train_acc 0.8510136675526295\n",
      "epoch 2189 lr 0.006275217202871303\n",
      "train_loss 0.3376518303202939 train_acc 0.8510136675526295\n",
      "epoch 2190 lr 0.0062626793105371925\n",
      "train_loss 0.3376459948074788 train_acc 0.8510247884253956\n",
      "epoch 2191 lr 0.006250166468928675\n",
      "train_loss 0.33764016692628745 train_acc 0.8510025466798634\n",
      "epoch 2192 lr 0.006237678627994361\n",
      "train_loss 0.33763434634512024 train_acc 0.8510581510436939\n",
      "epoch 2193 lr 0.006225215737782882\n",
      "train_loss 0.3376285431998184 train_acc 0.8510915136619922\n",
      "epoch 2194 lr 0.006212777748442653\n",
      "train_loss 0.33762276050921153 train_acc 0.8510915136619922\n",
      "epoch 2195 lr 0.006200364610221703\n",
      "train_loss 0.337617006808711 train_acc 0.8510915136619922\n",
      "epoch 2196 lr 0.006187976273467455\n",
      "train_loss 0.33761126187438867 train_acc 0.8510915136619922\n",
      "epoch 2197 lr 0.006175612688626557\n",
      "train_loss 0.337605545397846 train_acc 0.8511026345347583\n",
      "epoch 2198 lr 0.006163273806244648\n",
      "train_loss 0.337599821656802 train_acc 0.8510915136619922\n",
      "epoch 2199 lr 0.0061509595769661815\n",
      "train_loss 0.33759409253220285 train_acc 0.8510915136619922\n",
      "\n",
      "val loss = 0.3425742442885448, \n",
      "val acc = 0.8512810248198559\n",
      "\n",
      "epoch 2200 lr 0.006138669951534218\n",
      "train_loss 0.3375883837049077 train_acc 0.8511026345347583\n",
      "epoch 2201 lr 0.006126404880790252\n",
      "train_loss 0.3375826787198041 train_acc 0.8511026345347583\n",
      "epoch 2202 lr 0.006114164315673977\n",
      "train_loss 0.337576999453983 train_acc 0.8511026345347583\n",
      "epoch 2203 lr 0.006101948207223117\n",
      "train_loss 0.3375713548481737 train_acc 0.8510915136619922\n",
      "epoch 2204 lr 0.0060897565065732165\n",
      "train_loss 0.33756571284443015 train_acc 0.8511137554075244\n",
      "epoch 2205 lr 0.006077589164957467\n",
      "train_loss 0.3375600794922933 train_acc 0.8511137554075244\n",
      "epoch 2206 lr 0.006065446133706482\n",
      "train_loss 0.3375544556948831 train_acc 0.8511471180258227\n",
      "epoch 2207 lr 0.006053327364248118\n",
      "train_loss 0.33754882933672137 train_acc 0.8511582388985888\n",
      "epoch 2208 lr 0.006041232808107277\n",
      "train_loss 0.33754321794757686 train_acc 0.8511582388985888\n",
      "epoch 2209 lr 0.006029162416905729\n",
      "train_loss 0.33753762603984533 train_acc 0.8511582388985888\n",
      "epoch 2210 lr 0.006017116142361887\n",
      "train_loss 0.33753202992780584 train_acc 0.851180480644121\n",
      "epoch 2211 lr 0.006005093936290638\n",
      "train_loss 0.3375264385601551 train_acc 0.8511693597713549\n",
      "epoch 2212 lr 0.005993095750603136\n",
      "train_loss 0.337520849640368 train_acc 0.851180480644121\n",
      "epoch 2213 lr 0.005981121537306631\n",
      "train_loss 0.33751528300843936 train_acc 0.851191601516887\n",
      "epoch 2214 lr 0.005969171248504251\n",
      "train_loss 0.33750969902768746 train_acc 0.851191601516887\n",
      "epoch 2215 lr 0.005957244836394824\n",
      "train_loss 0.3375041120161173 train_acc 0.851191601516887\n",
      "epoch 2216 lr 0.005945342253272679\n",
      "train_loss 0.33749852916894046 train_acc 0.851191601516887\n",
      "epoch 2217 lr 0.005933463451527481\n",
      "train_loss 0.3374929287587626 train_acc 0.8512027223896531\n",
      "epoch 2218 lr 0.0059216083836439995\n",
      "train_loss 0.33748732315686375 train_acc 0.8512027223896531\n",
      "epoch 2219 lr 0.005909777002201948\n",
      "train_loss 0.3374816906042293 train_acc 0.851191601516887\n",
      "epoch 2220 lr 0.005897969259875781\n",
      "train_loss 0.33747602215376926 train_acc 0.8512027223896531\n",
      "epoch 2221 lr 0.005886185109434522\n",
      "train_loss 0.33747033442065555 train_acc 0.851191601516887\n",
      "epoch 2222 lr 0.005874424503741549\n",
      "train_loss 0.33746461474529876 train_acc 0.8511471180258227\n",
      "epoch 2223 lr 0.005862687395754423\n",
      "train_loss 0.33745885760613986 train_acc 0.8511359971530565\n",
      "epoch 2224 lr 0.005850973738524692\n",
      "train_loss 0.3374531082467788 train_acc 0.8511471180258227\n",
      "epoch 2225 lr 0.005839283485197722\n",
      "train_loss 0.33744737649795864 train_acc 0.8511359971530565\n",
      "epoch 2226 lr 0.0058276165890124776\n",
      "train_loss 0.3374416547474104 train_acc 0.8511471180258227\n",
      "epoch 2227 lr 0.00581597300330136\n",
      "train_loss 0.3374359747896302 train_acc 0.8511471180258227\n",
      "epoch 2228 lr 0.0058043526814900055\n",
      "train_loss 0.3374302979273081 train_acc 0.8511471180258227\n",
      "epoch 2229 lr 0.005792755577097121\n",
      "train_loss 0.33742460735935975 train_acc 0.8511693597713549\n",
      "epoch 2230 lr 0.005781181643734268\n",
      "train_loss 0.3374189230709769 train_acc 0.8511693597713549\n",
      "epoch 2231 lr 0.0057696308351056986\n",
      "train_loss 0.3374132466164154 train_acc 0.8511693597713549\n",
      "epoch 2232 lr 0.005758103105008158\n",
      "train_loss 0.33740758359470213 train_acc 0.851180480644121\n",
      "epoch 2233 lr 0.00574659840733072\n",
      "train_loss 0.3374019249303544 train_acc 0.851180480644121\n",
      "epoch 2234 lr 0.005735116696054572\n",
      "train_loss 0.33739628786461373 train_acc 0.851180480644121\n",
      "epoch 2235 lr 0.005723657925252856\n",
      "train_loss 0.33739066355393776 train_acc 0.8511693597713549\n",
      "epoch 2236 lr 0.005712222049090467\n",
      "train_loss 0.3373850405442523 train_acc 0.851180480644121\n",
      "epoch 2237 lr 0.005700809021823896\n",
      "train_loss 0.33737940352352075 train_acc 0.851180480644121\n",
      "epoch 2238 lr 0.0056894187978010135\n",
      "train_loss 0.3373737686208688 train_acc 0.851180480644121\n",
      "epoch 2239 lr 0.005678051331460908\n",
      "train_loss 0.3373681494325205 train_acc 0.8512138432624192\n",
      "epoch 2240 lr 0.005666706577333694\n",
      "train_loss 0.33736251803160006 train_acc 0.8512027223896531\n",
      "epoch 2241 lr 0.005655384490040351\n",
      "train_loss 0.3373569014478442 train_acc 0.8512138432624192\n",
      "epoch 2242 lr 0.005644085024292507\n",
      "train_loss 0.3373513051483319 train_acc 0.8512249641351853\n",
      "epoch 2243 lr 0.005632808134892286\n",
      "train_loss 0.33734569278706317 train_acc 0.8512360850079514\n",
      "epoch 2244 lr 0.0056215537767321105\n",
      "train_loss 0.3373400649310359 train_acc 0.8512249641351853\n",
      "epoch 2245 lr 0.005610321904794542\n",
      "train_loss 0.33733443760313236 train_acc 0.8512360850079514\n",
      "epoch 2246 lr 0.005599112474152073\n",
      "train_loss 0.33732881302286605 train_acc 0.8512138432624192\n",
      "epoch 2247 lr 0.005587925439966967\n",
      "train_loss 0.33732317420423 train_acc 0.8512583267534836\n",
      "epoch 2248 lr 0.005576760757491066\n",
      "train_loss 0.3373175392044846 train_acc 0.8512583267534836\n",
      "epoch 2249 lr 0.005565618382065635\n",
      "train_loss 0.33731190677416323 train_acc 0.8512583267534836\n",
      "\n",
      "val loss = 0.3424647471484883, \n",
      "val acc = 0.850880704563651\n",
      "\n",
      "epoch 2250 lr 0.005554498269121154\n",
      "train_loss 0.3373062741357713 train_acc 0.8512694476262497\n",
      "epoch 2251 lr 0.005543400374177155\n",
      "train_loss 0.3373006503784648 train_acc 0.8512805684990158\n",
      "epoch 2252 lr 0.005532324652842043\n",
      "train_loss 0.33729502538766765 train_acc 0.851302810244548\n",
      "epoch 2253 lr 0.005521271060812915\n",
      "train_loss 0.33728939670217306 train_acc 0.851302810244548\n",
      "epoch 2254 lr 0.005510239553875396\n",
      "train_loss 0.33728379583207796 train_acc 0.8513250519900801\n",
      "epoch 2255 lr 0.0054992300879034405\n",
      "train_loss 0.3372782001697772 train_acc 0.8513250519900801\n",
      "epoch 2256 lr 0.005488242618859169\n",
      "train_loss 0.33727259684518074 train_acc 0.851302810244548\n",
      "epoch 2257 lr 0.005477277102792685\n",
      "train_loss 0.3372669935076776 train_acc 0.8512916893717819\n",
      "epoch 2258 lr 0.00546633349584192\n",
      "train_loss 0.3372614090772255 train_acc 0.8512916893717819\n",
      "epoch 2259 lr 0.005455411754232427\n",
      "train_loss 0.33725583683267085 train_acc 0.8512805684990158\n",
      "epoch 2260 lr 0.005444511834277225\n",
      "train_loss 0.3372502719821422 train_acc 0.851302810244548\n",
      "epoch 2261 lr 0.005433633692376615\n",
      "train_loss 0.3372447248789587 train_acc 0.8513250519900801\n",
      "epoch 2262 lr 0.005422777285018023\n",
      "train_loss 0.3372391819177327 train_acc 0.8513361728628462\n",
      "epoch 2263 lr 0.005411942568775803\n",
      "train_loss 0.33723363505277937 train_acc 0.8513139311173141\n",
      "epoch 2264 lr 0.005401129500311073\n",
      "train_loss 0.3372280771331206 train_acc 0.8513139311173141\n",
      "epoch 2265 lr 0.005390338036371541\n",
      "train_loss 0.33722251157464567 train_acc 0.8513250519900801\n",
      "epoch 2266 lr 0.005379568133791346\n",
      "train_loss 0.3372169283808367 train_acc 0.8513584146083785\n",
      "epoch 2267 lr 0.00536881974949086\n",
      "train_loss 0.33721132193833714 train_acc 0.8513584146083785\n",
      "epoch 2268 lr 0.0053580928404765304\n",
      "train_loss 0.3372057054693394 train_acc 0.8513695354811446\n",
      "epoch 2269 lr 0.005347387363840701\n",
      "train_loss 0.33720006543314696 train_acc 0.8513472937356124\n",
      "epoch 2270 lr 0.005336703276761463\n",
      "train_loss 0.33719444089300504 train_acc 0.8513472937356124\n",
      "epoch 2271 lr 0.005326040536502446\n",
      "train_loss 0.3371888238868428 train_acc 0.8513250519900801\n",
      "epoch 2272 lr 0.0053153991004126775\n",
      "train_loss 0.33718322242644044 train_acc 0.8513472937356124\n",
      "epoch 2273 lr 0.005304778925926392\n",
      "train_loss 0.33717762465302126 train_acc 0.8513250519900801\n",
      "epoch 2274 lr 0.005294179970562889\n",
      "train_loss 0.3371720251374761 train_acc 0.8513472937356124\n",
      "epoch 2275 lr 0.005283602191926327\n",
      "train_loss 0.3371664124262177 train_acc 0.8513695354811446\n",
      "epoch 2276 lr 0.0052730455477055784\n",
      "train_loss 0.3371607956863106 train_acc 0.8513917772266768\n",
      "epoch 2277 lr 0.005262509995674045\n",
      "train_loss 0.33715518002448963 train_acc 0.8513806563539107\n",
      "epoch 2278 lr 0.005251995493689517\n",
      "train_loss 0.3371495676463769 train_acc 0.8513695354811446\n",
      "epoch 2279 lr 0.005241501999693966\n",
      "train_loss 0.33714394780978757 train_acc 0.8513917772266768\n",
      "epoch 2280 lr 0.005231029471713402\n",
      "train_loss 0.3371383403985096 train_acc 0.8513695354811446\n",
      "epoch 2281 lr 0.005220577867857695\n",
      "train_loss 0.3371327403828985 train_acc 0.8513361728628462\n",
      "epoch 2282 lr 0.005210147146320425\n",
      "train_loss 0.33712714208590755 train_acc 0.8513472937356124\n",
      "epoch 2283 lr 0.005199737265378687\n",
      "train_loss 0.3371215071652927 train_acc 0.8513361728628462\n",
      "epoch 2284 lr 0.005189348183392944\n",
      "train_loss 0.33711584677979217 train_acc 0.8513472937356124\n",
      "epoch 2285 lr 0.005178979858806848\n",
      "train_loss 0.33711016996363297 train_acc 0.8513361728628462\n",
      "epoch 2286 lr 0.005168632250147098\n",
      "train_loss 0.3371044742597415 train_acc 0.8513361728628462\n",
      "epoch 2287 lr 0.00515830531602324\n",
      "train_loss 0.3370987856626419 train_acc 0.8513250519900801\n",
      "epoch 2288 lr 0.005147999015127524\n",
      "train_loss 0.33709309499154455 train_acc 0.8513139311173141\n",
      "epoch 2289 lr 0.005137713306234727\n",
      "train_loss 0.3370874077415061 train_acc 0.851302810244548\n",
      "epoch 2290 lr 0.005127448148202011\n",
      "train_loss 0.33708174823462306 train_acc 0.851302810244548\n",
      "epoch 2291 lr 0.005117203499968724\n",
      "train_loss 0.3370760980583468 train_acc 0.8513250519900801\n",
      "epoch 2292 lr 0.00510697932055626\n",
      "train_loss 0.33707040241808456 train_acc 0.8513250519900801\n",
      "epoch 2293 lr 0.005096775569067883\n",
      "train_loss 0.33706472682515515 train_acc 0.8513250519900801\n",
      "epoch 2294 lr 0.005086592204688581\n",
      "train_loss 0.3370590982023289 train_acc 0.8513250519900801\n",
      "epoch 2295 lr 0.0050764291866848815\n",
      "train_loss 0.33705349869793105 train_acc 0.8513250519900801\n",
      "epoch 2296 lr 0.005066286474404697\n",
      "train_loss 0.3370479285893372 train_acc 0.8513361728628462\n",
      "epoch 2297 lr 0.005056164027277161\n",
      "train_loss 0.3370423890754347 train_acc 0.8513584146083785\n",
      "epoch 2298 lr 0.00504606180481248\n",
      "train_loss 0.33703686815864503 train_acc 0.8513361728628462\n",
      "epoch 2299 lr 0.005035979766601745\n",
      "train_loss 0.3370313404180098 train_acc 0.8513250519900801\n",
      "\n",
      "val loss = 0.34235573006566145, \n",
      "val acc = 0.8510808646917534\n",
      "\n",
      "epoch 2300 lr 0.005025917872316792\n",
      "train_loss 0.3370258054097374 train_acc 0.8513139311173141\n",
      "epoch 2301 lr 0.005015876081710026\n",
      "train_loss 0.3370202905060105 train_acc 0.8513139311173141\n",
      "epoch 2302 lr 0.005005854354614278\n",
      "train_loss 0.3370147833214122 train_acc 0.851302810244548\n",
      "epoch 2303 lr 0.004995852650942623\n",
      "train_loss 0.3370092727847578 train_acc 0.8512916893717819\n",
      "epoch 2304 lr 0.004985870930688233\n",
      "train_loss 0.33700377503293716 train_acc 0.8512694476262497\n",
      "epoch 2305 lr 0.00497590915392421\n",
      "train_loss 0.33699828547128685 train_acc 0.8512694476262497\n",
      "epoch 2306 lr 0.00496596728080344\n",
      "train_loss 0.3369928018107225 train_acc 0.8512583267534836\n",
      "epoch 2307 lr 0.004956045271558416\n",
      "train_loss 0.33698730936879345 train_acc 0.8512916893717819\n",
      "epoch 2308 lr 0.004946143086501086\n",
      "train_loss 0.33698180765476843 train_acc 0.8513139311173141\n",
      "epoch 2309 lr 0.004936260686022691\n",
      "train_loss 0.33697630821134233 train_acc 0.8513139311173141\n",
      "epoch 2310 lr 0.004926398030593628\n",
      "train_loss 0.3369708001255711 train_acc 0.8513250519900801\n",
      "epoch 2311 lr 0.004916555080763255\n",
      "train_loss 0.3369652912020836 train_acc 0.8513250519900801\n",
      "epoch 2312 lr 0.004906731797159761\n",
      "train_loss 0.3369597664998196 train_acc 0.8513250519900801\n",
      "epoch 2313 lr 0.004896928140489993\n",
      "train_loss 0.3369542376706322 train_acc 0.8513361728628462\n",
      "epoch 2314 lr 0.004887144071539321\n",
      "train_loss 0.336948727627708 train_acc 0.8513472937356124\n",
      "epoch 2315 lr 0.004877379551171452\n",
      "train_loss 0.33694320700789065 train_acc 0.8513695354811446\n",
      "epoch 2316 lr 0.004867634540328289\n",
      "train_loss 0.33693768587891176 train_acc 0.8513584146083785\n",
      "epoch 2317 lr 0.0048579090000297745\n",
      "train_loss 0.33693218067762243 train_acc 0.8513472937356124\n",
      "epoch 2318 lr 0.0048482028913737416\n",
      "train_loss 0.3369266627567934 train_acc 0.8513361728628462\n",
      "epoch 2319 lr 0.004838516175535739\n",
      "train_loss 0.3369211287551868 train_acc 0.8513361728628462\n",
      "epoch 2320 lr 0.004828848813768888\n",
      "train_loss 0.3369155913062877 train_acc 0.8513139311173141\n",
      "epoch 2321 lr 0.004819200767403728\n",
      "train_loss 0.3369100350718774 train_acc 0.851302810244548\n",
      "epoch 2322 lr 0.004809571997848067\n",
      "train_loss 0.3369044732850651 train_acc 0.851302810244548\n",
      "epoch 2323 lr 0.00479996246658681\n",
      "train_loss 0.33689889777098236 train_acc 0.8512916893717819\n",
      "epoch 2324 lr 0.004790372135181819\n",
      "train_loss 0.33689334598737614 train_acc 0.8512583267534836\n",
      "epoch 2325 lr 0.004780800965271752\n",
      "train_loss 0.3368878043179167 train_acc 0.8512583267534836\n",
      "epoch 2326 lr 0.004771248918571925\n",
      "train_loss 0.3368822589663599 train_acc 0.8512583267534836\n",
      "epoch 2327 lr 0.0047617159568741334\n",
      "train_loss 0.33687673014379416 train_acc 0.8512583267534836\n",
      "epoch 2328 lr 0.004752202042046519\n",
      "train_loss 0.3368712125452342 train_acc 0.8512583267534836\n",
      "epoch 2329 lr 0.004742707136033404\n",
      "train_loss 0.33686570645792596 train_acc 0.8512694476262497\n",
      "epoch 2330 lr 0.0047332312008551616\n",
      "train_loss 0.33686020927392024 train_acc 0.8512916893717819\n",
      "epoch 2331 lr 0.004723774198608033\n",
      "train_loss 0.33685470855283967 train_acc 0.8512916893717819\n",
      "epoch 2332 lr 0.004714336091463997\n",
      "train_loss 0.3368492267683258 train_acc 0.8512805684990158\n",
      "epoch 2333 lr 0.00470491684167061\n",
      "train_loss 0.3368437528201787 train_acc 0.8512805684990158\n",
      "epoch 2334 lr 0.004695516411550866\n",
      "train_loss 0.3368382568248422 train_acc 0.8512916893717819\n",
      "epoch 2335 lr 0.004686134763503029\n",
      "train_loss 0.3368327739212562 train_acc 0.8512916893717819\n",
      "epoch 2336 lr 0.004676771860000493\n",
      "train_loss 0.3368272967358485 train_acc 0.8512916893717819\n",
      "epoch 2337 lr 0.0046674276635916305\n",
      "train_loss 0.33682182193464366 train_acc 0.8513250519900801\n",
      "epoch 2338 lr 0.004658102136899649\n",
      "train_loss 0.3368163693309997 train_acc 0.8513250519900801\n",
      "epoch 2339 lr 0.0046487952426224255\n",
      "train_loss 0.33681092038554006 train_acc 0.8513361728628462\n",
      "epoch 2340 lr 0.004639506943532371\n",
      "train_loss 0.33680546086746316 train_acc 0.8513472937356124\n",
      "epoch 2341 lr 0.004630237202476273\n",
      "train_loss 0.3367999942485078 train_acc 0.8513472937356124\n",
      "epoch 2342 lr 0.004620985982375162\n",
      "train_loss 0.33679454453970714 train_acc 0.8513806563539107\n",
      "epoch 2343 lr 0.004611753246224142\n",
      "train_loss 0.3367890912141812 train_acc 0.8513917772266768\n",
      "epoch 2344 lr 0.004602538957092257\n",
      "train_loss 0.33678367007445875 train_acc 0.8513695354811446\n",
      "epoch 2345 lr 0.004593343078122332\n",
      "train_loss 0.33677826569099245 train_acc 0.8513584146083785\n",
      "epoch 2346 lr 0.004584165572530848\n",
      "train_loss 0.3367728723064752 train_acc 0.8513695354811446\n",
      "epoch 2347 lr 0.0045750064036077665\n",
      "train_loss 0.336767500191081 train_acc 0.8513695354811446\n",
      "epoch 2348 lr 0.004565865534716399\n",
      "train_loss 0.33676213829256824 train_acc 0.8513361728628462\n",
      "epoch 2349 lr 0.004556742929293255\n",
      "train_loss 0.3367567644816243 train_acc 0.8513361728628462\n",
      "\n",
      "val loss = 0.3422526301495398, \n",
      "val acc = 0.8517814251401121\n",
      "\n",
      "epoch 2350 lr 0.004547638550847908\n",
      "train_loss 0.3367514014641894 train_acc 0.8513361728628462\n",
      "epoch 2351 lr 0.004538552362962827\n",
      "train_loss 0.33674604273756786 train_acc 0.8513139311173141\n",
      "epoch 2352 lr 0.004529484329293249\n",
      "train_loss 0.33674068446435435 train_acc 0.8513139311173141\n",
      "epoch 2353 lr 0.004520434413567025\n",
      "train_loss 0.3367353306896161 train_acc 0.851302810244548\n",
      "epoch 2354 lr 0.004511402579584485\n",
      "train_loss 0.3367299828193548 train_acc 0.8512916893717819\n",
      "epoch 2355 lr 0.004502388791218279\n",
      "train_loss 0.33672466402488177 train_acc 0.8513139311173141\n",
      "epoch 2356 lr 0.0044933930124132415\n",
      "train_loss 0.33671934811434084 train_acc 0.8513361728628462\n",
      "epoch 2357 lr 0.004484415207186241\n",
      "train_loss 0.33671404689603407 train_acc 0.8513472937356124\n",
      "epoch 2358 lr 0.004475455339626052\n",
      "train_loss 0.3367087652947433 train_acc 0.8513695354811446\n",
      "epoch 2359 lr 0.004466513373893188\n",
      "train_loss 0.3367034844656963 train_acc 0.8513806563539107\n",
      "epoch 2360 lr 0.004457589274219776\n",
      "train_loss 0.33669819036719195 train_acc 0.8513917772266768\n",
      "epoch 2361 lr 0.0044486830049094\n",
      "train_loss 0.33669289643752076 train_acc 0.8513806563539107\n",
      "epoch 2362 lr 0.0044397945303369804\n",
      "train_loss 0.33668761018486315 train_acc 0.8513695354811446\n",
      "epoch 2363 lr 0.004430923814948601\n",
      "train_loss 0.3366823195342908 train_acc 0.8513584146083785\n",
      "epoch 2364 lr 0.004422070823261388\n",
      "train_loss 0.3366770304863461 train_acc 0.8513472937356124\n",
      "epoch 2365 lr 0.004413235519863361\n",
      "train_loss 0.3366717531025293 train_acc 0.8513472937356124\n",
      "epoch 2366 lr 0.0044044178694133025\n",
      "train_loss 0.3366664857914843 train_acc 0.8513472937356124\n",
      "epoch 2367 lr 0.004395617836640594\n",
      "train_loss 0.33666121349936723 train_acc 0.8513361728628462\n",
      "epoch 2368 lr 0.004386835386345092\n",
      "train_loss 0.3366559352390747 train_acc 0.8513250519900801\n",
      "epoch 2369 lr 0.004378070483396981\n",
      "train_loss 0.33665067300393997 train_acc 0.8513361728628462\n",
      "epoch 2370 lr 0.004369323092736645\n",
      "train_loss 0.3366454165809892 train_acc 0.8513361728628462\n",
      "epoch 2371 lr 0.004360593179374506\n",
      "train_loss 0.3366401408975954 train_acc 0.8513139311173141\n",
      "epoch 2372 lr 0.004351880708390899\n",
      "train_loss 0.33663485228598905 train_acc 0.8513584146083785\n",
      "epoch 2373 lr 0.004343185644935923\n",
      "train_loss 0.3366295671611355 train_acc 0.8513584146083785\n",
      "epoch 2374 lr 0.004334507954229322\n",
      "train_loss 0.3366242769739046 train_acc 0.8513584146083785\n",
      "epoch 2375 lr 0.004325847601560317\n",
      "train_loss 0.3366190116987939 train_acc 0.8513472937356124\n",
      "epoch 2376 lr 0.004317204552287486\n",
      "train_loss 0.3366137553384134 train_acc 0.8513917772266768\n",
      "epoch 2377 lr 0.004308578771838621\n",
      "train_loss 0.3366085035264611 train_acc 0.8513806563539107\n",
      "epoch 2378 lr 0.004299970225710584\n",
      "train_loss 0.3366032610352234 train_acc 0.8513695354811446\n",
      "epoch 2379 lr 0.004291378879469188\n",
      "train_loss 0.3365980450860196 train_acc 0.8513695354811446\n",
      "epoch 2380 lr 0.00428280469874903\n",
      "train_loss 0.336592844674554 train_acc 0.8513695354811446\n",
      "epoch 2381 lr 0.004274247649253379\n",
      "train_loss 0.33658764699086935 train_acc 0.8513806563539107\n",
      "epoch 2382 lr 0.004265707696754019\n",
      "train_loss 0.33658245342893856 train_acc 0.8513806563539107\n",
      "epoch 2383 lr 0.004257184807091138\n",
      "train_loss 0.33657724936005246 train_acc 0.8513806563539107\n",
      "epoch 2384 lr 0.004248678946173161\n",
      "train_loss 0.33657205689115266 train_acc 0.8513806563539107\n",
      "epoch 2385 lr 0.004240190079976634\n",
      "train_loss 0.3365668943321144 train_acc 0.8513917772266768\n",
      "epoch 2386 lr 0.004231718174546076\n",
      "train_loss 0.33656175995403637 train_acc 0.8513917772266768\n",
      "epoch 2387 lr 0.004223263195993863\n",
      "train_loss 0.3365566312062477 train_acc 0.8514028980994428\n",
      "epoch 2388 lr 0.004214825110500065\n",
      "train_loss 0.33655151419978363 train_acc 0.8513806563539107\n",
      "epoch 2389 lr 0.004206403884312329\n",
      "train_loss 0.3365464067355498 train_acc 0.8513917772266768\n",
      "epoch 2390 lr 0.004197999483745735\n",
      "train_loss 0.33654130967590606 train_acc 0.8513806563539107\n",
      "epoch 2391 lr 0.0041896118751826765\n",
      "train_loss 0.33653622071315487 train_acc 0.8513695354811446\n",
      "epoch 2392 lr 0.004181241025072706\n",
      "train_loss 0.33653114587398986 train_acc 0.8513806563539107\n",
      "epoch 2393 lr 0.00417288689993241\n",
      "train_loss 0.33652607085007935 train_acc 0.8513806563539107\n",
      "epoch 2394 lr 0.004164549466345273\n",
      "train_loss 0.33652100120695827 train_acc 0.8513806563539107\n",
      "epoch 2395 lr 0.004156228690961559\n",
      "train_loss 0.3365159321406032 train_acc 0.8513806563539107\n",
      "epoch 2396 lr 0.0041479245404981505\n",
      "train_loss 0.33651085644315554 train_acc 0.8513695354811446\n",
      "epoch 2397 lr 0.004139636981738434\n",
      "train_loss 0.3365057545255162 train_acc 0.8513695354811446\n",
      "epoch 2398 lr 0.004131365981532161\n",
      "train_loss 0.3365006404183364 train_acc 0.8513695354811446\n",
      "epoch 2399 lr 0.004123111506795325\n",
      "train_loss 0.3364955054732719 train_acc 0.8513695354811446\n",
      "\n",
      "val loss = 0.3421729785290682, \n",
      "val acc = 0.8522818254603683\n",
      "\n",
      "epoch 2400 lr 0.004114873524510015\n",
      "train_loss 0.33649036419024686 train_acc 0.8513584146083785\n",
      "epoch 2401 lr 0.004106652001724289\n",
      "train_loss 0.3364852238887462 train_acc 0.8513695354811446\n",
      "epoch 2402 lr 0.004098446905552042\n",
      "train_loss 0.3364801066130897 train_acc 0.8513584146083785\n",
      "epoch 2403 lr 0.004090258203172885\n",
      "train_loss 0.33647499835327604 train_acc 0.8513584146083785\n",
      "epoch 2404 lr 0.004082085861831995\n",
      "train_loss 0.3364699000101805 train_acc 0.8513584146083785\n",
      "epoch 2405 lr 0.004073929848839994\n",
      "train_loss 0.33646477824287835 train_acc 0.8513584146083785\n",
      "epoch 2406 lr 0.004065790131572818\n",
      "train_loss 0.33645964613421353 train_acc 0.8513584146083785\n",
      "epoch 2407 lr 0.004057666677471592\n",
      "train_loss 0.3364545219855932 train_acc 0.8513584146083785\n",
      "epoch 2408 lr 0.004049559454042487\n",
      "train_loss 0.3364494101516162 train_acc 0.8513695354811446\n",
      "epoch 2409 lr 0.004041468428856596\n",
      "train_loss 0.33644431187529183 train_acc 0.8513695354811446\n",
      "epoch 2410 lr 0.004033393569549807\n",
      "train_loss 0.3364392132779667 train_acc 0.8513584146083785\n",
      "epoch 2411 lr 0.004025334843822678\n",
      "train_loss 0.33643412083433566 train_acc 0.8513584146083785\n",
      "epoch 2412 lr 0.00401729221944029\n",
      "train_loss 0.33642901573415335 train_acc 0.8513472937356124\n",
      "epoch 2413 lr 0.004009265664232137\n",
      "train_loss 0.33642389952157414 train_acc 0.8513472937356124\n",
      "epoch 2414 lr 0.004001255146091983\n",
      "train_loss 0.3364187709783187 train_acc 0.8513361728628462\n",
      "epoch 2415 lr 0.003993260632977751\n",
      "train_loss 0.3364136437066879 train_acc 0.8513361728628462\n",
      "epoch 2416 lr 0.003985282092911376\n",
      "train_loss 0.33640852798540916 train_acc 0.8513250519900801\n",
      "epoch 2417 lr 0.003977319493978686\n",
      "train_loss 0.3364034244860975 train_acc 0.8513250519900801\n",
      "epoch 2418 lr 0.003969372804329272\n",
      "train_loss 0.3363983397247038 train_acc 0.8513139311173141\n",
      "epoch 2419 lr 0.003961441992176371\n",
      "train_loss 0.3363932657554785 train_acc 0.8513139311173141\n",
      "epoch 2420 lr 0.003953527025796721\n",
      "train_loss 0.3363881940221579 train_acc 0.8513139311173141\n",
      "epoch 2421 lr 0.003945627873530445\n",
      "train_loss 0.33638312523678854 train_acc 0.8513250519900801\n",
      "epoch 2422 lr 0.003937744503780921\n",
      "train_loss 0.33637806897911854 train_acc 0.851302810244548\n",
      "epoch 2423 lr 0.003929876885014665\n",
      "train_loss 0.336373032847889 train_acc 0.8512916893717819\n",
      "epoch 2424 lr 0.00392202498576119\n",
      "train_loss 0.3363680090380523 train_acc 0.8512805684990158\n",
      "epoch 2425 lr 0.003914188774612887\n",
      "train_loss 0.33636299976983963 train_acc 0.8512694476262497\n",
      "epoch 2426 lr 0.003906368220224898\n",
      "train_loss 0.33635798599274896 train_acc 0.8512472058807176\n",
      "epoch 2427 lr 0.0038985632913150024\n",
      "train_loss 0.33635295239899093 train_acc 0.8512472058807176\n",
      "epoch 2428 lr 0.003890773956663469\n",
      "train_loss 0.3363479299773802 train_acc 0.8512472058807176\n",
      "epoch 2429 lr 0.0038830001851129507\n",
      "train_loss 0.33634290425358676 train_acc 0.8512694476262497\n",
      "epoch 2430 lr 0.0038752419455683465\n",
      "train_loss 0.336337882740322 train_acc 0.8512805684990158\n",
      "epoch 2431 lr 0.003867499206996695\n",
      "train_loss 0.33633285100259297 train_acc 0.8512916893717819\n",
      "epoch 2432 lr 0.003859771938427028\n",
      "train_loss 0.3363278262710871 train_acc 0.851302810244548\n",
      "epoch 2433 lr 0.003852060108950261\n",
      "train_loss 0.33632280926658237 train_acc 0.8513139311173141\n",
      "epoch 2434 lr 0.003844363687719063\n",
      "train_loss 0.33631781560894325 train_acc 0.8513139311173141\n",
      "epoch 2435 lr 0.0038366826439477446\n",
      "train_loss 0.3363128126977093 train_acc 0.851302810244548\n",
      "epoch 2436 lr 0.003829016946912118\n",
      "train_loss 0.3363078133569948 train_acc 0.8512916893717819\n",
      "epoch 2437 lr 0.0038213665659493842\n",
      "train_loss 0.3363028077340849 train_acc 0.8513139311173141\n",
      "epoch 2438 lr 0.0038137314704580058\n",
      "train_loss 0.3362977986348861 train_acc 0.8513250519900801\n",
      "epoch 2439 lr 0.0038061116298975977\n",
      "train_loss 0.33629278863192996 train_acc 0.8513250519900801\n",
      "epoch 2440 lr 0.003798507013788784\n",
      "train_loss 0.3362877882809751 train_acc 0.8513361728628462\n",
      "epoch 2441 lr 0.00379091759171309\n",
      "train_loss 0.3362828025138535 train_acc 0.8513250519900801\n",
      "epoch 2442 lr 0.003783343333312814\n",
      "train_loss 0.33627784511209197 train_acc 0.8513139311173141\n",
      "epoch 2443 lr 0.0037757842082909196\n",
      "train_loss 0.3362728986926005 train_acc 0.851302810244548\n",
      "epoch 2444 lr 0.0037682401864108923\n",
      "train_loss 0.33626795821560646 train_acc 0.8513250519900801\n",
      "epoch 2445 lr 0.003760711237496635\n",
      "train_loss 0.3362630024027972 train_acc 0.8513361728628462\n",
      "epoch 2446 lr 0.003753197331432339\n",
      "train_loss 0.3362580282713383 train_acc 0.8513250519900801\n",
      "epoch 2447 lr 0.0037456984381623757\n",
      "train_loss 0.3362530473336443 train_acc 0.8513250519900801\n",
      "epoch 2448 lr 0.0037382145276911596\n",
      "train_loss 0.3362480665683029 train_acc 0.8513139311173141\n",
      "epoch 2449 lr 0.0037307455700830387\n",
      "train_loss 0.3362431120848195 train_acc 0.8512916893717819\n",
      "\n",
      "val loss = 0.34211256893334113, \n",
      "val acc = 0.8521817453963171\n",
      "\n",
      "epoch 2450 lr 0.003723291535462169\n",
      "train_loss 0.3362381624810308 train_acc 0.8513139311173141\n",
      "epoch 2451 lr 0.003715852394012409\n",
      "train_loss 0.3362332092441539 train_acc 0.851302810244548\n",
      "epoch 2452 lr 0.0037084281159771794\n",
      "train_loss 0.33622824950505886 train_acc 0.8513139311173141\n",
      "epoch 2453 lr 0.0037010186716593583\n",
      "train_loss 0.3362232826525445 train_acc 0.851302810244548\n",
      "epoch 2454 lr 0.003693624031421155\n",
      "train_loss 0.33621833559832703 train_acc 0.8512916893717819\n",
      "epoch 2455 lr 0.0036862441656840056\n",
      "train_loss 0.3362134112028498 train_acc 0.8513139311173141\n",
      "epoch 2456 lr 0.003678879044928434\n",
      "train_loss 0.3362084749823785 train_acc 0.851302810244548\n",
      "epoch 2457 lr 0.003671528639693948\n",
      "train_loss 0.33620353114454765 train_acc 0.851302810244548\n",
      "epoch 2458 lr 0.003664192920578912\n",
      "train_loss 0.33619858942342273 train_acc 0.8513139311173141\n",
      "epoch 2459 lr 0.0036568718582404474\n",
      "train_loss 0.3361936609178271 train_acc 0.8513139311173141\n",
      "epoch 2460 lr 0.0036495654233942914\n",
      "train_loss 0.336188736611352 train_acc 0.8513250519900801\n",
      "epoch 2461 lr 0.003642273586814695\n",
      "train_loss 0.3361838354681325 train_acc 0.8513139311173141\n",
      "epoch 2462 lr 0.0036349963193342996\n",
      "train_loss 0.33617894553725375 train_acc 0.8513250519900801\n",
      "epoch 2463 lr 0.003627733591844031\n",
      "train_loss 0.3361740677473392 train_acc 0.8513250519900801\n",
      "epoch 2464 lr 0.0036204853752929665\n",
      "train_loss 0.336169189537535 train_acc 0.8513250519900801\n",
      "epoch 2465 lr 0.0036132516406882313\n",
      "train_loss 0.3361643144103668 train_acc 0.8513361728628462\n",
      "epoch 2466 lr 0.0036060323590948727\n",
      "train_loss 0.3361594181283209 train_acc 0.8513472937356124\n",
      "epoch 2467 lr 0.0035988275016357618\n",
      "train_loss 0.3361545133438294 train_acc 0.8513584146083785\n",
      "epoch 2468 lr 0.0035916370394914556\n",
      "train_loss 0.33614961771447643 train_acc 0.8513584146083785\n",
      "epoch 2469 lr 0.003584460943900097\n",
      "train_loss 0.33614472386031125 train_acc 0.8513806563539107\n",
      "epoch 2470 lr 0.0035772991861572896\n",
      "train_loss 0.3361398354615734 train_acc 0.8513806563539107\n",
      "epoch 2471 lr 0.0035701517376159997\n",
      "train_loss 0.33613493257049587 train_acc 0.8514140189722089\n",
      "epoch 2472 lr 0.0035630185696864207\n",
      "train_loss 0.3361300214539199 train_acc 0.851425139844975\n",
      "epoch 2473 lr 0.003555899653835871\n",
      "train_loss 0.3361251120677363 train_acc 0.8514473815905073\n",
      "epoch 2474 lr 0.0035487949615886742\n",
      "train_loss 0.3361202301560962 train_acc 0.8514585024632734\n",
      "epoch 2475 lr 0.0035417044645260592\n",
      "train_loss 0.336115349964567 train_acc 0.8514585024632734\n",
      "epoch 2476 lr 0.0035346281342860247\n",
      "train_loss 0.3361104551020595 train_acc 0.8514585024632734\n",
      "epoch 2477 lr 0.00352756594256324\n",
      "train_loss 0.33610557505346184 train_acc 0.8514585024632734\n",
      "epoch 2478 lr 0.003520517861108926\n",
      "train_loss 0.33610071158074073 train_acc 0.8514585024632734\n",
      "epoch 2479 lr 0.003513483861730753\n",
      "train_loss 0.33609583168035273 train_acc 0.8514918650815716\n",
      "epoch 2480 lr 0.0035064639162927123\n",
      "train_loss 0.3360909590412152 train_acc 0.8514918650815716\n",
      "epoch 2481 lr 0.0034994579967150114\n",
      "train_loss 0.33608607581439004 train_acc 0.8514807442088055\n",
      "epoch 2482 lr 0.0034924660749739607\n",
      "train_loss 0.33608118974947043 train_acc 0.8514807442088055\n",
      "epoch 2483 lr 0.0034854881231018695\n",
      "train_loss 0.33607631502583174 train_acc 0.8514696233360394\n",
      "epoch 2484 lr 0.003478524113186918\n",
      "train_loss 0.336071442132349 train_acc 0.8514473815905073\n",
      "epoch 2485 lr 0.003471574017373057\n",
      "train_loss 0.336066589827988 train_acc 0.8514473815905073\n",
      "epoch 2486 lr 0.0034646378078598914\n",
      "train_loss 0.3360617400271896 train_acc 0.8514696233360394\n",
      "epoch 2487 lr 0.00345771545690258\n",
      "train_loss 0.3360569130601428 train_acc 0.8514918650815716\n",
      "epoch 2488 lr 0.003450806936811706\n",
      "train_loss 0.3360520880589655 train_acc 0.8514918650815716\n",
      "epoch 2489 lr 0.003443912219953181\n",
      "train_loss 0.3360472670280769 train_acc 0.8515252276998699\n",
      "epoch 2490 lr 0.003437031278748124\n",
      "train_loss 0.3360424464572001 train_acc 0.8515363485726359\n",
      "epoch 2491 lr 0.0034301640856727682\n",
      "train_loss 0.3360376534853407 train_acc 0.851547469445402\n",
      "epoch 2492 lr 0.003423310613258329\n",
      "train_loss 0.3360328663881986 train_acc 0.851547469445402\n",
      "epoch 2493 lr 0.0034164708340909066\n",
      "train_loss 0.33602809757223273 train_acc 0.8515808320637004\n",
      "epoch 2494 lr 0.0034096447208113727\n",
      "train_loss 0.33602333970160564 train_acc 0.8515585903181682\n",
      "epoch 2495 lr 0.0034028322461152716\n",
      "train_loss 0.3360185861658011 train_acc 0.8515697111909343\n",
      "epoch 2496 lr 0.003396033382752692\n",
      "train_loss 0.3360138308637622 train_acc 0.8515808320637004\n",
      "epoch 2497 lr 0.0033892481035281714\n",
      "train_loss 0.3360090797415263 train_acc 0.8515697111909343\n",
      "epoch 2498 lr 0.003382476381300581\n",
      "train_loss 0.33600433724340256 train_acc 0.8515808320637004\n",
      "epoch 2499 lr 0.0033757181889830287\n",
      "train_loss 0.33599959661941536 train_acc 0.8515808320637004\n",
      "\n",
      "val loss = 0.34205669592134325, \n",
      "val acc = 0.8526821457165733\n",
      "\n",
      "epoch 2500 lr 0.0033689734995427335\n",
      "train_loss 0.3359948614678954 train_acc 0.851547469445402\n",
      "epoch 2501 lr 0.0033622422860009283\n",
      "train_loss 0.3359901367880691 train_acc 0.8515363485726359\n",
      "epoch 2502 lr 0.00335552452143275\n",
      "train_loss 0.3359854048764331 train_acc 0.8515252276998699\n",
      "epoch 2503 lr 0.0033488201789671286\n",
      "train_loss 0.33598067388667235 train_acc 0.8515252276998699\n",
      "epoch 2504 lr 0.003342129231786691\n",
      "train_loss 0.3359759507625826 train_acc 0.8515363485726359\n",
      "epoch 2505 lr 0.0033354516531276367\n",
      "train_loss 0.3359712387577958 train_acc 0.8515363485726359\n",
      "epoch 2506 lr 0.0033287874162796424\n",
      "train_loss 0.3359665412115513 train_acc 0.8515252276998699\n",
      "epoch 2507 lr 0.0033221364945857485\n",
      "train_loss 0.3359618465817492 train_acc 0.8515697111909343\n",
      "epoch 2508 lr 0.0033154988614422657\n",
      "train_loss 0.33595715366894713 train_acc 0.8515585903181682\n",
      "epoch 2509 lr 0.0033088744902986487\n",
      "train_loss 0.33595246614673 train_acc 0.8515808320637004\n",
      "epoch 2510 lr 0.003302263354657405\n",
      "train_loss 0.33594779160739735 train_acc 0.8515919529364665\n",
      "epoch 2511 lr 0.0032956654280739805\n",
      "train_loss 0.33594311813732824 train_acc 0.8515919529364665\n",
      "epoch 2512 lr 0.003289080684156665\n",
      "train_loss 0.33593844112287996 train_acc 0.8515808320637004\n",
      "epoch 2513 lr 0.0032825090965664717\n",
      "train_loss 0.335933754157799 train_acc 0.8515808320637004\n",
      "epoch 2514 lr 0.0032759506390170412\n",
      "train_loss 0.33592905906872383 train_acc 0.8515808320637004\n",
      "epoch 2515 lr 0.0032694052852745323\n",
      "train_loss 0.3359243686502829 train_acc 0.8515697111909343\n",
      "epoch 2516 lr 0.0032628730091575258\n",
      "train_loss 0.3359196702780784 train_acc 0.8515808320637004\n",
      "epoch 2517 lr 0.003256353784536907\n",
      "train_loss 0.33591496971326884 train_acc 0.8515697111909343\n",
      "epoch 2518 lr 0.003249847585335768\n",
      "train_loss 0.33591027244429444 train_acc 0.8515363485726359\n",
      "epoch 2519 lr 0.0032433543855293003\n",
      "train_loss 0.3359055854031408 train_acc 0.8515363485726359\n",
      "epoch 2520 lr 0.0032368741591447025\n",
      "train_loss 0.33590092264542204 train_acc 0.8515252276998699\n",
      "epoch 2521 lr 0.003230406880261057\n",
      "train_loss 0.3358962712377344 train_acc 0.8515252276998699\n",
      "epoch 2522 lr 0.0032239525230092396\n",
      "train_loss 0.33589162260677413 train_acc 0.8515252276998699\n",
      "epoch 2523 lr 0.0032175110615718103\n",
      "train_loss 0.3358869547515305 train_acc 0.8515363485726359\n",
      "epoch 2524 lr 0.0032110824701829196\n",
      "train_loss 0.3358822802711146 train_acc 0.851547469445402\n",
      "epoch 2525 lr 0.0032046667231281916\n",
      "train_loss 0.3358776082213807 train_acc 0.8515585903181682\n",
      "epoch 2526 lr 0.003198263794744629\n",
      "train_loss 0.335872919586384 train_acc 0.8515697111909343\n",
      "epoch 2527 lr 0.0031918736594205065\n",
      "train_loss 0.3358682283478262 train_acc 0.8515585903181682\n",
      "epoch 2528 lr 0.0031854962915952804\n",
      "train_loss 0.3358635400983052 train_acc 0.8515585903181682\n",
      "epoch 2529 lr 0.0031791316657594684\n",
      "train_loss 0.33585885945729943 train_acc 0.8515585903181682\n",
      "epoch 2530 lr 0.003172779756454558\n",
      "train_loss 0.33585418221339747 train_acc 0.8515585903181682\n",
      "epoch 2531 lr 0.0031664405382729006\n",
      "train_loss 0.3358495083093487 train_acc 0.8515363485726359\n",
      "epoch 2532 lr 0.0031601139858576217\n",
      "train_loss 0.3358448555122942 train_acc 0.8515363485726359\n",
      "epoch 2533 lr 0.0031538000739024996\n",
      "train_loss 0.3358402246926216 train_acc 0.8515697111909343\n",
      "epoch 2534 lr 0.003147498777151878\n",
      "train_loss 0.33583560090444053 train_acc 0.8515697111909343\n",
      "epoch 2535 lr 0.003141210070400559\n",
      "train_loss 0.3358309781228198 train_acc 0.8515363485726359\n",
      "epoch 2536 lr 0.0031349339284937124\n",
      "train_loss 0.33582634439999515 train_acc 0.851547469445402\n",
      "epoch 2537 lr 0.00312867032632676\n",
      "train_loss 0.33582170207129874 train_acc 0.851547469445402\n",
      "epoch 2538 lr 0.0031224192388452842\n",
      "train_loss 0.3358170725974384 train_acc 0.851547469445402\n",
      "epoch 2539 lr 0.0031161806410449243\n",
      "train_loss 0.3358124459572383 train_acc 0.8515363485726359\n",
      "epoch 2540 lr 0.0031099545079712864\n",
      "train_loss 0.33580782468055115 train_acc 0.8515141068271038\n",
      "epoch 2541 lr 0.0031037408147198266\n",
      "train_loss 0.33580320064951874 train_acc 0.8515141068271038\n",
      "epoch 2542 lr 0.0030975395364357646\n",
      "train_loss 0.3357985781531433 train_acc 0.8515141068271038\n",
      "epoch 2543 lr 0.003091350648313975\n",
      "train_loss 0.33579394895977155 train_acc 0.8515141068271038\n",
      "epoch 2544 lr 0.0030851741255989037\n",
      "train_loss 0.3357893286887527 train_acc 0.8515252276998699\n",
      "epoch 2545 lr 0.003079009943584448\n",
      "train_loss 0.3357847142962151 train_acc 0.8515363485726359\n",
      "epoch 2546 lr 0.0030728580776138727\n",
      "train_loss 0.3357801114793183 train_acc 0.8515363485726359\n",
      "epoch 2547 lr 0.0030667185030797016\n",
      "train_loss 0.3357755102078747 train_acc 0.8515363485726359\n",
      "epoch 2548 lr 0.003060591195423635\n",
      "train_loss 0.33577089625504347 train_acc 0.8515363485726359\n",
      "epoch 2549 lr 0.0030544761301364303\n",
      "train_loss 0.3357662785813745 train_acc 0.8515363485726359\n",
      "\n",
      "val loss = 0.34200117241462513, \n",
      "val acc = 0.8522818254603683\n",
      "\n",
      "epoch 2550 lr 0.003048373282757819\n",
      "train_loss 0.3357616482159749 train_acc 0.851547469445402\n",
      "epoch 2551 lr 0.0030422826288764005\n",
      "train_loss 0.3357570051446619 train_acc 0.8515141068271038\n",
      "epoch 2552 lr 0.0030362041441295566\n",
      "train_loss 0.3357523494972997 train_acc 0.8515252276998699\n",
      "epoch 2553 lr 0.0030301378042033376\n",
      "train_loss 0.3357476968602639 train_acc 0.8515363485726359\n",
      "epoch 2554 lr 0.0030240835848323756\n",
      "train_loss 0.33574303899441604 train_acc 0.8515141068271038\n",
      "epoch 2555 lr 0.0030180414617997824\n",
      "train_loss 0.33573840087704093 train_acc 0.8515141068271038\n",
      "epoch 2556 lr 0.0030120114109370632\n",
      "train_loss 0.3357337675425311 train_acc 0.8515252276998699\n",
      "epoch 2557 lr 0.0030059934081240035\n",
      "train_loss 0.33572914439268164 train_acc 0.8514918650815716\n",
      "epoch 2558 lr 0.0029999874292885847\n",
      "train_loss 0.3357245391531579 train_acc 0.8515029859543377\n",
      "epoch 2559 lr 0.00299399345040688\n",
      "train_loss 0.3357199420013068 train_acc 0.8514918650815716\n",
      "epoch 2560 lr 0.0029880114475029714\n",
      "train_loss 0.33571534281670795 train_acc 0.8515029859543377\n",
      "epoch 2561 lr 0.002982041396648837\n",
      "train_loss 0.3357107474908481 train_acc 0.8515141068271038\n",
      "epoch 2562 lr 0.0029760832739642654\n",
      "train_loss 0.33570615215064986 train_acc 0.8515141068271038\n",
      "epoch 2563 lr 0.002970137055616755\n",
      "train_loss 0.33570154626840076 train_acc 0.8515029859543377\n",
      "epoch 2564 lr 0.00296420271782143\n",
      "train_loss 0.3356969488723843 train_acc 0.8515252276998699\n",
      "epoch 2565 lr 0.0029582802368409286\n",
      "train_loss 0.3356923644166618 train_acc 0.8515363485726359\n",
      "epoch 2566 lr 0.0029523695889853187\n",
      "train_loss 0.33568779391516135 train_acc 0.8515252276998699\n",
      "epoch 2567 lr 0.002946470750611999\n",
      "train_loss 0.33568325097343293 train_acc 0.8515252276998699\n",
      "epoch 2568 lr 0.0029405836981256125\n",
      "train_loss 0.3356787137422614 train_acc 0.8515252276998699\n",
      "epoch 2569 lr 0.0029347084079779395\n",
      "train_loss 0.3356741810377645 train_acc 0.8515252276998699\n",
      "epoch 2570 lr 0.0029288448566678112\n",
      "train_loss 0.33566965439573637 train_acc 0.8515252276998699\n",
      "epoch 2571 lr 0.0029229930207410127\n",
      "train_loss 0.33566513457995895 train_acc 0.8515029859543377\n",
      "epoch 2572 lr 0.0029171528767901965\n",
      "train_loss 0.33566059233907053 train_acc 0.8515141068271038\n",
      "epoch 2573 lr 0.0029113244014547773\n",
      "train_loss 0.33565604282430034 train_acc 0.8515141068271038\n",
      "epoch 2574 lr 0.0029055075714208454\n",
      "train_loss 0.33565149684031176 train_acc 0.8515252276998699\n",
      "epoch 2575 lr 0.0028997023634210707\n",
      "train_loss 0.33564694673105444 train_acc 0.8515363485726359\n",
      "epoch 2576 lr 0.0028939087542346185\n",
      "train_loss 0.3356423771991743 train_acc 0.8515252276998699\n",
      "epoch 2577 lr 0.0028881267206870417\n",
      "train_loss 0.3356377974309556 train_acc 0.8515252276998699\n",
      "epoch 2578 lr 0.002882356239650199\n",
      "train_loss 0.33563320162959637 train_acc 0.8515029859543377\n",
      "epoch 2579 lr 0.002876597288042155\n",
      "train_loss 0.33562859870625356 train_acc 0.8515141068271038\n",
      "epoch 2580 lr 0.0028708498428271015\n",
      "train_loss 0.3356240110577686 train_acc 0.8515252276998699\n",
      "epoch 2581 lr 0.0028651138810152467\n",
      "train_loss 0.3356194148413941 train_acc 0.8515363485726359\n",
      "epoch 2582 lr 0.0028593893796627365\n",
      "train_loss 0.33561482097617296 train_acc 0.8515363485726359\n",
      "epoch 2583 lr 0.002853676315871555\n",
      "train_loss 0.3356102366721202 train_acc 0.8515363485726359\n",
      "epoch 2584 lr 0.002847974666789444\n",
      "train_loss 0.33560565297183714 train_acc 0.8515141068271038\n",
      "epoch 2585 lr 0.0028422844096097975\n",
      "train_loss 0.3356010673268968 train_acc 0.8515141068271038\n",
      "epoch 2586 lr 0.0028366055215715796\n",
      "train_loss 0.335596504901311 train_acc 0.8515141068271038\n",
      "epoch 2587 lr 0.002830937979959227\n",
      "train_loss 0.3355919592591709 train_acc 0.8515141068271038\n",
      "epoch 2588 lr 0.002825281762102572\n",
      "train_loss 0.3355874401998354 train_acc 0.8515252276998699\n",
      "epoch 2589 lr 0.002819636845376732\n",
      "train_loss 0.3355829293145173 train_acc 0.8515363485726359\n",
      "epoch 2590 lr 0.002814003207202033\n",
      "train_loss 0.3355784095181962 train_acc 0.8515252276998699\n",
      "epoch 2591 lr 0.0028083808250439126\n",
      "train_loss 0.3355738918843757 train_acc 0.8515029859543377\n",
      "epoch 2592 lr 0.002802769676412839\n",
      "train_loss 0.33556939207360026 train_acc 0.8514918650815716\n",
      "epoch 2593 lr 0.0027971697388642085\n",
      "train_loss 0.3355648915115361 train_acc 0.8514918650815716\n",
      "epoch 2594 lr 0.0027915809899982627\n",
      "train_loss 0.33556039698733686 train_acc 0.8514918650815716\n",
      "epoch 2595 lr 0.0027860034074599967\n",
      "train_loss 0.33555590013870645 train_acc 0.8515029859543377\n",
      "epoch 2596 lr 0.0027804369689390777\n",
      "train_loss 0.33555139787299987 train_acc 0.8515029859543377\n",
      "epoch 2597 lr 0.0027748816521697413\n",
      "train_loss 0.3355469049408918 train_acc 0.8514807442088055\n",
      "epoch 2598 lr 0.002769337434930714\n",
      "train_loss 0.3355424271317969 train_acc 0.8514696233360394\n",
      "epoch 2599 lr 0.002763804295045116\n",
      "train_loss 0.335537979870135 train_acc 0.8514473815905073\n",
      "\n",
      "val loss = 0.3419416716414807, \n",
      "val acc = 0.8522818254603683\n",
      "\n",
      "epoch 2600 lr 0.0027582822103803858\n",
      "train_loss 0.33553353866908026 train_acc 0.8514473815905073\n",
      "epoch 2601 lr 0.002752771158848175\n",
      "train_loss 0.33552908893764705 train_acc 0.8514362607177411\n",
      "epoch 2602 lr 0.00274727111840427\n",
      "train_loss 0.335524638850388 train_acc 0.8514696233360394\n",
      "epoch 2603 lr 0.0027417820670484986\n",
      "train_loss 0.33552020033455315 train_acc 0.8514807442088055\n",
      "epoch 2604 lr 0.002736303982824654\n",
      "train_loss 0.33551579895186073 train_acc 0.8514807442088055\n",
      "epoch 2605 lr 0.002730836843820389\n",
      "train_loss 0.3355114052307675 train_acc 0.8514696233360394\n",
      "epoch 2606 lr 0.0027253806281671406\n",
      "train_loss 0.33550701166589764 train_acc 0.8514696233360394\n",
      "epoch 2607 lr 0.0027199353140400363\n",
      "train_loss 0.33550261902605855 train_acc 0.8514807442088055\n",
      "epoch 2608 lr 0.002714500879657817\n",
      "train_loss 0.33549824309278514 train_acc 0.8514918650815716\n",
      "epoch 2609 lr 0.0027090773032827356\n",
      "train_loss 0.33549386389369423 train_acc 0.8514918650815716\n",
      "epoch 2610 lr 0.0027036645632204795\n",
      "train_loss 0.3354894809069611 train_acc 0.8514918650815716\n",
      "epoch 2611 lr 0.002698262637820079\n",
      "train_loss 0.3354850879164613 train_acc 0.8514807442088055\n",
      "epoch 2612 lr 0.00269287150547383\n",
      "train_loss 0.3354807024178732 train_acc 0.8514473815905073\n",
      "epoch 2613 lr 0.0026874911446171925\n",
      "train_loss 0.33547634316693126 train_acc 0.8514585024632734\n",
      "epoch 2614 lr 0.0026821215337287175\n",
      "train_loss 0.3354719930475137 train_acc 0.8514696233360394\n",
      "epoch 2615 lr 0.002676762651329951\n",
      "train_loss 0.3354676564845563 train_acc 0.8514696233360394\n",
      "epoch 2616 lr 0.0026714144759853614\n",
      "train_loss 0.3354633373917192 train_acc 0.8514696233360394\n",
      "epoch 2617 lr 0.0026660769863022377\n",
      "train_loss 0.3354590352533473 train_acc 0.8514696233360394\n",
      "epoch 2618 lr 0.0026607501609306134\n",
      "train_loss 0.33545474443533 train_acc 0.8514918650815716\n",
      "epoch 2619 lr 0.002655433978563179\n",
      "train_loss 0.3354504578433941 train_acc 0.8515029859543377\n",
      "epoch 2620 lr 0.002650128417935201\n",
      "train_loss 0.3354461760114688 train_acc 0.8515141068271038\n",
      "epoch 2621 lr 0.0026448334578244286\n",
      "train_loss 0.33544189113473016 train_acc 0.8515141068271038\n",
      "epoch 2622 lr 0.002639549077051014\n",
      "train_loss 0.3354375933410848 train_acc 0.8515141068271038\n",
      "epoch 2623 lr 0.0026342752544774245\n",
      "train_loss 0.33543329140238193 train_acc 0.8514807442088055\n",
      "epoch 2624 lr 0.0026290119690083676\n",
      "train_loss 0.3354289883059023 train_acc 0.8514807442088055\n",
      "epoch 2625 lr 0.0026237591995906923\n",
      "train_loss 0.3354246875818071 train_acc 0.8514807442088055\n",
      "epoch 2626 lr 0.0026185169252133135\n",
      "train_loss 0.3354203654278208 train_acc 0.8514807442088055\n",
      "epoch 2627 lr 0.0026132851249071267\n",
      "train_loss 0.3354160532268266 train_acc 0.8514918650815716\n",
      "epoch 2628 lr 0.002608063777744922\n",
      "train_loss 0.3354117540034718 train_acc 0.8514918650815716\n",
      "epoch 2629 lr 0.0026028528628413076\n",
      "train_loss 0.3354074591870139 train_acc 0.8514807442088055\n",
      "epoch 2630 lr 0.0025976523593526156\n",
      "train_loss 0.33540318875931424 train_acc 0.8514585024632734\n",
      "epoch 2631 lr 0.002592462246476824\n",
      "train_loss 0.3353989274492499 train_acc 0.8514362607177411\n",
      "epoch 2632 lr 0.002587282503453473\n",
      "train_loss 0.33539465237423327 train_acc 0.8514362607177411\n",
      "epoch 2633 lr 0.002582113109563588\n",
      "train_loss 0.3353903743961432 train_acc 0.851425139844975\n",
      "epoch 2634 lr 0.0025769540441295835\n",
      "train_loss 0.3353861120835485 train_acc 0.851425139844975\n",
      "epoch 2635 lr 0.0025718052865151917\n",
      "train_loss 0.33538184585334296 train_acc 0.8514362607177411\n",
      "epoch 2636 lr 0.0025666668161253726\n",
      "train_loss 0.3353775796949213 train_acc 0.8514473815905073\n",
      "epoch 2637 lr 0.002561538612406243\n",
      "train_loss 0.3353733163241258 train_acc 0.851425139844975\n",
      "epoch 2638 lr 0.002556420654844978\n",
      "train_loss 0.3353690625352237 train_acc 0.851425139844975\n",
      "epoch 2639 lr 0.002551312922969741\n",
      "train_loss 0.33536480637563537 train_acc 0.8514362607177411\n",
      "epoch 2640 lr 0.002546215396349595\n",
      "train_loss 0.33536054597086423 train_acc 0.8514140189722089\n",
      "epoch 2641 lr 0.0025411280545944324\n",
      "train_loss 0.3353563043860154 train_acc 0.8514362607177411\n",
      "epoch 2642 lr 0.002536050877354876\n",
      "train_loss 0.33535207891555097 train_acc 0.8514362607177411\n",
      "epoch 2643 lr 0.0025309838443222103\n",
      "train_loss 0.33534784536259665 train_acc 0.8514362607177411\n",
      "epoch 2644 lr 0.0025259269352282945\n",
      "train_loss 0.33534360377380695 train_acc 0.8514362607177411\n",
      "epoch 2645 lr 0.0025208801298454895\n",
      "train_loss 0.3353393465411987 train_acc 0.8514473815905073\n",
      "epoch 2646 lr 0.002515843407986565\n",
      "train_loss 0.3353350791978757 train_acc 0.8514362607177411\n",
      "epoch 2647 lr 0.002510816749504627\n",
      "train_loss 0.33533084107567124 train_acc 0.8514473815905073\n",
      "epoch 2648 lr 0.0025058001342930327\n",
      "train_loss 0.3353265932578577 train_acc 0.8514585024632734\n",
      "epoch 2649 lr 0.002500793542285319\n",
      "train_loss 0.3353223328091463 train_acc 0.8514473815905073\n",
      "\n",
      "val loss = 0.3418573561881367, \n",
      "val acc = 0.8519815852682145\n",
      "\n",
      "epoch 2650 lr 0.0024957969534551085\n",
      "train_loss 0.3353180780395976 train_acc 0.8514362607177411\n",
      "epoch 2651 lr 0.00249081034781604\n",
      "train_loss 0.3353138163729184 train_acc 0.8514473815905073\n",
      "epoch 2652 lr 0.002485833705421681\n",
      "train_loss 0.3353095645371372 train_acc 0.8514473815905073\n",
      "epoch 2653 lr 0.0024808670063654606\n",
      "train_loss 0.33530531605330827 train_acc 0.8514362607177411\n",
      "epoch 2654 lr 0.0024759102307805735\n",
      "train_loss 0.33530106951394 train_acc 0.8514585024632734\n",
      "epoch 2655 lr 0.002470963358839911\n",
      "train_loss 0.3352968310956312 train_acc 0.8514585024632734\n",
      "epoch 2656 lr 0.002466026370755976\n",
      "train_loss 0.3352925976425957 train_acc 0.8514585024632734\n",
      "epoch 2657 lr 0.002461099246780814\n",
      "train_loss 0.3352883537821477 train_acc 0.8514585024632734\n",
      "epoch 2658 lr 0.002456181967205921\n",
      "train_loss 0.33528411640666744 train_acc 0.8514696233360394\n",
      "epoch 2659 lr 0.0024512745123621716\n",
      "train_loss 0.3352798825108111 train_acc 0.8515029859543377\n",
      "epoch 2660 lr 0.002446376862619738\n",
      "train_loss 0.3352756569944832 train_acc 0.8514918650815716\n",
      "epoch 2661 lr 0.002441488998388019\n",
      "train_loss 0.3352714366635979 train_acc 0.8515029859543377\n",
      "epoch 2662 lr 0.002436610900115548\n",
      "train_loss 0.3352672186975727 train_acc 0.8515029859543377\n",
      "epoch 2663 lr 0.002431742548289927\n",
      "train_loss 0.33526300845357926 train_acc 0.8515363485726359\n",
      "epoch 2664 lr 0.0024268839234377394\n",
      "train_loss 0.3352587948767692 train_acc 0.8515141068271038\n",
      "epoch 2665 lr 0.0024220350061244836\n",
      "train_loss 0.3352545985170631 train_acc 0.8515029859543377\n",
      "epoch 2666 lr 0.0024171957769544812\n",
      "train_loss 0.3352504063246918 train_acc 0.8514807442088055\n",
      "epoch 2667 lr 0.00241236621657081\n",
      "train_loss 0.3352462162754593 train_acc 0.8515029859543377\n",
      "epoch 2668 lr 0.002407546305655219\n",
      "train_loss 0.33524202682526777 train_acc 0.8515363485726359\n",
      "epoch 2669 lr 0.002402736024928063\n",
      "train_loss 0.33523783151646436 train_acc 0.8515585903181682\n",
      "epoch 2670 lr 0.0023979353551482107\n",
      "train_loss 0.3352336264257366 train_acc 0.8515585903181682\n",
      "epoch 2671 lr 0.0023931442771129756\n",
      "train_loss 0.33522941678148394 train_acc 0.851547469445402\n",
      "epoch 2672 lr 0.002388362771658038\n",
      "train_loss 0.33522520652005605 train_acc 0.8515585903181682\n",
      "epoch 2673 lr 0.0023835908196573738\n",
      "train_loss 0.3352210014892436 train_acc 0.8515585903181682\n",
      "epoch 2674 lr 0.0023788284020231664\n",
      "train_loss 0.33521678162755647 train_acc 0.8515585903181682\n",
      "epoch 2675 lr 0.002374075499705739\n",
      "train_loss 0.33521257601942595 train_acc 0.8515585903181682\n",
      "epoch 2676 lr 0.002369332093693473\n",
      "train_loss 0.3352083722907651 train_acc 0.8515697111909343\n",
      "epoch 2677 lr 0.0023645981650127434\n",
      "train_loss 0.3352041457577258 train_acc 0.8515585903181682\n",
      "epoch 2678 lr 0.0023598736947278267\n",
      "train_loss 0.33519991974526453 train_acc 0.8515585903181682\n",
      "epoch 2679 lr 0.0023551586639408355\n",
      "train_loss 0.33519568724265203 train_acc 0.8515585903181682\n",
      "epoch 2680 lr 0.002350453053791638\n",
      "train_loss 0.3351914442642244 train_acc 0.8515585903181682\n",
      "epoch 2681 lr 0.0023457568454577915\n",
      "train_loss 0.33518720681381314 train_acc 0.8515585903181682\n",
      "epoch 2682 lr 0.002341070020154455\n",
      "train_loss 0.3351829878294459 train_acc 0.8515585903181682\n",
      "epoch 2683 lr 0.00233639255913432\n",
      "train_loss 0.33517878199577744 train_acc 0.8515697111909343\n",
      "epoch 2684 lr 0.0023317244436875354\n",
      "train_loss 0.3351745830874794 train_acc 0.8515697111909343\n",
      "epoch 2685 lr 0.002327065655141636\n",
      "train_loss 0.33517040778209706 train_acc 0.8515697111909343\n",
      "epoch 2686 lr 0.00232241617486146\n",
      "train_loss 0.3351662357319507 train_acc 0.8515697111909343\n",
      "epoch 2687 lr 0.00231777598424908\n",
      "train_loss 0.33516206705520074 train_acc 0.8516030738092325\n",
      "epoch 2688 lr 0.0023131450647437255\n",
      "train_loss 0.3351578967924906 train_acc 0.8515808320637004\n",
      "epoch 2689 lr 0.002308523397821716\n",
      "train_loss 0.3351537285826709 train_acc 0.8515808320637004\n",
      "epoch 2690 lr 0.002303910964996376\n",
      "train_loss 0.33514956480533403 train_acc 0.8515585903181682\n",
      "epoch 2691 lr 0.0022993077478179677\n",
      "train_loss 0.33514539692427603 train_acc 0.8515363485726359\n",
      "epoch 2692 lr 0.0022947137278736146\n",
      "train_loss 0.33514122646992067 train_acc 0.851547469445402\n",
      "epoch 2693 lr 0.0022901288867872346\n",
      "train_loss 0.3351370481365455 train_acc 0.8515585903181682\n",
      "epoch 2694 lr 0.002285553206219455\n",
      "train_loss 0.3351328811191368 train_acc 0.8515363485726359\n",
      "epoch 2695 lr 0.0022809866678675478\n",
      "train_loss 0.3351287236098945 train_acc 0.851547469445402\n",
      "epoch 2696 lr 0.0022764292534653515\n",
      "train_loss 0.3351245803333279 train_acc 0.851547469445402\n",
      "epoch 2697 lr 0.002271880944783206\n",
      "train_loss 0.3351204528968729 train_acc 0.8515363485726359\n",
      "epoch 2698 lr 0.0022673417236278694\n",
      "train_loss 0.33511634608892565 train_acc 0.8515252276998699\n",
      "epoch 2699 lr 0.00226281157184245\n",
      "train_loss 0.33511223974489496 train_acc 0.8515141068271038\n",
      "\n",
      "val loss = 0.3417676403977835, \n",
      "val acc = 0.8515812650120096\n",
      "\n",
      "epoch 2700 lr 0.002258290471306333\n",
      "train_loss 0.3351081400356015 train_acc 0.8515141068271038\n",
      "epoch 2701 lr 0.002253778403935114\n",
      "train_loss 0.33510405315508723 train_acc 0.8515141068271038\n",
      "epoch 2702 lr 0.0022492753516805165\n",
      "train_loss 0.33509995794805625 train_acc 0.8515252276998699\n",
      "epoch 2703 lr 0.0022447812965303245\n",
      "train_loss 0.3350958684913887 train_acc 0.8515252276998699\n",
      "epoch 2704 lr 0.0022402962205083097\n",
      "train_loss 0.33509177859267947 train_acc 0.8515363485726359\n",
      "epoch 2705 lr 0.002235820105674166\n",
      "train_loss 0.3350876792339177 train_acc 0.8515363485726359\n",
      "epoch 2706 lr 0.002231352934123426\n",
      "train_loss 0.33508358376921 train_acc 0.851547469445402\n",
      "epoch 2707 lr 0.0022268946879873976\n",
      "train_loss 0.3350794863324863 train_acc 0.8515585903181682\n",
      "epoch 2708 lr 0.0022224453494330883\n",
      "train_loss 0.33507539703471295 train_acc 0.8515363485726359\n",
      "epoch 2709 lr 0.002218004900663142\n",
      "train_loss 0.33507131421319086 train_acc 0.851547469445402\n",
      "epoch 2710 lr 0.002213573323915756\n",
      "train_loss 0.33506722922957566 train_acc 0.8515363485726359\n",
      "epoch 2711 lr 0.002209150601464617\n",
      "train_loss 0.33506315386488017 train_acc 0.8514918650815716\n",
      "epoch 2712 lr 0.002204736715618827\n",
      "train_loss 0.33505907932761503 train_acc 0.8514807442088055\n",
      "epoch 2713 lr 0.0022003316487228413\n",
      "train_loss 0.33505500017592504 train_acc 0.8514807442088055\n",
      "epoch 2714 lr 0.002195935383156384\n",
      "train_loss 0.3350509193318761 train_acc 0.8514807442088055\n",
      "epoch 2715 lr 0.002191547901334388\n",
      "train_loss 0.33504684389932443 train_acc 0.8514807442088055\n",
      "epoch 2716 lr 0.002187169185706917\n",
      "train_loss 0.3350427738542522 train_acc 0.8514807442088055\n",
      "epoch 2717 lr 0.002182799218759107\n",
      "train_loss 0.33503869490813376 train_acc 0.8514807442088055\n",
      "epoch 2718 lr 0.0021784379830110823\n",
      "train_loss 0.3350346179879868 train_acc 0.8514696233360394\n",
      "epoch 2719 lr 0.0021740854610178945\n",
      "train_loss 0.3350305576219097 train_acc 0.8514585024632734\n",
      "epoch 2720 lr 0.0021697416353694474\n",
      "train_loss 0.3350265116479493 train_acc 0.8514473815905073\n",
      "epoch 2721 lr 0.002165406488690437\n",
      "train_loss 0.33502247521221834 train_acc 0.8514585024632734\n",
      "epoch 2722 lr 0.0021610800036402683\n",
      "train_loss 0.3350184299776174 train_acc 0.8514585024632734\n",
      "epoch 2723 lr 0.0021567621629129956\n",
      "train_loss 0.3350143829769588 train_acc 0.8514585024632734\n",
      "epoch 2724 lr 0.0021524529492372483\n",
      "train_loss 0.3350103399851511 train_acc 0.8514696233360394\n",
      "epoch 2725 lr 0.00214815234537617\n",
      "train_loss 0.3350063086207296 train_acc 0.8514696233360394\n",
      "epoch 2726 lr 0.0021438603341273374\n",
      "train_loss 0.3350022854765292 train_acc 0.8514696233360394\n",
      "epoch 2727 lr 0.0021395768983226995\n",
      "train_loss 0.33499825786110254 train_acc 0.8514696233360394\n",
      "epoch 2728 lr 0.002135302020828506\n",
      "train_loss 0.33499422970761555 train_acc 0.8514473815905073\n",
      "epoch 2729 lr 0.0021310356845452446\n",
      "train_loss 0.33499021899725645 train_acc 0.8514585024632734\n",
      "epoch 2730 lr 0.0021267778724075627\n",
      "train_loss 0.3349862146494952 train_acc 0.8514585024632734\n",
      "epoch 2731 lr 0.0021225285673842063\n",
      "train_loss 0.33498221403290146 train_acc 0.8514473815905073\n",
      "epoch 2732 lr 0.0021182877524779475\n",
      "train_loss 0.33497821788417637 train_acc 0.851425139844975\n",
      "epoch 2733 lr 0.0021140554107255253\n",
      "train_loss 0.33497422035104624 train_acc 0.8514585024632734\n",
      "epoch 2734 lr 0.002109831525197564\n",
      "train_loss 0.3349702230815285 train_acc 0.8514585024632734\n",
      "epoch 2735 lr 0.002105616078998517\n",
      "train_loss 0.33496620739512906 train_acc 0.8514585024632734\n",
      "epoch 2736 lr 0.002101409055266592\n",
      "train_loss 0.3349621804781482 train_acc 0.8514585024632734\n",
      "epoch 2737 lr 0.0020972104371736913\n",
      "train_loss 0.3349581405044691 train_acc 0.8514585024632734\n",
      "epoch 2738 lr 0.002093020207925336\n",
      "train_loss 0.33495410493283057 train_acc 0.851425139844975\n",
      "epoch 2739 lr 0.002088838350760603\n",
      "train_loss 0.33495006810314026 train_acc 0.851425139844975\n",
      "epoch 2740 lr 0.0020846648489520558\n",
      "train_loss 0.33494603618921615 train_acc 0.8514362607177411\n",
      "epoch 2741 lr 0.002080499685805686\n",
      "train_loss 0.3349420065261683 train_acc 0.8514362607177411\n",
      "epoch 2742 lr 0.0020763428446608336\n",
      "train_loss 0.3349379648536456 train_acc 0.8514473815905073\n",
      "epoch 2743 lr 0.002072194308890128\n",
      "train_loss 0.33493393605622174 train_acc 0.8514362607177411\n",
      "epoch 2744 lr 0.0020680540618994198\n",
      "train_loss 0.3349299105985129 train_acc 0.8514362607177411\n",
      "epoch 2745 lr 0.002063922087127718\n",
      "train_loss 0.33492589993352745 train_acc 0.851425139844975\n",
      "epoch 2746 lr 0.0020597983680471165\n",
      "train_loss 0.33492189583234877 train_acc 0.8514362607177411\n",
      "epoch 2747 lr 0.0020556828881627335\n",
      "train_loss 0.3349178953762807 train_acc 0.8514362607177411\n",
      "epoch 2748 lr 0.0020515756310126422\n",
      "train_loss 0.3349138936333074 train_acc 0.8514362607177411\n",
      "epoch 2749 lr 0.0020474765801678126\n",
      "train_loss 0.3349098777784752 train_acc 0.8514473815905073\n",
      "\n",
      "val loss = 0.3416988511710745, \n",
      "val acc = 0.8518815052041633\n",
      "\n",
      "epoch 2750 lr 0.0020433857192320333\n",
      "train_loss 0.3349058577659376 train_acc 0.8514473815905073\n",
      "epoch 2751 lr 0.0020393030318418557\n",
      "train_loss 0.33490182956372955 train_acc 0.8514473815905073\n",
      "epoch 2752 lr 0.0020352285016665248\n",
      "train_loss 0.3348977909623724 train_acc 0.8514473815905073\n",
      "epoch 2753 lr 0.002031162112407912\n",
      "train_loss 0.3348937473029795 train_acc 0.8514473815905073\n",
      "epoch 2754 lr 0.0020271038478004585\n",
      "train_loss 0.33488970791482947 train_acc 0.8514585024632734\n",
      "epoch 2755 lr 0.0020230536916110995\n",
      "train_loss 0.33488566436765876 train_acc 0.8514585024632734\n",
      "epoch 2756 lr 0.0020190116276392043\n",
      "train_loss 0.33488163382688085 train_acc 0.8514696233360394\n",
      "epoch 2757 lr 0.0020149776397165096\n",
      "train_loss 0.33487760930825666 train_acc 0.8514807442088055\n",
      "epoch 2758 lr 0.002010951711707062\n",
      "train_loss 0.3348735843717716 train_acc 0.8514696233360394\n",
      "epoch 2759 lr 0.0020069338275071433\n",
      "train_loss 0.3348695543392667 train_acc 0.8514807442088055\n",
      "epoch 2760 lr 0.00200292397104521\n",
      "train_loss 0.3348655113638038 train_acc 0.8514918650815716\n",
      "epoch 2761 lr 0.00199892212628183\n",
      "train_loss 0.3348614692897925 train_acc 0.8514918650815716\n",
      "epoch 2762 lr 0.001994928277209622\n",
      "train_loss 0.3348574174318767 train_acc 0.8514696233360394\n",
      "epoch 2763 lr 0.0019909424078531825\n",
      "train_loss 0.3348533782373058 train_acc 0.8514696233360394\n",
      "epoch 2764 lr 0.0019869645022690292\n",
      "train_loss 0.3348493494555334 train_acc 0.8514696233360394\n",
      "epoch 2765 lr 0.0019829945445455324\n",
      "train_loss 0.3348453312020527 train_acc 0.8514696233360394\n",
      "epoch 2766 lr 0.0019790325188028595\n",
      "train_loss 0.3348413065565749 train_acc 0.8514807442088055\n",
      "epoch 2767 lr 0.001975078409192901\n",
      "train_loss 0.3348372850249952 train_acc 0.8514918650815716\n",
      "epoch 2768 lr 0.001971132199899212\n",
      "train_loss 0.33483327192576773 train_acc 0.8515141068271038\n",
      "epoch 2769 lr 0.0019671938751369493\n",
      "train_loss 0.3348292643805123 train_acc 0.8515029859543377\n",
      "epoch 2770 lr 0.001963263419152812\n",
      "train_loss 0.33482525807771635 train_acc 0.8515029859543377\n",
      "epoch 2771 lr 0.0019593408162249686\n",
      "train_loss 0.3348212557994789 train_acc 0.8515141068271038\n",
      "epoch 2772 lr 0.001955426050663003\n",
      "train_loss 0.334817255694232 train_acc 0.8515363485726359\n",
      "epoch 2773 lr 0.0019515191068078456\n",
      "train_loss 0.3348132529305158 train_acc 0.8515252276998699\n",
      "epoch 2774 lr 0.001947619969031719\n",
      "train_loss 0.33480925749956303 train_acc 0.8515252276998699\n",
      "epoch 2775 lr 0.0019437286217380654\n",
      "train_loss 0.3348052731113207 train_acc 0.8515029859543377\n",
      "epoch 2776 lr 0.0019398450493614903\n",
      "train_loss 0.334801292626967 train_acc 0.8514918650815716\n",
      "epoch 2777 lr 0.0019359692363676972\n",
      "train_loss 0.3347973113103262 train_acc 0.8514918650815716\n",
      "epoch 2778 lr 0.0019321011672534328\n",
      "train_loss 0.33479332228445485 train_acc 0.8514918650815716\n",
      "epoch 2779 lr 0.0019282408265464137\n",
      "train_loss 0.33478931990931904 train_acc 0.8514807442088055\n",
      "epoch 2780 lr 0.0019243881988052715\n",
      "train_loss 0.3347853073962888 train_acc 0.8514473815905073\n",
      "epoch 2781 lr 0.0019205432686194889\n",
      "train_loss 0.33478129652269717 train_acc 0.8514362607177411\n",
      "epoch 2782 lr 0.001916706020609343\n",
      "train_loss 0.3347772786983861 train_acc 0.8514473815905073\n",
      "epoch 2783 lr 0.0019128764394258351\n",
      "train_loss 0.3347732684950251 train_acc 0.8514585024632734\n",
      "epoch 2784 lr 0.0019090545097506357\n",
      "train_loss 0.33476927765012965 train_acc 0.8514696233360394\n",
      "epoch 2785 lr 0.0019052402162960187\n",
      "train_loss 0.3347652899152615 train_acc 0.8514585024632734\n",
      "epoch 2786 lr 0.001901433543804809\n",
      "train_loss 0.334761301221522 train_acc 0.8514585024632734\n",
      "epoch 2787 lr 0.0018976344770503099\n",
      "train_loss 0.3347573114920408 train_acc 0.8514696233360394\n",
      "epoch 2788 lr 0.001893843000836249\n",
      "train_loss 0.33475332500707494 train_acc 0.8514696233360394\n",
      "epoch 2789 lr 0.001890059099996715\n",
      "train_loss 0.33474935480012474 train_acc 0.8514696233360394\n",
      "epoch 2790 lr 0.0018862827593961026\n",
      "train_loss 0.33474538269413356 train_acc 0.8514918650815716\n",
      "epoch 2791 lr 0.001882513963929043\n",
      "train_loss 0.334741409907193 train_acc 0.8515029859543377\n",
      "epoch 2792 lr 0.0018787526985203492\n",
      "train_loss 0.3347374259511891 train_acc 0.8515141068271038\n",
      "epoch 2793 lr 0.0018749989481249526\n",
      "train_loss 0.3347334430901177 train_acc 0.8515363485726359\n",
      "epoch 2794 lr 0.0018712526977278502\n",
      "train_loss 0.334729455706812 train_acc 0.8515363485726359\n",
      "epoch 2795 lr 0.0018675139323440337\n",
      "train_loss 0.33472546346101256 train_acc 0.8515363485726359\n",
      "epoch 2796 lr 0.0018637826370184367\n",
      "train_loss 0.33472147148898684 train_acc 0.8515585903181682\n",
      "epoch 2797 lr 0.001860058796825871\n",
      "train_loss 0.33471748840996557 train_acc 0.8515697111909343\n",
      "epoch 2798 lr 0.0018563423968709746\n",
      "train_loss 0.334713509910411 train_acc 0.8515585903181682\n",
      "epoch 2799 lr 0.0018526334222881407\n",
      "train_loss 0.33470950750292744 train_acc 0.851547469445402\n",
      "\n",
      "val loss = 0.3416305488151603, \n",
      "val acc = 0.8517814251401121\n",
      "\n",
      "epoch 2800 lr 0.001848931858241466\n",
      "train_loss 0.3347055005495434 train_acc 0.8515585903181682\n",
      "epoch 2801 lr 0.001845237689924688\n",
      "train_loss 0.3347014764482825 train_acc 0.8515808320637004\n",
      "epoch 2802 lr 0.0018415509025611317\n",
      "train_loss 0.3346974560461433 train_acc 0.8515697111909343\n",
      "epoch 2803 lr 0.001837871481403641\n",
      "train_loss 0.33469344476692015 train_acc 0.851547469445402\n",
      "epoch 2804 lr 0.0018341994117345264\n",
      "train_loss 0.3346894382264938 train_acc 0.851547469445402\n",
      "epoch 2805 lr 0.0018305346788655026\n",
      "train_loss 0.3346854323612917 train_acc 0.8515363485726359\n",
      "epoch 2806 lr 0.0018268772681376366\n",
      "train_loss 0.33468144530503313 train_acc 0.8515363485726359\n",
      "epoch 2807 lr 0.001823227164921279\n",
      "train_loss 0.3346774713808982 train_acc 0.8515585903181682\n",
      "epoch 2808 lr 0.0018195843546160123\n",
      "train_loss 0.3346735101609264 train_acc 0.8515697111909343\n",
      "epoch 2809 lr 0.0018159488226505884\n",
      "train_loss 0.3346695534023505 train_acc 0.8515697111909343\n",
      "epoch 2810 lr 0.0018123205544828779\n",
      "train_loss 0.33466559465243406 train_acc 0.8515585903181682\n",
      "epoch 2811 lr 0.001808699535599802\n",
      "train_loss 0.33466162386449333 train_acc 0.8515808320637004\n",
      "epoch 2812 lr 0.0018050857515172797\n",
      "train_loss 0.3346576501674356 train_acc 0.8515919529364665\n",
      "epoch 2813 lr 0.001801479187780169\n",
      "train_loss 0.3346536714994509 train_acc 0.8515697111909343\n",
      "epoch 2814 lr 0.001797879829962213\n",
      "train_loss 0.33464969346332585 train_acc 0.8515919529364665\n",
      "epoch 2815 lr 0.0017942876636659738\n",
      "train_loss 0.3346457202489948 train_acc 0.8515808320637004\n",
      "epoch 2816 lr 0.0017907026745227817\n",
      "train_loss 0.33464175540232877 train_acc 0.8515808320637004\n",
      "epoch 2817 lr 0.0017871248481926738\n",
      "train_loss 0.33463779521476505 train_acc 0.8515919529364665\n",
      "epoch 2818 lr 0.001783554170364343\n",
      "train_loss 0.33463385474799995 train_acc 0.8515808320637004\n",
      "epoch 2819 lr 0.0017799906267550718\n",
      "train_loss 0.3346298928792323 train_acc 0.8515808320637004\n",
      "epoch 2820 lr 0.001776434203110681\n",
      "train_loss 0.3346259279099838 train_acc 0.8515919529364665\n",
      "epoch 2821 lr 0.0017728848852054694\n",
      "train_loss 0.33462195552745083 train_acc 0.8516030738092325\n",
      "epoch 2822 lr 0.0017693426588421641\n",
      "train_loss 0.3346179797965303 train_acc 0.8516253155547647\n",
      "epoch 2823 lr 0.0017658075098518535\n",
      "train_loss 0.33461401933412754 train_acc 0.851647557300297\n",
      "epoch 2824 lr 0.0017622794240939367\n",
      "train_loss 0.3346100768045455 train_acc 0.8516364364275308\n",
      "epoch 2825 lr 0.0017587583874560642\n",
      "train_loss 0.33460614301863284 train_acc 0.8516253155547647\n",
      "epoch 2826 lr 0.0017552443858540883\n",
      "train_loss 0.33460221862435285 train_acc 0.8516253155547647\n",
      "epoch 2827 lr 0.0017517374052319961\n",
      "train_loss 0.33459831014609426 train_acc 0.8516253155547647\n",
      "epoch 2828 lr 0.0017482374315618604\n",
      "train_loss 0.3345944045584169 train_acc 0.8516141946819986\n",
      "epoch 2829 lr 0.0017447444508437804\n",
      "train_loss 0.3345905070654921 train_acc 0.8516253155547647\n",
      "epoch 2830 lr 0.0017412584491058316\n",
      "train_loss 0.33458662226930386 train_acc 0.8516364364275308\n",
      "epoch 2831 lr 0.001737779412404001\n",
      "train_loss 0.33458273027352703 train_acc 0.8516253155547647\n",
      "epoch 2832 lr 0.001734307326822137\n",
      "train_loss 0.33457882261294664 train_acc 0.8516253155547647\n",
      "epoch 2833 lr 0.0017308421784718911\n",
      "train_loss 0.3345749135544405 train_acc 0.8516141946819986\n",
      "epoch 2834 lr 0.0017273839534926686\n",
      "train_loss 0.33457099829666326 train_acc 0.8516141946819986\n",
      "epoch 2835 lr 0.0017239326380515633\n",
      "train_loss 0.3345670761294833 train_acc 0.8516141946819986\n",
      "epoch 2836 lr 0.0017204882183433085\n",
      "train_loss 0.33456313920996217 train_acc 0.8516141946819986\n",
      "epoch 2837 lr 0.0017170506805902197\n",
      "train_loss 0.3345591863644957 train_acc 0.8516141946819986\n",
      "epoch 2838 lr 0.001713620011042144\n",
      "train_loss 0.3345552293374539 train_acc 0.8516253155547647\n",
      "epoch 2839 lr 0.0017101961959763976\n",
      "train_loss 0.33455127688882963 train_acc 0.851647557300297\n",
      "epoch 2840 lr 0.0017067792216977152\n",
      "train_loss 0.33454733004292536 train_acc 0.8516253155547647\n",
      "epoch 2841 lr 0.0017033690745381937\n",
      "train_loss 0.3345433703748823 train_acc 0.8516141946819986\n",
      "epoch 2842 lr 0.0016999657408572433\n",
      "train_loss 0.3345393859983371 train_acc 0.8516364364275308\n",
      "epoch 2843 lr 0.0016965692070415226\n",
      "train_loss 0.33453540628173467 train_acc 0.8516364364275308\n",
      "epoch 2844 lr 0.0016931794595048924\n",
      "train_loss 0.3345314346745506 train_acc 0.8516364364275308\n",
      "epoch 2845 lr 0.0016897964846883562\n",
      "train_loss 0.3345274702068348 train_acc 0.8516364364275308\n",
      "epoch 2846 lr 0.0016864202690600133\n",
      "train_loss 0.3345235037674009 train_acc 0.8516364364275308\n",
      "epoch 2847 lr 0.0016830507991149953\n",
      "train_loss 0.33451953983114635 train_acc 0.851647557300297\n",
      "epoch 2848 lr 0.0016796880613754177\n",
      "train_loss 0.33451559218852056 train_acc 0.851647557300297\n",
      "epoch 2849 lr 0.0016763320423903239\n",
      "train_loss 0.33451164152473983 train_acc 0.8516253155547647\n",
      "\n",
      "val loss = 0.3415678291042525, \n",
      "val acc = 0.8517814251401121\n",
      "\n",
      "epoch 2850 lr 0.001672982728735636\n",
      "train_loss 0.33450768504094897 train_acc 0.8516364364275308\n",
      "epoch 2851 lr 0.0016696401070140938\n",
      "train_loss 0.33450372785602017 train_acc 0.851647557300297\n",
      "epoch 2852 lr 0.0016663041638552058\n",
      "train_loss 0.3344997749947487 train_acc 0.8516697990458291\n",
      "epoch 2853 lr 0.0016629748859151936\n",
      "train_loss 0.3344958243145885 train_acc 0.8516920407913613\n",
      "epoch 2854 lr 0.0016596522598769437\n",
      "train_loss 0.3344918765383174 train_acc 0.8516809199185952\n",
      "epoch 2855 lr 0.0016563362724499463\n",
      "train_loss 0.3344879175677716 train_acc 0.8516809199185952\n",
      "epoch 2856 lr 0.001653026910370247\n",
      "train_loss 0.3344839564309135 train_acc 0.8516920407913613\n",
      "epoch 2857 lr 0.001649724160400392\n",
      "train_loss 0.33447997605148405 train_acc 0.8516809199185952\n",
      "epoch 2858 lr 0.0016464280093293794\n",
      "train_loss 0.3344760061715512 train_acc 0.8517031616641274\n",
      "epoch 2859 lr 0.0016431384439725995\n",
      "train_loss 0.33447204256262997 train_acc 0.8517031616641274\n",
      "epoch 2860 lr 0.0016398554511717865\n",
      "train_loss 0.33446809071471273 train_acc 0.8516809199185952\n",
      "epoch 2861 lr 0.001636579017794963\n",
      "train_loss 0.3344641341829001 train_acc 0.8517031616641274\n",
      "epoch 2862 lr 0.0016333091307363943\n",
      "train_loss 0.3344601842622414 train_acc 0.8517031616641274\n",
      "epoch 2863 lr 0.0016300457769165262\n",
      "train_loss 0.3344562378171368 train_acc 0.8517031616641274\n",
      "epoch 2864 lr 0.0016267889432819392\n",
      "train_loss 0.33445228215741685 train_acc 0.8517031616641274\n",
      "epoch 2865 lr 0.0016235386168052931\n",
      "train_loss 0.33444833478314373 train_acc 0.8517254034096596\n",
      "epoch 2866 lr 0.0016202947844852803\n",
      "train_loss 0.3344443791363136 train_acc 0.8517365242824256\n",
      "epoch 2867 lr 0.0016170574333465657\n",
      "train_loss 0.334440411961858 train_acc 0.8517365242824256\n",
      "epoch 2868 lr 0.0016138265504397407\n",
      "train_loss 0.3344364745294922 train_acc 0.8517254034096596\n",
      "epoch 2869 lr 0.0016106021228412678\n",
      "train_loss 0.3344325361458862 train_acc 0.8517587660279579\n",
      "epoch 2870 lr 0.001607384137653435\n",
      "train_loss 0.3344285981957188 train_acc 0.8517476451551917\n",
      "epoch 2871 lr 0.0016041725820042962\n",
      "train_loss 0.33442465649358155 train_acc 0.8517476451551917\n",
      "epoch 2872 lr 0.0016009674430476242\n",
      "train_loss 0.3344207186897911 train_acc 0.8517476451551917\n",
      "epoch 2873 lr 0.0015977687079628575\n",
      "train_loss 0.3344167939500434 train_acc 0.8517476451551917\n",
      "epoch 2874 lr 0.0015945763639550546\n",
      "train_loss 0.3344128810879318 train_acc 0.8517476451551917\n",
      "epoch 2875 lr 0.0015913903982548334\n",
      "train_loss 0.3344089658840968 train_acc 0.8517476451551917\n",
      "epoch 2876 lr 0.0015882107981183273\n",
      "train_loss 0.33440503500249935 train_acc 0.8517476451551917\n",
      "epoch 2877 lr 0.0015850375508271312\n",
      "train_loss 0.33440110624386665 train_acc 0.8517476451551917\n",
      "epoch 2878 lr 0.0015818706436882505\n",
      "train_loss 0.3343971632274737 train_acc 0.8517476451551917\n",
      "epoch 2879 lr 0.001578710064034055\n",
      "train_loss 0.33439322982082637 train_acc 0.8517365242824256\n",
      "epoch 2880 lr 0.0015755557992222205\n",
      "train_loss 0.334389307064432 train_acc 0.8517476451551917\n",
      "epoch 2881 lr 0.0015724078366356838\n",
      "train_loss 0.3343854009923837 train_acc 0.8517587660279579\n",
      "epoch 2882 lr 0.0015692661636825887\n",
      "train_loss 0.334381512836618 train_acc 0.851769886900724\n",
      "epoch 2883 lr 0.0015661307677962422\n",
      "train_loss 0.33437762438574703 train_acc 0.851769886900724\n",
      "epoch 2884 lr 0.0015630016364350549\n",
      "train_loss 0.33437372834540335 train_acc 0.8517254034096596\n",
      "epoch 2885 lr 0.0015598787570824974\n",
      "train_loss 0.33436982776152735 train_acc 0.8517254034096596\n",
      "epoch 2886 lr 0.0015567621172470467\n",
      "train_loss 0.33436592172268303 train_acc 0.8517365242824256\n",
      "epoch 2887 lr 0.001553651704462142\n",
      "train_loss 0.33436203678901993 train_acc 0.8517365242824256\n",
      "epoch 2888 lr 0.0015505475062861267\n",
      "train_loss 0.334358153633227 train_acc 0.8516920407913613\n",
      "epoch 2889 lr 0.0015474495103022041\n",
      "train_loss 0.3343542574760959 train_acc 0.8517254034096596\n",
      "epoch 2890 lr 0.0015443577041183844\n",
      "train_loss 0.334350378289334 train_acc 0.8517254034096596\n",
      "epoch 2891 lr 0.0015412720753674419\n",
      "train_loss 0.3343464973887794 train_acc 0.8517142825368935\n",
      "epoch 2892 lr 0.0015381926117068556\n",
      "train_loss 0.3343426123431707 train_acc 0.8517031616641274\n",
      "epoch 2893 lr 0.0015351193008187672\n",
      "train_loss 0.33433875029654586 train_acc 0.8516920407913613\n",
      "epoch 2894 lr 0.0015320521304099275\n",
      "train_loss 0.33433489495425556 train_acc 0.8516697990458291\n",
      "epoch 2895 lr 0.0015289910882116536\n",
      "train_loss 0.33433104477902514 train_acc 0.8516697990458291\n",
      "epoch 2896 lr 0.0015259361619797713\n",
      "train_loss 0.33432718549753243 train_acc 0.8516697990458291\n",
      "epoch 2897 lr 0.0015228873394945712\n",
      "train_loss 0.33432332445400226 train_acc 0.8516586781730631\n",
      "epoch 2898 lr 0.0015198446085607587\n",
      "train_loss 0.33431946901149234 train_acc 0.8516697990458291\n",
      "epoch 2899 lr 0.0015168079570074078\n",
      "train_loss 0.3343156213960915 train_acc 0.8516697990458291\n",
      "\n",
      "val loss = 0.3414995787468971, \n",
      "val acc = 0.8517814251401121\n",
      "\n",
      "epoch 2900 lr 0.0015137773726879077\n",
      "train_loss 0.33431177734485684 train_acc 0.8516586781730631\n",
      "epoch 2901 lr 0.0015107528434799163\n",
      "train_loss 0.33430793154195126 train_acc 0.8516697990458291\n",
      "epoch 2902 lr 0.0015077343572853122\n",
      "train_loss 0.3343040760889052 train_acc 0.851647557300297\n",
      "epoch 2903 lr 0.0015047219020301488\n",
      "train_loss 0.33430022186133745 train_acc 0.8516586781730631\n",
      "epoch 2904 lr 0.0015017154656645998\n",
      "train_loss 0.33429637396228756 train_acc 0.8516697990458291\n",
      "epoch 2905 lr 0.0014987150361629158\n",
      "train_loss 0.33429253566098 train_acc 0.8516697990458291\n",
      "epoch 2906 lr 0.0014957206015233733\n",
      "train_loss 0.3342887042430823 train_acc 0.8516809199185952\n",
      "epoch 2907 lr 0.0014927321497682324\n",
      "train_loss 0.33428487096433 train_acc 0.8516809199185952\n",
      "epoch 2908 lr 0.0014897496689436811\n",
      "train_loss 0.3342810457713952 train_acc 0.8516809199185952\n",
      "epoch 2909 lr 0.0014867731471197919\n",
      "train_loss 0.3342772124085912 train_acc 0.8516809199185952\n",
      "epoch 2910 lr 0.001483802572390472\n",
      "train_loss 0.3342733842950918 train_acc 0.8516809199185952\n",
      "epoch 2911 lr 0.0014808379328734216\n",
      "train_loss 0.33426954693574196 train_acc 0.8516809199185952\n",
      "epoch 2912 lr 0.0014778792167100773\n",
      "train_loss 0.33426571284627915 train_acc 0.8516697990458291\n",
      "epoch 2913 lr 0.00147492641206557\n",
      "train_loss 0.3342618880603668 train_acc 0.8516809199185952\n",
      "epoch 2914 lr 0.0014719795071286763\n",
      "train_loss 0.3342580633859869 train_acc 0.8516920407913613\n",
      "epoch 2915 lr 0.0014690384901117752\n",
      "train_loss 0.33425424279006266 train_acc 0.8516920407913613\n",
      "epoch 2916 lr 0.001466103349250793\n",
      "train_loss 0.3342504186901988 train_acc 0.8516920407913613\n",
      "epoch 2917 lr 0.001463174072805163\n",
      "train_loss 0.33424660546548124 train_acc 0.8517031616641274\n",
      "epoch 2918 lr 0.0014602506490577734\n",
      "train_loss 0.33424279073530994 train_acc 0.8516697990458291\n",
      "epoch 2919 lr 0.0014573330663149287\n",
      "train_loss 0.3342389684216371 train_acc 0.8516697990458291\n",
      "epoch 2920 lr 0.001454421312906292\n",
      "train_loss 0.33423512585689436 train_acc 0.8516586781730631\n",
      "epoch 2921 lr 0.0014515153771848465\n",
      "train_loss 0.3342312856940795 train_acc 0.851647557300297\n",
      "epoch 2922 lr 0.0014486152475268437\n",
      "train_loss 0.3342274250849216 train_acc 0.8516364364275308\n",
      "epoch 2923 lr 0.0014457209123317637\n",
      "train_loss 0.3342235569423843 train_acc 0.8516253155547647\n",
      "epoch 2924 lr 0.0014428323600222607\n",
      "train_loss 0.33421968941156477 train_acc 0.8516364364275308\n",
      "epoch 2925 lr 0.0014399495790441217\n",
      "train_loss 0.33421581612198265 train_acc 0.8516141946819986\n",
      "epoch 2926 lr 0.0014370725578662174\n",
      "train_loss 0.3342119449927627 train_acc 0.8516364364275308\n",
      "epoch 2927 lr 0.001434201284980462\n",
      "train_loss 0.3342080705403734 train_acc 0.851647557300297\n",
      "epoch 2928 lr 0.0014313357489017585\n",
      "train_loss 0.3342041936292089 train_acc 0.8516586781730631\n",
      "epoch 2929 lr 0.0014284759381679593\n",
      "train_loss 0.3342003081646653 train_acc 0.851647557300297\n",
      "epoch 2930 lr 0.0014256218413398161\n",
      "train_loss 0.3341964152674528 train_acc 0.8516586781730631\n",
      "epoch 2931 lr 0.0014227734470009404\n",
      "train_loss 0.334192516628908 train_acc 0.851647557300297\n",
      "epoch 2932 lr 0.0014199307437577499\n",
      "train_loss 0.33418863444945957 train_acc 0.851647557300297\n",
      "epoch 2933 lr 0.0014170937202394273\n",
      "train_loss 0.3341847536509406 train_acc 0.851647557300297\n",
      "epoch 2934 lr 0.0014142623650978741\n",
      "train_loss 0.33418088803914514 train_acc 0.8516586781730631\n",
      "epoch 2935 lr 0.0014114366670076681\n",
      "train_loss 0.3341770194945648 train_acc 0.8516920407913613\n",
      "epoch 2936 lr 0.0014086166146660122\n",
      "train_loss 0.33417314385297614 train_acc 0.8516920407913613\n",
      "epoch 2937 lr 0.001405802196792693\n",
      "train_loss 0.3341692709013511 train_acc 0.8516920407913613\n",
      "epoch 2938 lr 0.001402993402130034\n",
      "train_loss 0.33416542157761714 train_acc 0.8517031616641274\n",
      "epoch 2939 lr 0.0014001902194428558\n",
      "train_loss 0.33416156262010926 train_acc 0.8516920407913613\n",
      "epoch 2940 lr 0.001397392637518422\n",
      "train_loss 0.33415771287051615 train_acc 0.8517142825368935\n",
      "epoch 2941 lr 0.0013946006451664016\n",
      "train_loss 0.3341538604216878 train_acc 0.8517254034096596\n",
      "epoch 2942 lr 0.00139181423121882\n",
      "train_loss 0.3341500093464651 train_acc 0.8517254034096596\n",
      "epoch 2943 lr 0.0013890333845300203\n",
      "train_loss 0.33414617709638 train_acc 0.8517142825368935\n",
      "epoch 2944 lr 0.0013862580939766108\n",
      "train_loss 0.33414233493906187 train_acc 0.8517365242824256\n",
      "epoch 2945 lr 0.0013834883484574254\n",
      "train_loss 0.33413850327717076 train_acc 0.8517365242824256\n",
      "epoch 2946 lr 0.0013807241368934773\n",
      "train_loss 0.3341346735325296 train_acc 0.8517365242824256\n",
      "epoch 2947 lr 0.001377965448227919\n",
      "train_loss 0.3341308467470621 train_acc 0.8517142825368935\n",
      "epoch 2948 lr 0.001375212271425991\n",
      "train_loss 0.3341270279752563 train_acc 0.8517254034096596\n",
      "epoch 2949 lr 0.0013724645954749821\n",
      "train_loss 0.33412321696905495 train_acc 0.8517476451551917\n",
      "\n",
      "val loss = 0.34142264753387874, \n",
      "val acc = 0.8513811048839072\n",
      "\n",
      "epoch 2950 lr 0.001369722409384184\n",
      "train_loss 0.3341194132246171 train_acc 0.8517365242824256\n",
      "epoch 2951 lr 0.001366985702184851\n",
      "train_loss 0.33411560488828224 train_acc 0.8517810077734901\n",
      "epoch 2952 lr 0.0013642544629301494\n",
      "train_loss 0.33411180222832293 train_acc 0.851769886900724\n",
      "epoch 2953 lr 0.0013615286806951184\n",
      "train_loss 0.33410801278112273 train_acc 0.851769886900724\n",
      "epoch 2954 lr 0.0013588083445766244\n",
      "train_loss 0.3341042114744926 train_acc 0.851769886900724\n",
      "epoch 2955 lr 0.0013560934436933217\n",
      "train_loss 0.3341003880770927 train_acc 0.851769886900724\n",
      "epoch 2956 lr 0.001353383967185602\n",
      "train_loss 0.33409654951209816 train_acc 0.851769886900724\n",
      "epoch 2957 lr 0.001350679904215555\n",
      "train_loss 0.33409271037849725 train_acc 0.8517587660279579\n",
      "epoch 2958 lr 0.0013479812439669253\n",
      "train_loss 0.3340888606638166 train_acc 0.8517476451551917\n",
      "epoch 2959 lr 0.0013452879756450694\n",
      "train_loss 0.33408498071079834 train_acc 0.8517476451551917\n",
      "epoch 2960 lr 0.00134260008847691\n",
      "train_loss 0.3340810986153049 train_acc 0.8517587660279579\n",
      "epoch 2961 lr 0.001339917571710895\n",
      "train_loss 0.3340772149701472 train_acc 0.8517476451551917\n",
      "epoch 2962 lr 0.0013372404146169516\n",
      "train_loss 0.33407332755607805 train_acc 0.8517476451551917\n",
      "epoch 2963 lr 0.0013345686064864513\n",
      "train_loss 0.33406944072280026 train_acc 0.8517476451551917\n",
      "epoch 2964 lr 0.0013319021366321562\n",
      "train_loss 0.3340655583499063 train_acc 0.8517476451551917\n",
      "epoch 2965 lr 0.0013292409943881835\n",
      "train_loss 0.33406168069541425 train_acc 0.8517587660279579\n",
      "epoch 2966 lr 0.0013265851691099595\n",
      "train_loss 0.3340577984436471 train_acc 0.8517365242824256\n",
      "epoch 2967 lr 0.001323934650174182\n",
      "train_loss 0.3340539186866399 train_acc 0.8517476451551917\n",
      "epoch 2968 lr 0.0013212894269787703\n",
      "train_loss 0.3340500578137396 train_acc 0.8517476451551917\n",
      "epoch 2969 lr 0.0013186494889428284\n",
      "train_loss 0.3340461952611283 train_acc 0.8517476451551917\n",
      "epoch 2970 lr 0.0013160148255065992\n",
      "train_loss 0.33404233870213285 train_acc 0.8517365242824256\n",
      "epoch 2971 lr 0.0013133854261314277\n",
      "train_loss 0.3340384839687863 train_acc 0.8517254034096596\n",
      "epoch 2972 lr 0.0013107612802997122\n",
      "train_loss 0.3340346430316606 train_acc 0.8517254034096596\n",
      "epoch 2973 lr 0.0013081423775148653\n",
      "train_loss 0.33403080737205154 train_acc 0.8517142825368935\n",
      "epoch 2974 lr 0.0013055287073012716\n",
      "train_loss 0.33402698686069826 train_acc 0.8517031616641274\n",
      "epoch 2975 lr 0.0013029202592042492\n",
      "train_loss 0.3340231676537099 train_acc 0.8517142825368935\n",
      "epoch 2976 lr 0.0013003170227900006\n",
      "train_loss 0.3340193343040932 train_acc 0.8517142825368935\n",
      "epoch 2977 lr 0.0012977189876455769\n",
      "train_loss 0.3340155079607274 train_acc 0.8517031616641274\n",
      "epoch 2978 lr 0.001295126143378833\n",
      "train_loss 0.33401169387313534 train_acc 0.8517031616641274\n",
      "epoch 2979 lr 0.0012925384796183906\n",
      "train_loss 0.33400789292536603 train_acc 0.8517031616641274\n",
      "epoch 2980 lr 0.00128995598601359\n",
      "train_loss 0.33400409622307653 train_acc 0.8517254034096596\n",
      "epoch 2981 lr 0.0012873786522344536\n",
      "train_loss 0.3340003066945546 train_acc 0.8517254034096596\n",
      "epoch 2982 lr 0.0012848064679716411\n",
      "train_loss 0.3339965351703496 train_acc 0.8517476451551917\n",
      "epoch 2983 lr 0.001282239422936415\n",
      "train_loss 0.3339927699389262 train_acc 0.851769886900724\n",
      "epoch 2984 lr 0.0012796775068605903\n",
      "train_loss 0.33398901176006957 train_acc 0.8517810077734901\n",
      "epoch 2985 lr 0.0012771207094964992\n",
      "train_loss 0.3339852640797007 train_acc 0.8517810077734901\n",
      "epoch 2986 lr 0.0012745690206169477\n",
      "train_loss 0.33398151601730125 train_acc 0.8517476451551917\n",
      "epoch 2987 lr 0.0012720224300151795\n",
      "train_loss 0.3339777675158966 train_acc 0.8517476451551917\n",
      "epoch 2988 lr 0.0012694809275048272\n",
      "train_loss 0.3339740260388022 train_acc 0.8517365242824256\n",
      "epoch 2989 lr 0.0012669445029198775\n",
      "train_loss 0.3339703012228483 train_acc 0.8517365242824256\n",
      "epoch 2990 lr 0.0012644131461146278\n",
      "train_loss 0.333966572204683 train_acc 0.8517476451551917\n",
      "epoch 2991 lr 0.0012618868469636494\n",
      "train_loss 0.33396285886828164 train_acc 0.8517365242824256\n",
      "epoch 2992 lr 0.0012593655953617414\n",
      "train_loss 0.33395914744865074 train_acc 0.8517476451551917\n",
      "epoch 2993 lr 0.001256849381223894\n",
      "train_loss 0.33395542630571895 train_acc 0.8517365242824256\n",
      "epoch 2994 lr 0.0012543381944852463\n",
      "train_loss 0.3339517005600784 train_acc 0.8517476451551917\n",
      "epoch 2995 lr 0.00125183202510105\n",
      "train_loss 0.3339479831195263 train_acc 0.8517476451551917\n",
      "epoch 2996 lr 0.0012493308630466232\n",
      "train_loss 0.3339442673227917 train_acc 0.8517476451551917\n",
      "epoch 2997 lr 0.0012468346983173144\n",
      "train_loss 0.3339405618698632 train_acc 0.8517587660279579\n",
      "epoch 2998 lr 0.0012443435209284603\n",
      "train_loss 0.3339368579090774 train_acc 0.8517365242824256\n",
      "epoch 2999 lr 0.00124185732091535\n",
      "train_loss 0.33393314921252787 train_acc 0.8517365242824256\n",
      "\n",
      "val loss = 0.34134717512802837, \n",
      "val acc = 0.8515812650120096\n",
      "\n",
      "epoch 3000 lr 0.0012393760883331792\n",
      "train_loss 0.3339294502816463 train_acc 0.851769886900724\n",
      "\n",
      "-----training done-----\n",
      "\n",
      "model0 training took 53.31 minutes\n",
      "\n",
      "-----model1 training-----\n",
      "\n",
      "epoch 1 lr 0.4990009993336666\n",
      "train_loss 0.6929007551405006 train_acc 0.5201965925862242\n",
      "epoch 2 lr 0.4980039946719958\n",
      "train_loss 0.6888877975463468 train_acc 0.6422931980684635\n",
      "epoch 3 lr 0.4970089820269677\n",
      "train_loss 0.6852688675914641 train_acc 0.6422931980684635\n",
      "epoch 4 lr 0.49601595741853033\n",
      "train_loss 0.6820049251802066 train_acc 0.6422931980684635\n",
      "epoch 5 lr 0.49502491687458405\n",
      "train_loss 0.6790606028671183 train_acc 0.6422931980684635\n",
      "epoch 6 lr 0.4940358564309653\n",
      "train_loss 0.6764041483710053 train_acc 0.6422931980684635\n",
      "epoch 7 lr 0.493048772131431\n",
      "train_loss 0.6740070078355191 train_acc 0.6422931980684635\n",
      "epoch 8 lr 0.49206366002764257\n",
      "train_loss 0.6718433675693533 train_acc 0.6422931980684635\n",
      "epoch 9 lr 0.4910805161791504\n",
      "train_loss 0.6698899932835605 train_acc 0.6422931980684635\n",
      "epoch 10 lr 0.4900993366533777\n",
      "train_loss 0.6681260742260151 train_acc 0.6422931980684635\n",
      "epoch 11 lr 0.4891201175256051\n",
      "train_loss 0.6665329363009442 train_acc 0.6422931980684635\n",
      "epoch 12 lr 0.4881428548789547\n",
      "train_loss 0.6650935850312624 train_acc 0.6422931980684635\n",
      "epoch 13 lr 0.4871675448043747\n",
      "train_loss 0.6637928560402071 train_acc 0.6422931980684635\n",
      "epoch 14 lr 0.4861941834006235\n",
      "train_loss 0.662617086001987 train_acc 0.6422931980684635\n",
      "epoch 15 lr 0.48522276677425413\n",
      "train_loss 0.6615539442773011 train_acc 0.6422931980684635\n",
      "epoch 16 lr 0.4842532910395988\n",
      "train_loss 0.6605923832778315 train_acc 0.6422931980684635\n",
      "epoch 17 lr 0.48328575231875337\n",
      "train_loss 0.6597224190544247 train_acc 0.6422931980684635\n",
      "epoch 18 lr 0.48232014674156154\n",
      "train_loss 0.658934963882116 train_acc 0.6422931980684635\n",
      "epoch 19 lr 0.4813564704455998\n",
      "train_loss 0.6582218827349426 train_acc 0.6422931980684635\n",
      "epoch 20 lr 0.48039471957616164\n",
      "train_loss 0.657575735205103 train_acc 0.6422931980684635\n",
      "epoch 21 lr 0.4794348902862423\n",
      "train_loss 0.6569900888459028 train_acc 0.6422931980684635\n",
      "epoch 22 lr 0.47847697873652334\n",
      "train_loss 0.6564591025990268 train_acc 0.6422931980684635\n",
      "epoch 23 lr 0.47752098109535734\n",
      "train_loss 0.6559774325675899 train_acc 0.6422931980684635\n",
      "epoch 24 lr 0.47656689353875237\n",
      "train_loss 0.6555402071485306 train_acc 0.6422931980684635\n",
      "epoch 25 lr 0.475614712250357\n",
      "train_loss 0.6551432260449148 train_acc 0.6422931980684635\n",
      "epoch 26 lr 0.47466443342144476\n",
      "train_loss 0.6547825154351262 train_acc 0.6422931980684635\n",
      "epoch 27 lr 0.47371605325089916\n",
      "train_loss 0.6544544966617881 train_acc 0.6422931980684635\n",
      "epoch 28 lr 0.47276956794519814\n",
      "train_loss 0.6541560543441534 train_acc 0.6422931980684635\n",
      "epoch 29 lr 0.47182497371839927\n",
      "train_loss 0.6538842932359777 train_acc 0.6422931980684635\n",
      "epoch 30 lr 0.47088226679212436\n",
      "train_loss 0.6536366379392876 train_acc 0.6422931980684635\n",
      "epoch 31 lr 0.46994144339554444\n",
      "train_loss 0.6534107121658714 train_acc 0.6422931980684635\n",
      "epoch 32 lr 0.46900249976536473\n",
      "train_loss 0.6532044891578098 train_acc 0.6422931980684635\n",
      "epoch 33 lr 0.4680654321458094\n",
      "train_loss 0.6530160280340015 train_acc 0.6422931980684635\n",
      "epoch 34 lr 0.46713023678860677\n",
      "train_loss 0.6528436154597486 train_acc 0.6422931980684635\n",
      "epoch 35 lr 0.46619690995297414\n",
      "train_loss 0.6526857224476674 train_acc 0.6422931980684635\n",
      "epoch 36 lr 0.46526544790560287\n",
      "train_loss 0.6525409141665204 train_acc 0.6422931980684635\n",
      "epoch 37 lr 0.4643358469206436\n",
      "train_loss 0.6524079181365456 train_acc 0.6422931980684635\n",
      "epoch 38 lr 0.4634081032796911\n",
      "train_loss 0.6522856360727687 train_acc 0.6422931980684635\n",
      "epoch 39 lr 0.46248221327176964\n",
      "train_loss 0.6521729467166287 train_acc 0.6422931980684635\n",
      "epoch 40 lr 0.4615581731933179\n",
      "train_loss 0.6520689579050004 train_acc 0.6422931980684635\n",
      "epoch 41 lr 0.4606359793481743\n",
      "train_loss 0.6519728379275811 train_acc 0.6422931980684635\n",
      "epoch 42 lr 0.45971562804756233\n",
      "train_loss 0.6518837965900304 train_acc 0.6422931980684635\n",
      "epoch 43 lr 0.45879711561007547\n",
      "train_loss 0.6518010917067902 train_acc 0.6422931980684635\n",
      "epoch 44 lr 0.4578804383616628\n",
      "train_loss 0.6517241317813661 train_acc 0.6422931980684635\n",
      "epoch 45 lr 0.4569655926356141\n",
      "train_loss 0.6516523431159136 train_acc 0.6422931980684635\n",
      "epoch 46 lr 0.45605257477254524\n",
      "train_loss 0.6515852193679025 train_acc 0.6422931980684635\n",
      "epoch 47 lr 0.4551413811203835\n",
      "train_loss 0.6515222789208428 train_acc 0.6422931980684635\n",
      "epoch 48 lr 0.4542320080343531\n",
      "train_loss 0.6514631105247958 train_acc 0.6422931980684635\n",
      "epoch 49 lr 0.45332445187696047\n",
      "train_loss 0.6514073486520707 train_acc 0.6422931980684635\n",
      "\n",
      "val loss = 0.6494027983254324, \n",
      "val acc = 0.6459058671824629\n",
      "\n",
      "epoch 50 lr 0.45241870901797976\n",
      "train_loss 0.6513546192982285 train_acc 0.6422931980684635\n",
      "epoch 51 lr 0.4515147758344384\n",
      "train_loss 0.6513045860249828 train_acc 0.6422931980684635\n",
      "epoch 52 lr 0.4506126487106024\n",
      "train_loss 0.6512569508138312 train_acc 0.6422931980684635\n",
      "epoch 53 lr 0.449712324037962\n",
      "train_loss 0.6512114796712392 train_acc 0.6422931980684635\n",
      "epoch 54 lr 0.44881379821521744\n",
      "train_loss 0.6511679406747365 train_acc 0.6422931980684635\n",
      "epoch 55 lr 0.4479170676482641\n",
      "train_loss 0.6511260934136168 train_acc 0.6422931980684635\n",
      "epoch 56 lr 0.4470221287501786\n",
      "train_loss 0.6510857542438415 train_acc 0.6422931980684635\n",
      "epoch 57 lr 0.44612897794120415\n",
      "train_loss 0.65104673488527 train_acc 0.6422931980684635\n",
      "epoch 58 lr 0.44523761164873626\n",
      "train_loss 0.6510088856129862 train_acc 0.6422931980684635\n",
      "epoch 59 lr 0.4443480263073087\n",
      "train_loss 0.6509720529297665 train_acc 0.6422931980684635\n",
      "epoch 60 lr 0.44346021835857874\n",
      "train_loss 0.6509360954964782 train_acc 0.6422931980684635\n",
      "epoch 61 lr 0.44257418425131356\n",
      "train_loss 0.6509008999190248 train_acc 0.6422931980684635\n",
      "epoch 62 lr 0.44168992044137545\n",
      "train_loss 0.650866339209399 train_acc 0.6422931980684635\n",
      "epoch 63 lr 0.44080742339170803\n",
      "train_loss 0.650832320309051 train_acc 0.6422931980684635\n",
      "epoch 64 lr 0.4399266895723219\n",
      "train_loss 0.6507987435027166 train_acc 0.6422931980684635\n",
      "epoch 65 lr 0.43904771546028065\n",
      "train_loss 0.6507655215636302 train_acc 0.6422931980684635\n",
      "epoch 66 lr 0.4381704975396867\n",
      "train_loss 0.6507325829522487 train_acc 0.6422931980684635\n",
      "epoch 67 lr 0.437295032301667\n",
      "train_loss 0.6506998528007817 train_acc 0.6422931980684635\n",
      "epoch 68 lr 0.43642131624435965\n",
      "train_loss 0.6506672566624846 train_acc 0.6422931980684635\n",
      "epoch 69 lr 0.4355493458728992\n",
      "train_loss 0.6506347169996949 train_acc 0.6422931980684635\n",
      "epoch 70 lr 0.4346791176994029\n",
      "train_loss 0.6506021850532034 train_acc 0.6422931980684635\n",
      "epoch 71 lr 0.433810628242957\n",
      "train_loss 0.6505696196001836 train_acc 0.6422931980684635\n",
      "epoch 72 lr 0.4329438740296025\n",
      "train_loss 0.6505369675210593 train_acc 0.6422931980684635\n",
      "epoch 73 lr 0.43207885159232134\n",
      "train_loss 0.6505041644118765 train_acc 0.6422931980684635\n",
      "epoch 74 lr 0.4312155574710227\n",
      "train_loss 0.6504711789464159 train_acc 0.6422931980684635\n",
      "epoch 75 lr 0.4303539882125289\n",
      "train_loss 0.6504379601345136 train_acc 0.6422931980684635\n",
      "epoch 76 lr 0.4294941403705617\n",
      "train_loss 0.650404477075418 train_acc 0.6422931980684635\n",
      "epoch 77 lr 0.4286360105057287\n",
      "train_loss 0.6503706889092679 train_acc 0.6422931980684635\n",
      "epoch 78 lr 0.42777959518550923\n",
      "train_loss 0.6503365620844983 train_acc 0.6422931980684635\n",
      "epoch 79 lr 0.42692489098424086\n",
      "train_loss 0.650302070445024 train_acc 0.6422931980684635\n",
      "epoch 80 lr 0.4260718944831057\n",
      "train_loss 0.6502671737418345 train_acc 0.6422931980684635\n",
      "epoch 81 lr 0.4252206022701165\n",
      "train_loss 0.650231836238496 train_acc 0.6422931980684635\n",
      "epoch 82 lr 0.4243710109401033\n",
      "train_loss 0.6501960413013391 train_acc 0.6422931980684635\n",
      "epoch 83 lr 0.4235231170946998\n",
      "train_loss 0.6501597499688407 train_acc 0.6422931980684635\n",
      "epoch 84 lr 0.4226769173423293\n",
      "train_loss 0.6501229436333285 train_acc 0.6422931980684635\n",
      "epoch 85 lr 0.4218324082981918\n",
      "train_loss 0.6500855839676066 train_acc 0.6422931980684635\n",
      "epoch 86 lr 0.42098958658424995\n",
      "train_loss 0.6500476465770019 train_acc 0.6422931980684635\n",
      "epoch 87 lr 0.4201484488292157\n",
      "train_loss 0.6500091059012029 train_acc 0.6422931980684635\n",
      "epoch 88 lr 0.419308991668537\n",
      "train_loss 0.6499699417503644 train_acc 0.6422931980684635\n",
      "epoch 89 lr 0.41847121174438406\n",
      "train_loss 0.6499301179227749 train_acc 0.6422931980684635\n",
      "epoch 90 lr 0.417635105705636\n",
      "train_loss 0.649889609366531 train_acc 0.6422931980684635\n",
      "epoch 91 lr 0.41680067020786765\n",
      "train_loss 0.6498483886881193 train_acc 0.6422931980684635\n",
      "epoch 92 lr 0.4159679019133359\n",
      "train_loss 0.6498064195300524 train_acc 0.6422931980684635\n",
      "epoch 93 lr 0.4151367974909663\n",
      "train_loss 0.6497636796644732 train_acc 0.6422931980684635\n",
      "epoch 94 lr 0.4143073536163403\n",
      "train_loss 0.6497201471818025 train_acc 0.6422931980684635\n",
      "epoch 95 lr 0.41347956697168115\n",
      "train_loss 0.6496758133433531 train_acc 0.6422931980684635\n",
      "epoch 96 lr 0.4126534342458412\n",
      "train_loss 0.6496306377779919 train_acc 0.6422931980684635\n",
      "epoch 97 lr 0.41182895213428844\n",
      "train_loss 0.6495845995552714 train_acc 0.6422931980684635\n",
      "epoch 98 lr 0.41100611733909326\n",
      "train_loss 0.649537667586271 train_acc 0.6422931980684635\n",
      "epoch 99 lr 0.41018492656891553\n",
      "train_loss 0.6494898209729171 train_acc 0.6422931980684635\n",
      "\n",
      "val loss = 0.6473340028496061, \n",
      "val acc = 0.6459058671824629\n",
      "\n",
      "epoch 100 lr 0.4093653765389909\n",
      "train_loss 0.6494410389679529 train_acc 0.6422931980684635\n",
      "epoch 101 lr 0.4085474639711183\n",
      "train_loss 0.6493912695319549 train_acc 0.6422931980684635\n",
      "epoch 102 lr 0.40773118559364635\n",
      "train_loss 0.6493404830325025 train_acc 0.6422931980684635\n",
      "epoch 103 lr 0.40691653814146034\n",
      "train_loss 0.6492886630525565 train_acc 0.6422931980684635\n",
      "epoch 104 lr 0.40610351835596953\n",
      "train_loss 0.6492357743027083 train_acc 0.6422931980684635\n",
      "epoch 105 lr 0.40529212298509354\n",
      "train_loss 0.649181780713705 train_acc 0.6422931980684635\n",
      "epoch 106 lr 0.4044823487832499\n",
      "train_loss 0.6491266379066327 train_acc 0.6422931980684635\n",
      "epoch 107 lr 0.40367419251134073\n",
      "train_loss 0.6490703241622668 train_acc 0.6422931980684635\n",
      "epoch 108 lr 0.4028676509367398\n",
      "train_loss 0.6490127885095822 train_acc 0.6422931980684635\n",
      "epoch 109 lr 0.4020627208332798\n",
      "train_loss 0.6489540149093864 train_acc 0.6422931980684635\n",
      "epoch 110 lr 0.40125939898123925\n",
      "train_loss 0.6488939676165485 train_acc 0.6422931980684635\n",
      "epoch 111 lr 0.4004576821673296\n",
      "train_loss 0.6488326153258203 train_acc 0.6422931980684635\n",
      "epoch 112 lr 0.39965756718468254\n",
      "train_loss 0.6487699084989778 train_acc 0.6422931980684635\n",
      "epoch 113 lr 0.3988590508328371\n",
      "train_loss 0.6487058022921168 train_acc 0.6422931980684635\n",
      "epoch 114 lr 0.3980621299177268\n",
      "train_loss 0.64864027582269 train_acc 0.6422931980684635\n",
      "epoch 115 lr 0.39726680125166697\n",
      "train_loss 0.6485732764173905 train_acc 0.6422931980684635\n",
      "epoch 116 lr 0.39647306165334184\n",
      "train_loss 0.6485047613179556 train_acc 0.6422931980684635\n",
      "epoch 117 lr 0.3956809079477919\n",
      "train_loss 0.6484346999937193 train_acc 0.6422931980684635\n",
      "epoch 118 lr 0.39489033696640136\n",
      "train_loss 0.6483630327133374 train_acc 0.6422931980684635\n",
      "epoch 119 lr 0.3941013455468852\n",
      "train_loss 0.6482896968050242 train_acc 0.6422931980684635\n",
      "epoch 120 lr 0.3933139305332767\n",
      "train_loss 0.6482146449627287 train_acc 0.6422931980684635\n",
      "epoch 121 lr 0.3925280887759147\n",
      "train_loss 0.6481378112362794 train_acc 0.6422931980684635\n",
      "epoch 122 lr 0.39174381713143125\n",
      "train_loss 0.6480591401951875 train_acc 0.6422931980684635\n",
      "epoch 123 lr 0.3909611124627386\n",
      "train_loss 0.6479785933506416 train_acc 0.6422931980684635\n",
      "epoch 124 lr 0.39017997163901713\n",
      "train_loss 0.6478961054067531 train_acc 0.6422931980684635\n",
      "epoch 125 lr 0.38940039153570244\n",
      "train_loss 0.6478116437539967 train_acc 0.6422931980684635\n",
      "epoch 126 lr 0.38862236903447306\n",
      "train_loss 0.6477251870161387 train_acc 0.6422931980684635\n",
      "epoch 127 lr 0.387845901023238\n",
      "train_loss 0.6476366358132815 train_acc 0.6422931980684635\n",
      "epoch 128 lr 0.38707098439612414\n",
      "train_loss 0.6475459507874325 train_acc 0.6422931980684635\n",
      "epoch 129 lr 0.386297616053464\n",
      "train_loss 0.6474530677068142 train_acc 0.6422931980684635\n",
      "epoch 130 lr 0.3855257929017831\n",
      "train_loss 0.647357908262176 train_acc 0.6422931980684635\n",
      "epoch 131 lr 0.3847555118537879\n",
      "train_loss 0.647260387118824 train_acc 0.6422931980684635\n",
      "epoch 132 lr 0.3839867698283531\n",
      "train_loss 0.6471604135088548 train_acc 0.6422931980684635\n",
      "epoch 133 lr 0.3832195637505096\n",
      "train_loss 0.6470579674267003 train_acc 0.6422931980684635\n",
      "epoch 134 lr 0.38245389055143203\n",
      "train_loss 0.6469529321409935 train_acc 0.6422931980684635\n",
      "epoch 135 lr 0.3816897471684266\n",
      "train_loss 0.6468452135783831 train_acc 0.6422931980684635\n",
      "epoch 136 lr 0.3809271305449188\n",
      "train_loss 0.6467347399393644 train_acc 0.6422931980684635\n",
      "epoch 137 lr 0.38016603763044104\n",
      "train_loss 0.6466214313095274 train_acc 0.6422931980684635\n",
      "epoch 138 lr 0.3794064653806207\n",
      "train_loss 0.6465051909942693 train_acc 0.6422931980684635\n",
      "epoch 139 lr 0.37864841075716776\n",
      "train_loss 0.64638593243387 train_acc 0.6422931980684635\n",
      "epoch 140 lr 0.37789187072786273\n",
      "train_loss 0.6462635432071077 train_acc 0.6422931980684635\n",
      "epoch 141 lr 0.3771368422665445\n",
      "train_loss 0.6461379279323428 train_acc 0.6422931980684635\n",
      "epoch 142 lr 0.3763833223530981\n",
      "train_loss 0.6460090129634394 train_acc 0.6422931980684635\n",
      "epoch 143 lr 0.375631307973443\n",
      "train_loss 0.6458766748979426 train_acc 0.6422931980684635\n",
      "epoch 144 lr 0.3748807961195207\n",
      "train_loss 0.6457408005449613 train_acc 0.6422931980684635\n",
      "epoch 145 lr 0.37413178378928263\n",
      "train_loss 0.6456012698828437 train_acc 0.6422931980684635\n",
      "epoch 146 lr 0.37338426798667856\n",
      "train_loss 0.645457971455874 train_acc 0.6422931980684635\n",
      "epoch 147 lr 0.37263824572164433\n",
      "train_loss 0.6453107848700264 train_acc 0.6422931980684635\n",
      "epoch 148 lr 0.3718937140100898\n",
      "train_loss 0.6451595857570257 train_acc 0.6422931980684635\n",
      "epoch 149 lr 0.3711506698738872\n",
      "train_loss 0.64500423134451 train_acc 0.6422931980684635\n",
      "\n",
      "val loss = 0.642753770770821, \n",
      "val acc = 0.6459058671824629\n",
      "\n",
      "epoch 150 lr 0.37040911034085894\n",
      "train_loss 0.6448445658734552 train_acc 0.6422931980684635\n",
      "epoch 151 lr 0.36966903244476595\n",
      "train_loss 0.6446804463936185 train_acc 0.6422931980684635\n",
      "epoch 152 lr 0.3689304332252956\n",
      "train_loss 0.6445117864481094 train_acc 0.6422931980684635\n",
      "epoch 153 lr 0.3681933097280501\n",
      "train_loss 0.6443383901623421 train_acc 0.6422931980684635\n",
      "epoch 154 lr 0.3674576590045344\n",
      "train_loss 0.6441601194073052 train_acc 0.6422931980684635\n",
      "epoch 155 lr 0.3667234781121447\n",
      "train_loss 0.6439767887099864 train_acc 0.6422931980684635\n",
      "epoch 156 lr 0.3659907641141563\n",
      "train_loss 0.6437882224737828 train_acc 0.6422931980684635\n",
      "epoch 157 lr 0.36525951407971247\n",
      "train_loss 0.6435942381911741 train_acc 0.6422931980684635\n",
      "epoch 158 lr 0.36452972508381193\n",
      "train_loss 0.6433946558303048 train_acc 0.6422931980684635\n",
      "epoch 159 lr 0.36380139420729773\n",
      "train_loss 0.6431892591347498 train_acc 0.6422931980684635\n",
      "epoch 160 lr 0.36307451853684547\n",
      "train_loss 0.6429777992262425 train_acc 0.6422931980684635\n",
      "epoch 161 lr 0.36234909516495145\n",
      "train_loss 0.6427600615359359 train_acc 0.6422931980684635\n",
      "epoch 162 lr 0.36162512118992124\n",
      "train_loss 0.6425359408025293 train_acc 0.6422931980684635\n",
      "epoch 163 lr 0.3609025937158579\n",
      "train_loss 0.6423052402865053 train_acc 0.6422931980684635\n",
      "epoch 164 lr 0.3601815098526507\n",
      "train_loss 0.6420677143386764 train_acc 0.6422931980684635\n",
      "epoch 165 lr 0.3594618667159631\n",
      "train_loss 0.6418230823770925 train_acc 0.6422931980684635\n",
      "epoch 166 lr 0.3587436614272217\n",
      "train_loss 0.6415710862935604 train_acc 0.6422931980684635\n",
      "epoch 167 lr 0.35802689111360425\n",
      "train_loss 0.6413114541095373 train_acc 0.6422931980684635\n",
      "epoch 168 lr 0.3573115529080287\n",
      "train_loss 0.641044008754219 train_acc 0.6422931980684635\n",
      "epoch 169 lr 0.3565976439491412\n",
      "train_loss 0.6407684207799916 train_acc 0.6422931980684635\n",
      "epoch 170 lr 0.3558851613813049\n",
      "train_loss 0.6404843351869415 train_acc 0.6422931980684635\n",
      "epoch 171 lr 0.35517410235458863\n",
      "train_loss 0.6401915492665188 train_acc 0.6422931980684635\n",
      "epoch 172 lr 0.3544644640247554\n",
      "train_loss 0.6398897860176631 train_acc 0.6422931980684635\n",
      "epoch 173 lr 0.35375624355325086\n",
      "train_loss 0.639578628211414 train_acc 0.6422931980684635\n",
      "epoch 174 lr 0.3530494381071922\n",
      "train_loss 0.6392577746965461 train_acc 0.6422931980684635\n",
      "epoch 175 lr 0.3523440448593567\n",
      "train_loss 0.6389269961482131 train_acc 0.6422931980684635\n",
      "epoch 176 lr 0.35164006098817047\n",
      "train_loss 0.6385859532980281 train_acc 0.6422931980684635\n",
      "epoch 177 lr 0.350937483677697\n",
      "train_loss 0.6382341861442917 train_acc 0.6422931980684635\n",
      "epoch 178 lr 0.3502363101176262\n",
      "train_loss 0.6378713210283791 train_acc 0.6422931980684635\n",
      "epoch 179 lr 0.3495365375032628\n",
      "train_loss 0.6374970103347137 train_acc 0.6422931980684635\n",
      "epoch 180 lr 0.3488381630355155\n",
      "train_loss 0.6371109451561425 train_acc 0.6422931980684635\n",
      "epoch 181 lr 0.3481411839208855\n",
      "train_loss 0.6367127420950001 train_acc 0.6422931980684635\n",
      "epoch 182 lr 0.3474455973714553\n",
      "train_loss 0.6363018654852193 train_acc 0.6422931980684635\n",
      "epoch 183 lr 0.34675140060487786\n",
      "train_loss 0.6358778778395272 train_acc 0.6422931980684635\n",
      "epoch 184 lr 0.3460585908443652\n",
      "train_loss 0.6354405224711553 train_acc 0.6422931980684635\n",
      "epoch 185 lr 0.34536716531867734\n",
      "train_loss 0.6349892684087126 train_acc 0.6422931980684635\n",
      "epoch 186 lr 0.3446771212621112\n",
      "train_loss 0.6345235656882595 train_acc 0.6422931980684635\n",
      "epoch 187 lr 0.3439884559144897\n",
      "train_loss 0.6340428825443775 train_acc 0.6422931980684635\n",
      "epoch 188 lr 0.3433011665211505\n",
      "train_loss 0.6335468462036785 train_acc 0.6422931980684635\n",
      "epoch 189 lr 0.3426152503329351\n",
      "train_loss 0.6330348839916836 train_acc 0.6422931980684635\n",
      "epoch 190 lr 0.3419307046061779\n",
      "train_loss 0.6325065667605594 train_acc 0.6422931980684635\n",
      "epoch 191 lr 0.34124752660269503\n",
      "train_loss 0.6319615114749377 train_acc 0.6422931980684635\n",
      "epoch 192 lr 0.34056571358977356\n",
      "train_loss 0.6313991178997619 train_acc 0.6422931980684635\n",
      "epoch 193 lr 0.3398852628401605\n",
      "train_loss 0.6308189295891728 train_acc 0.6422931980684635\n",
      "epoch 194 lr 0.339206171632052\n",
      "train_loss 0.6302204515522515 train_acc 0.6422931980684635\n",
      "epoch 195 lr 0.3385284372490823\n",
      "train_loss 0.6296031772809356 train_acc 0.6422931980684635\n",
      "epoch 196 lr 0.337852056980313\n",
      "train_loss 0.6289664819856734 train_acc 0.6422931980684635\n",
      "epoch 197 lr 0.3371770281202221\n",
      "train_loss 0.6283098849104135 train_acc 0.6422931980684635\n",
      "epoch 198 lr 0.3365033479686932\n",
      "train_loss 0.6276329176090334 train_acc 0.6422931980684635\n",
      "epoch 199 lr 0.3358310138310049\n",
      "train_loss 0.6269351448915492 train_acc 0.6422931980684635\n",
      "\n",
      "val loss = 0.6242404406190101, \n",
      "val acc = 0.6459058671824629\n",
      "\n",
      "epoch 200 lr 0.3351600230178196\n",
      "train_loss 0.6262160590160963 train_acc 0.6422931980684635\n",
      "epoch 201 lr 0.33449037284517336\n",
      "train_loss 0.6254751831889505 train_acc 0.6422931980684635\n",
      "epoch 202 lr 0.33382206063446446\n",
      "train_loss 0.6247120371724056 train_acc 0.6422931980684635\n",
      "epoch 203 lr 0.3331550837124432\n",
      "train_loss 0.6239262797862343 train_acc 0.6422931980684635\n",
      "epoch 204 lr 0.33248943941120096\n",
      "train_loss 0.6231174271755481 train_acc 0.6422931980684635\n",
      "epoch 205 lr 0.3318251250681597\n",
      "train_loss 0.6222853644520749 train_acc 0.6422931980684635\n",
      "epoch 206 lr 0.33116213802606115\n",
      "train_loss 0.6214296346351329 train_acc 0.6422931980684635\n",
      "epoch 207 lr 0.33050047563295626\n",
      "train_loss 0.6205499794615161 train_acc 0.6422931980684635\n",
      "epoch 208 lr 0.3298401352421945\n",
      "train_loss 0.6196461441147133 train_acc 0.6422931980684635\n",
      "epoch 209 lr 0.3291811142124136\n",
      "train_loss 0.6187179427929369 train_acc 0.6422931980684635\n",
      "epoch 210 lr 0.3285234099075284\n",
      "train_loss 0.617765332042577 train_acc 0.6422931980684635\n",
      "epoch 211 lr 0.3278670196967209\n",
      "train_loss 0.616788380374741 train_acc 0.6422931980684635\n",
      "epoch 212 lr 0.3272119409544293\n",
      "train_loss 0.6157868813945406 train_acc 0.6422931980684635\n",
      "epoch 213 lr 0.3265581710603378\n",
      "train_loss 0.6147609726100315 train_acc 0.6422931980684635\n",
      "epoch 214 lr 0.325905707399366\n",
      "train_loss 0.6137108083978835 train_acc 0.6422931980684635\n",
      "epoch 215 lr 0.32525454736165826\n",
      "train_loss 0.6126366689924834 train_acc 0.6422931980684635\n",
      "epoch 216 lr 0.3246046883425737\n",
      "train_loss 0.6115386902475974 train_acc 0.6422931980684635\n",
      "epoch 217 lr 0.3239561277426753\n",
      "train_loss 0.610417227439183 train_acc 0.6422931980684635\n",
      "epoch 218 lr 0.3233088629677198\n",
      "train_loss 0.6092727417753344 train_acc 0.6422931980684635\n",
      "epoch 219 lr 0.3226628914286473\n",
      "train_loss 0.6081057327332426 train_acc 0.6422931980684635\n",
      "epoch 220 lr 0.32201821054157065\n",
      "train_loss 0.6069169800703319 train_acc 0.6422931980684635\n",
      "epoch 221 lr 0.3213748177277656\n",
      "train_loss 0.6057073419970459 train_acc 0.6422931980684635\n",
      "epoch 222 lr 0.3207327104136599\n",
      "train_loss 0.6044778943369612 train_acc 0.6422931980684635\n",
      "epoch 223 lr 0.32009188603082356\n",
      "train_loss 0.6032293413992258 train_acc 0.6422931980684635\n",
      "epoch 224 lr 0.31945234201595807\n",
      "train_loss 0.6019625028234791 train_acc 0.6422931980684635\n",
      "epoch 225 lr 0.3188140758108866\n",
      "train_loss 0.600678544467438 train_acc 0.6422931980684635\n",
      "epoch 226 lr 0.31817708486254354\n",
      "train_loss 0.59937839160204 train_acc 0.6422931980684635\n",
      "epoch 227 lr 0.31754136662296406\n",
      "train_loss 0.5980633115116901 train_acc 0.6422931980684635\n",
      "epoch 228 lr 0.3169069185492745\n",
      "train_loss 0.5967347573120847 train_acc 0.6422931980684635\n",
      "epoch 229 lr 0.3162737381036817\n",
      "train_loss 0.595394104783229 train_acc 0.6422931980684635\n",
      "epoch 230 lr 0.315641822753463\n",
      "train_loss 0.5940426697401916 train_acc 0.6422931980684635\n",
      "epoch 231 lr 0.31501116997095613\n",
      "train_loss 0.5926816808305242 train_acc 0.6422931980684635\n",
      "epoch 232 lr 0.3143817772335492\n",
      "train_loss 0.5913126216744646 train_acc 0.6422931980684635\n",
      "epoch 233 lr 0.31375364202367034\n",
      "train_loss 0.5899371189522715 train_acc 0.6422931980684635\n",
      "epoch 234 lr 0.31312676182877797\n",
      "train_loss 0.5885564468443987 train_acc 0.6422931980684635\n",
      "epoch 235 lr 0.3125011341413504\n",
      "train_loss 0.5871723881843002 train_acc 0.6422931980684635\n",
      "epoch 236 lr 0.311876756458876\n",
      "train_loss 0.585786381171677 train_acc 0.6422931980684635\n",
      "epoch 237 lr 0.3112536262838434\n",
      "train_loss 0.5843996188227507 train_acc 0.6422931980684635\n",
      "epoch 238 lr 0.3106317411237308\n",
      "train_loss 0.5830131983265 train_acc 0.6422931980684635\n",
      "epoch 239 lr 0.310011098490997\n",
      "train_loss 0.5816287033633041 train_acc 0.6422931980684635\n",
      "epoch 240 lr 0.3093916959030704\n",
      "train_loss 0.5802473781113997 train_acc 0.6422931980684635\n",
      "epoch 241 lr 0.30877353088234\n",
      "train_loss 0.5788706064919118 train_acc 0.6422931980684635\n",
      "epoch 242 lr 0.30815660095614483\n",
      "train_loss 0.5774995070108219 train_acc 0.6422931980684635\n",
      "epoch 243 lr 0.30754090365676434\n",
      "train_loss 0.5761348197463347 train_acc 0.6422931980684635\n",
      "epoch 244 lr 0.3069264365214085\n",
      "train_loss 0.5747774757707244 train_acc 0.6422931980684635\n",
      "epoch 245 lr 0.30631319709220806\n",
      "train_loss 0.5734285415962971 train_acc 0.6422931980684635\n",
      "epoch 246 lr 0.30570118291620435\n",
      "train_loss 0.5720888548098668 train_acc 0.6422931980684635\n",
      "epoch 247 lr 0.3050903915453399\n",
      "train_loss 0.5707592410838964 train_acc 0.6422931980684635\n",
      "epoch 248 lr 0.3044808205364484\n",
      "train_loss 0.5694404609754292 train_acc 0.6422931980684635\n",
      "epoch 249 lr 0.3038724674512451\n",
      "train_loss 0.5681330685946382 train_acc 0.6422931980684635\n",
      "\n",
      "val loss = 0.565754725214577, \n",
      "val acc = 0.6459058671824629\n",
      "\n",
      "epoch 250 lr 0.3032653298563167\n",
      "train_loss 0.5668375821168238 train_acc 0.6422931980684635\n",
      "epoch 251 lr 0.3026594053231121\n",
      "train_loss 0.5655541534393655 train_acc 0.6422931980684635\n",
      "epoch 252 lr 0.30205469142793234\n",
      "train_loss 0.564283555792319 train_acc 0.6422931980684635\n",
      "epoch 253 lr 0.30145118575192104\n",
      "train_loss 0.5630256757241623 train_acc 0.6422931980684635\n",
      "epoch 254 lr 0.3008488858810547\n",
      "train_loss 0.5617801706063378 train_acc 0.6422931980684635\n",
      "epoch 255 lr 0.30024778940613295\n",
      "train_loss 0.5605475095744972 train_acc 0.6422931980684635\n",
      "epoch 256 lr 0.2996478939227692\n",
      "train_loss 0.5593279930552398 train_acc 0.6422931980684635\n",
      "epoch 257 lr 0.29904919703138066\n",
      "train_loss 0.5581214095861394 train_acc 0.6422931980684635\n",
      "epoch 258 lr 0.298451696337179\n",
      "train_loss 0.5569276561697598 train_acc 0.6422931980684635\n",
      "epoch 259 lr 0.2978553894501606\n",
      "train_loss 0.5557465540651544 train_acc 0.6422931980684635\n",
      "epoch 260 lr 0.29726027398509713\n",
      "train_loss 0.5545781006847359 train_acc 0.6422931980684635\n",
      "epoch 261 lr 0.296666347561526\n",
      "train_loss 0.5534221289110642 train_acc 0.6422931980684635\n",
      "epoch 262 lr 0.29607360780374065\n",
      "train_loss 0.5522785912652929 train_acc 0.6422931980684635\n",
      "epoch 263 lr 0.29548205234078123\n",
      "train_loss 0.5511470283935602 train_acc 0.6422931980684635\n",
      "epoch 264 lr 0.2948916788064252\n",
      "train_loss 0.5500269821304669 train_acc 0.6422931980684635\n",
      "epoch 265 lr 0.2943024848391776\n",
      "train_loss 0.5489182270630639 train_acc 0.6422931980684635\n",
      "epoch 266 lr 0.2937144680822617\n",
      "train_loss 0.5478204637975207 train_acc 0.6422931980684635\n",
      "epoch 267 lr 0.29312762618360977\n",
      "train_loss 0.5467334399247037 train_acc 0.6422931980684635\n",
      "epoch 268 lr 0.29254195679585343\n",
      "train_loss 0.545656701111327 train_acc 0.6422931980684635\n",
      "epoch 269 lr 0.2919574575763143\n",
      "train_loss 0.5445900150000861 train_acc 0.6422931980684635\n",
      "epoch 270 lr 0.2913741261869948\n",
      "train_loss 0.543532858957524 train_acc 0.6425367894653885\n",
      "epoch 271 lr 0.29079196029456855\n",
      "train_loss 0.542485299822216 train_acc 0.6448150854719225\n",
      "epoch 272 lr 0.29021095757037113\n",
      "train_loss 0.5414466704739832 train_acc 0.665763945607474\n",
      "epoch 273 lr 0.289631115690391\n",
      "train_loss 0.5404160671187859 train_acc 0.7011420137844073\n",
      "epoch 274 lr 0.2890524323352598\n",
      "train_loss 0.5393936232713538 train_acc 0.7141526601613435\n",
      "epoch 275 lr 0.2884749051902433\n",
      "train_loss 0.5383791168075055 train_acc 0.7181934115691585\n",
      "epoch 276 lr 0.28789853194523224\n",
      "train_loss 0.5373717697744067 train_acc 0.7214747309747954\n",
      "epoch 277 lr 0.2873233102947328\n",
      "train_loss 0.5363713112539231 train_acc 0.7246557480405221\n",
      "epoch 278 lr 0.28674923793785767\n",
      "train_loss 0.5353773383215933 train_acc 0.7268050838957428\n",
      "epoch 279 lr 0.2861763125783166\n",
      "train_loss 0.5343904112047947 train_acc 0.729269655676396\n",
      "epoch 280 lr 0.2856045319244074\n",
      "train_loss 0.5334095300752965 train_acc 0.7313330180974079\n",
      "epoch 281 lr 0.2850338936890067\n",
      "train_loss 0.5324344369220868 train_acc 0.733253091461405\n",
      "epoch 282 lr 0.28446439558956094\n",
      "train_loss 0.5314654554505277 train_acc 0.7347432976543581\n",
      "epoch 283 lr 0.28389603534807667\n",
      "train_loss 0.5305023637592582 train_acc 0.7365057530556391\n",
      "epoch 284 lr 0.2833288106911124\n",
      "train_loss 0.5295440615332135 train_acc 0.7379243147200848\n",
      "epoch 285 lr 0.2827627193497686\n",
      "train_loss 0.5285902782735706 train_acc 0.739600796687157\n",
      "epoch 286 lr 0.2821977590596792\n",
      "train_loss 0.5276410133314647 train_acc 0.7409047271059909\n",
      "epoch 287 lr 0.28163392756100236\n",
      "train_loss 0.5266957997379758 train_acc 0.7420940262792131\n",
      "epoch 288 lr 0.2810712225984112\n",
      "train_loss 0.5257549272150835 train_acc 0.7428391293756896\n",
      "epoch 289 lr 0.2805096419210853\n",
      "train_loss 0.5248177708787093 train_acc 0.744128730888822\n",
      "epoch 290 lr 0.279949183282701\n",
      "train_loss 0.5238852831417244 train_acc 0.7451030964765221\n",
      "epoch 291 lr 0.2793898444414232\n",
      "train_loss 0.5229574161590618 train_acc 0.7460631331585207\n",
      "epoch 292 lr 0.2788316231598956\n",
      "train_loss 0.52203427395862 train_acc 0.7470948143690266\n",
      "epoch 293 lr 0.27827451720523244\n",
      "train_loss 0.5211152967893857 train_acc 0.7477826018426973\n",
      "epoch 294 lr 0.2777185243490092\n",
      "train_loss 0.5202006182301387 train_acc 0.7486996518075915\n",
      "epoch 295 lr 0.27716364236725355\n",
      "train_loss 0.5192900408942025 train_acc 0.7498173064523063\n",
      "epoch 296 lr 0.27660986904043694\n",
      "train_loss 0.518382684326108 train_acc 0.7505337517373798\n",
      "epoch 297 lr 0.2760572021534653\n",
      "train_loss 0.5174783391151249 train_acc 0.7516514063820946\n",
      "epoch 298 lr 0.2755056394956704\n",
      "train_loss 0.5165773212839223 train_acc 0.7525971141583917\n",
      "epoch 299 lr 0.2749551788608008\n",
      "train_loss 0.5156798874287616 train_acc 0.7535141641232859\n",
      "\n",
      "val loss = 0.5150893373372254, \n",
      "val acc = 0.7595099935525468\n",
      "\n",
      "epoch 300 lr 0.27440581804701325\n",
      "train_loss 0.5147860711125569 train_acc 0.75443121408818\n",
      "epoch 301 lr 0.27385755485686375\n",
      "train_loss 0.5138947939718262 train_acc 0.7548897390706272\n",
      "epoch 302 lr 0.2733103870972988\n",
      "train_loss 0.5130060323683666 train_acc 0.7559644069982375\n",
      "epoch 303 lr 0.2727643125796467\n",
      "train_loss 0.5121204970923598 train_acc 0.7566092077548038\n",
      "epoch 304 lr 0.27221932911960856\n",
      "train_loss 0.5112386523875289 train_acc 0.7570390749258479\n",
      "epoch 305 lr 0.2716754345372499\n",
      "train_loss 0.5103598062279892 train_acc 0.7574689420968921\n",
      "epoch 306 lr 0.2711326266569916\n",
      "train_loss 0.5094840228975211 train_acc 0.7580277694192494\n",
      "epoch 307 lr 0.27059090330760144\n",
      "train_loss 0.5086125246200425 train_acc 0.7586582412701142\n",
      "epoch 308 lr 0.27005026232218526\n",
      "train_loss 0.5077451904294692 train_acc 0.7594033443665907\n",
      "epoch 309 lr 0.2695107015381785\n",
      "train_loss 0.5068818565597207 train_acc 0.759990829500351\n",
      "epoch 310 lr 0.26897221879733724\n",
      "train_loss 0.506021601609676 train_acc 0.7605783146341114\n",
      "epoch 311 lr 0.26843481194572977\n",
      "train_loss 0.5051653284704015 train_acc 0.7613520755419909\n",
      "epoch 312 lr 0.267898478833728\n",
      "train_loss 0.5043127534845827 train_acc 0.7619968762985571\n",
      "epoch 313 lr 0.26736321731599877\n",
      "train_loss 0.503463955819817 train_acc 0.7630858731318689\n",
      "epoch 314 lr 0.26682902525149527\n",
      "train_loss 0.502618776388852 train_acc 0.7638309762283454\n",
      "epoch 315 lr 0.2662959005034486\n",
      "train_loss 0.5017768853563402 train_acc 0.7644757769849116\n",
      "epoch 316 lr 0.26576384093935895\n",
      "train_loss 0.5009390949672321 train_acc 0.7651349066471793\n",
      "epoch 317 lr 0.26523284443098744\n",
      "train_loss 0.5001049744918017 train_acc 0.7655217871011191\n",
      "epoch 318 lr 0.2647029088543473\n",
      "train_loss 0.4992749890740922 train_acc 0.7661092722348795\n",
      "epoch 319 lr 0.2641740320896955\n",
      "train_loss 0.4984492073133063 train_acc 0.7667827308028485\n",
      "epoch 320 lr 0.2636462120215243\n",
      "train_loss 0.4976275170428208 train_acc 0.7673558870309074\n",
      "epoch 321 lr 0.2631194465385527\n",
      "train_loss 0.4968102439907607 train_acc 0.7682156213729957\n",
      "epoch 322 lr 0.26259373353371807\n",
      "train_loss 0.4959967736002449 train_acc 0.7688460932238604\n",
      "epoch 323 lr 0.2620690709041677\n",
      "train_loss 0.49518754440691726 train_acc 0.7692186447720988\n",
      "epoch 324 lr 0.2615454565512504\n",
      "train_loss 0.4943820550938012 train_acc 0.7697918010001576\n",
      "epoch 325 lr 0.261022888380508\n",
      "train_loss 0.49358124826513433 train_acc 0.7704222728510224\n",
      "epoch 326 lr 0.2605013643016672\n",
      "train_loss 0.49278524989720646 train_acc 0.7712103626646033\n",
      "epoch 327 lr 0.2599808822286309\n",
      "train_loss 0.4919935035364227 train_acc 0.7716545587413489\n",
      "epoch 328 lr 0.2594614400794702\n",
      "train_loss 0.49120675258288843 train_acc 0.7722420438751093\n",
      "epoch 329 lr 0.2589430357764157\n",
      "train_loss 0.4904244212856946 train_acc 0.772600266517646\n",
      "epoch 330 lr 0.2584256672458496\n",
      "train_loss 0.48964715561503247 train_acc 0.7730874493114961\n",
      "epoch 331 lr 0.25790933241829705\n",
      "train_loss 0.48887582303601484 train_acc 0.7735316453882417\n",
      "epoch 332 lr 0.2573940292284181\n",
      "train_loss 0.4881099804082289 train_acc 0.7738325524079726\n",
      "epoch 333 lr 0.2568797556149992\n",
      "train_loss 0.48735033797083654 train_acc 0.7741907750505094\n",
      "epoch 334 lr 0.25636650952094525\n",
      "train_loss 0.48659710046973653 train_acc 0.7746636289386579\n",
      "epoch 335 lr 0.2558542888932712\n",
      "train_loss 0.485847885372796 train_acc 0.7752797718838212\n",
      "epoch 336 lr 0.25534309168309394\n",
      "train_loss 0.48510369653089713 train_acc 0.7759532304517904\n",
      "epoch 337 lr 0.2548329158456238\n",
      "train_loss 0.4843650229819953 train_acc 0.7763401109057301\n",
      "epoch 338 lr 0.25432375934015683\n",
      "train_loss 0.4836321718706215 train_acc 0.7768416226052817\n",
      "epoch 339 lr 0.25381562013006637\n",
      "train_loss 0.4829044759396275 train_acc 0.7775294100789523\n",
      "epoch 340 lr 0.2533084961827948\n",
      "train_loss 0.4821823664855701 train_acc 0.778159881929817\n",
      "epoch 341 lr 0.25280238546984574\n",
      "train_loss 0.4814652349284498 train_acc 0.77867572253507\n",
      "epoch 342 lr 0.2522972859667756\n",
      "train_loss 0.4807533534074582 train_acc 0.7792345498574273\n",
      "epoch 343 lr 0.2517931956531857\n",
      "train_loss 0.48004788841701124 train_acc 0.7795354568771583\n",
      "epoch 344 lr 0.2512901125127142\n",
      "train_loss 0.47934831436299563 train_acc 0.7798936795196951\n",
      "epoch 345 lr 0.2507880345330278\n",
      "train_loss 0.4786549462244241 train_acc 0.7801515998223215\n",
      "epoch 346 lr 0.2502869597058139\n",
      "train_loss 0.477967822039722 train_acc 0.7806244537104702\n",
      "epoch 347 lr 0.24978688602677251\n",
      "train_loss 0.4772889573637197 train_acc 0.7811546232214246\n",
      "epoch 348 lr 0.2492878114956083\n",
      "train_loss 0.47661814526113 train_acc 0.7813838857126482\n",
      "epoch 349 lr 0.24878973411602245\n",
      "train_loss 0.47595461735474454 train_acc 0.7818137528836923\n",
      "\n",
      "val loss = 0.4750660945009206, \n",
      "val acc = 0.7889103803997422\n",
      "\n",
      "epoch 350 lr 0.2482926518957048\n",
      "train_loss 0.4752975908449024 train_acc 0.7825731848858702\n",
      "epoch 351 lr 0.24779656284632576\n",
      "train_loss 0.47464813220697116 train_acc 0.7831463411139291\n",
      "epoch 352 lr 0.2473014649835285\n",
      "train_loss 0.47400573240277727 train_acc 0.7833756036051527\n",
      "epoch 353 lr 0.24680735632692094\n",
      "train_loss 0.4733697256589415 train_acc 0.7838914442104057\n",
      "epoch 354 lr 0.24631423490006774\n",
      "train_loss 0.47274045770457984 train_acc 0.7844072848156586\n",
      "epoch 355 lr 0.24582209873048258\n",
      "train_loss 0.47211908867996405 train_acc 0.7847798363638969\n",
      "epoch 356 lr 0.2453309458496201\n",
      "train_loss 0.47150532610185947 train_acc 0.7850664144779264\n",
      "epoch 357 lr 0.2448407742928681\n",
      "train_loss 0.4708982706101993 train_acc 0.7853673214976572\n",
      "epoch 358 lr 0.24435158209953975\n",
      "train_loss 0.4702983750146369 train_acc 0.7856825574230896\n",
      "epoch 359 lr 0.2438633673128656\n",
      "train_loss 0.4697052976636947 train_acc 0.7861697402169396\n",
      "epoch 360 lr 0.24337612797998584\n",
      "train_loss 0.4691191985929667 train_acc 0.7865422917651779\n",
      "epoch 361 lr 0.24288986215194253\n",
      "train_loss 0.46853906101338816 train_acc 0.786699909727894\n",
      "epoch 362 lr 0.24240456788367165\n",
      "train_loss 0.46796524209392787 train_acc 0.7869578300305206\n",
      "epoch 363 lr 0.24192024323399552\n",
      "train_loss 0.4673986007792078 train_acc 0.7872873948616544\n",
      "epoch 364 lr 0.24143688626561488\n",
      "train_loss 0.46683916134516734 train_acc 0.7875883018813853\n",
      "epoch 365 lr 0.24095449504510122\n",
      "train_loss 0.4662876224348677 train_acc 0.7877889065612059\n",
      "epoch 366 lr 0.24047306764288903\n",
      "train_loss 0.46574333981804006 train_acc 0.7881328002980412\n",
      "epoch 367 lr 0.23999260213326803\n",
      "train_loss 0.4652066072575722 train_acc 0.7883620627892648\n",
      "epoch 368 lr 0.23951309659437556\n",
      "train_loss 0.46467772388581313 train_acc 0.7885769963747868\n",
      "epoch 369 lr 0.2390345491081888\n",
      "train_loss 0.46415670249492574 train_acc 0.7888062588660104\n",
      "epoch 370 lr 0.23855695776051722\n",
      "train_loss 0.4636425020745956 train_acc 0.7891788104142486\n",
      "epoch 371 lr 0.2380803206409947\n",
      "train_loss 0.463135469895763 train_acc 0.7894653885282781\n",
      "epoch 372 lr 0.23760463584307223\n",
      "train_loss 0.4626360315300637 train_acc 0.7899095846050237\n",
      "epoch 373 lr 0.23712990146400992\n",
      "train_loss 0.46214362801178904 train_acc 0.7899669002278296\n",
      "epoch 374 lr 0.23665611560486965\n",
      "train_loss 0.46165866701045405 train_acc 0.7903251228703664\n",
      "epoch 375 lr 0.23618327637050734\n",
      "train_loss 0.46118069650471577 train_acc 0.7906976744186046\n",
      "epoch 376 lr 0.23571138186956545\n",
      "train_loss 0.4607100131575629 train_acc 0.7911561994010518\n",
      "epoch 377 lr 0.23524043021446528\n",
      "train_loss 0.46024644488799404 train_acc 0.7913711329865738\n",
      "epoch 378 lr 0.23477041952139963\n",
      "train_loss 0.459788978384378 train_acc 0.7916577111006032\n",
      "epoch 379 lr 0.23430134791032511\n",
      "train_loss 0.459337685478792 train_acc 0.7920589204602444\n",
      "epoch 380 lr 0.23383321350495462\n",
      "train_loss 0.45889187301952206 train_acc 0.7922022095172592\n",
      "epoch 381 lr 0.23336601443274993\n",
      "train_loss 0.45845208231748363 train_acc 0.7924028141970798\n",
      "epoch 382 lr 0.23289974882491413\n",
      "train_loss 0.4580187328426744 train_acc 0.79250311653699\n",
      "epoch 383 lr 0.23243441481638413\n",
      "train_loss 0.4575918437608682 train_acc 0.7929186548023327\n",
      "epoch 384 lr 0.23197001054582334\n",
      "train_loss 0.45717115280692155 train_acc 0.7934488243132872\n",
      "epoch 385 lr 0.23150653415561404\n",
      "train_loss 0.4567565047238502 train_acc 0.7936924157102122\n",
      "epoch 386 lr 0.23104398379185\n",
      "train_loss 0.456348142372985 train_acc 0.7939360071071372\n",
      "epoch 387 lr 0.2305823576043292\n",
      "train_loss 0.455946839474986 train_acc 0.7940936250698534\n",
      "epoch 388 lr 0.23012165374654628\n",
      "train_loss 0.45555245042398557 train_acc 0.794294229749674\n",
      "epoch 389 lr 0.22966187037568517\n",
      "train_loss 0.45516397234257155 train_acc 0.7944805055237931\n",
      "epoch 390 lr 0.22920300565261176\n",
      "train_loss 0.4547813391023707 train_acc 0.7946811102036138\n",
      "epoch 391 lr 0.2287450577418666\n",
      "train_loss 0.4544046878147247 train_acc 0.7947957414492255\n",
      "epoch 392 lr 0.22828802481165736\n",
      "train_loss 0.4540339469484814 train_acc 0.7948960437891358\n",
      "epoch 393 lr 0.22783190503385176\n",
      "train_loss 0.45366940168573183 train_acc 0.7950250039404491\n",
      "epoch 394 lr 0.22737669658397008\n",
      "train_loss 0.45331029066591194 train_acc 0.7951253062803594\n",
      "epoch 395 lr 0.2269223976411779\n",
      "train_loss 0.45295643698865623 train_acc 0.7953402398658814\n",
      "epoch 396 lr 0.22646900638827885\n",
      "train_loss 0.4526082883515124 train_acc 0.7956124890742095\n",
      "epoch 397 lr 0.2260165210117073\n",
      "train_loss 0.45226535301508614 train_acc 0.7957557781312241\n",
      "epoch 398 lr 0.2255649397015212\n",
      "train_loss 0.4519275847640149 train_acc 0.7959993695281491\n",
      "epoch 399 lr 0.22511426065139462\n",
      "train_loss 0.4515951990995558 train_acc 0.7961713163965668\n",
      "\n",
      "val loss = 0.4500755656430726, \n",
      "val acc = 0.7984526112185687\n",
      "\n",
      "epoch 400 lr 0.22466448205861078\n",
      "train_loss 0.45126818926976453 train_acc 0.7964865523219992\n",
      "epoch 401 lr 0.22421560212405475\n",
      "train_loss 0.45094589131825613 train_acc 0.7966441702847153\n",
      "epoch 402 lr 0.22376761905220618\n",
      "train_loss 0.45062895656887914 train_acc 0.7967731304360286\n",
      "epoch 403 lr 0.22332053105113217\n",
      "train_loss 0.4503173332933707 train_acc 0.7968734327759389\n",
      "epoch 404 lr 0.2228743363324801\n",
      "train_loss 0.4500102083834759 train_acc 0.7969594062101477\n",
      "epoch 405 lr 0.22242903311147055\n",
      "train_loss 0.44970754100582827 train_acc 0.7971170241728639\n",
      "epoch 406 lr 0.22198461960689\n",
      "train_loss 0.44940916514654405 train_acc 0.7972459843241771\n",
      "epoch 407 lr 0.2215410940410839\n",
      "train_loss 0.44911543725424175 train_acc 0.7974036022868933\n",
      "epoch 408 lr 0.22109845463994934\n",
      "train_loss 0.4488264867738866 train_acc 0.7973462866640875\n",
      "epoch 409 lr 0.2206566996329281\n",
      "train_loss 0.44854226777406253 train_acc 0.7973749444754904\n",
      "epoch 410 lr 0.22021582725299965\n",
      "train_loss 0.4482627085281928 train_acc 0.7973892733811919\n",
      "epoch 411 lr 0.21977583573667378\n",
      "train_loss 0.4479877169577445 train_acc 0.7976471936838183\n",
      "epoch 412 lr 0.21933672332398393\n",
      "train_loss 0.44771764525363933 train_acc 0.7978048116465346\n",
      "epoch 413 lr 0.21889848825847982\n",
      "train_loss 0.4474519234571012 train_acc 0.7978907850807434\n",
      "epoch 414 lr 0.2184611287872206\n",
      "train_loss 0.44719033761232285 train_acc 0.7981057186662655\n",
      "epoch 415 lr 0.2180246431607678\n",
      "train_loss 0.44693273513680787 train_acc 0.7982633366289816\n",
      "epoch 416 lr 0.21758902963317836\n",
      "train_loss 0.4466789862421531 train_acc 0.7983206522517875\n",
      "epoch 417 lr 0.21715428646199755\n",
      "train_loss 0.44642904419128754 train_acc 0.7984496124031008\n",
      "epoch 418 lr 0.21672041190825214\n",
      "train_loss 0.4461830851006244 train_acc 0.7985355858373097\n",
      "epoch 419 lr 0.21628740423644333\n",
      "train_loss 0.44594041112696425 train_acc 0.7987075327057273\n",
      "epoch 420 lr 0.21585526171453984\n",
      "train_loss 0.4457012998145158 train_acc 0.7986645459886228\n",
      "epoch 421 lr 0.21542398261397103\n",
      "train_loss 0.4454659149354198 train_acc 0.7987361905171302\n",
      "epoch 422 lr 0.2149935652096199\n",
      "train_loss 0.44523378030490096 train_acc 0.7987648483285331\n",
      "epoch 423 lr 0.21456400777981627\n",
      "train_loss 0.445005073007093 train_acc 0.7987791772342346\n",
      "epoch 424 lr 0.21413530860632982\n",
      "train_loss 0.4447797019322945 train_acc 0.798879479574145\n",
      "epoch 425 lr 0.21370746597436333\n",
      "train_loss 0.4445579051900007 train_acc 0.7989081373855479\n",
      "epoch 426 lr 0.21328047817254567\n",
      "train_loss 0.4443393562953678 train_acc 0.7990800842539655\n",
      "epoch 427 lr 0.2128543434929251\n",
      "train_loss 0.4441239837303067 train_acc 0.7992233733109803\n",
      "epoch 428 lr 0.21242906023096228\n",
      "train_loss 0.443911679485157 train_acc 0.7991803865938758\n",
      "epoch 429 lr 0.21200462668552364\n",
      "train_loss 0.4437023329569291 train_acc 0.7992233733109803\n",
      "epoch 430 lr 0.2115810411588744\n",
      "train_loss 0.4434960451052092 train_acc 0.7994956225193082\n",
      "epoch 431 lr 0.2111583019566719\n",
      "train_loss 0.4432925016287567 train_acc 0.7995386092364126\n",
      "epoch 432 lr 0.2107364073879588\n",
      "train_loss 0.44309158197381027 train_acc 0.7998108584447405\n",
      "epoch 433 lr 0.2103153557651562\n",
      "train_loss 0.4428936489557692 train_acc 0.7997392139162333\n",
      "epoch 434 lr 0.20989514540405713\n",
      "train_loss 0.44269842391096664 train_acc 0.7999541475017553\n",
      "epoch 435 lr 0.2094757746238195\n",
      "train_loss 0.44250595520459945 train_acc 0.8000544498416656\n",
      "epoch 436 lr 0.20905724174695967\n",
      "train_loss 0.4423162471812943 train_acc 0.80009743655877\n",
      "epoch 437 lr 0.20863954509934557\n",
      "train_loss 0.442128924268894 train_acc 0.8002550545214862\n",
      "epoch 438 lr 0.20822268301019004\n",
      "train_loss 0.44194416715589196 train_acc 0.8004270013899039\n",
      "epoch 439 lr 0.2078066538120442\n",
      "train_loss 0.4417617579616402 train_acc 0.8004699881070083\n",
      "epoch 440 lr 0.2073914558407907\n",
      "train_loss 0.44158163237302084 train_acc 0.8004986459184112\n",
      "epoch 441 lr 0.20697708743563706\n",
      "train_loss 0.4414038074845409 train_acc 0.8004843170127097\n",
      "epoch 442 lr 0.20656354693910914\n",
      "train_loss 0.4412281799377291 train_acc 0.8005989482583216\n",
      "epoch 443 lr 0.20615083269704437\n",
      "train_loss 0.4410548065093038 train_acc 0.8007565662210377\n",
      "epoch 444 lr 0.20573894305858528\n",
      "train_loss 0.44088374298029526 train_acc 0.8009285130894553\n",
      "epoch 445 lr 0.20532787637617275\n",
      "train_loss 0.4407149409085603 train_acc 0.8009141841837539\n",
      "epoch 446 lr 0.20491763100553947\n",
      "train_loss 0.4405482847118371 train_acc 0.801100459957873\n",
      "epoch 447 lr 0.20450820530570346\n",
      "train_loss 0.4403838837937911 train_acc 0.8012150912034848\n",
      "epoch 448 lr 0.20409959763896135\n",
      "train_loss 0.4402216753514447 train_acc 0.8013583802604995\n",
      "epoch 449 lr 0.2036918063708819\n",
      "train_loss 0.4400616199296326 train_acc 0.8014586826004098\n",
      "\n",
      "val loss = 0.43818233674156326, \n",
      "val acc = 0.8030947775628626\n",
      "\n",
      "epoch 450 lr 0.20328482987029955\n",
      "train_loss 0.4399036106490949 train_acc 0.8015446560346187\n",
      "epoch 451 lr 0.20287866650930772\n",
      "train_loss 0.4397476012645085 train_acc 0.8016019716574245\n",
      "epoch 452 lr 0.20247331466325244\n",
      "train_loss 0.4395936508624935 train_acc 0.801644958374529\n",
      "epoch 453 lr 0.20206877271072576\n",
      "train_loss 0.43944142777439854 train_acc 0.8015589849403201\n",
      "epoch 454 lr 0.20166503903355937\n",
      "train_loss 0.43929096146419244 train_acc 0.8016019716574245\n",
      "epoch 455 lr 0.20126211201681798\n",
      "train_loss 0.43914204137164714 train_acc 0.8016879450916333\n",
      "epoch 456 lr 0.200859990048793\n",
      "train_loss 0.43899517131592486 train_acc 0.8016879450916333\n",
      "epoch 457 lr 0.20045867152099606\n",
      "train_loss 0.43885007160203693 train_acc 0.8017022739973348\n",
      "epoch 458 lr 0.20005815482815245\n",
      "train_loss 0.4387067766814396 train_acc 0.8017166029030363\n",
      "epoch 459 lr 0.1996584383681949\n",
      "train_loss 0.43856529878883355 train_acc 0.8017739185258422\n",
      "epoch 460 lr 0.19925952054225707\n",
      "train_loss 0.4384255075495477 train_acc 0.8017309318087378\n",
      "epoch 461 lr 0.19886139975466707\n",
      "train_loss 0.4382872689070022 train_acc 0.8017595896201407\n",
      "epoch 462 lr 0.19846407441294123\n",
      "train_loss 0.4381505269347699 train_acc 0.8017595896201407\n",
      "epoch 463 lr 0.19806754292777767\n",
      "train_loss 0.4380151977324843 train_acc 0.8018455630543495\n",
      "epoch 464 lr 0.1976718037130499\n",
      "train_loss 0.4378813669862759 train_acc 0.8019315364885584\n",
      "epoch 465 lr 0.19727685518580054\n",
      "train_loss 0.4377491428706964 train_acc 0.8019458653942598\n",
      "epoch 466 lr 0.196882695766235\n",
      "train_loss 0.43761851664897317 train_acc 0.801888549771454\n",
      "epoch 467 lr 0.19648932387771498\n",
      "train_loss 0.43748919385669444 train_acc 0.8018742208657524\n",
      "epoch 468 lr 0.19609673794675248\n",
      "train_loss 0.43736121332997663 train_acc 0.8019315364885584\n",
      "epoch 469 lr 0.19570493640300324\n",
      "train_loss 0.43723467218676815 train_acc 0.8020604966398717\n",
      "epoch 470 lr 0.19531391767926054\n",
      "train_loss 0.43710958834293734 train_acc 0.8020748255455731\n",
      "epoch 471 lr 0.19492368021144899\n",
      "train_loss 0.436985832390884 train_acc 0.8021894567911848\n",
      "epoch 472 lr 0.19453422243861818\n",
      "train_loss 0.43686330544282787 train_acc 0.8022181146025879\n",
      "epoch 473 lr 0.1941455428029365\n",
      "train_loss 0.4367420714464653 train_acc 0.8023327458481996\n",
      "epoch 474 lr 0.19375763974968488\n",
      "train_loss 0.4366221097539682 train_acc 0.8024903638109158\n",
      "epoch 475 lr 0.19337051172725062\n",
      "train_loss 0.43650365431313676 train_acc 0.8024187192824084\n",
      "epoch 476 lr 0.19298415718712106\n",
      "train_loss 0.4363866007923156 train_acc 0.802375732565304\n",
      "epoch 477 lr 0.1925985745838776\n",
      "train_loss 0.4362707360563921 train_acc 0.8024903638109158\n",
      "epoch 478 lr 0.19221376237518928\n",
      "train_loss 0.4361562061925104 train_acc 0.8025333505280202\n",
      "epoch 479 lr 0.19182971902180673\n",
      "train_loss 0.4360429110379019 train_acc 0.8024187192824084\n",
      "epoch 480 lr 0.19144644298755603\n",
      "train_loss 0.43593069306665805 train_acc 0.8025476794337216\n",
      "epoch 481 lr 0.19106393273933253\n",
      "train_loss 0.43581943770957055 train_acc 0.8026049950565275\n",
      "epoch 482 lr 0.19068218674709478\n",
      "train_loss 0.4357090979655162 train_acc 0.8025906661508261\n",
      "epoch 483 lr 0.19030120348385823\n",
      "train_loss 0.4355999029689452 train_acc 0.8027196263021393\n",
      "epoch 484 lr 0.18992098142568936\n",
      "train_loss 0.43549159428419815 train_acc 0.8028199286420497\n",
      "epoch 485 lr 0.18954151905169941\n",
      "train_loss 0.43538413493024974 train_acc 0.8029775466047658\n",
      "epoch 486 lr 0.1891628148440384\n",
      "train_loss 0.4352774730853569 train_acc 0.8029918755104672\n",
      "epoch 487 lr 0.18878486728788899\n",
      "train_loss 0.435171675150365 train_acc 0.8031065067560791\n",
      "epoch 488 lr 0.18840767487146046\n",
      "train_loss 0.43506681037454437 train_acc 0.8031065067560791\n",
      "epoch 489 lr 0.18803123608598257\n",
      "train_loss 0.4349628699315924 train_acc 0.8032211380016908\n",
      "epoch 490 lr 0.18765554942569979\n",
      "train_loss 0.4348598767030069 train_acc 0.8033071114358996\n",
      "epoch 491 lr 0.1872806133878649\n",
      "train_loss 0.4347579492442914 train_acc 0.8034217426815115\n",
      "epoch 492 lr 0.18690642647273326\n",
      "train_loss 0.4346568842131336 train_acc 0.8035507028328247\n",
      "epoch 493 lr 0.1865329871835567\n",
      "train_loss 0.4345566169958304 train_acc 0.8035650317385261\n",
      "epoch 494 lr 0.18616029402657763\n",
      "train_loss 0.43445703863430996 train_acc 0.803679662984138\n",
      "epoch 495 lr 0.18578834551102286\n",
      "train_loss 0.43435816040603364 train_acc 0.8038372809468541\n",
      "epoch 496 lr 0.18541714014909785\n",
      "train_loss 0.43426004089029513 train_acc 0.8038086231354511\n",
      "epoch 497 lr 0.18504667645598066\n",
      "train_loss 0.4341626738821981 train_acc 0.8038372809468541\n",
      "epoch 498 lr 0.184676952949816\n",
      "train_loss 0.43406613168970604 train_acc 0.8038086231354511\n",
      "epoch 499 lr 0.18430796815170944\n",
      "train_loss 0.43397035664682165 train_acc 0.8038086231354511\n",
      "\n",
      "val loss = 0.43199890747520975, \n",
      "val acc = 0.8051579626047711\n",
      "\n",
      "epoch 500 lr 0.1839397205857212\n",
      "train_loss 0.43387518122058 train_acc 0.8039232543810629\n",
      "epoch 501 lr 0.18357220877886052\n",
      "train_loss 0.4337805487339762 train_acc 0.8039805700038688\n",
      "epoch 502 lr 0.18320543126107974\n",
      "train_loss 0.4336867155313217 train_acc 0.8040522145323762\n",
      "epoch 503 lr 0.1828393865652683\n",
      "train_loss 0.4335935533220689 train_acc 0.8040808723437791\n",
      "epoch 504 lr 0.18247407322724687\n",
      "train_loss 0.43350105499348 train_acc 0.804138187966585\n",
      "epoch 505 lr 0.18210948978576166\n",
      "train_loss 0.4334092727675951 train_acc 0.8041811746836894\n",
      "epoch 506 lr 0.18174563478247843\n",
      "train_loss 0.4333180543893301 train_acc 0.8041811746836894\n",
      "epoch 507 lr 0.18138250676197665\n",
      "train_loss 0.43322752406731085 train_acc 0.8042384903064953\n",
      "epoch 508 lr 0.18102010427174375\n",
      "train_loss 0.43313778154953375 train_acc 0.8042528192121967\n",
      "epoch 509 lr 0.1806584258621693\n",
      "train_loss 0.4330485889257624 train_acc 0.8043674504578086\n",
      "epoch 510 lr 0.18029747008653915\n",
      "train_loss 0.4329600823935049 train_acc 0.8043961082692115\n",
      "epoch 511 lr 0.17993723550102977\n",
      "train_loss 0.4328723489556795 train_acc 0.8045250684205247\n",
      "epoch 512 lr 0.17957772066470232\n",
      "train_loss 0.4327853752751483 train_acc 0.8045393973262261\n",
      "epoch 513 lr 0.17921892413949694\n",
      "train_loss 0.4326989784903598 train_acc 0.8045107395148232\n",
      "epoch 514 lr 0.1788608444902271\n",
      "train_loss 0.4326132100717235 train_acc 0.8044964106091218\n",
      "epoch 515 lr 0.1785034802845737\n",
      "train_loss 0.4325280105675014 train_acc 0.8044964106091218\n",
      "epoch 516 lr 0.17814683009307944\n",
      "train_loss 0.43244342726006774 train_acc 0.8045393973262261\n",
      "epoch 517 lr 0.17779089248914307\n",
      "train_loss 0.4323593899182188 train_acc 0.8045393973262261\n",
      "epoch 518 lr 0.1774356660490137\n",
      "train_loss 0.43227579219418566 train_acc 0.8046396996661365\n",
      "epoch 519 lr 0.17708114935178515\n",
      "train_loss 0.43219269154038986 train_acc 0.8047543309117483\n",
      "epoch 520 lr 0.17672734097939005\n",
      "train_loss 0.43211011143494127 train_acc 0.8047543309117483\n",
      "epoch 521 lr 0.17637423951659456\n",
      "train_loss 0.4320282512880281 train_acc 0.8048403043459571\n",
      "epoch 522 lr 0.1760218435509923\n",
      "train_loss 0.43194701603069474 train_acc 0.80486896215736\n",
      "epoch 523 lr 0.1756701516729989\n",
      "train_loss 0.43186635745013296 train_acc 0.8049119488744645\n",
      "epoch 524 lr 0.17531916247584645\n",
      "train_loss 0.43178607202227404 train_acc 0.8049692644972704\n",
      "epoch 525 lr 0.17496887455557766\n",
      "train_loss 0.4317060568429765 train_acc 0.8050265801200762\n",
      "epoch 526 lr 0.1746192865110404\n",
      "train_loss 0.43162626235415985 train_acc 0.8050982246485836\n",
      "epoch 527 lr 0.17427039694388197\n",
      "train_loss 0.4315467992462401 train_acc 0.805169869177091\n",
      "epoch 528 lr 0.1739222044585437\n",
      "train_loss 0.4314678587842081 train_acc 0.8050265801200762\n",
      "epoch 529 lr 0.17357470766225516\n",
      "train_loss 0.4313895410044678 train_acc 0.8050838957428821\n",
      "epoch 530 lr 0.1732279051650287\n",
      "train_loss 0.4313117987715999 train_acc 0.805112553554285\n",
      "epoch 531 lr 0.17288179557965389\n",
      "train_loss 0.43123451612295965 train_acc 0.805169869177091\n",
      "epoch 532 lr 0.17253637752169187\n",
      "train_loss 0.43115774264473067 train_acc 0.8052701715170012\n",
      "epoch 533 lr 0.17219164960947\n",
      "train_loss 0.43108139934325906 train_acc 0.8052415137055983\n",
      "epoch 534 lr 0.17184761046407618\n",
      "train_loss 0.43100560377262914 train_acc 0.8052415137055983\n",
      "epoch 535 lr 0.17150425870935332\n",
      "train_loss 0.43093017578534565 train_acc 0.8051841980827924\n",
      "epoch 536 lr 0.17116159297189398\n",
      "train_loss 0.4308549487841184 train_acc 0.8052271847998969\n",
      "epoch 537 lr 0.17081961188103473\n",
      "train_loss 0.43078014923415453 train_acc 0.8052128558941953\n",
      "epoch 538 lr 0.17047831406885078\n",
      "train_loss 0.4307058451276255 train_acc 0.8051841980827924\n",
      "epoch 539 lr 0.1701376981701504\n",
      "train_loss 0.4306320498904327 train_acc 0.8051985269884939\n",
      "epoch 540 lr 0.16979776282246956\n",
      "train_loss 0.4305586768415288 train_acc 0.8052415137055983\n",
      "epoch 541 lr 0.1694585066660664\n",
      "train_loss 0.4304856589619069 train_acc 0.8052988293284042\n",
      "epoch 542 lr 0.16911992834391587\n",
      "train_loss 0.43041301849253993 train_acc 0.8053274871398072\n",
      "epoch 543 lr 0.16878202650170418\n",
      "train_loss 0.4303408071757209 train_acc 0.8053418160455086\n",
      "epoch 544 lr 0.16844479978782353\n",
      "train_loss 0.43026904604942 train_acc 0.8052988293284042\n",
      "epoch 545 lr 0.16810824685336664\n",
      "train_loss 0.4301976325802636 train_acc 0.8052988293284042\n",
      "epoch 546 lr 0.16777236635212134\n",
      "train_loss 0.430126615265096 train_acc 0.8053704738569115\n",
      "epoch 547 lr 0.1674371569405651\n",
      "train_loss 0.43005589227850144 train_acc 0.8054564472911204\n",
      "epoch 548 lr 0.16710261727785988\n",
      "train_loss 0.4299856243393867 train_acc 0.8054994340082248\n",
      "epoch 549 lr 0.1667687460258466\n",
      "train_loss 0.4299157464793593 train_acc 0.8055280918196277\n",
      "\n",
      "val loss = 0.42817719313862496, \n",
      "val acc = 0.8068343004513218\n",
      "\n",
      "epoch 550 lr 0.16643554184903978\n",
      "train_loss 0.42984624753287454 train_acc 0.8055567496310306\n",
      "epoch 551 lr 0.16610300341462225\n",
      "train_loss 0.42977699416797244 train_acc 0.8055424207253292\n",
      "epoch 552 lr 0.16577112939243985\n",
      "train_loss 0.42970782254316886 train_acc 0.8055424207253292\n",
      "epoch 553 lr 0.16543991845499603\n",
      "train_loss 0.42963888941304856 train_acc 0.8055424207253292\n",
      "epoch 554 lr 0.16510936927744665\n",
      "train_loss 0.4295702216484248 train_acc 0.8055997363481351\n",
      "epoch 555 lr 0.1647794805375945\n",
      "train_loss 0.4295019788195804 train_acc 0.8055997363481351\n",
      "epoch 556 lr 0.16445025091588422\n",
      "train_loss 0.4294340994763673 train_acc 0.805628394159538\n",
      "epoch 557 lr 0.16412167909539688\n",
      "train_loss 0.4293663741351546 train_acc 0.8056140652538366\n",
      "epoch 558 lr 0.16379376376184474\n",
      "train_loss 0.4292988894143497 train_acc 0.8055997363481351\n",
      "epoch 559 lr 0.16346650360356604\n",
      "train_loss 0.4292318191042093 train_acc 0.8056140652538366\n",
      "epoch 560 lr 0.16313989731151973\n",
      "train_loss 0.4291649527869955 train_acc 0.8055424207253292\n",
      "epoch 561 lr 0.16281394357928017\n",
      "train_loss 0.4290983878106664 train_acc 0.8055567496310306\n",
      "epoch 562 lr 0.162488641103032\n",
      "train_loss 0.42903195486892276 train_acc 0.8055854074424337\n",
      "epoch 563 lr 0.16216398858156494\n",
      "train_loss 0.4289657739988201 train_acc 0.8055997363481351\n",
      "epoch 564 lr 0.1618399847162684\n",
      "train_loss 0.42889991168221575 train_acc 0.8056140652538366\n",
      "epoch 565 lr 0.1615166282111265\n",
      "train_loss 0.42883421403731087 train_acc 0.8056427230652395\n",
      "epoch 566 lr 0.16119391777271277\n",
      "train_loss 0.4287687327351003 train_acc 0.8056427230652395\n",
      "epoch 567 lr 0.1608718521101851\n",
      "train_loss 0.42870372408470664 train_acc 0.8056713808766425\n",
      "epoch 568 lr 0.16055042993528035\n",
      "train_loss 0.4286390562252256 train_acc 0.8057286964994483\n",
      "epoch 569 lr 0.1602296499623094\n",
      "train_loss 0.4285747574404581 train_acc 0.8057286964994483\n",
      "epoch 570 lr 0.15990951090815195\n",
      "train_loss 0.4285106817746211 train_acc 0.8057716832165528\n",
      "epoch 571 lr 0.15959001149225135\n",
      "train_loss 0.4284467940917454 train_acc 0.8058003410279557\n",
      "epoch 572 lr 0.1592711504366095\n",
      "train_loss 0.42838318473811016 train_acc 0.8057860121222542\n",
      "epoch 573 lr 0.15895292646578177\n",
      "train_loss 0.42831987060680576 train_acc 0.8058289988393587\n",
      "epoch 574 lr 0.15863533830687182\n",
      "train_loss 0.42825674105048755 train_acc 0.8059579589906719\n",
      "epoch 575 lr 0.1583183846895266\n",
      "train_loss 0.4281937664325567 train_acc 0.8060009457077763\n",
      "epoch 576 lr 0.15800206434593128\n",
      "train_loss 0.42813097403567874 train_acc 0.8060869191419852\n",
      "epoch 577 lr 0.15768637601080396\n",
      "train_loss 0.4280685190617819 train_acc 0.8061299058590895\n",
      "epoch 578 lr 0.15737131842139096\n",
      "train_loss 0.42800633618229944 train_acc 0.8061585636704924\n",
      "epoch 579 lr 0.15705689031746148\n",
      "train_loss 0.42794449089756176 train_acc 0.8061585636704924\n",
      "epoch 580 lr 0.15674309044130266\n",
      "train_loss 0.42788295358665673 train_acc 0.8062158792932984\n",
      "epoch 581 lr 0.1564299175377146\n",
      "train_loss 0.42782165244701115 train_acc 0.8062015503875969\n",
      "epoch 582 lr 0.15611737035400527\n",
      "train_loss 0.4277606015213811 train_acc 0.8062731949161043\n",
      "epoch 583 lr 0.15580544763998552\n",
      "train_loss 0.4276997262492972 train_acc 0.8062875238218057\n",
      "epoch 584 lr 0.15549414814796406\n",
      "train_loss 0.4276391860586828 train_acc 0.8063161816332086\n",
      "epoch 585 lr 0.15518347063274252\n",
      "train_loss 0.4275790205308634 train_acc 0.8063018527275072\n",
      "epoch 586 lr 0.1548734138516104\n",
      "train_loss 0.42751917068102047 train_acc 0.8063448394446117\n",
      "epoch 587 lr 0.15456397656434023\n",
      "train_loss 0.42745948412031 train_acc 0.8063305105389101\n",
      "epoch 588 lr 0.15425515753318236\n",
      "train_loss 0.42740008408927754 train_acc 0.8063734972560146\n",
      "epoch 589 lr 0.1539469555228603\n",
      "train_loss 0.4273409386472287 train_acc 0.8063734972560146\n",
      "epoch 590 lr 0.15363936930056563\n",
      "train_loss 0.4272821610952955 train_acc 0.8064164839731189\n",
      "epoch 591 lr 0.153332397635953\n",
      "train_loss 0.42722377476428425 train_acc 0.8063591683503131\n",
      "epoch 592 lr 0.15302603930113534\n",
      "train_loss 0.4271656158485418 train_acc 0.8063448394446117\n",
      "epoch 593 lr 0.15272029307067891\n",
      "train_loss 0.4271075611779985 train_acc 0.8063448394446117\n",
      "epoch 594 lr 0.15241515772159842\n",
      "train_loss 0.42704969549742217 train_acc 0.806387826161716\n",
      "epoch 595 lr 0.15211063203335204\n",
      "train_loss 0.42699183739562957 train_acc 0.8064308128788205\n",
      "epoch 596 lr 0.15180671478783658\n",
      "train_loss 0.42693410250002095 train_acc 0.8064451417845219\n",
      "epoch 597 lr 0.1515034047693827\n",
      "train_loss 0.42687655322187834 train_acc 0.8065024574073278\n",
      "epoch 598 lr 0.1512007007647499\n",
      "train_loss 0.4268192456372266 train_acc 0.8065454441244322\n",
      "epoch 599 lr 0.15089860156312174\n",
      "train_loss 0.42676217362497704 train_acc 0.8065454441244322\n",
      "\n",
      "val loss = 0.42545218808552215, \n",
      "val acc = 0.8079948420373952\n",
      "\n",
      "epoch 600 lr 0.15059710595610104\n",
      "train_loss 0.42670536064853465 train_acc 0.8065741019358351\n",
      "epoch 601 lr 0.15029621273770497\n",
      "train_loss 0.42664879414976586 train_acc 0.8067317198985513\n",
      "epoch 602 lr 0.14999592070436024\n",
      "train_loss 0.4265924311223632 train_acc 0.8068033644270587\n",
      "epoch 603 lr 0.14969622865489834\n",
      "train_loss 0.4265362961532605 train_acc 0.8068320222384616\n",
      "epoch 604 lr 0.14939713539055063\n",
      "train_loss 0.42648025199134537 train_acc 0.8068463511441631\n",
      "epoch 605 lr 0.1490986397149437\n",
      "train_loss 0.42642426168903985 train_acc 0.8068750089555661\n",
      "epoch 606 lr 0.14880074043409441\n",
      "train_loss 0.42636834164739695 train_acc 0.8068893378612675\n",
      "epoch 607 lr 0.14850343635640526\n",
      "train_loss 0.4263127157652283 train_acc 0.8068750089555661\n",
      "epoch 608 lr 0.14820672629265955\n",
      "train_loss 0.42625741450717364 train_acc 0.8069179956726705\n",
      "epoch 609 lr 0.1479106090560166\n",
      "train_loss 0.4262023765966772 train_acc 0.8070182980125807\n",
      "epoch 610 lr 0.1476150834620071\n",
      "train_loss 0.42614761850910016 train_acc 0.8070899425410881\n",
      "epoch 611 lr 0.14732014832852827\n",
      "train_loss 0.4260930387351753 train_acc 0.8071042714467896\n",
      "epoch 612 lr 0.14702580247583918\n",
      "train_loss 0.42603871866179854 train_acc 0.807147258163894\n",
      "epoch 613 lr 0.14673204472655602\n",
      "train_loss 0.42598467548791885 train_acc 0.8071615870695955\n",
      "epoch 614 lr 0.14643887390564742\n",
      "train_loss 0.4259308240213836 train_acc 0.807147258163894\n",
      "epoch 615 lr 0.14614628884042968\n",
      "train_loss 0.4258771634294235 train_acc 0.8071615870695955\n",
      "epoch 616 lr 0.1458542883605622\n",
      "train_loss 0.42582374240373955 train_acc 0.8072045737867\n",
      "epoch 617 lr 0.1455628712980426\n",
      "train_loss 0.4257705333163483 train_acc 0.8072475605038043\n",
      "epoch 618 lr 0.14527203648720227\n",
      "train_loss 0.425717402168679 train_acc 0.8072762183152072\n",
      "epoch 619 lr 0.1449817827647016\n",
      "train_loss 0.42566451336989514 train_acc 0.8072189026924014\n",
      "epoch 620 lr 0.1446921089695253\n",
      "train_loss 0.4256118416224004 train_acc 0.8072332315981029\n",
      "epoch 621 lr 0.1444030139429778\n",
      "train_loss 0.4255593726086692 train_acc 0.8073048761266102\n",
      "epoch 622 lr 0.1441144965286786\n",
      "train_loss 0.42550711288997056 train_acc 0.8073192050323117\n",
      "epoch 623 lr 0.1438265555725577\n",
      "train_loss 0.4254550779149892 train_acc 0.8073335339380131\n",
      "epoch 624 lr 0.14353918992285084\n",
      "train_loss 0.4254033127203877 train_acc 0.8074338362779234\n",
      "epoch 625 lr 0.14325239843009505\n",
      "train_loss 0.425351633758223 train_acc 0.8074338362779234\n",
      "epoch 626 lr 0.14296617994712396\n",
      "train_loss 0.4253000458181189 train_acc 0.8074768229950279\n",
      "epoch 627 lr 0.14268053332906333\n",
      "train_loss 0.4252485012267576 train_acc 0.8075198097121323\n",
      "epoch 628 lr 0.1423954574333262\n",
      "train_loss 0.4251971413640762 train_acc 0.8075627964292367\n",
      "epoch 629 lr 0.14211095111960875\n",
      "train_loss 0.425145941025331 train_acc 0.8076487698634456\n",
      "epoch 630 lr 0.1418270132498852\n",
      "train_loss 0.42509498880789187 train_acc 0.8076201120520425\n",
      "epoch 631 lr 0.14154364268840375\n",
      "train_loss 0.4250441762644639 train_acc 0.807663098769147\n",
      "epoch 632 lr 0.1412608383016818\n",
      "train_loss 0.42499350547255965 train_acc 0.807663098769147\n",
      "epoch 633 lr 0.14097859895850137\n",
      "train_loss 0.42494295755176936 train_acc 0.8076487698634456\n",
      "epoch 634 lr 0.14069692352990476\n",
      "train_loss 0.42489261136071044 train_acc 0.8076917565805499\n",
      "epoch 635 lr 0.1404158108891899\n",
      "train_loss 0.42484243684896533 train_acc 0.8077204143919529\n",
      "epoch 636 lr 0.14013525991190579\n",
      "train_loss 0.4247924723579054 train_acc 0.8078207167318632\n",
      "epoch 637 lr 0.13985526947584817\n",
      "train_loss 0.4247425529434577 train_acc 0.8078637034489676\n",
      "epoch 638 lr 0.13957583846105492\n",
      "train_loss 0.42469287254234456 train_acc 0.8078493745432661\n",
      "epoch 639 lr 0.13929696574980163\n",
      "train_loss 0.42464324505056544 train_acc 0.8078923612603706\n",
      "epoch 640 lr 0.13901865022659707\n",
      "train_loss 0.42459386343424405 train_acc 0.8079210190717735\n",
      "epoch 641 lr 0.13874089077817878\n",
      "train_loss 0.4245446326392349 train_acc 0.8079496768831764\n",
      "epoch 642 lr 0.13846368629350858\n",
      "train_loss 0.424495541611615 train_acc 0.8079783346945794\n",
      "epoch 643 lr 0.13818703566376817\n",
      "train_loss 0.424446708015951 train_acc 0.8079783346945794\n",
      "epoch 644 lr 0.13791093778235466\n",
      "train_loss 0.4243980977824061 train_acc 0.8080356503173852\n",
      "epoch 645 lr 0.13763539154487617\n",
      "train_loss 0.4243495890742851 train_acc 0.8080643081287882\n",
      "epoch 646 lr 0.13736039584914736\n",
      "train_loss 0.42430122583452495 train_acc 0.8081216237515941\n",
      "epoch 647 lr 0.1370859495951851\n",
      "train_loss 0.4242529477018748 train_acc 0.8080786370344897\n",
      "epoch 648 lr 0.13681205168520402\n",
      "train_loss 0.424204849686372 train_acc 0.8081502815629971\n",
      "epoch 649 lr 0.1365387010236121\n",
      "train_loss 0.42415687978315375 train_acc 0.8081502815629971\n",
      "\n",
      "val loss = 0.42331412572992605, \n",
      "val acc = 0.8091553836234687\n",
      "\n",
      "epoch 650 lr 0.1362658965170063\n",
      "train_loss 0.4241089052417913 train_acc 0.8081789393744\n",
      "epoch 651 lr 0.13599363707416826\n",
      "train_loss 0.42406113985271887 train_acc 0.8081646104686985\n",
      "epoch 652 lr 0.13572192160605984\n",
      "train_loss 0.4240136451824706 train_acc 0.8081502815629971\n",
      "epoch 653 lr 0.13545074902581883\n",
      "train_loss 0.4239663803977811 train_acc 0.8081789393744\n",
      "epoch 654 lr 0.1351801182487545\n",
      "train_loss 0.4239192276288977 train_acc 0.8081932682801014\n",
      "epoch 655 lr 0.1349100281923434\n",
      "train_loss 0.42387232062476665 train_acc 0.8082219260915043\n",
      "epoch 656 lr 0.13464047777622498\n",
      "train_loss 0.42382566281316864 train_acc 0.8082505839029074\n",
      "epoch 657 lr 0.13437146592219718\n",
      "train_loss 0.42377922526050205 train_acc 0.8082505839029074\n",
      "epoch 658 lr 0.1341029915542122\n",
      "train_loss 0.423732986413119 train_acc 0.8082075971858029\n",
      "epoch 659 lr 0.13383505359837228\n",
      "train_loss 0.4236868750971149 train_acc 0.8081789393744\n",
      "epoch 660 lr 0.13356765098292517\n",
      "train_loss 0.42364089676794564 train_acc 0.8081932682801014\n",
      "epoch 661 lr 0.1333007826382601\n",
      "train_loss 0.42359517131488567 train_acc 0.8082075971858029\n",
      "epoch 662 lr 0.1330344474969033\n",
      "train_loss 0.4235496442156846 train_acc 0.8081789393744\n",
      "epoch 663 lr 0.1327686444935139\n",
      "train_loss 0.4235042253893607 train_acc 0.8082075971858029\n",
      "epoch 664 lr 0.13250337256487946\n",
      "train_loss 0.42345890032346545 train_acc 0.8081932682801014\n",
      "epoch 665 lr 0.13223863064991195\n",
      "train_loss 0.4234136133896831 train_acc 0.8082219260915043\n",
      "epoch 666 lr 0.13197441768964338\n",
      "train_loss 0.42336852772836214 train_acc 0.8083078995257132\n",
      "epoch 667 lr 0.13171073262722155\n",
      "train_loss 0.4233235118643999 train_acc 0.8083365573371162\n",
      "epoch 668 lr 0.1314475744079058\n",
      "train_loss 0.42327856802162456 train_acc 0.8084082018656236\n",
      "epoch 669 lr 0.13118494197906297\n",
      "train_loss 0.42323366062297185 train_acc 0.808393872959922\n",
      "epoch 670 lr 0.13092283429016296\n",
      "train_loss 0.4231889174947639 train_acc 0.8084082018656236\n",
      "epoch 671 lr 0.1306612502927747\n",
      "train_loss 0.42314440854696517 train_acc 0.8084941752998324\n",
      "epoch 672 lr 0.13040018894056182\n",
      "train_loss 0.42310002647794687 train_acc 0.8084798463941308\n",
      "epoch 673 lr 0.13013964918927856\n",
      "train_loss 0.4230557724439777 train_acc 0.8085228331112353\n",
      "epoch 674 lr 0.12987962999676558\n",
      "train_loss 0.42301165710422706 train_acc 0.8085085042055338\n",
      "epoch 675 lr 0.12962013032294575\n",
      "train_loss 0.42296772914472114 train_acc 0.8085371620169368\n",
      "epoch 676 lr 0.12936114912982002\n",
      "train_loss 0.4229238751017632 train_acc 0.8085801487340412\n",
      "epoch 677 lr 0.12910268538146333\n",
      "train_loss 0.4228800925739185 train_acc 0.8085801487340412\n",
      "epoch 678 lr 0.12884473804402027\n",
      "train_loss 0.42283643049966035 train_acc 0.8085944776397427\n",
      "epoch 679 lr 0.1285873060857012\n",
      "train_loss 0.4227928559164 train_acc 0.8086088065454441\n",
      "epoch 680 lr 0.12833038847677794\n",
      "train_loss 0.42274944348895477 train_acc 0.8085944776397427\n",
      "epoch 681 lr 0.12807398418957966\n",
      "train_loss 0.4227062432298189 train_acc 0.8085514909226382\n",
      "epoch 682 lr 0.12781809219848891\n",
      "train_loss 0.42266314121732007 train_acc 0.8085514909226382\n",
      "epoch 683 lr 0.1275627114799374\n",
      "train_loss 0.42262015761381455 train_acc 0.8085371620169368\n",
      "epoch 684 lr 0.12730784101240186\n",
      "train_loss 0.4225773767112961 train_acc 0.8085514909226382\n",
      "epoch 685 lr 0.12705347977640014\n",
      "train_loss 0.42253466328011907 train_acc 0.8085514909226382\n",
      "epoch 686 lr 0.12679962675448692\n",
      "train_loss 0.4224921345198837 train_acc 0.8085371620169368\n",
      "epoch 687 lr 0.12654628093124978\n",
      "train_loss 0.4224497725300929 train_acc 0.8085371620169368\n",
      "epoch 688 lr 0.12629344129330514\n",
      "train_loss 0.4224075151249866 train_acc 0.8086231354511456\n",
      "epoch 689 lr 0.126041106829294\n",
      "train_loss 0.4223653269773541 train_acc 0.8086231354511456\n",
      "epoch 690 lr 0.12578927652987826\n",
      "train_loss 0.42232342332690787 train_acc 0.8086804510739515\n",
      "epoch 691 lr 0.12553794938773635\n",
      "train_loss 0.4222815693114921 train_acc 0.8087234377910559\n",
      "epoch 692 lr 0.1252871243975594\n",
      "train_loss 0.4222398813593123 train_acc 0.8087807534138618\n",
      "epoch 693 lr 0.12503680055604707\n",
      "train_loss 0.42219838672297183 train_acc 0.8088094112252647\n",
      "epoch 694 lr 0.12478697686190368\n",
      "train_loss 0.42215694625814537 train_acc 0.8088094112252647\n",
      "epoch 695 lr 0.12453765231583412\n",
      "train_loss 0.4221156730140524 train_acc 0.8088237401309663\n",
      "epoch 696 lr 0.12428882592053987\n",
      "train_loss 0.4220745687165533 train_acc 0.8088667268480706\n",
      "epoch 697 lr 0.12404049668071501\n",
      "train_loss 0.4220335667982027 train_acc 0.8088667268480706\n",
      "epoch 698 lr 0.12379266360304228\n",
      "train_loss 0.4219926798207453 train_acc 0.8088953846594735\n",
      "epoch 699 lr 0.123545325696189\n",
      "train_loss 0.42195188863156036 train_acc 0.8089527002822794\n",
      "\n",
      "val loss = 0.42160788738172866, \n",
      "val acc = 0.8085106382978723\n",
      "\n",
      "epoch 700 lr 0.12329848197080326\n",
      "train_loss 0.42191114537622054 train_acc 0.8089670291879809\n",
      "epoch 701 lr 0.12305213143950978\n",
      "train_loss 0.42187051578792717 train_acc 0.8089670291879809\n",
      "epoch 702 lr 0.12280627311690613\n",
      "train_loss 0.4218299989800146 train_acc 0.8089527002822794\n",
      "epoch 703 lr 0.1225609060195587\n",
      "train_loss 0.4217896383603644 train_acc 0.808938371376578\n",
      "epoch 704 lr 0.12231602916599875\n",
      "train_loss 0.4217493722256551 train_acc 0.8089813580936824\n",
      "epoch 705 lr 0.12207164157671856\n",
      "train_loss 0.42170913591941 train_acc 0.8090243448107868\n",
      "epoch 706 lr 0.12182774227416744\n",
      "train_loss 0.4216689773548813 train_acc 0.8089956869993838\n",
      "epoch 707 lr 0.12158433028274784\n",
      "train_loss 0.4216288753405171 train_acc 0.8090530026221897\n",
      "epoch 708 lr 0.1213414046288115\n",
      "train_loss 0.4215888696255285 train_acc 0.8090100159050854\n",
      "epoch 709 lr 0.12109896434065545\n",
      "train_loss 0.42154893475808813 train_acc 0.8090243448107868\n",
      "epoch 710 lr 0.12085700844851824\n",
      "train_loss 0.42150908639427953 train_acc 0.8090243448107868\n",
      "epoch 711 lr 0.12061553598457596\n",
      "train_loss 0.42146939572463116 train_acc 0.8090530026221897\n",
      "epoch 712 lr 0.12037454598293844\n",
      "train_loss 0.42142988491341316 train_acc 0.8090243448107868\n",
      "epoch 713 lr 0.12013403747964535\n",
      "train_loss 0.42139049149854785 train_acc 0.8090386737164883\n",
      "epoch 714 lr 0.11989400951266237\n",
      "train_loss 0.421351194924829 train_acc 0.8090959893392942\n",
      "epoch 715 lr 0.11965446112187728\n",
      "train_loss 0.42131191368838433 train_acc 0.8091103182449956\n",
      "epoch 716 lr 0.11941539134909622\n",
      "train_loss 0.42127261685099954 train_acc 0.8091103182449956\n",
      "epoch 717 lr 0.11917679923803978\n",
      "train_loss 0.42123336579686554 train_acc 0.8091389760563986\n",
      "epoch 718 lr 0.1189386838343392\n",
      "train_loss 0.42119424476477324 train_acc 0.8092679362077119\n",
      "epoch 719 lr 0.11870104418553254\n",
      "train_loss 0.42115526970356904 train_acc 0.8092679362077119\n",
      "epoch 720 lr 0.11846387934106088\n",
      "train_loss 0.42111640125262234 train_acc 0.8092965940191148\n",
      "epoch 721 lr 0.11822718835226455\n",
      "train_loss 0.4210776257610625 train_acc 0.809396896359025\n",
      "epoch 722 lr 0.11799097027237926\n",
      "train_loss 0.42103892179830127 train_acc 0.8093825674533236\n",
      "epoch 723 lr 0.11775522415653238\n",
      "train_loss 0.4210003572181478 train_acc 0.809425554170428\n",
      "epoch 724 lr 0.11751994906173914\n",
      "train_loss 0.42096186065905744 train_acc 0.8094112252647265\n",
      "epoch 725 lr 0.11728514404689884\n",
      "train_loss 0.42092340054478294 train_acc 0.809396896359025\n",
      "epoch 726 lr 0.1170508081727911\n",
      "train_loss 0.42088503629775836 train_acc 0.809425554170428\n",
      "epoch 727 lr 0.11681694050207211\n",
      "train_loss 0.42084684736533856 train_acc 0.8094685408875324\n",
      "epoch 728 lr 0.1165835400992709\n",
      "train_loss 0.4208088285769903 train_acc 0.809454211981831\n",
      "epoch 729 lr 0.11635060603078552\n",
      "train_loss 0.4207708715878586 train_acc 0.8095115276046368\n",
      "epoch 730 lr 0.11611813736487941\n",
      "train_loss 0.4207329303656957 train_acc 0.8095545143217413\n",
      "epoch 731 lr 0.11588613317167758\n",
      "train_loss 0.42069509318756654 train_acc 0.8095545143217413\n",
      "epoch 732 lr 0.11565459252316296\n",
      "train_loss 0.4206573007031612 train_acc 0.8095688432274427\n",
      "epoch 733 lr 0.11542351449317262\n",
      "train_loss 0.42061962287394844 train_acc 0.8096404877559501\n",
      "epoch 734 lr 0.11519289815739416\n",
      "train_loss 0.4205820803388853 train_acc 0.8096834744730544\n",
      "epoch 735 lr 0.11496274259336192\n",
      "train_loss 0.4205446025402037 train_acc 0.8096261588502486\n",
      "epoch 736 lr 0.11473304688045334\n",
      "train_loss 0.4205071742644734 train_acc 0.8095831721331442\n",
      "epoch 737 lr 0.11450381009988526\n",
      "train_loss 0.42046982192965976 train_acc 0.8095831721331442\n",
      "epoch 738 lr 0.11427503133471024\n",
      "train_loss 0.42043264925493623 train_acc 0.8096118299445472\n",
      "epoch 739 lr 0.11404670966981294\n",
      "train_loss 0.42039553094193616 train_acc 0.8095975010388456\n",
      "epoch 740 lr 0.11381884419190637\n",
      "train_loss 0.4203584135338956 train_acc 0.8096261588502486\n",
      "epoch 741 lr 0.11359143398952833\n",
      "train_loss 0.42032142856325405 train_acc 0.8095975010388456\n",
      "epoch 742 lr 0.1133644781530377\n",
      "train_loss 0.42028459171574306 train_acc 0.809697803378756\n",
      "epoch 743 lr 0.11313797577461085\n",
      "train_loss 0.42024788079889547 train_acc 0.809697803378756\n",
      "epoch 744 lr 0.11291192594823793\n",
      "train_loss 0.420211304949485 train_acc 0.809697803378756\n",
      "epoch 745 lr 0.11268632776971936\n",
      "train_loss 0.42017480279297004 train_acc 0.8096834744730544\n",
      "epoch 746 lr 0.11246118033666212\n",
      "train_loss 0.42013835227820867 train_acc 0.8096834744730544\n",
      "epoch 747 lr 0.11223648274847618\n",
      "train_loss 0.42010196707422587 train_acc 0.809697803378756\n",
      "epoch 748 lr 0.11201223410637087\n",
      "train_loss 0.42006564629267323 train_acc 0.8097121322844575\n",
      "epoch 749 lr 0.11178843351335134\n",
      "train_loss 0.4200293661981005 train_acc 0.8097694479072634\n",
      "\n",
      "val loss = 0.42017100339155616, \n",
      "val acc = 0.8091553836234687\n",
      "\n",
      "epoch 750 lr 0.11156508007421491\n",
      "train_loss 0.4199931331650547 train_acc 0.8098840791528751\n",
      "epoch 751 lr 0.11134217289554754\n",
      "train_loss 0.4199569519846249 train_acc 0.8098840791528751\n",
      "epoch 752 lr 0.1111197110857202\n",
      "train_loss 0.41992078479480893 train_acc 0.809912736964278\n",
      "epoch 753 lr 0.11089769375488537\n",
      "train_loss 0.4198846169729312 train_acc 0.8099843814927854\n",
      "epoch 754 lr 0.11067612001497341\n",
      "train_loss 0.41984843555973805 train_acc 0.8100846838326957\n",
      "epoch 755 lr 0.1104549889796891\n",
      "train_loss 0.41981231828542653 train_acc 0.8100560260212928\n",
      "epoch 756 lr 0.11023429976450796\n",
      "train_loss 0.41977633902306044 train_acc 0.8101133416440987\n",
      "epoch 757 lr 0.11001405148667287\n",
      "train_loss 0.4197404589315394 train_acc 0.8101563283612031\n",
      "epoch 758 lr 0.10979424326519041\n",
      "train_loss 0.41970461818335814 train_acc 0.8101563283612031\n",
      "epoch 759 lr 0.1095748742208274\n",
      "train_loss 0.4196688098350202 train_acc 0.8101993150783074\n",
      "epoch 760 lr 0.10935594347610737\n",
      "train_loss 0.41963307892014806 train_acc 0.8102279728897104\n",
      "epoch 761 lr 0.10913745015530707\n",
      "train_loss 0.41959738317182754 train_acc 0.810213643984009\n",
      "epoch 762 lr 0.10891939338445289\n",
      "train_loss 0.4195618089840955 train_acc 0.8102566307011133\n",
      "epoch 763 lr 0.10870177229131747\n",
      "train_loss 0.4195263090316537 train_acc 0.8102709596068148\n",
      "epoch 764 lr 0.10848458600541616\n",
      "train_loss 0.4194908723189949 train_acc 0.8102709596068148\n",
      "epoch 765 lr 0.10826783365800352\n",
      "train_loss 0.41945549099259805 train_acc 0.8103569330410236\n",
      "epoch 766 lr 0.10805151438206988\n",
      "train_loss 0.4194202116563547 train_acc 0.8104142486638295\n",
      "epoch 767 lr 0.10783562731233781\n",
      "train_loss 0.4193850139751488 train_acc 0.810428577569531\n",
      "epoch 768 lr 0.10762017158525879\n",
      "train_loss 0.41934984995773805 train_acc 0.8104715642866355\n",
      "epoch 769 lr 0.1074051463390096\n",
      "train_loss 0.4193147262073806 train_acc 0.8105002220980384\n",
      "epoch 770 lr 0.10719055071348897\n",
      "train_loss 0.4192796467064275 train_acc 0.8105288799094413\n",
      "epoch 771 lr 0.10697638385031412\n",
      "train_loss 0.4192446487913073 train_acc 0.8105718666265457\n",
      "epoch 772 lr 0.1067626448928173\n",
      "train_loss 0.4192097851006073 train_acc 0.8106291822493517\n",
      "epoch 773 lr 0.1065493329860424\n",
      "train_loss 0.419175021072084 train_acc 0.8106005244379487\n",
      "epoch 774 lr 0.10633644727674152\n",
      "train_loss 0.4191403968923757 train_acc 0.8105575377208443\n",
      "epoch 775 lr 0.10612398691337152\n",
      "train_loss 0.4191059177228455 train_acc 0.8105575377208443\n",
      "epoch 776 lr 0.10591195104609068\n",
      "train_loss 0.41907162314664365 train_acc 0.8105002220980384\n",
      "epoch 777 lr 0.10570033882675522\n",
      "train_loss 0.4190374154545374 train_acc 0.8105145510037398\n",
      "epoch 778 lr 0.10548914940891603\n",
      "train_loss 0.4190032539919508 train_acc 0.8104858931923369\n",
      "epoch 779 lr 0.10527838194781511\n",
      "train_loss 0.4189691429691329 train_acc 0.8104858931923369\n",
      "epoch 780 lr 0.10506803560038236\n",
      "train_loss 0.418935111507543 train_acc 0.8105002220980384\n",
      "epoch 781 lr 0.1048581095252321\n",
      "train_loss 0.4189012202376285 train_acc 0.8105145510037398\n",
      "epoch 782 lr 0.10464860288265976\n",
      "train_loss 0.4188675233662137 train_acc 0.8105145510037398\n",
      "epoch 783 lr 0.10443951483463847\n",
      "train_loss 0.4188339347935771 train_acc 0.8104858931923369\n",
      "epoch 784 lr 0.10423084454481576\n",
      "train_loss 0.4188005079418712 train_acc 0.8104858931923369\n",
      "epoch 785 lr 0.10402259117851023\n",
      "train_loss 0.4187671415507136 train_acc 0.8105002220980384\n",
      "epoch 786 lr 0.1038147539027081\n",
      "train_loss 0.41873394252899876 train_acc 0.8105861955322472\n",
      "epoch 787 lr 0.10360733188606\n",
      "train_loss 0.4187007232341172 train_acc 0.8105861955322472\n",
      "epoch 788 lr 0.10340032429887758\n",
      "train_loss 0.4186675460149508 train_acc 0.8106148533436501\n",
      "epoch 789 lr 0.10319373031313023\n",
      "train_loss 0.41863445530217447 train_acc 0.8106148533436501\n",
      "epoch 790 lr 0.10298754910244173\n",
      "train_loss 0.41860143586047116 train_acc 0.8106005244379487\n",
      "epoch 791 lr 0.10278177984208695\n",
      "train_loss 0.41856854265913324 train_acc 0.8105432088151427\n",
      "epoch 792 lr 0.10257642170898858\n",
      "train_loss 0.41853568179860867 train_acc 0.8105145510037398\n",
      "epoch 793 lr 0.10237147388171382\n",
      "train_loss 0.41850287743761144 train_acc 0.8105718666265457\n",
      "epoch 794 lr 0.10216693554047107\n",
      "train_loss 0.4184701511016221 train_acc 0.8106578400607546\n",
      "epoch 795 lr 0.10196280586710671\n",
      "train_loss 0.4184375348092058 train_acc 0.810672168966456\n",
      "epoch 796 lr 0.10175908404510177\n",
      "train_loss 0.41840498830205414 train_acc 0.8106578400607546\n",
      "epoch 797 lr 0.10155576925956869\n",
      "train_loss 0.418372485485915 train_acc 0.8106578400607546\n",
      "epoch 798 lr 0.10135286069724805\n",
      "train_loss 0.41834014524150454 train_acc 0.810672168966456\n",
      "epoch 799 lr 0.10115035754650535\n",
      "train_loss 0.418307950783756 train_acc 0.8107008267778589\n",
      "\n",
      "val loss = 0.4188773972461505, \n",
      "val acc = 0.8098001289490652\n",
      "\n",
      "epoch 800 lr 0.10094825899732769\n",
      "train_loss 0.418275774879052 train_acc 0.8107868002120678\n",
      "epoch 801 lr 0.10074656424132063\n",
      "train_loss 0.4182437034480805 train_acc 0.8107581424006649\n",
      "epoch 802 lr 0.10054527247170485\n",
      "train_loss 0.4182116990481256 train_acc 0.8107724713063663\n",
      "epoch 803 lr 0.10034438288331303\n",
      "train_loss 0.41817974429030574 train_acc 0.810729484589262\n",
      "epoch 804 lr 0.10014389467258653\n",
      "train_loss 0.41814767635998573 train_acc 0.810672168966456\n",
      "epoch 805 lr 0.09994380703757223\n",
      "train_loss 0.4181155952388794 train_acc 0.8107008267778589\n",
      "epoch 806 lr 0.09974411917791937\n",
      "train_loss 0.41808354672525416 train_acc 0.8107724713063663\n",
      "epoch 807 lr 0.0995448302948762\n",
      "train_loss 0.41805157060443465 train_acc 0.8107008267778589\n",
      "epoch 808 lr 0.09934593959128692\n",
      "train_loss 0.4180195993161838 train_acc 0.810729484589262\n",
      "epoch 809 lr 0.09914744627158849\n",
      "train_loss 0.4179877224992587 train_acc 0.8108011291177692\n",
      "epoch 810 lr 0.09894934954180733\n",
      "train_loss 0.4179559391150605 train_acc 0.8108297869291722\n",
      "epoch 811 lr 0.09875164860955626\n",
      "train_loss 0.4179242241131369 train_acc 0.8108584447405751\n",
      "epoch 812 lr 0.09855434268403132\n",
      "train_loss 0.4178926263730159 train_acc 0.8108584447405751\n",
      "epoch 813 lr 0.09835743097600853\n",
      "train_loss 0.4178610923865693 train_acc 0.8109014314576796\n",
      "epoch 814 lr 0.09816091269784077\n",
      "train_loss 0.41782961369361094 train_acc 0.810944418174784\n",
      "epoch 815 lr 0.09796478706345468\n",
      "train_loss 0.4177981577225553 train_acc 0.8109874048918884\n",
      "epoch 816 lr 0.09776905328834747\n",
      "train_loss 0.41776682180278024 train_acc 0.810973075986187\n",
      "epoch 817 lr 0.09757371058958376\n",
      "train_loss 0.4177355698665673 train_acc 0.8109587470804854\n",
      "epoch 818 lr 0.09737875818579252\n",
      "train_loss 0.4177043195178357 train_acc 0.8109874048918884\n",
      "epoch 819 lr 0.09718419529716385\n",
      "train_loss 0.4176731144568246 train_acc 0.8110303916089928\n",
      "epoch 820 lr 0.09699002114544596\n",
      "train_loss 0.41764185095356016 train_acc 0.8110447205146943\n",
      "epoch 821 lr 0.09679623495394196\n",
      "train_loss 0.4176106775753214 train_acc 0.8110160627032913\n",
      "epoch 822 lr 0.09660283594750685\n",
      "train_loss 0.41757952810416366 train_acc 0.8110447205146943\n",
      "epoch 823 lr 0.09640982335254432\n",
      "train_loss 0.4175482391089582 train_acc 0.8110590494203958\n",
      "epoch 824 lr 0.09621719639700377\n",
      "train_loss 0.4175168989839551 train_acc 0.8110733783260973\n",
      "epoch 825 lr 0.09602495431037707\n",
      "train_loss 0.41748561142030366 train_acc 0.8110733783260973\n",
      "epoch 826 lr 0.09583309632369566\n",
      "train_loss 0.41745433673787724 train_acc 0.8110877072317987\n",
      "epoch 827 lr 0.0956416216695273\n",
      "train_loss 0.41742307635500464 train_acc 0.8110733783260973\n",
      "epoch 828 lr 0.09545052958197317\n",
      "train_loss 0.4173917912576812 train_acc 0.8110733783260973\n",
      "epoch 829 lr 0.09525981929666462\n",
      "train_loss 0.4173605603642223 train_acc 0.8110877072317987\n",
      "epoch 830 lr 0.09506949005076028\n",
      "train_loss 0.41732932828331487 train_acc 0.8110733783260973\n",
      "epoch 831 lr 0.09487954108294289\n",
      "train_loss 0.4172981944174602 train_acc 0.8110733783260973\n",
      "epoch 832 lr 0.09468997163341634\n",
      "train_loss 0.41726717301739463 train_acc 0.8111020361375002\n",
      "epoch 833 lr 0.09450078094390259\n",
      "train_loss 0.41723613875584986 train_acc 0.8111306939489031\n",
      "epoch 834 lr 0.0943119682576386\n",
      "train_loss 0.417205114558893 train_acc 0.8111020361375002\n",
      "epoch 835 lr 0.0941235328193734\n",
      "train_loss 0.41717411239749386 train_acc 0.8111163650432016\n",
      "epoch 836 lr 0.09393547387536497\n",
      "train_loss 0.41714319813044437 train_acc 0.8111736806660076\n",
      "epoch 837 lr 0.09374779067337728\n",
      "train_loss 0.4171123454953035 train_acc 0.8112453251945149\n",
      "epoch 838 lr 0.0935604824626773\n",
      "train_loss 0.417081630143697 train_acc 0.8113599564401267\n",
      "epoch 839 lr 0.09337354849403191\n",
      "train_loss 0.4170510712557129 train_acc 0.8113456275344252\n",
      "epoch 840 lr 0.09318698801970499\n",
      "train_loss 0.4170206071547859 train_acc 0.8113169697230223\n",
      "epoch 841 lr 0.09300080029345441\n",
      "train_loss 0.41699030899961037 train_acc 0.8113456275344252\n",
      "epoch 842 lr 0.09281498457052899\n",
      "train_loss 0.41696006738103275 train_acc 0.811402943157231\n",
      "epoch 843 lr 0.09262954010766561\n",
      "train_loss 0.4169298916352181 train_acc 0.811431600968634\n",
      "epoch 844 lr 0.09244446616308617\n",
      "train_loss 0.41689972856433377 train_acc 0.8113742853458281\n",
      "epoch 845 lr 0.09225976199649465\n",
      "train_loss 0.4168695845912557 train_acc 0.811431600968634\n",
      "epoch 846 lr 0.09207542686907412\n",
      "train_loss 0.41683943344461843 train_acc 0.8114172720629326\n",
      "epoch 847 lr 0.09189146004348384\n",
      "train_loss 0.41680931549787087 train_acc 0.811431600968634\n",
      "epoch 848 lr 0.09170786078385623\n",
      "train_loss 0.41677920214623004 train_acc 0.81148891659144\n",
      "epoch 849 lr 0.09152462835579406\n",
      "train_loss 0.41674921567053286 train_acc 0.8114602587800369\n",
      "\n",
      "val loss = 0.4177133920701096, \n",
      "val acc = 0.8104448742746615\n",
      "\n",
      "epoch 850 lr 0.09134176202636733\n",
      "train_loss 0.41671923307229136 train_acc 0.8114459298743355\n",
      "epoch 851 lr 0.09115926106411051\n",
      "train_loss 0.41668929742896105 train_acc 0.81148891659144\n",
      "epoch 852 lr 0.09097712473901948\n",
      "train_loss 0.416659424248276 train_acc 0.8114745876857384\n",
      "epoch 853 lr 0.09079535232254872\n",
      "train_loss 0.4166295945680371 train_acc 0.8114602587800369\n",
      "epoch 854 lr 0.0906139430876083\n",
      "train_loss 0.41659990386064166 train_acc 0.8114745876857384\n",
      "epoch 855 lr 0.09043289630856105\n",
      "train_loss 0.4165702791308428 train_acc 0.8114745876857384\n",
      "epoch 856 lr 0.09025221126121961\n",
      "train_loss 0.416540569921731 train_acc 0.8115175744028429\n",
      "epoch 857 lr 0.09007188722284357\n",
      "train_loss 0.4165109668613141 train_acc 0.8116035478370517\n",
      "epoch 858 lr 0.0898919234721365\n",
      "train_loss 0.41648143666329696 train_acc 0.8116178767427532\n",
      "epoch 859 lr 0.08971231928924317\n",
      "train_loss 0.41645188455620225 train_acc 0.811703850176962\n",
      "epoch 860 lr 0.08953307395574663\n",
      "train_loss 0.41642241145005515 train_acc 0.8117325079883649\n",
      "epoch 861 lr 0.08935418675466528\n",
      "train_loss 0.41639298618371806 train_acc 0.8117754947054694\n",
      "epoch 862 lr 0.08917565697045009\n",
      "train_loss 0.41636361106283987 train_acc 0.8117754947054694\n",
      "epoch 863 lr 0.08899748388898167\n",
      "train_loss 0.4163343600302123 train_acc 0.8117754947054694\n",
      "epoch 864 lr 0.08881966679756749\n",
      "train_loss 0.41630527824847585 train_acc 0.8117611657997679\n",
      "epoch 865 lr 0.08864220498493891\n",
      "train_loss 0.41627626180444005 train_acc 0.8117754947054694\n",
      "epoch 866 lr 0.08846509774124847\n",
      "train_loss 0.41624728838023733 train_acc 0.8118041525168723\n",
      "epoch 867 lr 0.08828834435806693\n",
      "train_loss 0.41621826308862575 train_acc 0.8118614681396782\n",
      "epoch 868 lr 0.08811194412838055\n",
      "train_loss 0.41618910777947815 train_acc 0.8118471392339767\n",
      "epoch 869 lr 0.08793589634658817\n",
      "train_loss 0.4161599701199057 train_acc 0.8118184814225737\n",
      "epoch 870 lr 0.08776020030849843\n",
      "train_loss 0.4161308840473731 train_acc 0.8118041525168723\n",
      "epoch 871 lr 0.08758485531132694\n",
      "train_loss 0.41610177728449993 train_acc 0.8117754947054694\n",
      "epoch 872 lr 0.08740986065369347\n",
      "train_loss 0.4160726001320539 train_acc 0.8117611657997679\n",
      "epoch 873 lr 0.08723521563561916\n",
      "train_loss 0.4160434673673697 train_acc 0.8117611657997679\n",
      "epoch 874 lr 0.0870609195585237\n",
      "train_loss 0.41601439699499626 train_acc 0.8117754947054694\n",
      "epoch 875 lr 0.08688697172522256\n",
      "train_loss 0.41598536998961044 train_acc 0.8117898236111708\n",
      "epoch 876 lr 0.08671337143992418\n",
      "train_loss 0.415956439724599 train_acc 0.8117898236111708\n",
      "epoch 877 lr 0.08654011800822715\n",
      "train_loss 0.4159274178428921 train_acc 0.8117898236111708\n",
      "epoch 878 lr 0.08636721073711758\n",
      "train_loss 0.41589830434295977 train_acc 0.8118471392339767\n",
      "epoch 879 lr 0.08619464893496608\n",
      "train_loss 0.41586917902285014 train_acc 0.8118614681396782\n",
      "epoch 880 lr 0.08602243191152525\n",
      "train_loss 0.41584005015494047 train_acc 0.8118901259510811\n",
      "epoch 881 lr 0.08585055897792677\n",
      "train_loss 0.41581085921036554 train_acc 0.8118901259510811\n",
      "epoch 882 lr 0.08567902944667868\n",
      "train_loss 0.4157816655271409 train_acc 0.811918783762484\n",
      "epoch 883 lr 0.08550784263166261\n",
      "train_loss 0.4157524617421727 train_acc 0.8118757970453796\n",
      "epoch 884 lr 0.08533699784813108\n",
      "train_loss 0.41572324064110805 train_acc 0.8119617704795885\n",
      "epoch 885 lr 0.08516649441270471\n",
      "train_loss 0.4156941026398513 train_acc 0.8119904282909914\n",
      "epoch 886 lr 0.08499633164336956\n",
      "train_loss 0.4156649987184221 train_acc 0.8119904282909914\n",
      "epoch 887 lr 0.0848265088594743\n",
      "train_loss 0.4156358721843981 train_acc 0.8120190861023944\n",
      "epoch 888 lr 0.08465702538172759\n",
      "train_loss 0.4156068148478167 train_acc 0.8120334150080958\n",
      "epoch 889 lr 0.08448788053219529\n",
      "train_loss 0.41557780549942475 train_acc 0.8120047571966929\n",
      "epoch 890 lr 0.08431907363429776\n",
      "train_loss 0.41554893108008717 train_acc 0.8119617704795885\n",
      "epoch 891 lr 0.08415060401280719\n",
      "train_loss 0.415520196467038 train_acc 0.811947441573887\n",
      "epoch 892 lr 0.08398247099384487\n",
      "train_loss 0.41549154320400294 train_acc 0.8119617704795885\n",
      "epoch 893 lr 0.0838146739048785\n",
      "train_loss 0.41546294887004676 train_acc 0.8119617704795885\n",
      "epoch 894 lr 0.0836472120747195\n",
      "train_loss 0.41543435331119516 train_acc 0.8119760993852899\n",
      "epoch 895 lr 0.08348008483352035\n",
      "train_loss 0.41540581713326846 train_acc 0.811947441573887\n",
      "epoch 896 lr 0.08331329151277182\n",
      "train_loss 0.4153773837848003 train_acc 0.8119760993852899\n",
      "epoch 897 lr 0.08314683144530044\n",
      "train_loss 0.41534900118717444 train_acc 0.8120477439137973\n",
      "epoch 898 lr 0.08298070396526569\n",
      "train_loss 0.4153206579407259 train_acc 0.8121050595366032\n",
      "epoch 899 lr 0.08281490840815746\n",
      "train_loss 0.4152922141280898 train_acc 0.8121193884423047\n",
      "\n",
      "val loss = 0.41665632354435717, \n",
      "val acc = 0.8112185686653772\n",
      "\n",
      "epoch 900 lr 0.08264944411079327\n",
      "train_loss 0.4152637970720225 train_acc 0.812162375159409\n",
      "epoch 901 lr 0.08248431041131572\n",
      "train_loss 0.41523539802433795 train_acc 0.8121480462537076\n",
      "epoch 902 lr 0.0823195066491898\n",
      "train_loss 0.41520703699969763 train_acc 0.8121480462537076\n",
      "epoch 903 lr 0.08215503216520023\n",
      "train_loss 0.41517868352160164 train_acc 0.8121480462537076\n",
      "epoch 904 lr 0.08199088630144886\n",
      "train_loss 0.4151503432233353 train_acc 0.8122483485936179\n",
      "epoch 905 lr 0.08182706840135202\n",
      "train_loss 0.415122049287643 train_acc 0.8122626774993194\n",
      "epoch 906 lr 0.0816635778096379\n",
      "train_loss 0.41509382429519015 train_acc 0.8122770064050209\n",
      "epoch 907 lr 0.08150041387234389\n",
      "train_loss 0.4150656323840573 train_acc 0.8122770064050209\n",
      "epoch 908 lr 0.08133757593681404\n",
      "train_loss 0.41503737333968893 train_acc 0.8122913353107223\n",
      "epoch 909 lr 0.08117506335169639\n",
      "train_loss 0.41500925341115 train_acc 0.8123629798392297\n",
      "epoch 910 lr 0.08101287546694037\n",
      "train_loss 0.414981124309624 train_acc 0.8124202954620355\n",
      "epoch 911 lr 0.08085101163379425\n",
      "train_loss 0.4149529806555074 train_acc 0.8124776110848414\n",
      "epoch 912 lr 0.08068947120480247\n",
      "train_loss 0.4149248425368619 train_acc 0.8124776110848414\n",
      "epoch 913 lr 0.08052825353380308\n",
      "train_loss 0.4148968247665117 train_acc 0.8125349267076474\n",
      "epoch 914 lr 0.08036735797592519\n",
      "train_loss 0.41486884210784974 train_acc 0.8125062688962444\n",
      "epoch 915 lr 0.08020678388758637\n",
      "train_loss 0.41484087115264945 train_acc 0.8124776110848414\n",
      "epoch 916 lr 0.08004653062649005\n",
      "train_loss 0.414812893198713 train_acc 0.8124489532734385\n",
      "epoch 917 lr 0.07988659755162296\n",
      "train_loss 0.41478495390338854 train_acc 0.8124919399905429\n",
      "epoch 918 lr 0.07972698402325258\n",
      "train_loss 0.41475698638738195 train_acc 0.8125349267076474\n",
      "epoch 919 lr 0.07956768940292461\n",
      "train_loss 0.4147289701371816 train_acc 0.8125205978019459\n",
      "epoch 920 lr 0.07940871305346034\n",
      "train_loss 0.41470090918467595 train_acc 0.8125492556133488\n",
      "epoch 921 lr 0.07925005433895416\n",
      "train_loss 0.41467277684481946 train_acc 0.8125062688962444\n",
      "epoch 922 lr 0.07909171262477101\n",
      "train_loss 0.41464447733807336 train_acc 0.8125062688962444\n",
      "epoch 923 lr 0.0789336872775438\n",
      "train_loss 0.414616190345066 train_acc 0.8125205978019459\n",
      "epoch 924 lr 0.07877597766517096\n",
      "train_loss 0.4145880312896899 train_acc 0.8125492556133488\n",
      "epoch 925 lr 0.0786185831568138\n",
      "train_loss 0.4145599435901194 train_acc 0.8125635845190503\n",
      "epoch 926 lr 0.0784615031228941\n",
      "train_loss 0.4145318164906935 train_acc 0.8125779134247517\n",
      "epoch 927 lr 0.0783047369350915\n",
      "train_loss 0.4145037404002888 train_acc 0.8125779134247517\n",
      "epoch 928 lr 0.07814828396634106\n",
      "train_loss 0.4144756149345268 train_acc 0.8126065712361547\n",
      "epoch 929 lr 0.07799214359083068\n",
      "train_loss 0.4144475487356035 train_acc 0.8126495579532591\n",
      "epoch 930 lr 0.07783631518399864\n",
      "train_loss 0.4144194931714876 train_acc 0.8126495579532591\n",
      "epoch 931 lr 0.07768079812253113\n",
      "train_loss 0.4143914800165173 train_acc 0.8126495579532591\n",
      "epoch 932 lr 0.07752559178435968\n",
      "train_loss 0.4143635558332606 train_acc 0.8127212024817665\n",
      "epoch 933 lr 0.07737069554865875\n",
      "train_loss 0.4143357119207955 train_acc 0.8127355313874679\n",
      "epoch 934 lr 0.07721610879584316\n",
      "train_loss 0.41430796543208964 train_acc 0.8127928470102739\n",
      "epoch 935 lr 0.0770618309075657\n",
      "train_loss 0.4142803483324459 train_acc 0.8128358337273782\n",
      "epoch 936 lr 0.07690786126671463\n",
      "train_loss 0.41425279732408876 train_acc 0.8128501626330797\n",
      "epoch 937 lr 0.07675419925741117\n",
      "train_loss 0.4142250797886579 train_acc 0.8128931493501841\n",
      "epoch 938 lr 0.0766008442650071\n",
      "train_loss 0.4141971992623294 train_acc 0.8128644915387812\n",
      "epoch 939 lr 0.0764477956760822\n",
      "train_loss 0.4141694562360604 train_acc 0.8129074782558856\n",
      "epoch 940 lr 0.07629505287844195\n",
      "train_loss 0.41414177162555316 train_acc 0.8129074782558856\n",
      "epoch 941 lr 0.07614261526111492\n",
      "train_loss 0.41411418545679557 train_acc 0.8129647938786915\n",
      "epoch 942 lr 0.07599048221435047\n",
      "train_loss 0.4140866724175701 train_acc 0.8130221095014973\n",
      "epoch 943 lr 0.0758386531296162\n",
      "train_loss 0.41405927183250496 train_acc 0.8130507673129003\n",
      "epoch 944 lr 0.07568712739959556\n",
      "train_loss 0.4140319433370404 train_acc 0.8130507673129003\n",
      "epoch 945 lr 0.07553590441818543\n",
      "train_loss 0.41400466773193306 train_acc 0.8130077805957959\n",
      "epoch 946 lr 0.0753849835804937\n",
      "train_loss 0.41397733979703394 train_acc 0.8129647938786915\n",
      "epoch 947 lr 0.0752343642828368\n",
      "train_loss 0.4139499653016749 train_acc 0.812979122784393\n",
      "epoch 948 lr 0.07508404592273733\n",
      "train_loss 0.4139225852209492 train_acc 0.8130221095014973\n",
      "epoch 949 lr 0.07493402789892167\n",
      "train_loss 0.41389513818005813 train_acc 0.8130364384071989\n",
      "\n",
      "val loss = 0.4155915053676183, \n",
      "val acc = 0.811605415860735\n",
      "\n",
      "epoch 950 lr 0.07478430961131753\n",
      "train_loss 0.4138677667497598 train_acc 0.8130507673129003\n",
      "epoch 951 lr 0.07463489046105154\n",
      "train_loss 0.4138405377111917 train_acc 0.8130650962186018\n",
      "epoch 952 lr 0.07448576985044691\n",
      "train_loss 0.413813393362168 train_acc 0.8130650962186018\n",
      "epoch 953 lr 0.07433694718302099\n",
      "train_loss 0.41378636078030606 train_acc 0.8130937540300047\n",
      "epoch 954 lr 0.07418842186348293\n",
      "train_loss 0.4137593741260754 train_acc 0.8130937540300047\n",
      "epoch 955 lr 0.07404019329773123\n",
      "train_loss 0.41373248008948754 train_acc 0.8130794251243033\n",
      "epoch 956 lr 0.07389226089285145\n",
      "train_loss 0.41370573338188504 train_acc 0.8131510696528106\n",
      "epoch 957 lr 0.07374462405711375\n",
      "train_loss 0.41367895969633695 train_acc 0.8131224118414077\n",
      "epoch 958 lr 0.07359728219997062\n",
      "train_loss 0.4136522303700237 train_acc 0.8131797274642135\n",
      "epoch 959 lr 0.0734502347320544\n",
      "train_loss 0.41362577480408164 train_acc 0.8131653985585121\n",
      "epoch 960 lr 0.07330348106517506\n",
      "train_loss 0.41359937735400426 train_acc 0.8131653985585121\n",
      "epoch 961 lr 0.07315702061231773\n",
      "train_loss 0.41357296349714506 train_acc 0.8132083852756165\n",
      "epoch 962 lr 0.07301085278764037\n",
      "train_loss 0.4135465142079161 train_acc 0.813222714181318\n",
      "epoch 963 lr 0.07286497700647152\n",
      "train_loss 0.41352008673777935 train_acc 0.813222714181318\n",
      "epoch 964 lr 0.07271939268530785\n",
      "train_loss 0.4134937922716974 train_acc 0.8131797274642135\n",
      "epoch 965 lr 0.07257409924181187\n",
      "train_loss 0.41346768215796514 train_acc 0.8131797274642135\n",
      "epoch 966 lr 0.07242909609480962\n",
      "train_loss 0.41344169964304667 train_acc 0.813222714181318\n",
      "epoch 967 lr 0.07228438266428833\n",
      "train_loss 0.4134157552495807 train_acc 0.8131797274642135\n",
      "epoch 968 lr 0.07213995837139407\n",
      "train_loss 0.4133897742632401 train_acc 0.8131653985585121\n",
      "epoch 969 lr 0.07199582263842949\n",
      "train_loss 0.4133638442194826 train_acc 0.8131797274642135\n",
      "epoch 970 lr 0.07185197488885146\n",
      "train_loss 0.41333798339248456 train_acc 0.8131797274642135\n",
      "epoch 971 lr 0.07170841454726878\n",
      "train_loss 0.41331223933065575 train_acc 0.8132083852756165\n",
      "epoch 972 lr 0.07156514103943991\n",
      "train_loss 0.41328654113864144 train_acc 0.8132513719927209\n",
      "epoch 973 lr 0.07142215379227061\n",
      "train_loss 0.4132608997535508 train_acc 0.8132657008984224\n",
      "epoch 974 lr 0.07127945223381171\n",
      "train_loss 0.4132353509289305 train_acc 0.8132943587098254\n",
      "epoch 975 lr 0.0711370357932568\n",
      "train_loss 0.4132098209488052 train_acc 0.8133230165212283\n",
      "epoch 976 lr 0.07099490390093989\n",
      "train_loss 0.4131844060989202 train_acc 0.8133373454269297\n",
      "epoch 977 lr 0.07085305598833325\n",
      "train_loss 0.41315911869132466 train_acc 0.8133803321440342\n",
      "epoch 978 lr 0.07071149148804504\n",
      "train_loss 0.41313385734625446 train_acc 0.8133230165212283\n",
      "epoch 979 lr 0.07057020983381705\n",
      "train_loss 0.4131086968410009 train_acc 0.8133516743326312\n",
      "epoch 980 lr 0.0704292104605225\n",
      "train_loss 0.41308352231984596 train_acc 0.8133660032383326\n",
      "epoch 981 lr 0.0702884928041637\n",
      "train_loss 0.4130583909701965 train_acc 0.8133946610497357\n",
      "epoch 982 lr 0.07014805630186983\n",
      "train_loss 0.41303325091119464 train_acc 0.81343764776684\n",
      "epoch 983 lr 0.0700079003918947\n",
      "train_loss 0.4130082375224723 train_acc 0.81343764776684\n",
      "epoch 984 lr 0.06986802451361449\n",
      "train_loss 0.4129833491984839 train_acc 0.8134806344839445\n",
      "epoch 985 lr 0.06972842810752547\n",
      "train_loss 0.4129585794500473 train_acc 0.8134806344839445\n",
      "epoch 986 lr 0.06958911061524187\n",
      "train_loss 0.41293378121650354 train_acc 0.8134519766725415\n",
      "epoch 987 lr 0.0694500714794935\n",
      "train_loss 0.4129089996665421 train_acc 0.8134806344839445\n",
      "epoch 988 lr 0.06931131014412366\n",
      "train_loss 0.41288424084688163 train_acc 0.8134806344839445\n",
      "epoch 989 lr 0.06917282605408681\n",
      "train_loss 0.41285955397057894 train_acc 0.813466305578243\n",
      "epoch 990 lr 0.06903461865544641\n",
      "train_loss 0.41283487588630124 train_acc 0.8134519766725415\n",
      "epoch 991 lr 0.06889668739537268\n",
      "train_loss 0.41281026145304567 train_acc 0.8134233188611386\n",
      "epoch 992 lr 0.06875903172214039\n",
      "train_loss 0.4127856778846397 train_acc 0.8134806344839445\n",
      "epoch 993 lr 0.06862165108512666\n",
      "train_loss 0.41276111380085173 train_acc 0.8134806344839445\n",
      "epoch 994 lr 0.06848454493480877\n",
      "train_loss 0.4127365407602789 train_acc 0.8135092922953474\n",
      "epoch 995 lr 0.06834771272276194\n",
      "train_loss 0.4127119370073013 train_acc 0.8135236212010489\n",
      "epoch 996 lr 0.06821115390165712\n",
      "train_loss 0.4126872689459138 train_acc 0.8134949633896459\n",
      "epoch 997 lr 0.06807486792525885\n",
      "train_loss 0.41266271720524994 train_acc 0.8135236212010489\n",
      "epoch 998 lr 0.06793885424842305\n",
      "train_loss 0.4126382884731403 train_acc 0.8135379501067503\n",
      "epoch 999 lr 0.06780311232709485\n",
      "train_loss 0.41261391058002217 train_acc 0.8135666079181533\n",
      "\n",
      "val loss = 0.4146443591415242, \n",
      "val acc = 0.8123791102514507\n",
      "\n",
      "epoch 1000 lr 0.06766764161830634\n",
      "train_loss 0.4125895302227334 train_acc 0.8135522790124519\n",
      "epoch 1001 lr 0.06753244158017455\n",
      "train_loss 0.41256521432658083 train_acc 0.8135522790124519\n",
      "epoch 1002 lr 0.0673975116718991\n",
      "train_loss 0.4125409428653886 train_acc 0.8135092922953474\n",
      "epoch 1003 lr 0.06726285135376021\n",
      "train_loss 0.41251672185516103 train_acc 0.8135666079181533\n",
      "epoch 1004 lr 0.06712846008711641\n",
      "train_loss 0.4124924985593053 train_acc 0.8135952657295562\n",
      "epoch 1005 lr 0.06699433733440249\n",
      "train_loss 0.41246829605497204 train_acc 0.8136525813523621\n",
      "epoch 1006 lr 0.0668604825591272\n",
      "train_loss 0.4124439517063372 train_acc 0.8136812391637651\n",
      "epoch 1007 lr 0.06672689522587133\n",
      "train_loss 0.4124194746314091 train_acc 0.8136812391637651\n",
      "epoch 1008 lr 0.0665935748002853\n",
      "train_loss 0.4123950091991395 train_acc 0.8136669102580636\n",
      "epoch 1009 lr 0.06646052074908729\n",
      "train_loss 0.4123705304986264 train_acc 0.8136812391637651\n",
      "epoch 1010 lr 0.06632773254006086\n",
      "train_loss 0.4123460882887724 train_acc 0.8136955680694665\n",
      "epoch 1011 lr 0.06619520964205305\n",
      "train_loss 0.4123216617473453 train_acc 0.8137242258808695\n",
      "epoch 1012 lr 0.06606295152497205\n",
      "train_loss 0.4122973012112578 train_acc 0.813738554786571\n",
      "epoch 1013 lr 0.06593095765978525\n",
      "train_loss 0.41227294753181404 train_acc 0.8137672125979739\n",
      "epoch 1014 lr 0.06579922751851698\n",
      "train_loss 0.41224859123249136 train_acc 0.8138531860321827\n",
      "epoch 1015 lr 0.06566776057424654\n",
      "train_loss 0.41222427915572274 train_acc 0.8138818438435856\n",
      "epoch 1016 lr 0.06553655630110594\n",
      "train_loss 0.41219997212928705 train_acc 0.8138961727492872\n",
      "epoch 1017 lr 0.06540561417427794\n",
      "train_loss 0.4121757458677112 train_acc 0.8139105016549886\n",
      "epoch 1018 lr 0.06527493366999382\n",
      "train_loss 0.41215153962409906 train_acc 0.8139248305606901\n",
      "epoch 1019 lr 0.06514451426553144\n",
      "train_loss 0.41212729552612315 train_acc 0.8139964750891975\n",
      "epoch 1020 lr 0.06501435543921295\n",
      "train_loss 0.41210313086093125 train_acc 0.8140251329006004\n",
      "epoch 1021 lr 0.06488445667040295\n",
      "train_loss 0.412078930619267 train_acc 0.8140537907120033\n",
      "epoch 1022 lr 0.06475481743950609\n",
      "train_loss 0.41205465150384873 train_acc 0.8140824485234063\n",
      "epoch 1023 lr 0.06462543722796536\n",
      "train_loss 0.4120303096612525 train_acc 0.8140967774291077\n",
      "epoch 1024 lr 0.0644963155182597\n",
      "train_loss 0.41200602490627475 train_acc 0.8140251329006004\n",
      "epoch 1025 lr 0.06436745179390212\n",
      "train_loss 0.4119817866924498 train_acc 0.8140251329006004\n",
      "epoch 1026 lr 0.06423884553943751\n",
      "train_loss 0.41195761663937513 train_acc 0.8139964750891975\n",
      "epoch 1027 lr 0.06411049624044075\n",
      "train_loss 0.4119333470253797 train_acc 0.8140251329006004\n",
      "epoch 1028 lr 0.0639824033835144\n",
      "train_loss 0.411909049139698 train_acc 0.8140394618063018\n",
      "epoch 1029 lr 0.06385456645628691\n",
      "train_loss 0.41188480196562505 train_acc 0.8140394618063018\n",
      "epoch 1030 lr 0.06372698494741037\n",
      "train_loss 0.41186052437417403 train_acc 0.8140537907120033\n",
      "epoch 1031 lr 0.06359965834655862\n",
      "train_loss 0.4118362151196461 train_acc 0.8140537907120033\n",
      "epoch 1032 lr 0.06347258614442501\n",
      "train_loss 0.4118119563566363 train_acc 0.8140537907120033\n",
      "epoch 1033 lr 0.06334576783272065\n",
      "train_loss 0.4117877580506996 train_acc 0.8140681196177048\n",
      "epoch 1034 lr 0.06321920290417204\n",
      "train_loss 0.411763580654098 train_acc 0.8140967774291077\n",
      "epoch 1035 lr 0.06309289085251939\n",
      "train_loss 0.4117395075908626 train_acc 0.8141254352405107\n",
      "epoch 1036 lr 0.06296683117251423\n",
      "train_loss 0.41171545153796113 train_acc 0.8141540930519137\n",
      "epoch 1037 lr 0.06284102335991774\n",
      "train_loss 0.4116914532967218 train_acc 0.8141111063348092\n",
      "epoch 1038 lr 0.06271546691149846\n",
      "train_loss 0.41166743993216587 train_acc 0.8141111063348092\n",
      "epoch 1039 lr 0.06259016132503047\n",
      "train_loss 0.4116433929228813 train_acc 0.8141254352405107\n",
      "epoch 1040 lr 0.062465106099291214\n",
      "train_loss 0.41161930758460913 train_acc 0.8141111063348092\n",
      "epoch 1041 lr 0.06234030073405966\n",
      "train_loss 0.41159527904780485 train_acc 0.8141254352405107\n",
      "epoch 1042 lr 0.06221574473011414\n",
      "train_loss 0.41157133242684324 train_acc 0.8141397641462121\n",
      "epoch 1043 lr 0.06209143758923052\n",
      "train_loss 0.4115474008204007 train_acc 0.8141254352405107\n",
      "epoch 1044 lr 0.06196737881418002\n",
      "train_loss 0.4115235269912352 train_acc 0.8141540930519137\n",
      "epoch 1045 lr 0.06184356790872742\n",
      "train_loss 0.4114996834590431 train_acc 0.8141827508633166\n",
      "epoch 1046 lr 0.06172000437762889\n",
      "train_loss 0.4114759085741379 train_acc 0.8141827508633166\n",
      "epoch 1047 lr 0.06159668772663019\n",
      "train_loss 0.4114522107321677 train_acc 0.8142400664861225\n",
      "epoch 1048 lr 0.061473617462464505\n",
      "train_loss 0.41142851467375674 train_acc 0.8142687242975254\n",
      "epoch 1049 lr 0.06135079309285066\n",
      "train_loss 0.41140481817082314 train_acc 0.8143260399203313\n",
      "\n",
      "val loss = 0.4137726019427323, \n",
      "val acc = 0.8112185686653772\n",
      "\n",
      "epoch 1050 lr 0.06122821412649095\n",
      "train_loss 0.41138117108234085 train_acc 0.8143546977317342\n",
      "epoch 1051 lr 0.06110588007306942\n",
      "train_loss 0.4113574289659453 train_acc 0.8143403688260328\n",
      "epoch 1052 lr 0.06098379044324963\n",
      "train_loss 0.4113337498239652 train_acc 0.8143403688260328\n",
      "epoch 1053 lr 0.06086194474867295\n",
      "train_loss 0.411310137227316 train_acc 0.8143833555431371\n",
      "epoch 1054 lr 0.06074034250195639\n",
      "train_loss 0.4112864852682919 train_acc 0.8143833555431371\n",
      "epoch 1055 lr 0.06061898321669085\n",
      "train_loss 0.4112627841449425 train_acc 0.8143690266374357\n",
      "epoch 1056 lr 0.06049786640743897\n",
      "train_loss 0.4112391148908253 train_acc 0.8144406711659431\n",
      "epoch 1057 lr 0.06037699158973341\n",
      "train_loss 0.411215375917018 train_acc 0.814469328977346\n",
      "epoch 1058 lr 0.06025635828007469\n",
      "train_loss 0.4111916864897469 train_acc 0.8145266446001519\n",
      "epoch 1059 lr 0.060135965995929457\n",
      "train_loss 0.41116786754190904 train_acc 0.814469328977346\n",
      "epoch 1060 lr 0.06001581425572836\n",
      "train_loss 0.4111440373906554 train_acc 0.8144836578830474\n",
      "epoch 1061 lr 0.05989590257886434\n",
      "train_loss 0.41112025699021615 train_acc 0.814469328977346\n",
      "epoch 1062 lr 0.05977623048569047\n",
      "train_loss 0.4110966298983424 train_acc 0.8145266446001519\n",
      "epoch 1063 lr 0.05965679749751827\n",
      "train_loss 0.41107308292045225 train_acc 0.8145409735058533\n",
      "epoch 1064 lr 0.05953760313661557\n",
      "train_loss 0.4110495947613253 train_acc 0.8145409735058533\n",
      "epoch 1065 lr 0.05941864692620483\n",
      "train_loss 0.41102621736275236 train_acc 0.8145553024115548\n",
      "epoch 1066 lr 0.05929992839046099\n",
      "train_loss 0.411002782972711 train_acc 0.8145982891286593\n",
      "epoch 1067 lr 0.059181447054509805\n",
      "train_loss 0.410979390773092 train_acc 0.8145839602229578\n",
      "epoch 1068 lr 0.05906320244442573\n",
      "train_loss 0.41095606276219887 train_acc 0.8146126180343607\n",
      "epoch 1069 lr 0.0589451940872302\n",
      "train_loss 0.41093287498085074 train_acc 0.8146412758457636\n",
      "epoch 1070 lr 0.05882742151088959\n",
      "train_loss 0.4109097573787428 train_acc 0.8146269469400622\n",
      "epoch 1071 lr 0.05870988424431349\n",
      "train_loss 0.410886685559997 train_acc 0.8146556047514651\n",
      "epoch 1072 lr 0.058592581817352614\n",
      "train_loss 0.4108636835443492 train_acc 0.8146556047514651\n",
      "epoch 1073 lr 0.05847551376079716\n",
      "train_loss 0.41084077374437783 train_acc 0.8146699336571666\n",
      "epoch 1074 lr 0.05835867960637469\n",
      "train_loss 0.41081793026214747 train_acc 0.8146842625628681\n",
      "epoch 1075 lr 0.05824207888674848\n",
      "train_loss 0.4107949927989595 train_acc 0.8146556047514651\n",
      "epoch 1076 lr 0.05812571113551546\n",
      "train_loss 0.41077208318003855 train_acc 0.8147845649027784\n",
      "epoch 1077 lr 0.05800957588720449\n",
      "train_loss 0.4107492357821823 train_acc 0.8147559070913755\n",
      "epoch 1078 lr 0.0578936726772744\n",
      "train_loss 0.4107264196487778 train_acc 0.8147559070913755\n",
      "epoch 1079 lr 0.05777800104211224\n",
      "train_loss 0.41070366522084717 train_acc 0.8147272492799725\n",
      "epoch 1080 lr 0.05766256051903125\n",
      "train_loss 0.4106809591003881 train_acc 0.8147415781856739\n",
      "epoch 1081 lr 0.05754735064626926\n",
      "train_loss 0.4106583388185404 train_acc 0.8147415781856739\n",
      "epoch 1082 lr 0.05743237096298654\n",
      "train_loss 0.410635679942771 train_acc 0.8147845649027784\n",
      "epoch 1083 lr 0.05731762100926429\n",
      "train_loss 0.41061301910107123 train_acc 0.8148132227141813\n",
      "epoch 1084 lr 0.05720310032610247\n",
      "train_loss 0.41059038080003385 train_acc 0.8148132227141813\n",
      "epoch 1085 lr 0.05708880845541825\n",
      "train_loss 0.4105677599591993 train_acc 0.8148132227141813\n",
      "epoch 1086 lr 0.05697474494004394\n",
      "train_loss 0.41054515835090954 train_acc 0.8147559070913755\n",
      "epoch 1087 lr 0.05686090932372539\n",
      "train_loss 0.4105225884833468 train_acc 0.8147988938084798\n",
      "epoch 1088 lr 0.056747301151119915\n",
      "train_loss 0.4104999809865121 train_acc 0.8147988938084798\n",
      "epoch 1089 lr 0.05663391996779474\n",
      "train_loss 0.41047734295641264 train_acc 0.8147988938084798\n",
      "epoch 1090 lr 0.056520765320224924\n",
      "train_loss 0.410454662129799 train_acc 0.8147988938084798\n",
      "epoch 1091 lr 0.05640783675579177\n",
      "train_loss 0.4104319562785697 train_acc 0.8148132227141813\n",
      "epoch 1092 lr 0.05629513382278083\n",
      "train_loss 0.4104092098098703 train_acc 0.8147988938084798\n",
      "epoch 1093 lr 0.05618265607038026\n",
      "train_loss 0.41038645182526823 train_acc 0.8147845649027784\n",
      "epoch 1094 lr 0.05607040304867886\n",
      "train_loss 0.41036368851030053 train_acc 0.8147702359970769\n",
      "epoch 1095 lr 0.05595837430866444\n",
      "train_loss 0.41034099878030006 train_acc 0.8147845649027784\n",
      "epoch 1096 lr 0.05584656940222184\n",
      "train_loss 0.41031823421622343 train_acc 0.8148132227141813\n",
      "epoch 1097 lr 0.05573498788213133\n",
      "train_loss 0.41029539431503936 train_acc 0.8148705383369872\n",
      "epoch 1098 lr 0.05562362930206665\n",
      "train_loss 0.410272518534827 train_acc 0.8148418805255843\n",
      "epoch 1099 lr 0.055512493216593364\n",
      "train_loss 0.4102497281670112 train_acc 0.8148418805255843\n",
      "\n",
      "val loss = 0.4128915726600006, \n",
      "val acc = 0.8112185686653772\n",
      "\n",
      "epoch 1100 lr 0.05540157918116693\n",
      "train_loss 0.410226977841089 train_acc 0.8148275516198827\n",
      "epoch 1101 lr 0.05529088675213112\n",
      "train_loss 0.4102042116255607 train_acc 0.8148132227141813\n",
      "epoch 1102 lr 0.05518041548671601\n",
      "train_loss 0.41018130659568863 train_acc 0.8147988938084798\n",
      "epoch 1103 lr 0.05507016494303645\n",
      "train_loss 0.4101584177275942 train_acc 0.8148132227141813\n",
      "epoch 1104 lr 0.05496013468009006\n",
      "train_loss 0.41013552721756913 train_acc 0.8148275516198827\n",
      "epoch 1105 lr 0.054850324257755705\n",
      "train_loss 0.4101127307146158 train_acc 0.8148275516198827\n",
      "epoch 1106 lr 0.05474073323679148\n",
      "train_loss 0.4100900242647993 train_acc 0.8148275516198827\n",
      "epoch 1107 lr 0.054631361178833215\n",
      "train_loss 0.41006733263225253 train_acc 0.8147845649027784\n",
      "epoch 1108 lr 0.054522207646392484\n",
      "train_loss 0.4100447129472044 train_acc 0.8148562094312858\n",
      "epoch 1109 lr 0.054413272202855065\n",
      "train_loss 0.41002214767204975 train_acc 0.8148418805255843\n",
      "epoch 1110 lr 0.05430455441247898\n",
      "train_loss 0.40999950082578596 train_acc 0.8147988938084798\n",
      "epoch 1111 lr 0.05419605384039297\n",
      "train_loss 0.4099769668985367 train_acc 0.8148275516198827\n",
      "epoch 1112 lr 0.05408777005259457\n",
      "train_loss 0.40995448762471703 train_acc 0.8148275516198827\n",
      "epoch 1113 lr 0.05397970261594851\n",
      "train_loss 0.40993190605016544 train_acc 0.8148562094312858\n",
      "epoch 1114 lr 0.05387185109818487\n",
      "train_loss 0.4099094079967302 train_acc 0.8148848672426887\n",
      "epoch 1115 lr 0.053764215067897476\n",
      "train_loss 0.409886960349648 train_acc 0.8148991961483901\n",
      "epoch 1116 lr 0.053656794094542014\n",
      "train_loss 0.4098645041792799 train_acc 0.8148991961483901\n",
      "epoch 1117 lr 0.05354958774843449\n",
      "train_loss 0.40984213445651657 train_acc 0.8149135250540916\n",
      "epoch 1118 lr 0.05344259560074934\n",
      "train_loss 0.4098198495582502 train_acc 0.8149135250540916\n",
      "epoch 1119 lr 0.05333581722351788\n",
      "train_loss 0.4097976329511219 train_acc 0.8149278539597931\n",
      "epoch 1120 lr 0.053229252189626396\n",
      "train_loss 0.4097754589982652 train_acc 0.814956511771196\n",
      "epoch 1121 lr 0.05312290007281467\n",
      "train_loss 0.40975336562996256 train_acc 0.8149994984883004\n",
      "epoch 1122 lr 0.05301676044767405\n",
      "train_loss 0.40973124044984427 train_acc 0.8149851695825989\n",
      "epoch 1123 lr 0.05291083288964592\n",
      "train_loss 0.40970910042670117 train_acc 0.8150424852054049\n",
      "epoch 1124 lr 0.052805116975019877\n",
      "train_loss 0.4096869264795888 train_acc 0.8150568141111063\n",
      "epoch 1125 lr 0.052699612280932166\n",
      "train_loss 0.409664800378844 train_acc 0.815013827394002\n",
      "epoch 1126 lr 0.052594318385363846\n",
      "train_loss 0.40964268487439004 train_acc 0.8150281562997034\n",
      "epoch 1127 lr 0.05248923486713917\n",
      "train_loss 0.40962060507669673 train_acc 0.815013827394002\n",
      "epoch 1128 lr 0.05238436130592397\n",
      "train_loss 0.4095985692418866 train_acc 0.8150281562997034\n",
      "epoch 1129 lr 0.052279697282223814\n",
      "train_loss 0.4095765752769685 train_acc 0.8150854719225092\n",
      "epoch 1130 lr 0.05217524237738252\n",
      "train_loss 0.4095545673296476 train_acc 0.8150711430168078\n",
      "epoch 1131 lr 0.052070996173580276\n",
      "train_loss 0.40953261394013984 train_acc 0.8151141297339122\n",
      "epoch 1132 lr 0.05196695825383218\n",
      "train_loss 0.4095106880070518 train_acc 0.8150854719225092\n",
      "epoch 1133 lr 0.051863128201986367\n",
      "train_loss 0.4094888034608157 train_acc 0.8150998008282108\n",
      "epoch 1134 lr 0.05175950560272253\n",
      "train_loss 0.4094669466147108 train_acc 0.8150998008282108\n",
      "epoch 1135 lr 0.0516560900415501\n",
      "train_loss 0.4094452082480797 train_acc 0.8150711430168078\n",
      "epoch 1136 lr 0.05155288110480673\n",
      "train_loss 0.4094234996229341 train_acc 0.8150854719225092\n",
      "epoch 1137 lr 0.0514498783796565\n",
      "train_loss 0.4094018680889037 train_acc 0.8151284586396137\n",
      "epoch 1138 lr 0.0513470814540884\n",
      "train_loss 0.4093803110875755 train_acc 0.8150568141111063\n",
      "epoch 1139 lr 0.05124448991691456\n",
      "train_loss 0.4093587170366807 train_acc 0.8150424852054049\n",
      "epoch 1140 lr 0.05114210335776874\n",
      "train_loss 0.4093370875365307 train_acc 0.8150568141111063\n",
      "epoch 1141 lr 0.051039921367104515\n",
      "train_loss 0.4093154759421804 train_acc 0.8150568141111063\n",
      "epoch 1142 lr 0.05093794353619384\n",
      "train_loss 0.4092938746346195 train_acc 0.8150424852054049\n",
      "epoch 1143 lr 0.0508361694571252\n",
      "train_loss 0.40927231544749043 train_acc 0.8151141297339122\n",
      "epoch 1144 lr 0.05073459872280219\n",
      "train_loss 0.40925081485549325 train_acc 0.8151714453567181\n",
      "epoch 1145 lr 0.0506332309269417\n",
      "train_loss 0.40922938077318993 train_acc 0.8152144320738225\n",
      "epoch 1146 lr 0.05053206566407245\n",
      "train_loss 0.4092080129190546 train_acc 0.8152717476966284\n",
      "epoch 1147 lr 0.05043110252953321\n",
      "train_loss 0.409186596528119 train_acc 0.815257418790927\n",
      "epoch 1148 lr 0.05033034111947135\n",
      "train_loss 0.40916512671456534 train_acc 0.8152717476966284\n",
      "epoch 1149 lr 0.05022978103084105\n",
      "train_loss 0.4091436671795273 train_acc 0.8153004055080314\n",
      "\n",
      "val loss = 0.4120434432116661, \n",
      "val acc = 0.8110896196002579\n",
      "\n",
      "epoch 1150 lr 0.050129421861401874\n",
      "train_loss 0.4091221982822897 train_acc 0.8153290633194343\n",
      "epoch 1151 lr 0.050029263209716957\n",
      "train_loss 0.40910075565413095 train_acc 0.8153863789422402\n",
      "epoch 1152 lr 0.04992930467515161\n",
      "train_loss 0.40907932668055347 train_acc 0.8154436945650461\n",
      "epoch 1153 lr 0.04982954585787151\n",
      "train_loss 0.4090578199087218 train_acc 0.8154293656593445\n",
      "epoch 1154 lr 0.04972998635884131\n",
      "train_loss 0.40903624957210166 train_acc 0.8154293656593445\n",
      "epoch 1155 lr 0.04963062577982282\n",
      "train_loss 0.409014628007255 train_acc 0.8154150367536431\n",
      "epoch 1156 lr 0.04953146372337366\n",
      "train_loss 0.40899301983347786 train_acc 0.8153863789422402\n",
      "epoch 1157 lr 0.0494324997928454\n",
      "train_loss 0.408971421340152 train_acc 0.8154150367536431\n",
      "epoch 1158 lr 0.049333733592382245\n",
      "train_loss 0.40894981869486124 train_acc 0.8154150367536431\n",
      "epoch 1159 lr 0.049235164726919224\n",
      "train_loss 0.40892821987394357 train_acc 0.8154007078479416\n",
      "epoch 1160 lr 0.04913679280218077\n",
      "train_loss 0.408906579153401 train_acc 0.8154293656593445\n",
      "epoch 1161 lr 0.04903861742467903\n",
      "train_loss 0.40888498335407425 train_acc 0.8154866812821505\n",
      "epoch 1162 lr 0.048940638201712384\n",
      "train_loss 0.40886349974143094 train_acc 0.815472352376449\n",
      "epoch 1163 lr 0.04884285474136378\n",
      "train_loss 0.40884201531408493 train_acc 0.8154436945650461\n",
      "epoch 1164 lr 0.048745266652499286\n",
      "train_loss 0.40882060652492197 train_acc 0.815472352376449\n",
      "epoch 1165 lr 0.04864787354476638\n",
      "train_loss 0.4087992390440335 train_acc 0.815472352376449\n",
      "epoch 1166 lr 0.04855067502859253\n",
      "train_loss 0.40877789283809585 train_acc 0.8154866812821505\n",
      "epoch 1167 lr 0.048453670715183514\n",
      "train_loss 0.4087565410173605 train_acc 0.8155296679992549\n",
      "epoch 1168 lr 0.04835686021652198\n",
      "train_loss 0.40873513281204327 train_acc 0.8155726547163593\n",
      "epoch 1169 lr 0.048260243145365776\n",
      "train_loss 0.4087136583656849 train_acc 0.8156442992448667\n",
      "epoch 1170 lr 0.04816381911524652\n",
      "train_loss 0.40869216733704267 train_acc 0.8156299703391652\n",
      "epoch 1171 lr 0.04806758774046792\n",
      "train_loss 0.4086707308752002 train_acc 0.8156442992448667\n",
      "epoch 1172 lr 0.04797154863610439\n",
      "train_loss 0.4086493709893204 train_acc 0.815715943773374\n",
      "epoch 1173 lr 0.04787570141799934\n",
      "train_loss 0.4086280593088098 train_acc 0.8157016148676726\n",
      "epoch 1174 lr 0.047780045702763826\n",
      "train_loss 0.4086067631013508 train_acc 0.8157589304904784\n",
      "epoch 1175 lr 0.04768458110777481\n",
      "train_loss 0.4085854637051876 train_acc 0.815744601584777\n",
      "epoch 1176 lr 0.047589307251173815\n",
      "train_loss 0.4085641567630053 train_acc 0.815744601584777\n",
      "epoch 1177 lr 0.04749422375186527\n",
      "train_loss 0.40854286730949224 train_acc 0.8157875883018814\n",
      "epoch 1178 lr 0.04739933022951507\n",
      "train_loss 0.40852158034509867 train_acc 0.8158019172075829\n",
      "epoch 1179 lr 0.047304626304548965\n",
      "train_loss 0.4085002793904993 train_acc 0.81577325939618\n",
      "epoch 1180 lr 0.04721011159815118\n",
      "train_loss 0.4084790434263229 train_acc 0.8158735617360903\n",
      "epoch 1181 lr 0.04711578573226271\n",
      "train_loss 0.40845789295234186 train_acc 0.8158735617360903\n",
      "epoch 1182 lr 0.04702164832958001\n",
      "train_loss 0.40843682651952595 train_acc 0.8159022195474932\n",
      "epoch 1183 lr 0.0469276990135533\n",
      "train_loss 0.4084157869690838 train_acc 0.8159595351702991\n",
      "epoch 1184 lr 0.046833937408385234\n",
      "train_loss 0.40839479150038704 train_acc 0.8159308773588961\n",
      "epoch 1185 lr 0.04674036313902923\n",
      "train_loss 0.4083738258335782 train_acc 0.8159308773588961\n",
      "epoch 1186 lr 0.046646975831188126\n",
      "train_loss 0.4083528430277045 train_acc 0.8159738640760005\n",
      "epoch 1187 lr 0.04655377511131252\n",
      "train_loss 0.4083318027971877 train_acc 0.8159595351702991\n",
      "epoch 1188 lr 0.04646076060659945\n",
      "train_loss 0.4083107518758654 train_acc 0.815988192981702\n",
      "epoch 1189 lr 0.04636793194499073\n",
      "train_loss 0.4082895821229745 train_acc 0.8159308773588961\n",
      "epoch 1190 lr 0.046275288755171645\n",
      "train_loss 0.40826848292339596 train_acc 0.8160168507931049\n",
      "epoch 1191 lr 0.04618283066656925\n",
      "train_loss 0.4082474893195468 train_acc 0.8160025218874034\n",
      "epoch 1192 lr 0.04609055730935113\n",
      "train_loss 0.40822651642389507 train_acc 0.8160025218874034\n",
      "epoch 1193 lr 0.045998468314423675\n",
      "train_loss 0.40820549995900873 train_acc 0.8159452062645975\n",
      "epoch 1194 lr 0.04590656331343083\n",
      "train_loss 0.4081843854321931 train_acc 0.8159452062645975\n",
      "epoch 1195 lr 0.045814841938752425\n",
      "train_loss 0.40816323689211176 train_acc 0.8159595351702991\n",
      "epoch 1196 lr 0.045723303823502884\n",
      "train_loss 0.4081420432254515 train_acc 0.8159452062645975\n",
      "epoch 1197 lr 0.045631948601529575\n",
      "train_loss 0.4081208274565711 train_acc 0.8159595351702991\n",
      "epoch 1198 lr 0.04554077590741154\n",
      "train_loss 0.4080996259367808 train_acc 0.8159595351702991\n",
      "epoch 1199 lr 0.04544978537645784\n",
      "train_loss 0.40807854801139054 train_acc 0.8160025218874034\n",
      "\n",
      "val loss = 0.4112470643920326, \n",
      "val acc = 0.8113475177304964\n",
      "\n",
      "epoch 1200 lr 0.04535897664470626\n",
      "train_loss 0.4080574890184054 train_acc 0.8159738640760005\n",
      "epoch 1201 lr 0.04526834934892172\n",
      "train_loss 0.40803648704473644 train_acc 0.815988192981702\n",
      "epoch 1202 lr 0.04517790312659495\n",
      "train_loss 0.40801547820574025 train_acc 0.8160025218874034\n",
      "epoch 1203 lr 0.04508763761594091\n",
      "train_loss 0.40799448721166914 train_acc 0.8160311796988065\n",
      "epoch 1204 lr 0.04499755245589746\n",
      "train_loss 0.40797355998757645 train_acc 0.8160025218874034\n",
      "epoch 1205 lr 0.04490764728612382\n",
      "train_loss 0.4079526713778882 train_acc 0.8160168507931049\n",
      "epoch 1206 lr 0.044817921746999216\n",
      "train_loss 0.40793178966304067 train_acc 0.8160025218874034\n",
      "epoch 1207 lr 0.044728375479621336\n",
      "train_loss 0.40791084896212393 train_acc 0.8159738640760005\n",
      "epoch 1208 lr 0.04463900812580504\n",
      "train_loss 0.4078899430392531 train_acc 0.8159738640760005\n",
      "epoch 1209 lr 0.04454981932808074\n",
      "train_loss 0.4078690286565672 train_acc 0.8160168507931049\n",
      "epoch 1210 lr 0.04446080872969317\n",
      "train_loss 0.40784814556709026 train_acc 0.8160168507931049\n",
      "epoch 1211 lr 0.044371975974599784\n",
      "train_loss 0.40782728977689253 train_acc 0.8160455086045079\n",
      "epoch 1212 lr 0.04428332070746948\n",
      "train_loss 0.40780641618658275 train_acc 0.8160311796988065\n",
      "epoch 1213 lr 0.04419484257368103\n",
      "train_loss 0.4077855643644828 train_acc 0.8160311796988065\n",
      "epoch 1214 lr 0.04410654121932182\n",
      "train_loss 0.4077647604525469 train_acc 0.8160455086045079\n",
      "epoch 1215 lr 0.044018416291186274\n",
      "train_loss 0.4077439891602449 train_acc 0.8160455086045079\n",
      "epoch 1216 lr 0.0439304674367746\n",
      "train_loss 0.4077232663174495 train_acc 0.8160455086045079\n",
      "epoch 1217 lr 0.04384269430429123\n",
      "train_loss 0.4077025624259254 train_acc 0.8160455086045079\n",
      "epoch 1218 lr 0.04375509654264356\n",
      "train_loss 0.4076819206750489 train_acc 0.8161028242273137\n",
      "epoch 1219 lr 0.043667673801440376\n",
      "train_loss 0.4076613462847406 train_acc 0.8160884953216123\n",
      "epoch 1220 lr 0.04358042573099065\n",
      "train_loss 0.40764084415027146 train_acc 0.8160598375102094\n",
      "epoch 1221 lr 0.04349335198230193\n",
      "train_loss 0.4076204054945478 train_acc 0.8160884953216123\n",
      "epoch 1222 lr 0.043406452207079144\n",
      "train_loss 0.4076000890932327 train_acc 0.8161028242273137\n",
      "epoch 1223 lr 0.043319726057723044\n",
      "train_loss 0.40757972812990834 train_acc 0.8161028242273137\n",
      "epoch 1224 lr 0.04323317318732896\n",
      "train_loss 0.4075594166786858 train_acc 0.8161458109444182\n",
      "epoch 1225 lr 0.04314679324968525\n",
      "train_loss 0.40753917064179485 train_acc 0.8161601398501196\n",
      "epoch 1226 lr 0.04306058589927208\n",
      "train_loss 0.40751890311232875 train_acc 0.8161744687558211\n",
      "epoch 1227 lr 0.042974550791259905\n",
      "train_loss 0.4074984771851564 train_acc 0.816231784378627\n",
      "epoch 1228 lr 0.04288868758150821\n",
      "train_loss 0.40747811185067356 train_acc 0.8162461132843285\n",
      "epoch 1229 lr 0.042802995926564016\n",
      "train_loss 0.4074577703725275 train_acc 0.8162604421900299\n",
      "epoch 1230 lr 0.04271747548366061\n",
      "train_loss 0.4074374646549812 train_acc 0.8162604421900299\n",
      "epoch 1231 lr 0.042632125910716086\n",
      "train_loss 0.40741715390860195 train_acc 0.8162747710957314\n",
      "epoch 1232 lr 0.04254694686633206\n",
      "train_loss 0.4073968391460097 train_acc 0.8162891000014328\n",
      "epoch 1233 lr 0.042461938009792206\n",
      "train_loss 0.407376603984848 train_acc 0.8163034289071344\n",
      "epoch 1234 lr 0.04237709900106103\n",
      "train_loss 0.40735640700168707 train_acc 0.8162891000014328\n",
      "epoch 1235 lr 0.042292429500782346\n",
      "train_loss 0.4073362903028449 train_acc 0.8163607445299402\n",
      "epoch 1236 lr 0.04220792917027807\n",
      "train_loss 0.4073162622015327 train_acc 0.8163894023413432\n",
      "epoch 1237 lr 0.042123597671546734\n",
      "train_loss 0.40729629720178295 train_acc 0.8164037312470447\n",
      "epoch 1238 lr 0.04203943466726227\n",
      "train_loss 0.4072763548570505 train_acc 0.8163894023413432\n",
      "epoch 1239 lr 0.0419554398207725\n",
      "train_loss 0.4072563978076933 train_acc 0.8164037312470447\n",
      "epoch 1240 lr 0.04187161279609798\n",
      "train_loss 0.4072364724412262 train_acc 0.8164323890584476\n",
      "epoch 1241 lr 0.04178795325793045\n",
      "train_loss 0.40721646732024297 train_acc 0.8164610468698505\n",
      "epoch 1242 lr 0.041704460871631696\n",
      "train_loss 0.4071964986683405 train_acc 0.8164610468698505\n",
      "epoch 1243 lr 0.041621135303232006\n",
      "train_loss 0.4071765831670702 train_acc 0.8164897046812535\n",
      "epoch 1244 lr 0.04153797621942905\n",
      "train_loss 0.4071567802720451 train_acc 0.8164897046812535\n",
      "epoch 1245 lr 0.04145498328758633\n",
      "train_loss 0.4071369755349743 train_acc 0.8165183624926564\n",
      "epoch 1246 lr 0.04137215617573206\n",
      "train_loss 0.4071171597626816 train_acc 0.816504033586955\n",
      "epoch 1247 lr 0.041289494552557635\n",
      "train_loss 0.4070973687633843 train_acc 0.816504033586955\n",
      "epoch 1248 lr 0.041206998087416485\n",
      "train_loss 0.407077526149956 train_acc 0.8166043359268652\n",
      "epoch 1249 lr 0.04112466645032262\n",
      "train_loss 0.4070576500611171 train_acc 0.8166329937382683\n",
      "\n",
      "val loss = 0.4105230453306615, \n",
      "val acc = 0.8122501611863314\n",
      "\n",
      "epoch 1250 lr 0.0410424993119494\n",
      "train_loss 0.40703780155356056 train_acc 0.8167046382667755\n",
      "epoch 1251 lr 0.040960496343628146\n",
      "train_loss 0.4070180204361459 train_acc 0.8167332960781785\n",
      "epoch 1252 lr 0.040878657217346875\n",
      "train_loss 0.4069982649155787 train_acc 0.8167762827952829\n",
      "epoch 1253 lr 0.04079698160574899\n",
      "train_loss 0.4069785789388214 train_acc 0.8168192695123874\n",
      "epoch 1254 lr 0.040715469182131904\n",
      "train_loss 0.4069589214214686 train_acc 0.8168192695123874\n",
      "epoch 1255 lr 0.04063411962044585\n",
      "train_loss 0.40693920896882224 train_acc 0.8168335984180888\n",
      "epoch 1256 lr 0.04055293259529245\n",
      "train_loss 0.4069194549997917 train_acc 0.8167906117009844\n",
      "epoch 1257 lr 0.040471907781923507\n",
      "train_loss 0.4068997383048133 train_acc 0.8167619538895815\n",
      "epoch 1258 lr 0.04039104485623964\n",
      "train_loss 0.40688003804752954 train_acc 0.8167619538895815\n",
      "epoch 1259 lr 0.040310343494789076\n",
      "train_loss 0.4068603967385536 train_acc 0.8167762827952829\n",
      "epoch 1260 lr 0.04022980337476621\n",
      "train_loss 0.4068407825090856 train_acc 0.8167906117009844\n",
      "epoch 1261 lr 0.04014942417401051\n",
      "train_loss 0.40682119528141997 train_acc 0.8167762827952829\n",
      "epoch 1262 lr 0.04006920557100502\n",
      "train_loss 0.4068015858156983 train_acc 0.81674762498388\n",
      "epoch 1263 lr 0.039989147244875255\n",
      "train_loss 0.4067819818099123 train_acc 0.81674762498388\n",
      "epoch 1264 lr 0.03990924887538777\n",
      "train_loss 0.4067623087043302 train_acc 0.8167762827952829\n",
      "epoch 1265 lr 0.03982951014294902\n",
      "train_loss 0.4067426276883479 train_acc 0.8167762827952829\n",
      "epoch 1266 lr 0.03974993072860393\n",
      "train_loss 0.40672302082679146 train_acc 0.81674762498388\n",
      "epoch 1267 lr 0.03967051031403477\n",
      "train_loss 0.4067034389278277 train_acc 0.81674762498388\n",
      "epoch 1268 lr 0.03959124858155974\n",
      "train_loss 0.40668391403015797 train_acc 0.8167332960781785\n",
      "epoch 1269 lr 0.03951214521413184\n",
      "train_loss 0.4066644194000458 train_acc 0.8167332960781785\n",
      "epoch 1270 lr 0.03943319989533747\n",
      "train_loss 0.40664497488596535 train_acc 0.8167619538895815\n",
      "epoch 1271 lr 0.03935441230939527\n",
      "train_loss 0.4066255833089236 train_acc 0.8167332960781785\n",
      "epoch 1272 lr 0.03927578214115477\n",
      "train_loss 0.40660615726754173 train_acc 0.81674762498388\n",
      "epoch 1273 lr 0.03919730907609521\n",
      "train_loss 0.4065866662810981 train_acc 0.816718967172477\n",
      "epoch 1274 lr 0.03911899280032421\n",
      "train_loss 0.40656718506613493 train_acc 0.8167046382667755\n",
      "epoch 1275 lr 0.039040833000576584\n",
      "train_loss 0.4065476596469613 train_acc 0.8167332960781785\n",
      "epoch 1276 lr 0.03896282936421299\n",
      "train_loss 0.4065281823680811 train_acc 0.8167619538895815\n",
      "epoch 1277 lr 0.03888498157921883\n",
      "train_loss 0.4065087200840913 train_acc 0.8167906117009844\n",
      "epoch 1278 lr 0.03880728933420281\n",
      "train_loss 0.4064892846909951 train_acc 0.8168192695123874\n",
      "epoch 1279 lr 0.03872975231839589\n",
      "train_loss 0.40646984892266563 train_acc 0.8168479273237903\n",
      "epoch 1280 lr 0.03865237022164987\n",
      "train_loss 0.4064504064455672 train_acc 0.8168909140408946\n",
      "epoch 1281 lr 0.03857514273443629\n",
      "train_loss 0.40643102467862163 train_acc 0.8169052429465962\n",
      "epoch 1282 lr 0.03849806954784506\n",
      "train_loss 0.40641163763412314 train_acc 0.816962558569402\n",
      "epoch 1283 lr 0.038421150353583365\n",
      "train_loss 0.40639226295215064 train_acc 0.8170198741922079\n",
      "epoch 1284 lr 0.0383443848439743\n",
      "train_loss 0.40637291187417096 train_acc 0.8170055452865065\n",
      "epoch 1285 lr 0.03826777271195576\n",
      "train_loss 0.4063535339117973 train_acc 0.8170485320036109\n",
      "epoch 1286 lr 0.03819131365107906\n",
      "train_loss 0.40633428448065684 train_acc 0.8170628609093123\n",
      "epoch 1287 lr 0.038115007355507914\n",
      "train_loss 0.40631511728647457 train_acc 0.8170485320036109\n",
      "epoch 1288 lr 0.03803885352001699\n",
      "train_loss 0.40629591173929025 train_acc 0.8170771898150139\n",
      "epoch 1289 lr 0.03796285183999089\n",
      "train_loss 0.4062767256622372 train_acc 0.8170628609093123\n",
      "epoch 1290 lr 0.03788700201142274\n",
      "train_loss 0.40625761048326486 train_acc 0.8170771898150139\n",
      "epoch 1291 lr 0.03781130373091317\n",
      "train_loss 0.4062385464164903 train_acc 0.8171201765321182\n",
      "epoch 1292 lr 0.03773575669566892\n",
      "train_loss 0.406219452034325 train_acc 0.8171201765321182\n",
      "epoch 1293 lr 0.03766036060350179\n",
      "train_loss 0.4062003720444184 train_acc 0.8171631632492227\n",
      "epoch 1294 lr 0.03758511515282727\n",
      "train_loss 0.4061812755825826 train_acc 0.8171488343435211\n",
      "epoch 1295 lr 0.03751002004266348\n",
      "train_loss 0.4061622016412829 train_acc 0.8171631632492227\n",
      "epoch 1296 lr 0.03743507497262987\n",
      "train_loss 0.4061431701927294 train_acc 0.817263465589133\n",
      "epoch 1297 lr 0.03736027964294608\n",
      "train_loss 0.4061240927060868 train_acc 0.8172921234005359\n",
      "epoch 1298 lr 0.037285633754430655\n",
      "train_loss 0.40610501701483637 train_acc 0.817263465589133\n",
      "epoch 1299 lr 0.03721113700849998\n",
      "train_loss 0.4060860162844843 train_acc 0.8172777944948344\n",
      "\n",
      "val loss = 0.4098130201617709, \n",
      "val acc = 0.8136686009026435\n",
      "\n",
      "epoch 1300 lr 0.03713678910716693\n",
      "train_loss 0.40606700302929105 train_acc 0.8173064523062373\n",
      "epoch 1301 lr 0.03706258975303985\n",
      "train_loss 0.4060479783471231 train_acc 0.8172921234005359\n",
      "epoch 1302 lr 0.03698853864932118\n",
      "train_loss 0.4060290724159472 train_acc 0.8173351101176403\n",
      "epoch 1303 lr 0.03691463549980645\n",
      "train_loss 0.40601022477888543 train_acc 0.8172921234005359\n",
      "epoch 1304 lr 0.03684088000888291\n",
      "train_loss 0.4059914517047768 train_acc 0.8172921234005359\n",
      "epoch 1305 lr 0.03676727188152855\n",
      "train_loss 0.40597269322897367 train_acc 0.8172777944948344\n",
      "epoch 1306 lr 0.03669381082331072\n",
      "train_loss 0.40595399563127477 train_acc 0.8173064523062373\n",
      "epoch 1307 lr 0.03662049654038512\n",
      "train_loss 0.4059353670387996 train_acc 0.8172921234005359\n",
      "epoch 1308 lr 0.0365473287394945\n",
      "train_loss 0.4059167251336874 train_acc 0.817263465589133\n",
      "epoch 1309 lr 0.03647430712796758\n",
      "train_loss 0.40589810592914144 train_acc 0.81723480777773\n",
      "epoch 1310 lr 0.036401431413717794\n",
      "train_loss 0.40587960976047466 train_acc 0.8172491366834315\n",
      "epoch 1311 lr 0.036328701305242204\n",
      "train_loss 0.4058611053354577 train_acc 0.817263465589133\n",
      "epoch 1312 lr 0.036256116511620265\n",
      "train_loss 0.4058426044315796 train_acc 0.81723480777773\n",
      "epoch 1313 lr 0.03618367674251273\n",
      "train_loss 0.40582416844172414 train_acc 0.8172491366834315\n",
      "epoch 1314 lr 0.03611138170816039\n",
      "train_loss 0.4058057189238029 train_acc 0.8172921234005359\n",
      "epoch 1315 lr 0.03603923111938305\n",
      "train_loss 0.405787341282162 train_acc 0.8173064523062373\n",
      "epoch 1316 lr 0.03596722468757822\n",
      "train_loss 0.4057689859119469 train_acc 0.8173064523062373\n",
      "epoch 1317 lr 0.035895362124720116\n",
      "train_loss 0.40575064969712005 train_acc 0.8173064523062373\n",
      "epoch 1318 lr 0.035823643143358355\n",
      "train_loss 0.4057323850779068 train_acc 0.8173207812119389\n",
      "epoch 1319 lr 0.03575206745661695\n",
      "train_loss 0.40571411141065694 train_acc 0.8173494390233418\n",
      "epoch 1320 lr 0.03568063477819302\n",
      "train_loss 0.4056958750950764 train_acc 0.8173494390233418\n",
      "epoch 1321 lr 0.035609344822355796\n",
      "train_loss 0.40567760839086875 train_acc 0.8173637679290433\n",
      "epoch 1322 lr 0.035538197303945335\n",
      "train_loss 0.4056593305346525 train_acc 0.8173637679290433\n",
      "epoch 1323 lr 0.03546719193837148\n",
      "train_loss 0.40564107094498614 train_acc 0.8174067546461476\n",
      "epoch 1324 lr 0.03539632844161265\n",
      "train_loss 0.40562284316733677 train_acc 0.8174354124575506\n",
      "epoch 1325 lr 0.0353256065302148\n",
      "train_loss 0.4056046768945731 train_acc 0.8174497413632521\n",
      "epoch 1326 lr 0.03525502592129015\n",
      "train_loss 0.40558651354189346 train_acc 0.8174927280803566\n",
      "epoch 1327 lr 0.03518458633251621\n",
      "train_loss 0.4055684478001635 train_acc 0.8175213858917595\n",
      "epoch 1328 lr 0.03511428748213451\n",
      "train_loss 0.4055504047633159 train_acc 0.8174640702689535\n",
      "epoch 1329 lr 0.035044129088949556\n",
      "train_loss 0.4055323971456442 train_acc 0.8174497413632521\n",
      "epoch 1330 lr 0.03497411087232768\n",
      "train_loss 0.40551440531131305 train_acc 0.8174640702689535\n",
      "epoch 1331 lr 0.034904232552195935\n",
      "train_loss 0.40549653728970253 train_acc 0.817478399174655\n",
      "epoch 1332 lr 0.03483449384904092\n",
      "train_loss 0.4054787136319172 train_acc 0.8174927280803566\n",
      "epoch 1333 lr 0.034764894483907766\n",
      "train_loss 0.40546091252404437 train_acc 0.8174927280803566\n",
      "epoch 1334 lr 0.03469543417839889\n",
      "train_loss 0.40544304162478584 train_acc 0.817507056986058\n",
      "epoch 1335 lr 0.034626112654673\n",
      "train_loss 0.40542512144196163 train_acc 0.8175213858917595\n",
      "epoch 1336 lr 0.03455692963544388\n",
      "train_loss 0.4054072602382551 train_acc 0.8175500437031624\n",
      "epoch 1337 lr 0.03448788484397939\n",
      "train_loss 0.40538939728174916 train_acc 0.8175643726088638\n",
      "epoch 1338 lr 0.034418978004100244\n",
      "train_loss 0.40537150636818414 train_acc 0.8175643726088638\n",
      "epoch 1339 lr 0.03435020884017903\n",
      "train_loss 0.4053535508705301 train_acc 0.8175500437031624\n",
      "epoch 1340 lr 0.034281577077138956\n",
      "train_loss 0.40533560620759923 train_acc 0.8174927280803566\n",
      "epoch 1341 lr 0.034213082440452916\n",
      "train_loss 0.4053176382463961 train_acc 0.8175213858917595\n",
      "epoch 1342 lr 0.03414472465614224\n",
      "train_loss 0.405299679319082 train_acc 0.8175357147974609\n",
      "epoch 1343 lr 0.03407650345077572\n",
      "train_loss 0.40528168675158954 train_acc 0.8175643726088638\n",
      "epoch 1344 lr 0.03400841855146844\n",
      "train_loss 0.4052637158007693 train_acc 0.8175643726088638\n",
      "epoch 1345 lr 0.03394046968588072\n",
      "train_loss 0.4052457321798655 train_acc 0.8175213858917595\n",
      "epoch 1346 lr 0.03387265658221698\n",
      "train_loss 0.405227817021603 train_acc 0.8175787015145654\n",
      "epoch 1347 lr 0.03380497896922475\n",
      "train_loss 0.40520995231396395 train_acc 0.8176360171373712\n",
      "epoch 1348 lr 0.03373743657619345\n",
      "train_loss 0.4051920619840203 train_acc 0.8176646749487742\n",
      "epoch 1349 lr 0.03367002913295346\n",
      "train_loss 0.40517420815550065 train_acc 0.8176216882316697\n",
      "\n",
      "val loss = 0.4091432186265231, \n",
      "val acc = 0.8136686009026435\n",
      "\n",
      "epoch 1350 lr 0.03360275636987487\n",
      "train_loss 0.40515639934101 train_acc 0.8176216882316697\n",
      "epoch 1351 lr 0.033535618017866586\n",
      "train_loss 0.405138625680231 train_acc 0.8176073593259683\n",
      "epoch 1352 lr 0.033468613808375076\n",
      "train_loss 0.4051208229199564 train_acc 0.8176646749487742\n",
      "epoch 1353 lr 0.033401743473383434\n",
      "train_loss 0.4051029538465601 train_acc 0.8176790038544757\n",
      "epoch 1354 lr 0.033335006745410206\n",
      "train_loss 0.4050851608032651 train_acc 0.8176503460430727\n",
      "epoch 1355 lr 0.03326840335750843\n",
      "train_loss 0.4050674086921582 train_acc 0.8176646749487742\n",
      "epoch 1356 lr 0.033201933043264416\n",
      "train_loss 0.40504963339575295 train_acc 0.8177649772886845\n",
      "epoch 1357 lr 0.03313559553679686\n",
      "train_loss 0.405031847193702 train_acc 0.8178222929114903\n",
      "epoch 1358 lr 0.03306939057275562\n",
      "train_loss 0.40501407597944533 train_acc 0.8178509507228933\n",
      "epoch 1359 lr 0.03300331788632078\n",
      "train_loss 0.4049963467929224 train_acc 0.8178509507228933\n",
      "epoch 1360 lr 0.032937377213201474\n",
      "train_loss 0.4049786344337945 train_acc 0.8178796085342962\n",
      "epoch 1361 lr 0.03287156828963495\n",
      "train_loss 0.40496089968774024 train_acc 0.8178939374399977\n",
      "epoch 1362 lr 0.032805890852385396\n",
      "train_loss 0.40494311328270005 train_acc 0.8179225952514007\n",
      "epoch 1363 lr 0.032740344638743014\n",
      "train_loss 0.40492529418508794 train_acc 0.8179082663456991\n",
      "epoch 1364 lr 0.032674929386522826\n",
      "train_loss 0.4049075456168716 train_acc 0.8178796085342962\n",
      "epoch 1365 lr 0.03260964483406376\n",
      "train_loss 0.4048897697290466 train_acc 0.8179225952514007\n",
      "epoch 1366 lr 0.032544490720227505\n",
      "train_loss 0.40487193778655445 train_acc 0.8179512530628036\n",
      "epoch 1367 lr 0.032479466784397525\n",
      "train_loss 0.40485402572478413 train_acc 0.8179655819685051\n",
      "epoch 1368 lr 0.03241457276647798\n",
      "train_loss 0.4048361569312956 train_acc 0.8179655819685051\n",
      "epoch 1369 lr 0.032349808406892736\n",
      "train_loss 0.40481831176778593 train_acc 0.8179225952514007\n",
      "epoch 1370 lr 0.032285173446584235\n",
      "train_loss 0.4048004295776834 train_acc 0.8179512530628036\n",
      "epoch 1371 lr 0.03222066762701259\n",
      "train_loss 0.4047825664876655 train_acc 0.8179512530628036\n",
      "epoch 1372 lr 0.03215629069015439\n",
      "train_loss 0.40476473386688056 train_acc 0.817994239779908\n",
      "epoch 1373 lr 0.03209204237850184\n",
      "train_loss 0.4047469312384569 train_acc 0.818022897591311\n",
      "epoch 1374 lr 0.032027922435061584\n",
      "train_loss 0.40472918325718976 train_acc 0.8180658843084153\n",
      "epoch 1375 lr 0.031963930603353785\n",
      "train_loss 0.4047114439573836 train_acc 0.8180658843084153\n",
      "epoch 1376 lr 0.03190006662741102\n",
      "train_loss 0.4046936938067491 train_acc 0.8180802132141168\n",
      "epoch 1377 lr 0.03183633025177728\n",
      "train_loss 0.4046760089169117 train_acc 0.8180658843084153\n",
      "epoch 1378 lr 0.03177272122150701\n",
      "train_loss 0.40465836098703833 train_acc 0.818022897591311\n",
      "epoch 1379 lr 0.03170923928216398\n",
      "train_loss 0.40464076000681637 train_acc 0.8180945421198184\n",
      "epoch 1380 lr 0.031645884179820366\n",
      "train_loss 0.4046232279029524 train_acc 0.8181231999312213\n",
      "epoch 1381 lr 0.031582655661055656\n",
      "train_loss 0.40460577088496624 train_acc 0.8180802132141168\n",
      "epoch 1382 lr 0.031519553472955715\n",
      "train_loss 0.4045883046396337 train_acc 0.8180945421198184\n",
      "epoch 1383 lr 0.03145657736311167\n",
      "train_loss 0.4045708569102733 train_acc 0.8181375288369227\n",
      "epoch 1384 lr 0.031393727079619044\n",
      "train_loss 0.40455338296310445 train_acc 0.8181805155540272\n",
      "epoch 1385 lr 0.031331002371076576\n",
      "train_loss 0.40453595655245456 train_acc 0.8181948444597286\n",
      "epoch 1386 lr 0.031268402986585384\n",
      "train_loss 0.4045185807463442 train_acc 0.8181948444597286\n",
      "epoch 1387 lr 0.031205928675747813\n",
      "train_loss 0.4045012204425159 train_acc 0.8181948444597286\n",
      "epoch 1388 lr 0.031143579188666566\n",
      "train_loss 0.4044838740282237 train_acc 0.8181948444597286\n",
      "epoch 1389 lr 0.031081354275943586\n",
      "train_loss 0.4044665265194861 train_acc 0.8181518577426242\n",
      "epoch 1390 lr 0.031019253688679162\n",
      "train_loss 0.40444920373604676 train_acc 0.8181661866483256\n",
      "epoch 1391 lr 0.03095727717847084\n",
      "train_loss 0.40443191573180876 train_acc 0.8181231999312213\n",
      "epoch 1392 lr 0.030895424497412522\n",
      "train_loss 0.4044146383001517 train_acc 0.8181661866483256\n",
      "epoch 1393 lr 0.030833695398093375\n",
      "train_loss 0.40439735022934536 train_acc 0.8181518577426242\n",
      "epoch 1394 lr 0.030772089633596945\n",
      "train_loss 0.40438007514276286 train_acc 0.8181661866483256\n",
      "epoch 1395 lr 0.030710606957500067\n",
      "train_loss 0.40436278838527634 train_acc 0.8181375288369227\n",
      "epoch 1396 lr 0.030649247123871976\n",
      "train_loss 0.4043454629161544 train_acc 0.8181088710255198\n",
      "epoch 1397 lr 0.030588009887273237\n",
      "train_loss 0.4043281378170174 train_acc 0.8181518577426242\n",
      "epoch 1398 lr 0.03052689500275484\n",
      "train_loss 0.40431085779930637 train_acc 0.8181805155540272\n",
      "epoch 1399 lr 0.030465902225857145\n",
      "train_loss 0.4042936503255523 train_acc 0.8181805155540272\n",
      "\n",
      "val loss = 0.40847147036531256, \n",
      "val acc = 0.8143133462282398\n",
      "\n",
      "epoch 1400 lr 0.03040503131260899\n",
      "train_loss 0.4042763913271002 train_acc 0.8181661866483256\n",
      "epoch 1401 lr 0.03034428201952661\n",
      "train_loss 0.4042590843573772 train_acc 0.8181518577426242\n",
      "epoch 1402 lr 0.03028365410361278\n",
      "train_loss 0.4042417078755528 train_acc 0.8181518577426242\n",
      "epoch 1403 lr 0.03022314732235573\n",
      "train_loss 0.4042243374936496 train_acc 0.8181375288369227\n",
      "epoch 1404 lr 0.030162761433728282\n",
      "train_loss 0.4042069848634162 train_acc 0.8181661866483256\n",
      "epoch 1405 lr 0.03010249619618677\n",
      "train_loss 0.40418965301601506 train_acc 0.8181375288369227\n",
      "epoch 1406 lr 0.030042351368670197\n",
      "train_loss 0.40417234531226914 train_acc 0.8181518577426242\n",
      "epoch 1407 lr 0.02998232671059914\n",
      "train_loss 0.4041550851729824 train_acc 0.8181948444597286\n",
      "epoch 1408 lr 0.02992242198187491\n",
      "train_loss 0.40413784321003066 train_acc 0.8181948444597286\n",
      "epoch 1409 lr 0.029862636942878495\n",
      "train_loss 0.4041205999471516 train_acc 0.8181661866483256\n",
      "epoch 1410 lr 0.029802971354469684\n",
      "train_loss 0.40410335775908407 train_acc 0.8181948444597286\n",
      "epoch 1411 lr 0.029743424977986013\n",
      "train_loss 0.4040861426010782 train_acc 0.8181805155540272\n",
      "epoch 1412 lr 0.029683997575241924\n",
      "train_loss 0.4040689794155697 train_acc 0.8182235022711316\n",
      "epoch 1413 lr 0.0296246889085277\n",
      "train_loss 0.404051740484729 train_acc 0.818237831176833\n",
      "epoch 1414 lr 0.029565498740608626\n",
      "train_loss 0.40403447587095226 train_acc 0.818237831176833\n",
      "epoch 1415 lr 0.02950642683472392\n",
      "train_loss 0.40401719514357004 train_acc 0.818266488988236\n",
      "epoch 1416 lr 0.02944747295458591\n",
      "train_loss 0.40399992522018857 train_acc 0.8183238046110418\n",
      "epoch 1417 lr 0.029388636864378967\n",
      "train_loss 0.4039826495946458 train_acc 0.8183094757053404\n",
      "epoch 1418 lr 0.02932991832875868\n",
      "train_loss 0.40396529874542947 train_acc 0.8183238046110418\n",
      "epoch 1419 lr 0.0292713171128508\n",
      "train_loss 0.4039479280057113 train_acc 0.8183524624224447\n",
      "epoch 1420 lr 0.029212832982250414\n",
      "train_loss 0.4039305593732617 train_acc 0.8183524624224447\n",
      "epoch 1421 lr 0.029154465703020896\n",
      "train_loss 0.40391318730082265 train_acc 0.8183954491395492\n",
      "epoch 1422 lr 0.029096215041693074\n",
      "train_loss 0.4038957899871257 train_acc 0.8183954491395492\n",
      "epoch 1423 lr 0.0290380807652642\n",
      "train_loss 0.40387829722227314 train_acc 0.8184527647623551\n",
      "epoch 1424 lr 0.028980062641197117\n",
      "train_loss 0.4038608135353315 train_acc 0.8184957514794595\n",
      "epoch 1425 lr 0.028922160437419228\n",
      "train_loss 0.403843334148681 train_acc 0.8185100803851609\n",
      "epoch 1426 lr 0.028864373922321666\n",
      "train_loss 0.40382590503577925 train_acc 0.818481422573758\n",
      "epoch 1427 lr 0.02880670286475826\n",
      "train_loss 0.4038084946985761 train_acc 0.818538738196564\n",
      "epoch 1428 lr 0.028749147034044742\n",
      "train_loss 0.4037911027653843 train_acc 0.8185817249136683\n",
      "epoch 1429 lr 0.028691706199957676\n",
      "train_loss 0.4037737313109923 train_acc 0.8186247116307728\n",
      "epoch 1430 lr 0.02863438013273368\n",
      "train_loss 0.403756394559529 train_acc 0.8186103827250713\n",
      "epoch 1431 lr 0.02857716860306838\n",
      "train_loss 0.40373908183916074 train_acc 0.8186103827250713\n",
      "epoch 1432 lr 0.028520071382115608\n",
      "train_loss 0.4037217772989076 train_acc 0.8185960538193698\n",
      "epoch 1433 lr 0.028463088241486377\n",
      "train_loss 0.4037044952045458 train_acc 0.8186247116307728\n",
      "epoch 1434 lr 0.028406218953248078\n",
      "train_loss 0.4036873174161033 train_acc 0.8186390405364742\n",
      "epoch 1435 lr 0.02834946328992345\n",
      "train_loss 0.4036701519801114 train_acc 0.8186820272535786\n",
      "epoch 1436 lr 0.0282928210244898\n",
      "train_loss 0.403653049718399 train_acc 0.8187106850649816\n",
      "epoch 1437 lr 0.028236291930377955\n",
      "train_loss 0.4036359748674259 train_acc 0.8187106850649816\n",
      "epoch 1438 lr 0.028179875781471495\n",
      "train_loss 0.40361893175290076 train_acc 0.8187393428763845\n",
      "epoch 1439 lr 0.02812357235210572\n",
      "train_loss 0.4036019114652779 train_acc 0.8187250139706831\n",
      "epoch 1440 lr 0.028067381417066863\n",
      "train_loss 0.40358494387121363 train_acc 0.8186963561592802\n",
      "epoch 1441 lr 0.028011302751591086\n",
      "train_loss 0.4035679898903768 train_acc 0.8187106850649816\n",
      "epoch 1442 lr 0.027955336131363678\n",
      "train_loss 0.40355107487422703 train_acc 0.818753671782086\n",
      "epoch 1443 lr 0.027899481332518055\n",
      "train_loss 0.40353419204290225 train_acc 0.818753671782086\n",
      "epoch 1444 lr 0.027843738131634974\n",
      "train_loss 0.4035173835375417 train_acc 0.818753671782086\n",
      "epoch 1445 lr 0.02778810630574153\n",
      "train_loss 0.4035005702435974 train_acc 0.818782329593489\n",
      "epoch 1446 lr 0.027732585632310375\n",
      "train_loss 0.4034837480670563 train_acc 0.8187966584991904\n",
      "epoch 1447 lr 0.027677175889258714\n",
      "train_loss 0.40346693081392127 train_acc 0.8188109874048919\n",
      "epoch 1448 lr 0.027621876854947523\n",
      "train_loss 0.40345014883832453 train_acc 0.8188109874048919\n",
      "epoch 1449 lr 0.02756668830818057\n",
      "train_loss 0.40343342187580084 train_acc 0.8187966584991904\n",
      "\n",
      "val loss = 0.4078015204542142, \n",
      "val acc = 0.8135396518375242\n",
      "\n",
      "epoch 1450 lr 0.027511610028203615\n",
      "train_loss 0.40341673489296687 train_acc 0.8187966584991904\n",
      "epoch 1451 lr 0.027456641794703446\n",
      "train_loss 0.40340008020471724 train_acc 0.8187966584991904\n",
      "epoch 1452 lr 0.027401783387807077\n",
      "train_loss 0.4033834000488408 train_acc 0.818782329593489\n",
      "epoch 1453 lr 0.02734703458808078\n",
      "train_loss 0.4033667747762628 train_acc 0.8187680006877874\n",
      "epoch 1454 lr 0.027292395176529313\n",
      "train_loss 0.4033502103354366 train_acc 0.8187250139706831\n",
      "epoch 1455 lr 0.02723786493459493\n",
      "train_loss 0.4033336238915084 train_acc 0.818753671782086\n",
      "epoch 1456 lr 0.02718344364415661\n",
      "train_loss 0.403317059878789 train_acc 0.818782329593489\n",
      "epoch 1457 lr 0.027129131087529103\n",
      "train_loss 0.40330050906952664 train_acc 0.8187680006877874\n",
      "epoch 1458 lr 0.02707492704746213\n",
      "train_loss 0.4032839726005387 train_acc 0.8187966584991904\n",
      "epoch 1459 lr 0.027020831307139434\n",
      "train_loss 0.40326742872735355 train_acc 0.8188253163105934\n",
      "epoch 1460 lr 0.02696684365017801\n",
      "train_loss 0.4032508458720762 train_acc 0.8188683030276978\n",
      "epoch 1461 lr 0.026912963860627127\n",
      "train_loss 0.40323426872265755 train_acc 0.8188826319333993\n",
      "epoch 1462 lr 0.026859191722967583\n",
      "train_loss 0.4032176893138097 train_acc 0.8188539741219963\n",
      "epoch 1463 lr 0.02680552702211073\n",
      "train_loss 0.4032011760150002 train_acc 0.8188396452162948\n",
      "epoch 1464 lr 0.02675196954339772\n",
      "train_loss 0.40318469952873287 train_acc 0.8188539741219963\n",
      "epoch 1465 lr 0.02669851907259854\n",
      "train_loss 0.40316824003928614 train_acc 0.8189256186505036\n",
      "epoch 1466 lr 0.02664517539591126\n",
      "train_loss 0.40315183207721345 train_acc 0.8189542764619065\n",
      "epoch 1467 lr 0.02659193829996108\n",
      "train_loss 0.4031354424405491 train_acc 0.8189686053676081\n",
      "epoch 1468 lr 0.026538807571799567\n",
      "train_loss 0.40311908304563915 train_acc 0.8188969608391007\n",
      "epoch 1469 lr 0.026485782998903713\n",
      "train_loss 0.40310273489352505 train_acc 0.8189256186505036\n",
      "epoch 1470 lr 0.02643286436917518\n",
      "train_loss 0.4030864206499844 train_acc 0.8189399475562051\n",
      "epoch 1471 lr 0.02638005147093936\n",
      "train_loss 0.40307010694967116 train_acc 0.8189542764619065\n",
      "epoch 1472 lr 0.026327344092944606\n",
      "train_loss 0.403053814568798 train_acc 0.8189399475562051\n",
      "epoch 1473 lr 0.02627474202436132\n",
      "train_loss 0.40303761427936163 train_acc 0.8189542764619065\n",
      "epoch 1474 lr 0.02622224505478117\n",
      "train_loss 0.4030214764800726 train_acc 0.8190115920847125\n",
      "epoch 1475 lr 0.02616985297421619\n",
      "train_loss 0.4030053713138274 train_acc 0.8190115920847125\n",
      "epoch 1476 lr 0.026117565573098016\n",
      "train_loss 0.40298930080139994 train_acc 0.818997263179011\n",
      "epoch 1477 lr 0.026065382642276945\n",
      "train_loss 0.40297323532229495 train_acc 0.818997263179011\n",
      "epoch 1478 lr 0.026013303973021207\n",
      "train_loss 0.4029571485073615 train_acc 0.8190259209904139\n",
      "epoch 1479 lr 0.025961329357016033\n",
      "train_loss 0.4029410973208189 train_acc 0.8189829342733096\n",
      "epoch 1480 lr 0.025909458586362916\n",
      "train_loss 0.4029251029872744 train_acc 0.8190402498961155\n",
      "epoch 1481 lr 0.02585769145357868\n",
      "train_loss 0.4029091003206226 train_acc 0.8190975655189213\n",
      "epoch 1482 lr 0.025806027751594744\n",
      "train_loss 0.40289311708309933 train_acc 0.8191118944246228\n",
      "epoch 1483 lr 0.025754467273756212\n",
      "train_loss 0.4028771229559641 train_acc 0.8191548811417272\n",
      "epoch 1484 lr 0.025703009813821127\n",
      "train_loss 0.4028611421131242 train_acc 0.8191548811417272\n",
      "epoch 1485 lr 0.025651655165959554\n",
      "train_loss 0.40284514063249066 train_acc 0.8191548811417272\n",
      "epoch 1486 lr 0.02560040312475286\n",
      "train_loss 0.40282915907225286 train_acc 0.8190975655189213\n",
      "epoch 1487 lr 0.02554925348519279\n",
      "train_loss 0.4028131501247956 train_acc 0.8190832366132198\n",
      "epoch 1488 lr 0.025498206042680733\n",
      "train_loss 0.4027971461993159 train_acc 0.8190832366132198\n",
      "epoch 1489 lr 0.025447260593026835\n",
      "train_loss 0.4027811672894618 train_acc 0.8190975655189213\n",
      "epoch 1490 lr 0.02539641693244925\n",
      "train_loss 0.4027651953033578 train_acc 0.8190975655189213\n",
      "epoch 1491 lr 0.025345674857573247\n",
      "train_loss 0.4027492234078463 train_acc 0.8191548811417272\n",
      "epoch 1492 lr 0.02529503416543048\n",
      "train_loss 0.40273328981936357 train_acc 0.8191262233303243\n",
      "epoch 1493 lr 0.025244494653458086\n",
      "train_loss 0.40271737859094 train_acc 0.8191262233303243\n",
      "epoch 1494 lr 0.02519405611949798\n",
      "train_loss 0.40270147324824934 train_acc 0.8191692100474287\n",
      "epoch 1495 lr 0.025143718361795932\n",
      "train_loss 0.4026856033878584 train_acc 0.8191692100474287\n",
      "epoch 1496 lr 0.025093481179000867\n",
      "train_loss 0.40266976332890947 train_acc 0.8191405522360258\n",
      "epoch 1497 lr 0.025043344370163964\n",
      "train_loss 0.4026539782835837 train_acc 0.8191262233303243\n",
      "epoch 1498 lr 0.024993307734737943\n",
      "train_loss 0.4026382273572193 train_acc 0.8191262233303243\n",
      "epoch 1499 lr 0.024943371072576177\n",
      "train_loss 0.4026224774552375 train_acc 0.8191548811417272\n",
      "\n",
      "val loss = 0.40717598188629406, \n",
      "val acc = 0.8135396518375242\n",
      "\n",
      "epoch 1500 lr 0.02489353418393197\n",
      "train_loss 0.4026067224797829 train_acc 0.8191978678588316\n",
      "\n",
      "-----training done-----\n",
      "\n",
      "model1 training took 23.09 minutes\n",
      "-----model2 training-----\n",
      "\n",
      "epoch 1 lr 0.4990009993336666\n",
      "train_loss 0.6930908922457573 train_acc 0.5195288567577503\n",
      "epoch 2 lr 0.4980039946719958\n",
      "train_loss 0.6925391143083857 train_acc 0.5519084670996202\n",
      "epoch 3 lr 0.4970089820269677\n",
      "train_loss 0.6920411160134436 train_acc 0.5526283543683372\n",
      "epoch 4 lr 0.49601595741853033\n",
      "train_loss 0.6915916373715647 train_acc 0.5526283543683372\n",
      "epoch 5 lr 0.49502491687458405\n",
      "train_loss 0.6911858956075625 train_acc 0.5526283543683372\n",
      "epoch 6 lr 0.4940358564309653\n",
      "train_loss 0.6908194963072005 train_acc 0.5526283543683372\n",
      "epoch 7 lr 0.493048772131431\n",
      "train_loss 0.6904885397212407 train_acc 0.5526283543683372\n",
      "epoch 8 lr 0.49206366002764257\n",
      "train_loss 0.6901894491753017 train_acc 0.5526283543683372\n",
      "epoch 9 lr 0.4910805161791504\n",
      "train_loss 0.6899190002647759 train_acc 0.5526283543683372\n",
      "epoch 10 lr 0.4900993366533777\n",
      "train_loss 0.689674373599258 train_acc 0.5526283543683372\n",
      "epoch 11 lr 0.4891201175256051\n",
      "train_loss 0.6894529910840713 train_acc 0.5526283543683372\n",
      "epoch 12 lr 0.4881428548789547\n",
      "train_loss 0.6892525642412745 train_acc 0.5526283543683372\n",
      "epoch 13 lr 0.4871675448043747\n",
      "train_loss 0.6890710914833181 train_acc 0.5526283543683372\n",
      "epoch 14 lr 0.4861941834006235\n",
      "train_loss 0.6889066656275291 train_acc 0.5526283543683372\n",
      "epoch 15 lr 0.48522276677425413\n",
      "train_loss 0.6887574835812693 train_acc 0.5526283543683372\n",
      "epoch 16 lr 0.4842532910395988\n",
      "train_loss 0.6886221404932064 train_acc 0.5526283543683372\n",
      "epoch 17 lr 0.48328575231875337\n",
      "train_loss 0.6884992390348695 train_acc 0.5526283543683372\n",
      "epoch 18 lr 0.48232014674156154\n",
      "train_loss 0.688387501619748 train_acc 0.5526283543683372\n",
      "epoch 19 lr 0.4813564704455998\n",
      "train_loss 0.688285862512239 train_acc 0.5526283543683372\n",
      "epoch 20 lr 0.48039471957616164\n",
      "train_loss 0.6881932522119619 train_acc 0.5526283543683372\n",
      "epoch 21 lr 0.4794348902862423\n",
      "train_loss 0.6881087862116321 train_acc 0.5526283543683372\n",
      "epoch 22 lr 0.47847697873652334\n",
      "train_loss 0.6880316408990409 train_acc 0.5526283543683372\n",
      "epoch 23 lr 0.47752098109535734\n",
      "train_loss 0.6879611298546926 train_acc 0.5526283543683372\n",
      "epoch 24 lr 0.47656689353875237\n",
      "train_loss 0.6878965545222093 train_acc 0.5526283543683372\n",
      "epoch 25 lr 0.475614712250357\n",
      "train_loss 0.687837319169504 train_acc 0.5526283543683372\n",
      "epoch 26 lr 0.47466443342144476\n",
      "train_loss 0.687782931111367 train_acc 0.5526283543683372\n",
      "epoch 27 lr 0.47371605325089916\n",
      "train_loss 0.687732907228446 train_acc 0.5526283543683372\n",
      "epoch 28 lr 0.47276956794519814\n",
      "train_loss 0.6876867674479004 train_acc 0.5526283543683372\n",
      "epoch 29 lr 0.47182497371839927\n",
      "train_loss 0.6876441069641795 train_acc 0.5526283543683372\n",
      "epoch 30 lr 0.47088226679212436\n",
      "train_loss 0.6876046008168962 train_acc 0.5526283543683372\n",
      "epoch 31 lr 0.46994144339554444\n",
      "train_loss 0.6875679166121086 train_acc 0.5526283543683372\n",
      "epoch 32 lr 0.46900249976536473\n",
      "train_loss 0.6875337336414068 train_acc 0.5526283543683372\n",
      "epoch 33 lr 0.4680654321458094\n",
      "train_loss 0.6875018064941347 train_acc 0.5526283543683372\n",
      "epoch 34 lr 0.46713023678860677\n",
      "train_loss 0.687471914194963 train_acc 0.5526283543683372\n",
      "epoch 35 lr 0.46619690995297414\n",
      "train_loss 0.6874438273319652 train_acc 0.5526283543683372\n",
      "epoch 36 lr 0.46526544790560287\n",
      "train_loss 0.6874173882643682 train_acc 0.5526283543683372\n",
      "epoch 37 lr 0.4643358469206436\n",
      "train_loss 0.6873924378567334 train_acc 0.5526283543683372\n",
      "epoch 38 lr 0.4634081032796911\n",
      "train_loss 0.6873687947011442 train_acc 0.5526283543683372\n",
      "epoch 39 lr 0.46248221327176964\n",
      "train_loss 0.6873463198740603 train_acc 0.5526283543683372\n",
      "epoch 40 lr 0.4615581731933179\n",
      "train_loss 0.6873248549771025 train_acc 0.5526283543683372\n",
      "epoch 41 lr 0.4606359793481743\n",
      "train_loss 0.687304316527137 train_acc 0.5526283543683372\n",
      "epoch 42 lr 0.45971562804756233\n",
      "train_loss 0.6872846147252963 train_acc 0.5526283543683372\n",
      "epoch 43 lr 0.45879711561007547\n",
      "train_loss 0.6872656682745276 train_acc 0.5526283543683372\n",
      "epoch 44 lr 0.4578804383616628\n",
      "train_loss 0.6872473706117437 train_acc 0.5526283543683372\n",
      "epoch 45 lr 0.4569655926356141\n",
      "train_loss 0.6872296181650892 train_acc 0.5526283543683372\n",
      "epoch 46 lr 0.45605257477254524\n",
      "train_loss 0.687212332660756 train_acc 0.5526283543683372\n",
      "epoch 47 lr 0.4551413811203835\n",
      "train_loss 0.687195458257355 train_acc 0.5526283543683372\n",
      "epoch 48 lr 0.4542320080343531\n",
      "train_loss 0.6871789552802888 train_acc 0.5526283543683372\n",
      "epoch 49 lr 0.45332445187696047\n",
      "train_loss 0.687162796829957 train_acc 0.5526283543683372\n",
      "\n",
      "val loss = 0.6874317774226547, \n",
      "val acc = 0.5510682288077188\n",
      "\n",
      "epoch 50 lr 0.45241870901797976\n",
      "train_loss 0.6871469108035704 train_acc 0.5526283543683372\n",
      "epoch 51 lr 0.4515147758344384\n",
      "train_loss 0.6871312721147709 train_acc 0.5526283543683372\n",
      "epoch 52 lr 0.4506126487106024\n",
      "train_loss 0.6871158260421154 train_acc 0.5526283543683372\n",
      "epoch 53 lr 0.449712324037962\n",
      "train_loss 0.687100528484791 train_acc 0.5526283543683372\n",
      "epoch 54 lr 0.44881379821521744\n",
      "train_loss 0.6870853632191624 train_acc 0.5526283543683372\n",
      "epoch 55 lr 0.4479170676482641\n",
      "train_loss 0.6870703049751293 train_acc 0.5526283543683372\n",
      "epoch 56 lr 0.4470221287501786\n",
      "train_loss 0.6870553158407218 train_acc 0.5526283543683372\n",
      "epoch 57 lr 0.44612897794120415\n",
      "train_loss 0.6870403774812207 train_acc 0.5526283543683372\n",
      "epoch 58 lr 0.44523761164873626\n",
      "train_loss 0.6870254755675647 train_acc 0.5526283543683372\n",
      "epoch 59 lr 0.4443480263073087\n",
      "train_loss 0.6870105842860589 train_acc 0.5526283543683372\n",
      "epoch 60 lr 0.44346021835857874\n",
      "train_loss 0.6869956810811028 train_acc 0.5526283543683372\n",
      "epoch 61 lr 0.44257418425131356\n",
      "train_loss 0.6869807352568993 train_acc 0.5526283543683372\n",
      "epoch 62 lr 0.44168992044137545\n",
      "train_loss 0.6869657578636678 train_acc 0.5526283543683372\n",
      "epoch 63 lr 0.44080742339170803\n",
      "train_loss 0.6869507066140478 train_acc 0.5526283543683372\n",
      "epoch 64 lr 0.4399266895723219\n",
      "train_loss 0.6869355721957782 train_acc 0.5526283543683372\n",
      "epoch 65 lr 0.43904771546028065\n",
      "train_loss 0.6869203502838981 train_acc 0.5526283543683372\n",
      "epoch 66 lr 0.4381704975396867\n",
      "train_loss 0.6869049997697648 train_acc 0.5526283543683372\n",
      "epoch 67 lr 0.437295032301667\n",
      "train_loss 0.6868895373278121 train_acc 0.5526283543683372\n",
      "epoch 68 lr 0.43642131624435965\n",
      "train_loss 0.686873949122825 train_acc 0.5526283543683372\n",
      "epoch 69 lr 0.4355493458728992\n",
      "train_loss 0.6868582289536997 train_acc 0.5526283543683372\n",
      "epoch 70 lr 0.4346791176994029\n",
      "train_loss 0.6868423517191213 train_acc 0.5526283543683372\n",
      "epoch 71 lr 0.433810628242957\n",
      "train_loss 0.6868263026812419 train_acc 0.5526283543683372\n",
      "epoch 72 lr 0.4329438740296025\n",
      "train_loss 0.6868100719073642 train_acc 0.5526283543683372\n",
      "epoch 73 lr 0.43207885159232134\n",
      "train_loss 0.6867936539130285 train_acc 0.5526283543683372\n",
      "epoch 74 lr 0.4312155574710227\n",
      "train_loss 0.6867770615914457 train_acc 0.5526283543683372\n",
      "epoch 75 lr 0.4303539882125289\n",
      "train_loss 0.6867602752007517 train_acc 0.5526283543683372\n",
      "epoch 76 lr 0.4294941403705617\n",
      "train_loss 0.6867432725564407 train_acc 0.5526283543683372\n",
      "epoch 77 lr 0.4286360105057287\n",
      "train_loss 0.6867260470778191 train_acc 0.5526283543683372\n",
      "epoch 78 lr 0.42777959518550923\n",
      "train_loss 0.6867086048893257 train_acc 0.5526283543683372\n",
      "epoch 79 lr 0.42692489098424086\n",
      "train_loss 0.6866909054922926 train_acc 0.5526283543683372\n",
      "epoch 80 lr 0.4260718944831057\n",
      "train_loss 0.6866729598365057 train_acc 0.5526283543683372\n",
      "epoch 81 lr 0.4252206022701165\n",
      "train_loss 0.6866547536498778 train_acc 0.5526283543683372\n",
      "epoch 82 lr 0.4243710109401033\n",
      "train_loss 0.6866362843203438 train_acc 0.5526283543683372\n",
      "epoch 83 lr 0.4235231170946998\n",
      "train_loss 0.6866175381494236 train_acc 0.5526283543683372\n",
      "epoch 84 lr 0.4226769173423293\n",
      "train_loss 0.6865985008922786 train_acc 0.5526283543683372\n",
      "epoch 85 lr 0.4218324082981918\n",
      "train_loss 0.686579154374337 train_acc 0.5526283543683372\n",
      "epoch 86 lr 0.42098958658424995\n",
      "train_loss 0.6865594952486008 train_acc 0.5526283543683372\n",
      "epoch 87 lr 0.4201484488292157\n",
      "train_loss 0.6865395268521364 train_acc 0.5526283543683372\n",
      "epoch 88 lr 0.419308991668537\n",
      "train_loss 0.6865192409855533 train_acc 0.5526283543683372\n",
      "epoch 89 lr 0.41847121174438406\n",
      "train_loss 0.6864986255438263 train_acc 0.5526283543683372\n",
      "epoch 90 lr 0.417635105705636\n",
      "train_loss 0.6864776621741336 train_acc 0.5526283543683372\n",
      "epoch 91 lr 0.41680067020786765\n",
      "train_loss 0.6864563475489972 train_acc 0.5526283543683372\n",
      "epoch 92 lr 0.4159679019133359\n",
      "train_loss 0.6864346920088317 train_acc 0.5526283543683372\n",
      "epoch 93 lr 0.4151367974909663\n",
      "train_loss 0.6864126769439445 train_acc 0.5526283543683372\n",
      "epoch 94 lr 0.4143073536163403\n",
      "train_loss 0.686390295792599 train_acc 0.5526283543683372\n",
      "epoch 95 lr 0.41347956697168115\n",
      "train_loss 0.6863675334784823 train_acc 0.5526283543683372\n",
      "epoch 96 lr 0.4126534342458412\n",
      "train_loss 0.6863443802837456 train_acc 0.5526283543683372\n",
      "epoch 97 lr 0.41182895213428844\n",
      "train_loss 0.6863208114343514 train_acc 0.5526283543683372\n",
      "epoch 98 lr 0.41100611733909326\n",
      "train_loss 0.6862968127255322 train_acc 0.5526283543683372\n",
      "epoch 99 lr 0.41018492656891553\n",
      "train_loss 0.6862723778584487 train_acc 0.5526283543683372\n",
      "\n",
      "val loss = 0.6865668801823791, \n",
      "val acc = 0.5510682288077188\n",
      "\n",
      "epoch 100 lr 0.4093653765389909\n",
      "train_loss 0.686247496640808 train_acc 0.5526283543683372\n",
      "epoch 101 lr 0.4085474639711183\n",
      "train_loss 0.6862221503749933 train_acc 0.5526283543683372\n",
      "epoch 102 lr 0.40773118559364635\n",
      "train_loss 0.6861963416696121 train_acc 0.5526283543683372\n",
      "epoch 103 lr 0.40691653814146034\n",
      "train_loss 0.6861700328974338 train_acc 0.5526283543683372\n",
      "epoch 104 lr 0.40610351835596953\n",
      "train_loss 0.6861432209278181 train_acc 0.5526283543683372\n",
      "epoch 105 lr 0.40529212298509354\n",
      "train_loss 0.6861158893480778 train_acc 0.5526283543683372\n",
      "epoch 106 lr 0.4044823487832499\n",
      "train_loss 0.6860880561125596 train_acc 0.5526283543683372\n",
      "epoch 107 lr 0.40367419251134073\n",
      "train_loss 0.6860597010038724 train_acc 0.5526283543683372\n",
      "epoch 108 lr 0.4028676509367398\n",
      "train_loss 0.6860308007412639 train_acc 0.5526283543683372\n",
      "epoch 109 lr 0.4020627208332798\n",
      "train_loss 0.6860013250015464 train_acc 0.5526283543683372\n",
      "epoch 110 lr 0.40125939898123925\n",
      "train_loss 0.6859712973787278 train_acc 0.5526283543683372\n",
      "epoch 111 lr 0.4004576821673296\n",
      "train_loss 0.6859407016007066 train_acc 0.5526283543683372\n",
      "epoch 112 lr 0.39965756718468254\n",
      "train_loss 0.6859095077379531 train_acc 0.5526283543683372\n",
      "epoch 113 lr 0.3988590508328371\n",
      "train_loss 0.6858777257303064 train_acc 0.5526283543683372\n",
      "epoch 114 lr 0.3980621299177268\n",
      "train_loss 0.6858452968533276 train_acc 0.5526283543683372\n",
      "epoch 115 lr 0.39726680125166697\n",
      "train_loss 0.6858122301119499 train_acc 0.5526283543683372\n",
      "epoch 116 lr 0.39647306165334184\n",
      "train_loss 0.685778526609195 train_acc 0.5526283543683372\n",
      "epoch 117 lr 0.3956809079477919\n",
      "train_loss 0.6857441915992742 train_acc 0.5526283543683372\n",
      "epoch 118 lr 0.39489033696640136\n",
      "train_loss 0.6857091685398717 train_acc 0.5526283543683372\n",
      "epoch 119 lr 0.3941013455468852\n",
      "train_loss 0.6856734681924497 train_acc 0.5526283543683372\n",
      "epoch 120 lr 0.3933139305332767\n",
      "train_loss 0.6856370658950216 train_acc 0.5526283543683372\n",
      "epoch 121 lr 0.3925280887759147\n",
      "train_loss 0.6855999430012197 train_acc 0.5526283543683372\n",
      "epoch 122 lr 0.39174381713143125\n",
      "train_loss 0.6855621096200714 train_acc 0.5526283543683372\n",
      "epoch 123 lr 0.3909611124627386\n",
      "train_loss 0.685523541148864 train_acc 0.5526283543683372\n",
      "epoch 124 lr 0.39017997163901713\n",
      "train_loss 0.6854842365429624 train_acc 0.5526283543683372\n",
      "epoch 125 lr 0.38940039153570244\n",
      "train_loss 0.6854442134010021 train_acc 0.5526283543683372\n",
      "epoch 126 lr 0.38862236903447306\n",
      "train_loss 0.6854034141615659 train_acc 0.5526283543683372\n",
      "epoch 127 lr 0.387845901023238\n",
      "train_loss 0.6853617963046531 train_acc 0.5526283543683372\n",
      "epoch 128 lr 0.38707098439612414\n",
      "train_loss 0.6853193505372697 train_acc 0.5526283543683372\n",
      "epoch 129 lr 0.386297616053464\n",
      "train_loss 0.6852760281680105 train_acc 0.5526283543683372\n",
      "epoch 130 lr 0.3855257929017831\n",
      "train_loss 0.6852318413968713 train_acc 0.5526283543683372\n",
      "epoch 131 lr 0.3847555118537879\n",
      "train_loss 0.6851867431744492 train_acc 0.5526283543683372\n",
      "epoch 132 lr 0.3839867698283531\n",
      "train_loss 0.6851406718248451 train_acc 0.5526283543683372\n",
      "epoch 133 lr 0.3832195637505096\n",
      "train_loss 0.6850936227118669 train_acc 0.5526283543683372\n",
      "epoch 134 lr 0.38245389055143203\n",
      "train_loss 0.685045608782375 train_acc 0.5526283543683372\n",
      "epoch 135 lr 0.3816897471684266\n",
      "train_loss 0.6849966073811641 train_acc 0.5526283543683372\n",
      "epoch 136 lr 0.3809271305449188\n",
      "train_loss 0.6849466023957628 train_acc 0.5526283543683372\n",
      "epoch 137 lr 0.38016603763044104\n",
      "train_loss 0.684895597175019 train_acc 0.5526283543683372\n",
      "epoch 138 lr 0.3794064653806207\n",
      "train_loss 0.6848435272689983 train_acc 0.5526283543683372\n",
      "epoch 139 lr 0.37864841075716776\n",
      "train_loss 0.6847903694644322 train_acc 0.5526283543683372\n",
      "epoch 140 lr 0.37789187072786273\n",
      "train_loss 0.6847361090319919 train_acc 0.5526283543683372\n",
      "epoch 141 lr 0.3771368422665445\n",
      "train_loss 0.6846807315409773 train_acc 0.5526283543683372\n",
      "epoch 142 lr 0.3763833223530981\n",
      "train_loss 0.684624181393111 train_acc 0.5526283543683372\n",
      "epoch 143 lr 0.375631307973443\n",
      "train_loss 0.68456645498333 train_acc 0.5526283543683372\n",
      "epoch 144 lr 0.3748807961195207\n",
      "train_loss 0.6845075015281474 train_acc 0.5526283543683372\n",
      "epoch 145 lr 0.37413178378928263\n",
      "train_loss 0.6844472901796165 train_acc 0.5526283543683372\n",
      "epoch 146 lr 0.37338426798667856\n",
      "train_loss 0.6843857784975175 train_acc 0.5526283543683372\n",
      "epoch 147 lr 0.37263824572164433\n",
      "train_loss 0.6843229019891246 train_acc 0.5526283543683372\n",
      "epoch 148 lr 0.3718937140100898\n",
      "train_loss 0.684258608361385 train_acc 0.5526283543683372\n",
      "epoch 149 lr 0.3711506698738872\n",
      "train_loss 0.6841928891353708 train_acc 0.5526283543683372\n",
      "\n",
      "val loss = 0.6844792778489461, \n",
      "val acc = 0.5510682288077188\n",
      "\n",
      "epoch 150 lr 0.37040911034085894\n",
      "train_loss 0.6841257422651423 train_acc 0.5526283543683372\n",
      "epoch 151 lr 0.36966903244476595\n",
      "train_loss 0.6840571157722681 train_acc 0.5526283543683372\n",
      "epoch 152 lr 0.3689304332252956\n",
      "train_loss 0.6839869538082406 train_acc 0.5526283543683372\n",
      "epoch 153 lr 0.3681933097280501\n",
      "train_loss 0.6839151705509907 train_acc 0.5526283543683372\n",
      "epoch 154 lr 0.3674576590045344\n",
      "train_loss 0.6838417468213465 train_acc 0.5526283543683372\n",
      "epoch 155 lr 0.3667234781121447\n",
      "train_loss 0.6837666280295605 train_acc 0.5526283543683372\n",
      "epoch 156 lr 0.3659907641141563\n",
      "train_loss 0.6836897487316825 train_acc 0.5526283543683372\n",
      "epoch 157 lr 0.36525951407971247\n",
      "train_loss 0.6836110511393025 train_acc 0.5526283543683372\n",
      "epoch 158 lr 0.36452972508381193\n",
      "train_loss 0.6835304963827854 train_acc 0.5526283543683372\n",
      "epoch 159 lr 0.36380139420729773\n",
      "train_loss 0.6834480211604381 train_acc 0.5526283543683372\n",
      "epoch 160 lr 0.36307451853684547\n",
      "train_loss 0.6833635914732282 train_acc 0.5526283543683372\n",
      "epoch 161 lr 0.36234909516495145\n",
      "train_loss 0.6832771452162723 train_acc 0.5526283543683372\n",
      "epoch 162 lr 0.36162512118992124\n",
      "train_loss 0.6831886724989411 train_acc 0.5526283543683372\n",
      "epoch 163 lr 0.3609025937158579\n",
      "train_loss 0.6830981131350873 train_acc 0.5526283543683372\n",
      "epoch 164 lr 0.3601815098526507\n",
      "train_loss 0.6830053417002234 train_acc 0.5526283543683372\n",
      "epoch 165 lr 0.3594618667159631\n",
      "train_loss 0.682910270667591 train_acc 0.5526283543683372\n",
      "epoch 166 lr 0.3587436614272217\n",
      "train_loss 0.682812872343825 train_acc 0.5526283543683372\n",
      "epoch 167 lr 0.35802689111360425\n",
      "train_loss 0.6827130867473234 train_acc 0.5526283543683372\n",
      "epoch 168 lr 0.3573115529080287\n",
      "train_loss 0.6826108309933566 train_acc 0.5526283543683372\n",
      "epoch 169 lr 0.3565976439491412\n",
      "train_loss 0.6825060431980057 train_acc 0.5526283543683372\n",
      "epoch 170 lr 0.3558851613813049\n",
      "train_loss 0.6823986827383384 train_acc 0.5526283543683372\n",
      "epoch 171 lr 0.35517410235458863\n",
      "train_loss 0.6822885867628117 train_acc 0.5526283543683372\n",
      "epoch 172 lr 0.3544644640247554\n",
      "train_loss 0.6821756987371194 train_acc 0.5526283543683372\n",
      "epoch 173 lr 0.35375624355325086\n",
      "train_loss 0.6820599186459239 train_acc 0.5526283543683372\n",
      "epoch 174 lr 0.3530494381071922\n",
      "train_loss 0.6819411488532705 train_acc 0.5526283543683372\n",
      "epoch 175 lr 0.3523440448593567\n",
      "train_loss 0.6818193230153489 train_acc 0.5526283543683372\n",
      "epoch 176 lr 0.35164006098817047\n",
      "train_loss 0.6816942981003925 train_acc 0.5526283543683372\n",
      "epoch 177 lr 0.350937483677697\n",
      "train_loss 0.6815659776407051 train_acc 0.5526283543683372\n",
      "epoch 178 lr 0.3502363101176262\n",
      "train_loss 0.6814342585597368 train_acc 0.5526283543683372\n",
      "epoch 179 lr 0.3495365375032628\n",
      "train_loss 0.6812990307617189 train_acc 0.5526283543683372\n",
      "epoch 180 lr 0.3488381630355155\n",
      "train_loss 0.681160174137372 train_acc 0.5526283543683372\n",
      "epoch 181 lr 0.3481411839208855\n",
      "train_loss 0.6810175517436581 train_acc 0.5526283543683372\n",
      "epoch 182 lr 0.3474455973714553\n",
      "train_loss 0.6808710955925884 train_acc 0.5526283543683372\n",
      "epoch 183 lr 0.34675140060487786\n",
      "train_loss 0.6807206983923998 train_acc 0.5526283543683372\n",
      "epoch 184 lr 0.3460585908443652\n",
      "train_loss 0.6805662091329936 train_acc 0.5526283543683372\n",
      "epoch 185 lr 0.34536716531867734\n",
      "train_loss 0.6804074676408959 train_acc 0.5526283543683372\n",
      "epoch 186 lr 0.3446771212621112\n",
      "train_loss 0.6802443408039437 train_acc 0.5526283543683372\n",
      "epoch 187 lr 0.3439884559144897\n",
      "train_loss 0.6800766916753129 train_acc 0.5526283543683372\n",
      "epoch 188 lr 0.3433011665211505\n",
      "train_loss 0.6799043492752246 train_acc 0.5526283543683372\n",
      "epoch 189 lr 0.3426152503329351\n",
      "train_loss 0.6797272075715732 train_acc 0.5526283543683372\n",
      "epoch 190 lr 0.3419307046061779\n",
      "train_loss 0.6795451185662305 train_acc 0.5526283543683372\n",
      "epoch 191 lr 0.34124752660269503\n",
      "train_loss 0.6793579140931227 train_acc 0.5526283543683372\n",
      "epoch 192 lr 0.34056571358977356\n",
      "train_loss 0.6791653295838906 train_acc 0.5526283543683372\n",
      "epoch 193 lr 0.3398852628401605\n",
      "train_loss 0.6789672270699687 train_acc 0.5526283543683372\n",
      "epoch 194 lr 0.339206171632052\n",
      "train_loss 0.6787634846667079 train_acc 0.5526283543683372\n",
      "epoch 195 lr 0.3385284372490823\n",
      "train_loss 0.67855384001469 train_acc 0.5526283543683372\n",
      "epoch 196 lr 0.337852056980313\n",
      "train_loss 0.6783380442250444 train_acc 0.5526283543683372\n",
      "epoch 197 lr 0.3371770281202221\n",
      "train_loss 0.6781159846388485 train_acc 0.5526283543683372\n",
      "epoch 198 lr 0.3365033479686932\n",
      "train_loss 0.6778873942470717 train_acc 0.5526283543683372\n",
      "epoch 199 lr 0.3358310138310049\n",
      "train_loss 0.6776520562332031 train_acc 0.5526283543683372\n",
      "\n",
      "val loss = 0.677915585770578, \n",
      "val acc = 0.5510682288077188\n",
      "\n",
      "epoch 200 lr 0.3351600230178196\n",
      "train_loss 0.6774097517352303 train_acc 0.5526283543683372\n",
      "epoch 201 lr 0.33449037284517336\n",
      "train_loss 0.6771603201387406 train_acc 0.5526283543683372\n",
      "epoch 202 lr 0.33382206063446446\n",
      "train_loss 0.6769034329276322 train_acc 0.5526283543683372\n",
      "epoch 203 lr 0.3331550837124432\n",
      "train_loss 0.6766388559700003 train_acc 0.5526283543683372\n",
      "epoch 204 lr 0.33248943941120096\n",
      "train_loss 0.6763662659337873 train_acc 0.5526283543683372\n",
      "epoch 205 lr 0.3318251250681597\n",
      "train_loss 0.6760853754725044 train_acc 0.5526283543683372\n",
      "epoch 206 lr 0.33116213802606115\n",
      "train_loss 0.6757959052116611 train_acc 0.5526283543683372\n",
      "epoch 207 lr 0.33050047563295626\n",
      "train_loss 0.6754975286737658 train_acc 0.5526283543683372\n",
      "epoch 208 lr 0.3298401352421945\n",
      "train_loss 0.6751898629877856 train_acc 0.5526283543683372\n",
      "epoch 209 lr 0.3291811142124136\n",
      "train_loss 0.6748726042487481 train_acc 0.5526283543683372\n",
      "epoch 210 lr 0.3285234099075284\n",
      "train_loss 0.6745454253101063 train_acc 0.5526283543683372\n",
      "epoch 211 lr 0.3278670196967209\n",
      "train_loss 0.6742079991555822 train_acc 0.5526283543683372\n",
      "epoch 212 lr 0.3272119409544293\n",
      "train_loss 0.6738600184541096 train_acc 0.5526283543683372\n",
      "epoch 213 lr 0.3265581710603378\n",
      "train_loss 0.6735011085025531 train_acc 0.5526283543683372\n",
      "epoch 214 lr 0.325905707399366\n",
      "train_loss 0.673130954950777 train_acc 0.5526283543683372\n",
      "epoch 215 lr 0.32525454736165826\n",
      "train_loss 0.6727490729629164 train_acc 0.5526283543683372\n",
      "epoch 216 lr 0.3246046883425737\n",
      "train_loss 0.6723549594160055 train_acc 0.5526283543683372\n",
      "epoch 217 lr 0.3239561277426753\n",
      "train_loss 0.671948276684149 train_acc 0.5526283543683372\n",
      "epoch 218 lr 0.3233088629677198\n",
      "train_loss 0.6715285338477773 train_acc 0.5526283543683372\n",
      "epoch 219 lr 0.3226628914286473\n",
      "train_loss 0.671095242222256 train_acc 0.5526283543683372\n",
      "epoch 220 lr 0.32201821054157065\n",
      "train_loss 0.6706479934258269 train_acc 0.5526283543683372\n",
      "epoch 221 lr 0.3213748177277656\n",
      "train_loss 0.670186285852579 train_acc 0.5526283543683372\n",
      "epoch 222 lr 0.3207327104136599\n",
      "train_loss 0.6697094806108218 train_acc 0.5526283543683372\n",
      "epoch 223 lr 0.32009188603082356\n",
      "train_loss 0.669217212931383 train_acc 0.5526283543683372\n",
      "epoch 224 lr 0.31945234201595807\n",
      "train_loss 0.6687088702067697 train_acc 0.5526283543683372\n",
      "epoch 225 lr 0.3188140758108866\n",
      "train_loss 0.6681839285876175 train_acc 0.5526283543683372\n",
      "epoch 226 lr 0.31817708486254354\n",
      "train_loss 0.6676418000766454 train_acc 0.5526283543683372\n",
      "epoch 227 lr 0.31754136662296406\n",
      "train_loss 0.6670816519609992 train_acc 0.5526283543683372\n",
      "epoch 228 lr 0.3169069185492745\n",
      "train_loss 0.6665028777549268 train_acc 0.5526283543683372\n",
      "epoch 229 lr 0.3162737381036817\n",
      "train_loss 0.6659049513154626 train_acc 0.5526283543683372\n",
      "epoch 230 lr 0.315641822753463\n",
      "train_loss 0.6652871052756539 train_acc 0.5526283543683372\n",
      "epoch 231 lr 0.31501116997095613\n",
      "train_loss 0.6646487267166985 train_acc 0.5526283543683372\n",
      "epoch 232 lr 0.3143817772335492\n",
      "train_loss 0.6639892807078872 train_acc 0.5526283543683372\n",
      "epoch 233 lr 0.31375364202367034\n",
      "train_loss 0.6633078815280582 train_acc 0.5526283543683372\n",
      "epoch 234 lr 0.31312676182877797\n",
      "train_loss 0.6626038045305641 train_acc 0.5526283543683372\n",
      "epoch 235 lr 0.3125011341413504\n",
      "train_loss 0.6618763809163533 train_acc 0.5526896213699302\n",
      "epoch 236 lr 0.311876756458876\n",
      "train_loss 0.66112476384827 train_acc 0.5527968386227178\n",
      "epoch 237 lr 0.3112536262838434\n",
      "train_loss 0.6603482055000792 train_acc 0.553133807131479\n",
      "epoch 238 lr 0.3106317411237308\n",
      "train_loss 0.6595457592576877 train_acc 0.5537311603970102\n",
      "epoch 239 lr 0.310011098490997\n",
      "train_loss 0.6587166310685917 train_acc 0.5555691704447985\n",
      "epoch 240 lr 0.3093916959030704\n",
      "train_loss 0.6578598833616529 train_acc 0.558402769268472\n",
      "epoch 241 lr 0.30877353088234\n",
      "train_loss 0.6569745585560808 train_acc 0.5629518441367479\n",
      "epoch 242 lr 0.30815660095614483\n",
      "train_loss 0.6560596508325409 train_acc 0.5702273005759099\n",
      "epoch 243 lr 0.30754090365676434\n",
      "train_loss 0.6551142599427757 train_acc 0.5789118980517094\n",
      "epoch 244 lr 0.3069264365214085\n",
      "train_loss 0.6541379042883076 train_acc 0.5897714740840583\n",
      "epoch 245 lr 0.30631319709220806\n",
      "train_loss 0.6531296348480757 train_acc 0.6009220683739738\n",
      "epoch 246 lr 0.30570118291620435\n",
      "train_loss 0.6520884722561118 train_acc 0.6128691336845975\n",
      "epoch 247 lr 0.3050903915453399\n",
      "train_loss 0.6510135432282549 train_acc 0.6237440264673447\n",
      "epoch 248 lr 0.3044808205364484\n",
      "train_loss 0.649903979141421 train_acc 0.6333629457174366\n",
      "epoch 249 lr 0.3038724674512451\n",
      "train_loss 0.6487589851246628 train_acc 0.6419403259404485\n",
      "\n",
      "val loss = 0.6488485777017888, \n",
      "val acc = 0.6526533425223984\n",
      "\n",
      "epoch 250 lr 0.3032653298563167\n",
      "train_loss 0.6475776960175005 train_acc 0.6486337458644774\n",
      "epoch 251 lr 0.3026594053231121\n",
      "train_loss 0.6463593685326399 train_acc 0.6544081607646122\n",
      "epoch 252 lr 0.30205469142793234\n",
      "train_loss 0.6451035267492875 train_acc 0.6601366254135522\n",
      "epoch 253 lr 0.30145118575192104\n",
      "train_loss 0.6438091576254946 train_acc 0.6642568312706776\n",
      "epoch 254 lr 0.3008488858810547\n",
      "train_loss 0.6424755515179001 train_acc 0.6691888248989094\n",
      "epoch 255 lr 0.30024778940613295\n",
      "train_loss 0.6411020856545036 train_acc 0.6733090307560348\n",
      "epoch 256 lr 0.2996478939227692\n",
      "train_loss 0.6396882175087395 train_acc 0.6773373361107707\n",
      "epoch 257 lr 0.29904919703138066\n",
      "train_loss 0.6382330754247643 train_acc 0.6810746232079402\n",
      "epoch 258 lr 0.298451696337179\n",
      "train_loss 0.6367367589331101 train_acc 0.6846281093003308\n",
      "epoch 259 lr 0.2978553894501606\n",
      "train_loss 0.63519846950438 train_acc 0.6885032471510845\n",
      "epoch 260 lr 0.29726027398509713\n",
      "train_loss 0.6336176731073272 train_acc 0.6921945839970591\n",
      "epoch 261 lr 0.296666347561526\n",
      "train_loss 0.6319945246808975 train_acc 0.6951354000735204\n",
      "epoch 262 lr 0.29607360780374065\n",
      "train_loss 0.6303289443897419 train_acc 0.6976167136380346\n",
      "epoch 263 lr 0.29548205234078123\n",
      "train_loss 0.6286213794879809 train_acc 0.6996844749417963\n",
      "epoch 264 lr 0.2948916788064252\n",
      "train_loss 0.626871656663643 train_acc 0.7016909692439652\n",
      "epoch 265 lr 0.2943024848391776\n",
      "train_loss 0.625079821328537 train_acc 0.7038353142997181\n",
      "epoch 266 lr 0.2937144680822617\n",
      "train_loss 0.6232470605762425 train_acc 0.7053823060899399\n",
      "epoch 267 lr 0.29312762618360977\n",
      "train_loss 0.6213738404631604 train_acc 0.7076032348976841\n",
      "epoch 268 lr 0.29254195679585343\n",
      "train_loss 0.6194611174290774 train_acc 0.7089357921823306\n",
      "epoch 269 lr 0.2919574575763143\n",
      "train_loss 0.617510134320618 train_acc 0.7106359514765347\n",
      "epoch 270 lr 0.2913741261869948\n",
      "train_loss 0.6155213513021636 train_acc 0.7117234407548094\n",
      "epoch 271 lr 0.29079196029456855\n",
      "train_loss 0.6134962888326938 train_acc 0.7131632152922436\n",
      "epoch 272 lr 0.29021095757037113\n",
      "train_loss 0.6114367770827792 train_acc 0.7146948903320671\n",
      "epoch 273 lr 0.289631115690391\n",
      "train_loss 0.6093445499859904 train_acc 0.7156445288567578\n",
      "epoch 274 lr 0.2890524323352598\n",
      "train_loss 0.6072214710256866 train_acc 0.7173293714005636\n",
      "epoch 275 lr 0.2884749051902433\n",
      "train_loss 0.6050700343749902 train_acc 0.7184321774292366\n",
      "epoch 276 lr 0.28789853194523224\n",
      "train_loss 0.6028924156017025 train_acc 0.7196422007106972\n",
      "epoch 277 lr 0.2873233102947328\n",
      "train_loss 0.6006909745091327 train_acc 0.720408038230609\n",
      "epoch 278 lr 0.28674923793785767\n",
      "train_loss 0.5984682853487121 train_acc 0.7212810930033084\n",
      "epoch 279 lr 0.2861763125783166\n",
      "train_loss 0.5962268109422326 train_acc 0.7222000980272025\n",
      "epoch 280 lr 0.2856045319244074\n",
      "train_loss 0.5939693240109617 train_acc 0.7225677000367602\n",
      "epoch 281 lr 0.2850338936890067\n",
      "train_loss 0.5916994368104351 train_acc 0.7227515010415391\n",
      "epoch 282 lr 0.28446439558956094\n",
      "train_loss 0.589420155841502 train_acc 0.7234407548094596\n",
      "epoch 283 lr 0.28389603534807667\n",
      "train_loss 0.587134528410196 train_acc 0.7240227913245926\n",
      "epoch 284 lr 0.2833288106911124\n",
      "train_loss 0.5848455850781651 train_acc 0.7249877465996815\n",
      "epoch 285 lr 0.2827627193497686\n",
      "train_loss 0.5825564558497675 train_acc 0.7251255973532655\n",
      "epoch 286 lr 0.2821977590596792\n",
      "train_loss 0.5802703813698943 train_acc 0.7263662541355226\n",
      "epoch 287 lr 0.28163392756100236\n",
      "train_loss 0.577991277037319 train_acc 0.7271627251562308\n",
      "epoch 288 lr 0.2810712225984112\n",
      "train_loss 0.5757218127447656 train_acc 0.727499693664992\n",
      "epoch 289 lr 0.2805096419210853\n",
      "train_loss 0.5734647974059662 train_acc 0.7277447616713638\n",
      "epoch 290 lr 0.279949183282701\n",
      "train_loss 0.5712231146293522 train_acc 0.7281889474329126\n",
      "epoch 291 lr 0.2793898444414232\n",
      "train_loss 0.5689993384964096 train_acc 0.7286790834456561\n",
      "epoch 292 lr 0.2788316231598956\n",
      "train_loss 0.5667964259220988 train_acc 0.7291998529591962\n",
      "epoch 293 lr 0.27827451720523244\n",
      "train_loss 0.5646165540466772 train_acc 0.7295980884695503\n",
      "epoch 294 lr 0.2777185243490092\n",
      "train_loss 0.5624621780588772 train_acc 0.7299350569783115\n",
      "epoch 295 lr 0.27716364236725355\n",
      "train_loss 0.560335549971607 train_acc 0.7305630437446391\n",
      "epoch 296 lr 0.27660986904043694\n",
      "train_loss 0.5582380574749545 train_acc 0.7313901482661439\n",
      "epoch 297 lr 0.2760572021534653\n",
      "train_loss 0.5561708820453176 train_acc 0.7320181350324715\n",
      "epoch 298 lr 0.2755056394956704\n",
      "train_loss 0.5541349788901967 train_acc 0.7324470040436221\n",
      "epoch 299 lr 0.2749551788608008\n",
      "train_loss 0.552131338782704 train_acc 0.7329218233059674\n",
      "\n",
      "val loss = 0.5560679591980441, \n",
      "val acc = 0.7251550654720882\n",
      "\n",
      "epoch 300 lr 0.27440581804701325\n",
      "train_loss 0.5501598245593413 train_acc 0.7334272760691092\n",
      "epoch 301 lr 0.27385755485686375\n",
      "train_loss 0.548220494781129 train_acc 0.733871461830658\n",
      "epoch 302 lr 0.2733103870972988\n",
      "train_loss 0.5463139563211291 train_acc 0.7344228648449945\n",
      "epoch 303 lr 0.2727643125796467\n",
      "train_loss 0.5444405874173864 train_acc 0.7349895846097292\n",
      "epoch 304 lr 0.27221932911960856\n",
      "train_loss 0.5425997919525974 train_acc 0.7355869378752604\n",
      "epoch 305 lr 0.2716754345372499\n",
      "train_loss 0.540791023262744 train_acc 0.7360923906384021\n",
      "epoch 306 lr 0.2711326266569916\n",
      "train_loss 0.5390130234138933 train_acc 0.7369041784095086\n",
      "epoch 307 lr 0.27059090330760144\n",
      "train_loss 0.5372648192495887 train_acc 0.7378078666830046\n",
      "epoch 308 lr 0.27005026232218526\n",
      "train_loss 0.5355463437487993 train_acc 0.7382061021933587\n",
      "epoch 309 lr 0.2695107015381785\n",
      "train_loss 0.5338554367519464 train_acc 0.7389259894620758\n",
      "epoch 310 lr 0.26897221879733724\n",
      "train_loss 0.5321903871793533 train_acc 0.739462075726014\n",
      "epoch 311 lr 0.26843481194572977\n",
      "train_loss 0.5305496133686304 train_acc 0.7402585467467222\n",
      "epoch 312 lr 0.267898478833728\n",
      "train_loss 0.5289321464346302 train_acc 0.740702732508271\n",
      "epoch 313 lr 0.26736321731599877\n",
      "train_loss 0.5273357664581103 train_acc 0.7417136380345546\n",
      "epoch 314 lr 0.26682902525149527\n",
      "train_loss 0.5257592988883987 train_acc 0.7424794755544664\n",
      "epoch 315 lr 0.2662959005034486\n",
      "train_loss 0.5241998274097549 train_acc 0.7431227790711923\n",
      "epoch 316 lr 0.26576384093935895\n",
      "train_loss 0.5226573358042621 train_acc 0.7440571008454846\n",
      "epoch 317 lr 0.26523284443098744\n",
      "train_loss 0.5211307831164023 train_acc 0.7447769881142017\n",
      "epoch 318 lr 0.2647029088543473\n",
      "train_loss 0.5196171034112698 train_acc 0.7456653596372993\n",
      "epoch 319 lr 0.2641740320896955\n",
      "train_loss 0.5181151551850898 train_acc 0.7462014459012376\n",
      "epoch 320 lr 0.2636462120215243\n",
      "train_loss 0.516624085536736 train_acc 0.7472123514275212\n",
      "epoch 321 lr 0.2631194465385527\n",
      "train_loss 0.515141402553322 train_acc 0.7478250214434505\n",
      "epoch 322 lr 0.26259373353371807\n",
      "train_loss 0.5136646212436436 train_acc 0.7483764244577871\n",
      "epoch 323 lr 0.2620690709041677\n",
      "train_loss 0.5121937186910985 train_acc 0.7491422619776988\n",
      "epoch 324 lr 0.2615454565512504\n",
      "train_loss 0.510727638859542 train_acc 0.75026038475677\n",
      "epoch 325 lr 0.261022888380508\n",
      "train_loss 0.5092652557847753 train_acc 0.751102806028673\n",
      "epoch 326 lr 0.2605013643016672\n",
      "train_loss 0.5078059800338016 train_acc 0.7519758608013724\n",
      "epoch 327 lr 0.2599808822286309\n",
      "train_loss 0.5063491639977803 train_acc 0.7530786668300453\n",
      "epoch 328 lr 0.2594614400794702\n",
      "train_loss 0.5048950934711525 train_acc 0.7541202058571254\n",
      "epoch 329 lr 0.2589430357764157\n",
      "train_loss 0.5034429356766149 train_acc 0.7550698443818159\n",
      "epoch 330 lr 0.2584256672458496\n",
      "train_loss 0.5019887618766158 train_acc 0.7559275824041172\n",
      "epoch 331 lr 0.25790933241829705\n",
      "train_loss 0.5005320921026659 train_acc 0.756892537679206\n",
      "epoch 332 lr 0.2573940292284181\n",
      "train_loss 0.499074697868921 train_acc 0.7577809092023037\n",
      "epoch 333 lr 0.2568797556149992\n",
      "train_loss 0.4976147465858326 train_acc 0.7586845974757995\n",
      "epoch 334 lr 0.25636650952094525\n",
      "train_loss 0.4961543408104107 train_acc 0.7594044847445166\n",
      "epoch 335 lr 0.2558542888932712\n",
      "train_loss 0.49469036441843295 train_acc 0.760537924273986\n",
      "epoch 336 lr 0.25534309168309394\n",
      "train_loss 0.49321952143940145 train_acc 0.7615181962994731\n",
      "epoch 337 lr 0.2548329158456238\n",
      "train_loss 0.49174485340901175 train_acc 0.762881387084916\n",
      "epoch 338 lr 0.25432375934015683\n",
      "train_loss 0.490265430458921 train_acc 0.7638616591104032\n",
      "epoch 339 lr 0.25381562013006637\n",
      "train_loss 0.4887836447644065 train_acc 0.7650104153902708\n",
      "epoch 340 lr 0.2533084961827948\n",
      "train_loss 0.48729811666642897 train_acc 0.7660366376669526\n",
      "epoch 341 lr 0.25280238546984574\n",
      "train_loss 0.485810366958062 train_acc 0.7671394436956256\n",
      "epoch 342 lr 0.2522972859667756\n",
      "train_loss 0.48431547151813764 train_acc 0.7682422497242984\n",
      "epoch 343 lr 0.2517931956531857\n",
      "train_loss 0.4828165571714584 train_acc 0.7691612547481926\n",
      "epoch 344 lr 0.2512901125127142\n",
      "train_loss 0.4813128886990659 train_acc 0.7704784952824408\n",
      "epoch 345 lr 0.2507880345330278\n",
      "train_loss 0.47980588981557154 train_acc 0.771458767307928\n",
      "epoch 346 lr 0.2502869597058139\n",
      "train_loss 0.47829523618932823 train_acc 0.7726381570885921\n",
      "epoch 347 lr 0.24978688602677251\n",
      "train_loss 0.4767796243818579 train_acc 0.7736643793652739\n",
      "epoch 348 lr 0.2492878114956083\n",
      "train_loss 0.47526296626048153 train_acc 0.7745987011395662\n",
      "epoch 349 lr 0.24878973411602245\n",
      "train_loss 0.4737435904826106 train_acc 0.7755483396642568\n",
      "\n",
      "val loss = 0.4843189437838588, \n",
      "val acc = 0.7662301860785665\n",
      "\n",
      "epoch 350 lr 0.2482926518957048\n",
      "train_loss 0.47222432781785695 train_acc 0.7765745619409387\n",
      "epoch 351 lr 0.24779656284632576\n",
      "train_loss 0.47070349624101676 train_acc 0.7772791324592574\n",
      "epoch 352 lr 0.2473014649835285\n",
      "train_loss 0.46918106047905594 train_acc 0.7781521872319569\n",
      "epoch 353 lr 0.24680735632692094\n",
      "train_loss 0.46765753354414213 train_acc 0.7796685455213822\n",
      "epoch 354 lr 0.24631423490006774\n",
      "train_loss 0.4661334289859779 train_acc 0.7805569170444798\n",
      "epoch 355 lr 0.24582209873048258\n",
      "train_loss 0.4646075135834689 train_acc 0.7813687048155863\n",
      "epoch 356 lr 0.2453309458496201\n",
      "train_loss 0.4630824074575046 train_acc 0.7824715108442593\n",
      "epoch 357 lr 0.2448407742928681\n",
      "train_loss 0.4615597252775823 train_acc 0.7835896336233305\n",
      "epoch 358 lr 0.24435158209953975\n",
      "train_loss 0.46004032739584716 train_acc 0.7846311726504105\n",
      "epoch 359 lr 0.2438633673128656\n",
      "train_loss 0.45852804687951215 train_acc 0.7857186619286852\n",
      "epoch 360 lr 0.24337612797998584\n",
      "train_loss 0.45702333989286736 train_acc 0.7869133684597476\n",
      "epoch 361 lr 0.24288986215194253\n",
      "train_loss 0.4555253983752067 train_acc 0.7878017399828452\n",
      "epoch 362 lr 0.24240456788367165\n",
      "train_loss 0.454031818548595 train_acc 0.788506310501164\n",
      "epoch 363 lr 0.24192024323399552\n",
      "train_loss 0.4525436414283441 train_acc 0.7894865825266512\n",
      "epoch 364 lr 0.24143688626561488\n",
      "train_loss 0.4510653784264875 train_acc 0.7904821713025365\n",
      "epoch 365 lr 0.24095449504510122\n",
      "train_loss 0.44959607966712084 train_acc 0.7915849773312094\n",
      "epoch 366 lr 0.24047306764288903\n",
      "train_loss 0.44813671929850496 train_acc 0.7926724666094841\n",
      "epoch 367 lr 0.23999260213326803\n",
      "train_loss 0.44668667973211545 train_acc 0.7938518563901482\n",
      "epoch 368 lr 0.23951309659437556\n",
      "train_loss 0.4452473163918985 train_acc 0.7945870604092635\n",
      "epoch 369 lr 0.2390345491081888\n",
      "train_loss 0.4438212082714961 train_acc 0.7959043009435118\n",
      "epoch 370 lr 0.23855695776051722\n",
      "train_loss 0.442406963518597 train_acc 0.79644038720745\n",
      "epoch 371 lr 0.2380803206409947\n",
      "train_loss 0.44100693871989094 train_acc 0.7972981252297513\n",
      "epoch 372 lr 0.23760463584307223\n",
      "train_loss 0.439620463960914 train_acc 0.79800269574807\n",
      "epoch 373 lr 0.23712990146400992\n",
      "train_loss 0.43824788247620433 train_acc 0.7988910672711678\n",
      "epoch 374 lr 0.23665611560486965\n",
      "train_loss 0.43689212638649366 train_acc 0.7995037372870971\n",
      "epoch 375 lr 0.23618327637050734\n",
      "train_loss 0.4355507222631318 train_acc 0.8002848915574072\n",
      "epoch 376 lr 0.23571138186956545\n",
      "train_loss 0.4342230688865551 train_acc 0.8010813625781155\n",
      "epoch 377 lr 0.23524043021446528\n",
      "train_loss 0.432910052382677 train_acc 0.8018931503492219\n",
      "epoch 378 lr 0.23477041952139963\n",
      "train_loss 0.43161285751729955 train_acc 0.8023986031123637\n",
      "epoch 379 lr 0.23430134791032511\n",
      "train_loss 0.43033212741965604 train_acc 0.803394191888249\n",
      "epoch 380 lr 0.23383321350495462\n",
      "train_loss 0.42906806192992436 train_acc 0.8040528121553732\n",
      "epoch 381 lr 0.23336601443274993\n",
      "train_loss 0.42782152389064804 train_acc 0.8047114324224972\n",
      "epoch 382 lr 0.23289974882491413\n",
      "train_loss 0.4265926773962549 train_acc 0.8056610709471879\n",
      "epoch 383 lr 0.23243441481638413\n",
      "train_loss 0.42537995808371015 train_acc 0.8060133562063473\n",
      "epoch 384 lr 0.23197001054582334\n",
      "train_loss 0.424185778909522 train_acc 0.8067638769758608\n",
      "epoch 385 lr 0.23150653415561404\n",
      "train_loss 0.42301039891792747 train_acc 0.8074837642445779\n",
      "epoch 386 lr 0.23104398379185\n",
      "train_loss 0.421854365816316 train_acc 0.8083415022668791\n",
      "epoch 387 lr 0.2305823576043292\n",
      "train_loss 0.42071756948008165 train_acc 0.8089388555324103\n",
      "epoch 388 lr 0.23012165374654628\n",
      "train_loss 0.4195976117867704 train_acc 0.8092758240411714\n",
      "epoch 389 lr 0.22966187037568517\n",
      "train_loss 0.4184958957270093 train_acc 0.8098425438059061\n",
      "epoch 390 lr 0.22920300565261176\n",
      "train_loss 0.41741111385488444 train_acc 0.8106083813258179\n",
      "epoch 391 lr 0.2287450577418666\n",
      "train_loss 0.4163444769355994 train_acc 0.8111904178409509\n",
      "epoch 392 lr 0.22828802481165736\n",
      "train_loss 0.41529620649708743 train_acc 0.8116958706040927\n",
      "epoch 393 lr 0.22783190503385176\n",
      "train_loss 0.4142652567206408 train_acc 0.8124923416248009\n",
      "epoch 394 lr 0.22737669658397008\n",
      "train_loss 0.41325311207162974 train_acc 0.8130743781399339\n",
      "epoch 395 lr 0.2269223976411779\n",
      "train_loss 0.412259573706911 train_acc 0.8135951476534738\n",
      "epoch 396 lr 0.22646900638827885\n",
      "train_loss 0.41128564386383276 train_acc 0.8139627496630315\n",
      "epoch 397 lr 0.2260165210117073\n",
      "train_loss 0.4103316373374329 train_acc 0.8146060531797574\n",
      "epoch 398 lr 0.2255649397015212\n",
      "train_loss 0.4093954973113205 train_acc 0.8150502389413062\n",
      "epoch 399 lr 0.22511426065139462\n",
      "train_loss 0.40847711180278923 train_acc 0.815555691704448\n",
      "\n",
      "val loss = 0.4217944485160481, \n",
      "val acc = 0.8041350792556857\n",
      "\n",
      "epoch 400 lr 0.22466448205861078\n",
      "train_loss 0.4075766201907213 train_acc 0.8159998774659968\n",
      "epoch 401 lr 0.22421560212405475\n",
      "train_loss 0.4066942418503471 train_acc 0.8164134297267491\n",
      "epoch 402 lr 0.22376761905220618\n",
      "train_loss 0.40583227702736924 train_acc 0.8169801494914839\n",
      "epoch 403 lr 0.22332053105113217\n",
      "train_loss 0.4049894169924478 train_acc 0.8172864844994486\n",
      "epoch 404 lr 0.2228743363324801\n",
      "train_loss 0.40416482972296364 train_acc 0.8179297880161744\n",
      "epoch 405 lr 0.22242903311147055\n",
      "train_loss 0.4033575290544307 train_acc 0.818481191030511\n",
      "epoch 406 lr 0.22198461960689\n",
      "train_loss 0.4025678820130139 train_acc 0.8189713270432545\n",
      "epoch 407 lr 0.2215410940410839\n",
      "train_loss 0.40179513009220025 train_acc 0.8195380468079893\n",
      "epoch 408 lr 0.22109845463994934\n",
      "train_loss 0.40103993733899856 train_acc 0.819783114814361\n",
      "epoch 409 lr 0.2206566996329281\n",
      "train_loss 0.4003011810039962 train_acc 0.8202885675775028\n",
      "epoch 410 lr 0.22021582725299965\n",
      "train_loss 0.39957976545554014 train_acc 0.8207021198382551\n",
      "epoch 411 lr 0.21977583573667378\n",
      "train_loss 0.3988749849506092 train_acc 0.8209012375934321\n",
      "epoch 412 lr 0.21933672332398393\n",
      "train_loss 0.39818595894672115 train_acc 0.8212994731037863\n",
      "epoch 413 lr 0.21889848825847982\n",
      "train_loss 0.39751322950473283 train_acc 0.8218508761181228\n",
      "epoch 414 lr 0.2184611287872206\n",
      "train_loss 0.39685631194104354 train_acc 0.8222797451292734\n",
      "epoch 415 lr 0.2180246431607678\n",
      "train_loss 0.39621381110543197 train_acc 0.8228311481436098\n",
      "epoch 416 lr 0.21758902963317836\n",
      "train_loss 0.3955861865302259 train_acc 0.8229383653963975\n",
      "epoch 417 lr 0.21715428646199755\n",
      "train_loss 0.3949730791124726 train_acc 0.8232600171547605\n",
      "epoch 418 lr 0.21672041190825214\n",
      "train_loss 0.3943745845921424 train_acc 0.8235510354123269\n",
      "epoch 419 lr 0.21628740423644333\n",
      "train_loss 0.39379080193952615 train_acc 0.8238573704202916\n",
      "epoch 420 lr 0.21585526171453984\n",
      "train_loss 0.3932214786578655 train_acc 0.8242402891802475\n",
      "epoch 421 lr 0.21542398261397103\n",
      "train_loss 0.39266576709567846 train_acc 0.8247763754441858\n",
      "epoch 422 lr 0.2149935652096199\n",
      "train_loss 0.3921228886977695 train_acc 0.8250827104521504\n",
      "epoch 423 lr 0.21456400777981627\n",
      "train_loss 0.3915935461977526 train_acc 0.8255115794633011\n",
      "epoch 424 lr 0.21413530860632982\n",
      "train_loss 0.391077381856613 train_acc 0.8257106972184781\n",
      "epoch 425 lr 0.21370746597436333\n",
      "train_loss 0.390574653258911 train_acc 0.8261855164808234\n",
      "epoch 426 lr 0.21328047817254567\n",
      "train_loss 0.3900843085073291 train_acc 0.8264305844871952\n",
      "epoch 427 lr 0.2128543434929251\n",
      "train_loss 0.3896052388783766 train_acc 0.8266297022423723\n",
      "epoch 428 lr 0.21242906023096228\n",
      "train_loss 0.3891375276962067 train_acc 0.8268900869991422\n",
      "epoch 429 lr 0.21200462668552364\n",
      "train_loss 0.3886814303213943 train_acc 0.827135155005514\n",
      "epoch 430 lr 0.2115810411588744\n",
      "train_loss 0.38823637965679353 train_acc 0.8276406077686558\n",
      "epoch 431 lr 0.2111583019566719\n",
      "train_loss 0.38780160961940513 train_acc 0.8277937752726382\n",
      "epoch 432 lr 0.2107364073879588\n",
      "train_loss 0.38737745443773275 train_acc 0.8277325082710452\n",
      "epoch 433 lr 0.2103153557651562\n",
      "train_loss 0.38696394965309533 train_acc 0.8280541600294081\n",
      "epoch 434 lr 0.20989514540405713\n",
      "train_loss 0.3865609715281235 train_acc 0.828437078789364\n",
      "epoch 435 lr 0.2094757746238195\n",
      "train_loss 0.3861671586506384 train_acc 0.8286515132949394\n",
      "epoch 436 lr 0.20905724174695967\n",
      "train_loss 0.38578342797650395 train_acc 0.8288965813013112\n",
      "epoch 437 lr 0.20863954509934557\n",
      "train_loss 0.3854095953666475 train_acc 0.8291722828084793\n",
      "epoch 438 lr 0.20822268301019004\n",
      "train_loss 0.3850449691624512 train_acc 0.8294173508148511\n",
      "epoch 439 lr 0.2078066538120442\n",
      "train_loss 0.38468906307978845 train_acc 0.8296011518196299\n",
      "epoch 440 lr 0.2073914558407907\n",
      "train_loss 0.3843416356684051 train_acc 0.8298462198260017\n",
      "epoch 441 lr 0.20697708743563706\n",
      "train_loss 0.38400154195099284 train_acc 0.8301831883347629\n",
      "epoch 442 lr 0.20656354693910914\n",
      "train_loss 0.3836696623451131 train_acc 0.8302750888371523\n",
      "epoch 443 lr 0.20615083269704437\n",
      "train_loss 0.38334541764676644 train_acc 0.8303516725891434\n",
      "epoch 444 lr 0.20573894305858528\n",
      "train_loss 0.3830290296548257 train_acc 0.8304282563411347\n",
      "epoch 445 lr 0.20532787637617275\n",
      "train_loss 0.3827197043768466 train_acc 0.830841808601887\n",
      "epoch 446 lr 0.20491763100553947\n",
      "train_loss 0.38241711334946393 train_acc 0.8309337091042764\n",
      "epoch 447 lr 0.20450820530570346\n",
      "train_loss 0.382120985436783 train_acc 0.8310868766082588\n",
      "epoch 448 lr 0.20409959763896135\n",
      "train_loss 0.3818319833797911 train_acc 0.8312553608626394\n",
      "epoch 449 lr 0.2036918063708819\n",
      "train_loss 0.38154975471949 train_acc 0.8314697953682146\n",
      "\n",
      "val loss = 0.39468500713059396, \n",
      "val acc = 0.8187456926257753\n",
      "\n",
      "epoch 450 lr 0.20328482987029955\n",
      "train_loss 0.3812739653373535 train_acc 0.8315616958706041\n",
      "epoch 451 lr 0.20287866650930772\n",
      "train_loss 0.3810048412350229 train_acc 0.8316995466241882\n",
      "epoch 452 lr 0.20247331466325244\n",
      "train_loss 0.3807418943164741 train_acc 0.8318527141281705\n",
      "epoch 453 lr 0.20206877271072576\n",
      "train_loss 0.380484560062074 train_acc 0.8320365151329494\n",
      "epoch 454 lr 0.20166503903355937\n",
      "train_loss 0.38023282233979444 train_acc 0.83220499938733\n",
      "epoch 455 lr 0.20126211201681798\n",
      "train_loss 0.3799867422358712 train_acc 0.8320518318833476\n",
      "epoch 456 lr 0.200859990048793\n",
      "train_loss 0.37974665997367 train_acc 0.8320824653841441\n",
      "epoch 457 lr 0.20045867152099606\n",
      "train_loss 0.3795119496352909 train_acc 0.8320824653841441\n",
      "epoch 458 lr 0.20005815482815245\n",
      "train_loss 0.37928262804828655 train_acc 0.8323428501409141\n",
      "epoch 459 lr 0.1996584383681949\n",
      "train_loss 0.37905828845134437 train_acc 0.8326032348976841\n",
      "epoch 460 lr 0.19925952054225707\n",
      "train_loss 0.3788386092880363 train_acc 0.8326185516480823\n",
      "epoch 461 lr 0.19886139975466707\n",
      "train_loss 0.37862293567573285 train_acc 0.83298615365764\n",
      "epoch 462 lr 0.19846407441294123\n",
      "train_loss 0.37841175019810674 train_acc 0.8330321039088348\n",
      "epoch 463 lr 0.19806754292777767\n",
      "train_loss 0.3782051592193118 train_acc 0.8331546379120206\n",
      "epoch 464 lr 0.1976718037130499\n",
      "train_loss 0.3780029932284742 train_acc 0.8332312216640118\n",
      "epoch 465 lr 0.19727685518580054\n",
      "train_loss 0.37780523450375736 train_acc 0.8333537556671976\n",
      "epoch 466 lr 0.196882695766235\n",
      "train_loss 0.37761181400541277 train_acc 0.83350692317118\n",
      "epoch 467 lr 0.19648932387771498\n",
      "train_loss 0.37742265879204806 train_acc 0.8336600906751623\n",
      "epoch 468 lr 0.19609673794675248\n",
      "train_loss 0.37723724190613783 train_acc 0.8337213576767553\n",
      "epoch 469 lr 0.19570493640300324\n",
      "train_loss 0.3770553936832178 train_acc 0.8338438916799412\n",
      "epoch 470 lr 0.19531391767926054\n",
      "train_loss 0.37687679137196184 train_acc 0.8339357921823306\n",
      "epoch 471 lr 0.19492368021144899\n",
      "train_loss 0.3767016200115629 train_acc 0.8339664256831271\n",
      "epoch 472 lr 0.19453422243861818\n",
      "train_loss 0.37652960787189144 train_acc 0.8339664256831271\n",
      "epoch 473 lr 0.1941455428029365\n",
      "train_loss 0.37636055408988556 train_acc 0.8340123759343218\n",
      "epoch 474 lr 0.19375763974968488\n",
      "train_loss 0.3761948095786717 train_acc 0.8341961769391006\n",
      "epoch 475 lr 0.19337051172725062\n",
      "train_loss 0.3760320269426832 train_acc 0.8343340276926847\n",
      "epoch 476 lr 0.19298415718712106\n",
      "train_loss 0.3758722369707843 train_acc 0.8345637789486583\n",
      "epoch 477 lr 0.1925985745838776\n",
      "train_loss 0.3757152537384221 train_acc 0.8347016297022424\n",
      "epoch 478 lr 0.19221376237518928\n",
      "train_loss 0.37556089630533973 train_acc 0.8349160642078177\n",
      "epoch 479 lr 0.19182971902180673\n",
      "train_loss 0.37540950625457326 train_acc 0.8349926479598089\n",
      "epoch 480 lr 0.19144644298755603\n",
      "train_loss 0.37526062751616407 train_acc 0.8350692317118\n",
      "epoch 481 lr 0.19106393273933253\n",
      "train_loss 0.37511400035038506 train_acc 0.8350079647102071\n",
      "epoch 482 lr 0.19068218674709478\n",
      "train_loss 0.3749698000695203 train_acc 0.835130498713393\n",
      "epoch 483 lr 0.19030120348385823\n",
      "train_loss 0.37482831232852354 train_acc 0.8350998652125965\n",
      "epoch 484 lr 0.18992098142568936\n",
      "train_loss 0.3746892874453318 train_acc 0.8351611322141894\n",
      "epoch 485 lr 0.18954151905169941\n",
      "train_loss 0.3745525631829155 train_acc 0.835130498713393\n",
      "epoch 486 lr 0.1891628148440384\n",
      "train_loss 0.3744180303766929 train_acc 0.8351917657149859\n",
      "epoch 487 lr 0.18878486728788899\n",
      "train_loss 0.37428585232513134 train_acc 0.8351458154637912\n",
      "epoch 488 lr 0.18840767487146046\n",
      "train_loss 0.3741557148029692 train_acc 0.835268349466977\n",
      "epoch 489 lr 0.18803123608598257\n",
      "train_loss 0.37402714816442273 train_acc 0.8354521504717559\n",
      "epoch 490 lr 0.18765554942569979\n",
      "train_loss 0.37389998816852493 train_acc 0.8355134174733488\n",
      "epoch 491 lr 0.1872806133878649\n",
      "train_loss 0.37377436295927463 train_acc 0.8356359514765347\n",
      "epoch 492 lr 0.18690642647273326\n",
      "train_loss 0.3736502708306093 train_acc 0.8357278519789242\n",
      "epoch 493 lr 0.1865329871835567\n",
      "train_loss 0.3735279431466673 train_acc 0.8357738022301189\n",
      "epoch 494 lr 0.18616029402657763\n",
      "train_loss 0.37340740392979915 train_acc 0.835911652983703\n",
      "epoch 495 lr 0.18578834551102286\n",
      "train_loss 0.37328864123698696 train_acc 0.8359422864844994\n",
      "epoch 496 lr 0.18541714014909785\n",
      "train_loss 0.3731715399890161 train_acc 0.8360341869868889\n",
      "epoch 497 lr 0.18504667645598066\n",
      "train_loss 0.37305607820159775 train_acc 0.836172037740473\n",
      "epoch 498 lr 0.184676952949816\n",
      "train_loss 0.3729420295250878 train_acc 0.8362179879916677\n",
      "epoch 499 lr 0.18430796815170944\n",
      "train_loss 0.3728296704288247 train_acc 0.8363405219948535\n",
      "\n",
      "val loss = 0.3862161702853968, \n",
      "val acc = 0.8249483115093039\n",
      "\n",
      "epoch 500 lr 0.1839397205857212\n",
      "train_loss 0.37271874640950925 train_acc 0.836432422497243\n",
      "epoch 501 lr 0.18357220877886052\n",
      "train_loss 0.3726090270668276 train_acc 0.836493689498836\n",
      "epoch 502 lr 0.18320543126107974\n",
      "train_loss 0.37250065098327695 train_acc 0.83663154025242\n",
      "epoch 503 lr 0.1828393865652683\n",
      "train_loss 0.37239368532704736 train_acc 0.8366468570028183\n",
      "epoch 504 lr 0.18247407322724687\n",
      "train_loss 0.37228808241812794 train_acc 0.836692807254013\n",
      "epoch 505 lr 0.18210948978576166\n",
      "train_loss 0.37218384538740246 train_acc 0.8367540742556059\n",
      "epoch 506 lr 0.18174563478247843\n",
      "train_loss 0.3720805003217914 train_acc 0.8368000245068007\n",
      "epoch 507 lr 0.18138250676197665\n",
      "train_loss 0.37197805316382293 train_acc 0.8367081240044112\n",
      "epoch 508 lr 0.18102010427174375\n",
      "train_loss 0.37187677900059096 train_acc 0.8367693910060041\n",
      "epoch 509 lr 0.1806584258621693\n",
      "train_loss 0.3717764452208606 train_acc 0.8367387575052077\n",
      "epoch 510 lr 0.18029747008653915\n",
      "train_loss 0.3716772280753213 train_acc 0.8367693910060041\n",
      "epoch 511 lr 0.17993723550102977\n",
      "train_loss 0.37157924492708394 train_acc 0.8368766082587918\n",
      "epoch 512 lr 0.17957772066470232\n",
      "train_loss 0.3714824105188542 train_acc 0.8368306580075972\n",
      "epoch 513 lr 0.17921892413949694\n",
      "train_loss 0.371386537216216 train_acc 0.8368612915083936\n",
      "epoch 514 lr 0.1788608444902271\n",
      "train_loss 0.37129159051814925 train_acc 0.8369378752603848\n",
      "epoch 515 lr 0.1785034802845737\n",
      "train_loss 0.37119756277013893 train_acc 0.8369072417595883\n",
      "epoch 516 lr 0.17814683009307944\n",
      "train_loss 0.37110455063047176 train_acc 0.8369225585099865\n",
      "epoch 517 lr 0.17779089248914307\n",
      "train_loss 0.37101248219922595 train_acc 0.8369991422619777\n",
      "epoch 518 lr 0.1774356660490137\n",
      "train_loss 0.37092130566439546 train_acc 0.8371369930155618\n",
      "epoch 519 lr 0.17708114935178515\n",
      "train_loss 0.3708310340716454 train_acc 0.8372288935179513\n",
      "epoch 520 lr 0.17672734097939005\n",
      "train_loss 0.37074152977116687 train_acc 0.8373514275211371\n",
      "epoch 521 lr 0.17637423951659456\n",
      "train_loss 0.3706528154519216 train_acc 0.8374433280235265\n",
      "epoch 522 lr 0.1760218435509923\n",
      "train_loss 0.37056505493457353 train_acc 0.837473961524323\n",
      "epoch 523 lr 0.1756701516729989\n",
      "train_loss 0.37047819563055095 train_acc 0.837473961524323\n",
      "epoch 524 lr 0.17531916247584645\n",
      "train_loss 0.37039211454984594 train_acc 0.8374586447739247\n",
      "epoch 525 lr 0.17496887455557766\n",
      "train_loss 0.37030659028588414 train_acc 0.8375352285259159\n",
      "epoch 526 lr 0.1746192865110404\n",
      "train_loss 0.3702219387341408 train_acc 0.8374586447739247\n",
      "epoch 527 lr 0.17427039694388197\n",
      "train_loss 0.37013799760197463 train_acc 0.8375352285259159\n",
      "epoch 528 lr 0.1739222044585437\n",
      "train_loss 0.370054748068546 train_acc 0.8376883960298983\n",
      "epoch 529 lr 0.17357470766225516\n",
      "train_loss 0.36997204635208364 train_acc 0.8377802965322877\n",
      "epoch 530 lr 0.1732279051650287\n",
      "train_loss 0.369889959596146 train_acc 0.8379028305354735\n",
      "epoch 531 lr 0.17288179557965389\n",
      "train_loss 0.3698084243771418 train_acc 0.8378568802842788\n",
      "epoch 532 lr 0.17253637752169187\n",
      "train_loss 0.369727597054121 train_acc 0.8379181472858719\n",
      "epoch 533 lr 0.17219164960947\n",
      "train_loss 0.3696474563341439 train_acc 0.8379334640362701\n",
      "epoch 534 lr 0.17184761046407618\n",
      "train_loss 0.369567816627602 train_acc 0.8379181472858719\n",
      "epoch 535 lr 0.17150425870935332\n",
      "train_loss 0.36948896543320153 train_acc 0.8378568802842788\n",
      "epoch 536 lr 0.17116159297189398\n",
      "train_loss 0.3694106992403274 train_acc 0.8378109300330842\n",
      "epoch 537 lr 0.17081961188103473\n",
      "train_loss 0.36933297156208084 train_acc 0.8378875137850753\n",
      "epoch 538 lr 0.17047831406885078\n",
      "train_loss 0.3692558228811395 train_acc 0.8379181472858719\n",
      "epoch 539 lr 0.1701376981701504\n",
      "train_loss 0.36917890968681655 train_acc 0.8379640975370666\n",
      "epoch 540 lr 0.16979776282246956\n",
      "train_loss 0.36910248824491626 train_acc 0.8380100477882613\n",
      "epoch 541 lr 0.1694585066660664\n",
      "train_loss 0.3690267722150525 train_acc 0.8381019482906507\n",
      "epoch 542 lr 0.16911992834391587\n",
      "train_loss 0.36895173578870194 train_acc 0.8380713147898542\n",
      "epoch 543 lr 0.16878202650170418\n",
      "train_loss 0.3688771256475144 train_acc 0.8381019482906507\n",
      "epoch 544 lr 0.16844479978782353\n",
      "train_loss 0.36880305967891647 train_acc 0.83819384879304\n",
      "epoch 545 lr 0.16810824685336664\n",
      "train_loss 0.3687295147191659 train_acc 0.838255115794633\n",
      "epoch 546 lr 0.16777236635212134\n",
      "train_loss 0.36865640461046445 train_acc 0.8381785320426418\n",
      "epoch 547 lr 0.1674371569405651\n",
      "train_loss 0.36858372562186437 train_acc 0.838255115794633\n",
      "epoch 548 lr 0.16710261727785988\n",
      "train_loss 0.3685115777174892 train_acc 0.838255115794633\n",
      "epoch 549 lr 0.1667687460258466\n",
      "train_loss 0.36843999588833415 train_acc 0.8383776497978189\n",
      "\n",
      "val loss = 0.3824011946821947, \n",
      "val acc = 0.8268780151619572\n",
      "\n",
      "epoch 550 lr 0.16643554184903978\n",
      "train_loss 0.36836882564526613 train_acc 0.8385308173018012\n",
      "epoch 551 lr 0.16610300341462225\n",
      "train_loss 0.3682980458837736 train_acc 0.8386074010537924\n",
      "epoch 552 lr 0.16577112939243985\n",
      "train_loss 0.3682276412569465 train_acc 0.8386533513049871\n",
      "epoch 553 lr 0.16543991845499603\n",
      "train_loss 0.3681577407191993 train_acc 0.8386533513049871\n",
      "epoch 554 lr 0.16510936927744665\n",
      "train_loss 0.36808827362503377 train_acc 0.8386839848057837\n",
      "epoch 555 lr 0.1647794805375945\n",
      "train_loss 0.36801918606625644 train_acc 0.8387605685577748\n",
      "epoch 556 lr 0.16445025091588422\n",
      "train_loss 0.36795058339587355 train_acc 0.8387912020585713\n",
      "epoch 557 lr 0.16412167909539688\n",
      "train_loss 0.367882545973753 train_acc 0.8387912020585713\n",
      "epoch 558 lr 0.16379376376184474\n",
      "train_loss 0.3678149939685116 train_acc 0.8387146183065801\n",
      "epoch 559 lr 0.16346650360356604\n",
      "train_loss 0.3677477299912568 train_acc 0.8387912020585713\n",
      "epoch 560 lr 0.16313989731151973\n",
      "train_loss 0.36768076245354325 train_acc 0.8387452518073766\n",
      "epoch 561 lr 0.16281394357928017\n",
      "train_loss 0.36761406221658083 train_acc 0.8387452518073766\n",
      "epoch 562 lr 0.162488641103032\n",
      "train_loss 0.3675478978396556 train_acc 0.8387299350569783\n",
      "epoch 563 lr 0.16216398858156494\n",
      "train_loss 0.3674820766218941 train_acc 0.8386686680553854\n",
      "epoch 564 lr 0.1618399847162684\n",
      "train_loss 0.36741669684990996 train_acc 0.8386839848057837\n",
      "epoch 565 lr 0.1615166282111265\n",
      "train_loss 0.3673514317829065 train_acc 0.8388218355593677\n",
      "epoch 566 lr 0.16119391777271277\n",
      "train_loss 0.36728626791728336 train_acc 0.8389443695625536\n",
      "epoch 567 lr 0.1608718521101851\n",
      "train_loss 0.36722118442948454 train_acc 0.8389443695625536\n",
      "epoch 568 lr 0.16055042993528035\n",
      "train_loss 0.367156340515885 train_acc 0.839036270064943\n",
      "epoch 569 lr 0.1602296499623094\n",
      "train_loss 0.3670918712949451 train_acc 0.8390056365641465\n",
      "epoch 570 lr 0.15990951090815195\n",
      "train_loss 0.3670278248108661 train_acc 0.8391741208185272\n",
      "epoch 571 lr 0.15959001149225135\n",
      "train_loss 0.3669640126239006 train_acc 0.8392507045705183\n",
      "epoch 572 lr 0.1592711504366095\n",
      "train_loss 0.3669004309448121 train_acc 0.8392660213209165\n",
      "epoch 573 lr 0.15895292646578177\n",
      "train_loss 0.3668369977147726 train_acc 0.839296654821713\n",
      "epoch 574 lr 0.15863533830687182\n",
      "train_loss 0.3667739230398779 train_acc 0.839296654821713\n",
      "epoch 575 lr 0.1583183846895266\n",
      "train_loss 0.36671111819083174 train_acc 0.8392660213209165\n",
      "epoch 576 lr 0.15800206434593128\n",
      "train_loss 0.366648558253161 train_acc 0.8393119715721112\n",
      "epoch 577 lr 0.15768637601080396\n",
      "train_loss 0.3665864721837502 train_acc 0.8393426050729077\n",
      "epoch 578 lr 0.15737131842139096\n",
      "train_loss 0.3665246624646878 train_acc 0.8393426050729077\n",
      "epoch 579 lr 0.15705689031746148\n",
      "train_loss 0.3664632628527247 train_acc 0.8394498223256954\n",
      "epoch 580 lr 0.15674309044130266\n",
      "train_loss 0.3664021047001392 train_acc 0.8394804558264919\n",
      "epoch 581 lr 0.1564299175377146\n",
      "train_loss 0.3663412221802594 train_acc 0.8395110893272884\n",
      "epoch 582 lr 0.15611737035400527\n",
      "train_loss 0.366280586040314 train_acc 0.8395264060776866\n",
      "epoch 583 lr 0.15580544763998552\n",
      "train_loss 0.3662201897341419 train_acc 0.839557039578483\n",
      "epoch 584 lr 0.15549414814796406\n",
      "train_loss 0.36616000056686066 train_acc 0.8395876730792795\n",
      "epoch 585 lr 0.15518347063274252\n",
      "train_loss 0.36610010983811975 train_acc 0.8396795735816689\n",
      "epoch 586 lr 0.1548734138516104\n",
      "train_loss 0.36604071758790824 train_acc 0.8396948903320671\n",
      "epoch 587 lr 0.15456397656434023\n",
      "train_loss 0.36598184496183944 train_acc 0.8396642568312707\n",
      "epoch 588 lr 0.15425515753318236\n",
      "train_loss 0.3659232319677348 train_acc 0.8397102070824654\n",
      "epoch 589 lr 0.1539469555228603\n",
      "train_loss 0.3658649880409058 train_acc 0.83975615733366\n",
      "epoch 590 lr 0.15363936930056563\n",
      "train_loss 0.365807045431806 train_acc 0.83975615733366\n",
      "epoch 591 lr 0.153332397635953\n",
      "train_loss 0.36574916989556755 train_acc 0.83975615733366\n",
      "epoch 592 lr 0.15302603930113534\n",
      "train_loss 0.36569152739019656 train_acc 0.8399093248376425\n",
      "epoch 593 lr 0.15272029307067891\n",
      "train_loss 0.36563432540868546 train_acc 0.8399246415880407\n",
      "epoch 594 lr 0.15241515772159842\n",
      "train_loss 0.3655775741235625 train_acc 0.8399399583384389\n",
      "epoch 595 lr 0.15211063203335204\n",
      "train_loss 0.36552109545783334 train_acc 0.8399859085896336\n",
      "epoch 596 lr 0.15180671478783658\n",
      "train_loss 0.3654650212994417 train_acc 0.8400624923416248\n",
      "epoch 597 lr 0.1515034047693827\n",
      "train_loss 0.36540923770607214 train_acc 0.8401237593432177\n",
      "epoch 598 lr 0.1512007007647499\n",
      "train_loss 0.3653537053388828 train_acc 0.840200343095209\n",
      "epoch 599 lr 0.15089860156312174\n",
      "train_loss 0.3652985404314343 train_acc 0.8402922435975984\n",
      "\n",
      "val loss = 0.37986024961258835, \n",
      "val acc = 0.8277050310130944\n",
      "\n",
      "epoch 600 lr 0.15059710595610104\n",
      "train_loss 0.36524354762082006 train_acc 0.8403075603479966\n",
      "epoch 601 lr 0.15029621273770497\n",
      "train_loss 0.3651887673655268 train_acc 0.840338193848793\n",
      "epoch 602 lr 0.14999592070436024\n",
      "train_loss 0.36513427440511403 train_acc 0.8404147776007842\n",
      "epoch 603 lr 0.14969622865489834\n",
      "train_loss 0.3650799467496665 train_acc 0.8404147776007842\n",
      "epoch 604 lr 0.14939713539055063\n",
      "train_loss 0.3650256868618993 train_acc 0.8404300943511824\n",
      "epoch 605 lr 0.1490986397149437\n",
      "train_loss 0.36497156827286675 train_acc 0.8404300943511824\n",
      "epoch 606 lr 0.14880074043409441\n",
      "train_loss 0.3649178231861899 train_acc 0.8404913613527754\n",
      "epoch 607 lr 0.14850343635640526\n",
      "train_loss 0.36486442711403666 train_acc 0.8405526283543684\n",
      "epoch 608 lr 0.14820672629265955\n",
      "train_loss 0.3648114161554349 train_acc 0.8405832618551649\n",
      "epoch 609 lr 0.1479106090560166\n",
      "train_loss 0.36475840726757897 train_acc 0.8405985786055631\n",
      "epoch 610 lr 0.1476150834620071\n",
      "train_loss 0.36470536413684507 train_acc 0.8406292121063595\n",
      "epoch 611 lr 0.14732014832852827\n",
      "train_loss 0.36465261132728366 train_acc 0.8407364293591472\n",
      "epoch 612 lr 0.14702580247583918\n",
      "train_loss 0.36460009302451357 train_acc 0.8407976963607401\n",
      "epoch 613 lr 0.14673204472655602\n",
      "train_loss 0.36454756886923045 train_acc 0.8407670628599436\n",
      "epoch 614 lr 0.14643887390564742\n",
      "train_loss 0.3644951213377626 train_acc 0.8407976963607401\n",
      "epoch 615 lr 0.14614628884042968\n",
      "train_loss 0.36444279655357226 train_acc 0.8408130131111383\n",
      "epoch 616 lr 0.1458542883605622\n",
      "train_loss 0.36439097359921196 train_acc 0.8408895968631295\n",
      "epoch 617 lr 0.1455628712980426\n",
      "train_loss 0.3643395061612393 train_acc 0.8409508638647225\n",
      "epoch 618 lr 0.14527203648720227\n",
      "train_loss 0.3642882907217488 train_acc 0.8409661806151207\n",
      "epoch 619 lr 0.1449817827647016\n",
      "train_loss 0.36423729455124504 train_acc 0.840981497365519\n",
      "epoch 620 lr 0.1446921089695253\n",
      "train_loss 0.36418644983764453 train_acc 0.840981497365519\n",
      "epoch 621 lr 0.1444030139429778\n",
      "train_loss 0.3641358237458638 train_acc 0.8409968141159172\n",
      "epoch 622 lr 0.1441144965286786\n",
      "train_loss 0.3640853821081981 train_acc 0.8410580811175101\n",
      "epoch 623 lr 0.1438265555725577\n",
      "train_loss 0.3640351133042713 train_acc 0.8410733978679084\n",
      "epoch 624 lr 0.14353918992285084\n",
      "train_loss 0.3639850282412641 train_acc 0.8410580811175101\n",
      "epoch 625 lr 0.14325239843009505\n",
      "train_loss 0.3639350876174384 train_acc 0.8410427643671119\n",
      "epoch 626 lr 0.14296617994712396\n",
      "train_loss 0.36388536645575825 train_acc 0.8411499816198995\n",
      "epoch 627 lr 0.14268053332906333\n",
      "train_loss 0.36383554874961505 train_acc 0.8412112486214924\n",
      "epoch 628 lr 0.1423954574333262\n",
      "train_loss 0.3637857670642543 train_acc 0.8412418821222889\n",
      "epoch 629 lr 0.14211095111960875\n",
      "train_loss 0.3637359969203079 train_acc 0.8412112486214924\n",
      "epoch 630 lr 0.1418270132498852\n",
      "train_loss 0.36368629768886723 train_acc 0.8412725156230854\n",
      "epoch 631 lr 0.14154364268840375\n",
      "train_loss 0.3636366759687143 train_acc 0.8412878323734836\n",
      "epoch 632 lr 0.1412608383016818\n",
      "train_loss 0.3635871682828629 train_acc 0.8413031491238819\n",
      "epoch 633 lr 0.14097859895850137\n",
      "train_loss 0.3635374235486404 train_acc 0.8412878323734836\n",
      "epoch 634 lr 0.14069692352990476\n",
      "train_loss 0.36348781798266194 train_acc 0.8413490993750766\n",
      "epoch 635 lr 0.1404158108891899\n",
      "train_loss 0.36343838010471036 train_acc 0.8413950496262713\n",
      "epoch 636 lr 0.14013525991190579\n",
      "train_loss 0.36338902889451163 train_acc 0.841440999877466\n",
      "epoch 637 lr 0.13985526947584817\n",
      "train_loss 0.36333985011148806 train_acc 0.8414256831270678\n",
      "epoch 638 lr 0.13957583846105492\n",
      "train_loss 0.3632908890657546 train_acc 0.8414103663766695\n",
      "epoch 639 lr 0.13929696574980163\n",
      "train_loss 0.36324218417395365 train_acc 0.8413797328758731\n",
      "epoch 640 lr 0.13901865022659707\n",
      "train_loss 0.3631935041942704 train_acc 0.8413797328758731\n",
      "epoch 641 lr 0.13874089077817878\n",
      "train_loss 0.36314488607194756 train_acc 0.8414103663766695\n",
      "epoch 642 lr 0.13846368629350858\n",
      "train_loss 0.3630964583135842 train_acc 0.8414256831270678\n",
      "epoch 643 lr 0.13818703566376817\n",
      "train_loss 0.36304824156588406 train_acc 0.8415022668790589\n",
      "epoch 644 lr 0.13791093778235466\n",
      "train_loss 0.363000127125996 train_acc 0.8415788506310501\n",
      "epoch 645 lr 0.13763539154487617\n",
      "train_loss 0.3629522424662516 train_acc 0.8416860678838378\n",
      "epoch 646 lr 0.13736039584914736\n",
      "train_loss 0.3629044558899372 train_acc 0.8417473348854307\n",
      "epoch 647 lr 0.1370859495951851\n",
      "train_loss 0.36285677317417725 train_acc 0.8418086018870237\n",
      "epoch 648 lr 0.13681205168520402\n",
      "train_loss 0.3628091661448869 train_acc 0.8419158191398113\n",
      "epoch 649 lr 0.1365387010236121\n",
      "train_loss 0.362761854247378 train_acc 0.8419464526406077\n",
      "\n",
      "val loss = 0.37790477788827853, \n",
      "val acc = 0.8277050310130944\n",
      "\n",
      "epoch 650 lr 0.1362658965170063\n",
      "train_loss 0.3627146963283414 train_acc 0.8419924028918024\n",
      "epoch 651 lr 0.13599363707416826\n",
      "train_loss 0.3626674425369778 train_acc 0.8420230363925989\n",
      "epoch 652 lr 0.13572192160605984\n",
      "train_loss 0.3626201744773316 train_acc 0.8419924028918024\n",
      "epoch 653 lr 0.13545074902581883\n",
      "train_loss 0.3625730682669685 train_acc 0.841961769391006\n",
      "epoch 654 lr 0.1351801182487545\n",
      "train_loss 0.3625260696716206 train_acc 0.841900502389413\n",
      "epoch 655 lr 0.1349100281923434\n",
      "train_loss 0.36247930155584385 train_acc 0.8419311358902095\n",
      "epoch 656 lr 0.13464047777622498\n",
      "train_loss 0.3624326081413132 train_acc 0.8419464526406077\n",
      "epoch 657 lr 0.13437146592219718\n",
      "train_loss 0.36238598927942195 train_acc 0.8420077196422007\n",
      "epoch 658 lr 0.1341029915542122\n",
      "train_loss 0.36233932968757937 train_acc 0.8420230363925989\n",
      "epoch 659 lr 0.13383505359837228\n",
      "train_loss 0.3622927151019683 train_acc 0.8419770861414042\n",
      "epoch 660 lr 0.13356765098292517\n",
      "train_loss 0.3622461767414724 train_acc 0.841961769391006\n",
      "epoch 661 lr 0.1333007826382601\n",
      "train_loss 0.3621996866752279 train_acc 0.8419770861414042\n",
      "epoch 662 lr 0.1330344474969033\n",
      "train_loss 0.3621533730979135 train_acc 0.841961769391006\n",
      "epoch 663 lr 0.1327686444935139\n",
      "train_loss 0.36210719154911336 train_acc 0.8419924028918024\n",
      "epoch 664 lr 0.13250337256487946\n",
      "train_loss 0.36206096956204536 train_acc 0.841961769391006\n",
      "epoch 665 lr 0.13223863064991195\n",
      "train_loss 0.3620148516638978 train_acc 0.8419464526406077\n",
      "epoch 666 lr 0.13197441768964338\n",
      "train_loss 0.361969060417276 train_acc 0.8419770861414042\n",
      "epoch 667 lr 0.13171073262722155\n",
      "train_loss 0.3619235088810682 train_acc 0.8419770861414042\n",
      "epoch 668 lr 0.1314475744079058\n",
      "train_loss 0.36187824317868705 train_acc 0.8420689866437937\n",
      "epoch 669 lr 0.13118494197906297\n",
      "train_loss 0.36183316874190175 train_acc 0.8421149368949884\n",
      "epoch 670 lr 0.13092283429016296\n",
      "train_loss 0.3617882149000268 train_acc 0.8421302536453866\n",
      "epoch 671 lr 0.1306612502927747\n",
      "train_loss 0.36174336529332973 train_acc 0.8420689866437937\n",
      "epoch 672 lr 0.13040018894056182\n",
      "train_loss 0.3616984505592494 train_acc 0.8420843033941919\n",
      "epoch 673 lr 0.13013964918927856\n",
      "train_loss 0.36165364608573186 train_acc 0.8420536698933954\n",
      "epoch 674 lr 0.12987962999676558\n",
      "train_loss 0.36160893930060506 train_acc 0.8421302536453866\n",
      "epoch 675 lr 0.12962013032294575\n",
      "train_loss 0.3615642573657353 train_acc 0.8421455703957849\n",
      "epoch 676 lr 0.12936114912982002\n",
      "train_loss 0.36151977965703036 train_acc 0.8422068373973778\n",
      "epoch 677 lr 0.12910268538146333\n",
      "train_loss 0.3614754393436586 train_acc 0.8421455703957849\n",
      "epoch 678 lr 0.12884473804402027\n",
      "train_loss 0.36143133855317156 train_acc 0.8421762038965813\n",
      "epoch 679 lr 0.1285873060857012\n",
      "train_loss 0.36138725289517976 train_acc 0.8420996201445902\n",
      "epoch 680 lr 0.12833038847677794\n",
      "train_loss 0.36134311764514926 train_acc 0.8421149368949884\n",
      "epoch 681 lr 0.12807398418957966\n",
      "train_loss 0.36129943780243456 train_acc 0.8421762038965813\n",
      "epoch 682 lr 0.12781809219848891\n",
      "train_loss 0.3612561601974659 train_acc 0.8421762038965813\n",
      "epoch 683 lr 0.1275627114799374\n",
      "train_loss 0.36121289194696166 train_acc 0.8422987378997672\n",
      "epoch 684 lr 0.12730784101240186\n",
      "train_loss 0.36116966939366735 train_acc 0.8423753216517583\n",
      "epoch 685 lr 0.12705347977640014\n",
      "train_loss 0.3611265967542605 train_acc 0.8424059551525548\n",
      "epoch 686 lr 0.12679962675448692\n",
      "train_loss 0.36108359171703985 train_acc 0.8424519054037496\n",
      "epoch 687 lr 0.12654628093124978\n",
      "train_loss 0.3610407307141867 train_acc 0.8424672221541478\n",
      "epoch 688 lr 0.12629344129330514\n",
      "train_loss 0.36099795493296855 train_acc 0.842543805906139\n",
      "epoch 689 lr 0.126041106829294\n",
      "train_loss 0.3609552848671329 train_acc 0.8425591226565372\n",
      "epoch 690 lr 0.12578927652987826\n",
      "train_loss 0.3609126156475814 train_acc 0.8425897561573337\n",
      "epoch 691 lr 0.12553794938773635\n",
      "train_loss 0.3608701527358774 train_acc 0.8426510231589266\n",
      "epoch 692 lr 0.1252871243975594\n",
      "train_loss 0.36082799552457273 train_acc 0.842681656659723\n",
      "epoch 693 lr 0.12503680055604707\n",
      "train_loss 0.36078585349391645 train_acc 0.8427122901605195\n",
      "epoch 694 lr 0.12478697686190368\n",
      "train_loss 0.36074398751324066 train_acc 0.8427735571621124\n",
      "epoch 695 lr 0.12453765231583412\n",
      "train_loss 0.36070223134843554 train_acc 0.842742923661316\n",
      "epoch 696 lr 0.12428882592053987\n",
      "train_loss 0.3606602547749256 train_acc 0.842742923661316\n",
      "epoch 697 lr 0.12404049668071501\n",
      "train_loss 0.36061818125693107 train_acc 0.8427735571621124\n",
      "epoch 698 lr 0.12379266360304228\n",
      "train_loss 0.36057607972832 train_acc 0.8428041906629089\n",
      "epoch 699 lr 0.123545325696189\n",
      "train_loss 0.36053406215332956 train_acc 0.842742923661316\n",
      "\n",
      "val loss = 0.3763522839328683, \n",
      "val acc = 0.8283942108890421\n",
      "\n",
      "epoch 700 lr 0.12329848197080326\n",
      "train_loss 0.3604921302484858 train_acc 0.842742923661316\n",
      "epoch 701 lr 0.12305213143950978\n",
      "train_loss 0.36045041251476284 train_acc 0.8428501409141037\n",
      "epoch 702 lr 0.12280627311690613\n",
      "train_loss 0.36040875714461507 train_acc 0.8429267246660949\n",
      "epoch 703 lr 0.1225609060195587\n",
      "train_loss 0.3603672476079782 train_acc 0.8429573581668913\n",
      "epoch 704 lr 0.12231602916599875\n",
      "train_loss 0.3603258037668773 train_acc 0.8429879916676878\n",
      "epoch 705 lr 0.12207164157671856\n",
      "train_loss 0.36028433863964043 train_acc 0.8430186251684842\n",
      "epoch 706 lr 0.12182774227416744\n",
      "train_loss 0.36024300450724606 train_acc 0.843003308418086\n",
      "epoch 707 lr 0.12158433028274784\n",
      "train_loss 0.36020174163585433 train_acc 0.8430492586692807\n",
      "epoch 708 lr 0.1213414046288115\n",
      "train_loss 0.36016071043666786 train_acc 0.8430492586692807\n",
      "epoch 709 lr 0.12109896434065545\n",
      "train_loss 0.3601200006384961 train_acc 0.8430645754196789\n",
      "epoch 710 lr 0.12085700844851824\n",
      "train_loss 0.3600793659969959 train_acc 0.8430798921700772\n",
      "epoch 711 lr 0.12061553598457596\n",
      "train_loss 0.3600389509935792 train_acc 0.8430952089204754\n",
      "epoch 712 lr 0.12037454598293844\n",
      "train_loss 0.35999860443547815 train_acc 0.8431411591716701\n",
      "epoch 713 lr 0.12013403747964535\n",
      "train_loss 0.3599584156873972 train_acc 0.8432024261732631\n",
      "epoch 714 lr 0.11989400951266237\n",
      "train_loss 0.35991834538696954 train_acc 0.8432024261732631\n",
      "epoch 715 lr 0.11965446112187728\n",
      "train_loss 0.3598782700712615 train_acc 0.8432483764244578\n",
      "epoch 716 lr 0.11941539134909622\n",
      "train_loss 0.35983831701868885 train_acc 0.8432483764244578\n",
      "epoch 717 lr 0.11917679923803978\n",
      "train_loss 0.3597985382132732 train_acc 0.8432483764244578\n",
      "epoch 718 lr 0.1189386838343392\n",
      "train_loss 0.3597589121372108 train_acc 0.8432177429236614\n",
      "epoch 719 lr 0.11870104418553254\n",
      "train_loss 0.3597192344758499 train_acc 0.8432177429236614\n",
      "epoch 720 lr 0.11846387934106088\n",
      "train_loss 0.3596793923478353 train_acc 0.8433096434260507\n",
      "epoch 721 lr 0.11822718835226455\n",
      "train_loss 0.35963960847417303 train_acc 0.8433402769268472\n",
      "epoch 722 lr 0.11799097027237926\n",
      "train_loss 0.35959996732997346 train_acc 0.8433709104276437\n",
      "epoch 723 lr 0.11775522415653238\n",
      "train_loss 0.35956045817985016 train_acc 0.8433862271780419\n",
      "epoch 724 lr 0.11751994906173914\n",
      "train_loss 0.3595210555679216 train_acc 0.8434628109300331\n",
      "epoch 725 lr 0.11728514404689884\n",
      "train_loss 0.35948170448489464 train_acc 0.8434168606788384\n",
      "epoch 726 lr 0.1170508081727911\n",
      "train_loss 0.3594424464259762 train_acc 0.8434321774292366\n",
      "epoch 727 lr 0.11681694050207211\n",
      "train_loss 0.3594035118229698 train_acc 0.8434628109300331\n",
      "epoch 728 lr 0.1165835400992709\n",
      "train_loss 0.3593647526673668 train_acc 0.8434015439284401\n",
      "epoch 729 lr 0.11635060603078552\n",
      "train_loss 0.3593261215557081 train_acc 0.8433862271780419\n",
      "epoch 730 lr 0.11611813736487941\n",
      "train_loss 0.3592874997105154 train_acc 0.8433862271780419\n",
      "epoch 731 lr 0.11588613317167758\n",
      "train_loss 0.3592488851187464 train_acc 0.8434474941796348\n",
      "epoch 732 lr 0.11565459252316296\n",
      "train_loss 0.3592105667125372 train_acc 0.8434168606788384\n",
      "epoch 733 lr 0.11542351449317262\n",
      "train_loss 0.35917244379460334 train_acc 0.8434934444308295\n",
      "epoch 734 lr 0.11519289815739416\n",
      "train_loss 0.3591345756342957 train_acc 0.8435087611812278\n",
      "epoch 735 lr 0.11496274259336192\n",
      "train_loss 0.35909679698068153 train_acc 0.8435087611812278\n",
      "epoch 736 lr 0.11473304688045334\n",
      "train_loss 0.3590589348902787 train_acc 0.843524077931626\n",
      "epoch 737 lr 0.11450381009988526\n",
      "train_loss 0.3590212952522432 train_acc 0.8435547114324224\n",
      "epoch 738 lr 0.11427503133471024\n",
      "train_loss 0.3589838022866502 train_acc 0.8435700281828208\n",
      "epoch 739 lr 0.11404670966981294\n",
      "train_loss 0.358946319964918 train_acc 0.8435547114324224\n",
      "epoch 740 lr 0.11381884419190637\n",
      "train_loss 0.35890878790881225 train_acc 0.8435087611812278\n",
      "epoch 741 lr 0.11359143398952833\n",
      "train_loss 0.35887128550939557 train_acc 0.8435393946820242\n",
      "epoch 742 lr 0.1133644781530377\n",
      "train_loss 0.3588336150755358 train_acc 0.843585344933219\n",
      "epoch 743 lr 0.11313797577461085\n",
      "train_loss 0.3587959923421956 train_acc 0.843585344933219\n",
      "epoch 744 lr 0.11291192594823793\n",
      "train_loss 0.35875846796846644 train_acc 0.8436466119348119\n",
      "epoch 745 lr 0.11268632776971936\n",
      "train_loss 0.35872109856519485 train_acc 0.8436925621860066\n",
      "epoch 746 lr 0.11246118033666212\n",
      "train_loss 0.358683734233974 train_acc 0.8436312951844137\n",
      "epoch 747 lr 0.11223648274847618\n",
      "train_loss 0.3586464360902894 train_acc 0.8436772454356084\n",
      "epoch 748 lr 0.11201223410637087\n",
      "train_loss 0.35860931144271585 train_acc 0.8437538291875996\n",
      "epoch 749 lr 0.11178843351335134\n",
      "train_loss 0.35857237757977006 train_acc 0.8437691459379978\n",
      "\n",
      "val loss = 0.37498354589306065, \n",
      "val acc = 0.830737422467264\n",
      "\n",
      "epoch 750 lr 0.11156508007421491\n",
      "train_loss 0.35853536246771694 train_acc 0.843784462688396\n",
      "epoch 751 lr 0.11134217289554754\n",
      "train_loss 0.3584982747178986 train_acc 0.8438150961891925\n",
      "epoch 752 lr 0.1111197110857202\n",
      "train_loss 0.35846112282740605 train_acc 0.8438304129395907\n",
      "epoch 753 lr 0.11089769375488537\n",
      "train_loss 0.3584239289938567 train_acc 0.8438763631907854\n",
      "epoch 754 lr 0.11067612001497341\n",
      "train_loss 0.35838689355688363 train_acc 0.8438610464403872\n",
      "epoch 755 lr 0.1104549889796891\n",
      "train_loss 0.3583500817438739 train_acc 0.8438304129395907\n",
      "epoch 756 lr 0.11023429976450796\n",
      "train_loss 0.35831348956604464 train_acc 0.8438610464403872\n",
      "epoch 757 lr 0.11001405148667287\n",
      "train_loss 0.35827704932848126 train_acc 0.8438304129395907\n",
      "epoch 758 lr 0.10979424326519041\n",
      "train_loss 0.3582407418446761 train_acc 0.8438150961891925\n",
      "epoch 759 lr 0.1095748742208274\n",
      "train_loss 0.3582045008347067 train_acc 0.8438150961891925\n",
      "epoch 760 lr 0.10935594347610737\n",
      "train_loss 0.3581684213465351 train_acc 0.8438304129395907\n",
      "epoch 761 lr 0.10913745015530707\n",
      "train_loss 0.35813266829993795 train_acc 0.8438150961891925\n",
      "epoch 762 lr 0.10891939338445289\n",
      "train_loss 0.35809703651084845 train_acc 0.8438610464403872\n",
      "epoch 763 lr 0.10870177229131747\n",
      "train_loss 0.35806145309916176 train_acc 0.8439223134419801\n",
      "epoch 764 lr 0.10848458600541616\n",
      "train_loss 0.35802613889728524 train_acc 0.8439223134419801\n",
      "epoch 765 lr 0.10826783365800352\n",
      "train_loss 0.3579908545285849 train_acc 0.8439223134419801\n",
      "epoch 766 lr 0.10805151438206988\n",
      "train_loss 0.3579555392250799 train_acc 0.8438916799411836\n",
      "epoch 767 lr 0.10783562731233781\n",
      "train_loss 0.35792022371437776 train_acc 0.8438457296899889\n",
      "epoch 768 lr 0.10762017158525879\n",
      "train_loss 0.35788490447120297 train_acc 0.8438150961891925\n",
      "epoch 769 lr 0.1074051463390096\n",
      "train_loss 0.357849597055087 train_acc 0.8438610464403872\n",
      "epoch 770 lr 0.10719055071348897\n",
      "train_loss 0.35781436248251813 train_acc 0.8438763631907854\n",
      "epoch 771 lr 0.10697638385031412\n",
      "train_loss 0.3577792739900383 train_acc 0.8439069966915819\n",
      "epoch 772 lr 0.1067626448928173\n",
      "train_loss 0.35774445127740867 train_acc 0.8439529469427767\n",
      "epoch 773 lr 0.1065493329860424\n",
      "train_loss 0.3577097288760163 train_acc 0.8439529469427767\n",
      "epoch 774 lr 0.10633644727674152\n",
      "train_loss 0.3576750517289818 train_acc 0.8439835804435731\n",
      "epoch 775 lr 0.10612398691337152\n",
      "train_loss 0.35764057258795234 train_acc 0.8439988971939714\n",
      "epoch 776 lr 0.10591195104609068\n",
      "train_loss 0.35760628374270503 train_acc 0.8440295306947678\n",
      "epoch 777 lr 0.10570033882675522\n",
      "train_loss 0.35757198804548496 train_acc 0.8440142139443696\n",
      "epoch 778 lr 0.10548914940891603\n",
      "train_loss 0.3575374047682204 train_acc 0.8440142139443696\n",
      "epoch 779 lr 0.10527838194781511\n",
      "train_loss 0.3575028221759105 train_acc 0.8440754809459625\n",
      "epoch 780 lr 0.10506803560038236\n",
      "train_loss 0.35746823458523735 train_acc 0.8441367479475554\n",
      "epoch 781 lr 0.1048581095252321\n",
      "train_loss 0.3574338445580915 train_acc 0.8441367479475554\n",
      "epoch 782 lr 0.10464860288265976\n",
      "train_loss 0.3573994771550489 train_acc 0.8441367479475554\n",
      "epoch 783 lr 0.10443951483463847\n",
      "train_loss 0.3573651816545855 train_acc 0.8442592819507413\n",
      "epoch 784 lr 0.10423084454481576\n",
      "train_loss 0.3573309346241326 train_acc 0.8442286484499448\n",
      "epoch 785 lr 0.10402259117851023\n",
      "train_loss 0.35729675460144794 train_acc 0.8442286484499448\n",
      "epoch 786 lr 0.1038147539027081\n",
      "train_loss 0.35726261522146696 train_acc 0.844305232201936\n",
      "epoch 787 lr 0.10360733188606\n",
      "train_loss 0.3572286099084782 train_acc 0.8442899154515378\n",
      "epoch 788 lr 0.10340032429887758\n",
      "train_loss 0.3571947719513763 train_acc 0.8442899154515378\n",
      "epoch 789 lr 0.10319373031313023\n",
      "train_loss 0.35716091490801927 train_acc 0.8443205489523343\n",
      "epoch 790 lr 0.10298754910244173\n",
      "train_loss 0.3571269952411091 train_acc 0.8443818159539273\n",
      "epoch 791 lr 0.10278177984208695\n",
      "train_loss 0.35709314492104427 train_acc 0.8443818159539273\n",
      "epoch 792 lr 0.10257642170898858\n",
      "train_loss 0.3570593635613818 train_acc 0.8443971327043255\n",
      "epoch 793 lr 0.10237147388171382\n",
      "train_loss 0.357025796794954 train_acc 0.8444277662051219\n",
      "epoch 794 lr 0.10216693554047107\n",
      "train_loss 0.356992286114054 train_acc 0.8444583997059184\n",
      "epoch 795 lr 0.10196280586710671\n",
      "train_loss 0.3569588164951677 train_acc 0.8444737164563166\n",
      "epoch 796 lr 0.10175908404510177\n",
      "train_loss 0.3569253503738178 train_acc 0.8444583997059184\n",
      "epoch 797 lr 0.10155576925956869\n",
      "train_loss 0.3568918426631481 train_acc 0.8444737164563166\n",
      "epoch 798 lr 0.10135286069724805\n",
      "train_loss 0.35685849208384296 train_acc 0.8444583997059184\n",
      "epoch 799 lr 0.10115035754650535\n",
      "train_loss 0.35682508356125286 train_acc 0.8444583997059184\n",
      "\n",
      "val loss = 0.37375268136702017, \n",
      "val acc = 0.8312887663680221\n",
      "\n",
      "epoch 800 lr 0.10094825899732769\n",
      "train_loss 0.35679166251077465 train_acc 0.8445503002083078\n",
      "epoch 801 lr 0.10074656424132063\n",
      "train_loss 0.3567582630224615 train_acc 0.8445962504595025\n",
      "epoch 802 lr 0.10054527247170485\n",
      "train_loss 0.3567249334274173 train_acc 0.8445809337091043\n",
      "epoch 803 lr 0.10034438288331303\n",
      "train_loss 0.3566915818113775 train_acc 0.8445503002083078\n",
      "epoch 804 lr 0.10014389467258653\n",
      "train_loss 0.3566583698792779 train_acc 0.8445043499571131\n",
      "epoch 805 lr 0.09994380703757223\n",
      "train_loss 0.3566252630284052 train_acc 0.8445196667075113\n",
      "epoch 806 lr 0.09974411917791937\n",
      "train_loss 0.3565923216767537 train_acc 0.8445349834579096\n",
      "epoch 807 lr 0.0995448302948762\n",
      "train_loss 0.35655947952478784 train_acc 0.844626883960299\n",
      "epoch 808 lr 0.09934593959128692\n",
      "train_loss 0.3565267953049889 train_acc 0.8445962504595025\n",
      "epoch 809 lr 0.09914744627158849\n",
      "train_loss 0.35649426125754424 train_acc 0.8446115672099007\n",
      "epoch 810 lr 0.09894934954180733\n",
      "train_loss 0.3564616786476154 train_acc 0.844626883960299\n",
      "epoch 811 lr 0.09875164860955626\n",
      "train_loss 0.35642901097687885 train_acc 0.8446728342114936\n",
      "epoch 812 lr 0.09855434268403132\n",
      "train_loss 0.3563964198418592 train_acc 0.8447034677122902\n",
      "epoch 813 lr 0.09835743097600853\n",
      "train_loss 0.3563640230898031 train_acc 0.8447341012130867\n",
      "epoch 814 lr 0.09816091269784077\n",
      "train_loss 0.35633171535435104 train_acc 0.8447800514642814\n",
      "epoch 815 lr 0.09796478706345468\n",
      "train_loss 0.35629947171817555 train_acc 0.8447647347138831\n",
      "epoch 816 lr 0.09776905328834747\n",
      "train_loss 0.3562671895490095 train_acc 0.8447800514642814\n",
      "epoch 817 lr 0.09757371058958376\n",
      "train_loss 0.35623503712757615 train_acc 0.8448260017154761\n",
      "epoch 818 lr 0.09737875818579252\n",
      "train_loss 0.35620311030660784 train_acc 0.8448106849650778\n",
      "epoch 819 lr 0.09718419529716385\n",
      "train_loss 0.3561712037132967 train_acc 0.8448566352162725\n",
      "epoch 820 lr 0.09699002114544596\n",
      "train_loss 0.35613925056139584 train_acc 0.8448719519666708\n",
      "epoch 821 lr 0.09679623495394196\n",
      "train_loss 0.3561073139328304 train_acc 0.844887268717069\n",
      "epoch 822 lr 0.09660283594750685\n",
      "train_loss 0.3560754685321992 train_acc 0.8449025854674672\n",
      "epoch 823 lr 0.09640982335254432\n",
      "train_loss 0.35604377226168554 train_acc 0.8448719519666708\n",
      "epoch 824 lr 0.09621719639700377\n",
      "train_loss 0.3560119687883371 train_acc 0.8448566352162725\n",
      "epoch 825 lr 0.09602495431037707\n",
      "train_loss 0.3559802249633488 train_acc 0.844887268717069\n",
      "epoch 826 lr 0.09583309632369566\n",
      "train_loss 0.3559485507155475 train_acc 0.8449179022178654\n",
      "epoch 827 lr 0.0956416216695273\n",
      "train_loss 0.3559170438454142 train_acc 0.8449025854674672\n",
      "epoch 828 lr 0.09545052958197317\n",
      "train_loss 0.35588580841140155 train_acc 0.844887268717069\n",
      "epoch 829 lr 0.09525981929666462\n",
      "train_loss 0.3558546307755107 train_acc 0.8449025854674672\n",
      "epoch 830 lr 0.09506949005076028\n",
      "train_loss 0.35582376981178543 train_acc 0.8449332189682637\n",
      "epoch 831 lr 0.09487954108294289\n",
      "train_loss 0.35579299959307004 train_acc 0.8449025854674672\n",
      "epoch 832 lr 0.09468997163341634\n",
      "train_loss 0.3557623110643547 train_acc 0.8449485357186619\n",
      "epoch 833 lr 0.09450078094390259\n",
      "train_loss 0.35573178058046306 train_acc 0.8449485357186619\n",
      "epoch 834 lr 0.0943119682576386\n",
      "train_loss 0.35570138523094996 train_acc 0.8449179022178654\n",
      "epoch 835 lr 0.0941235328193734\n",
      "train_loss 0.3556709778356623 train_acc 0.8449485357186619\n",
      "epoch 836 lr 0.09393547387536497\n",
      "train_loss 0.35564062669997226 train_acc 0.8449332189682637\n",
      "epoch 837 lr 0.09374779067337728\n",
      "train_loss 0.35561046918197553 train_acc 0.8449638524690601\n",
      "epoch 838 lr 0.0935604824626773\n",
      "train_loss 0.3555803329273578 train_acc 0.8449179022178654\n",
      "epoch 839 lr 0.09337354849403191\n",
      "train_loss 0.35555018755284673 train_acc 0.8449179022178654\n",
      "epoch 840 lr 0.09318698801970499\n",
      "train_loss 0.35552013881778743 train_acc 0.8449791692194584\n",
      "epoch 841 lr 0.09300080029345441\n",
      "train_loss 0.3554901896023221 train_acc 0.8449944859698566\n",
      "epoch 842 lr 0.09281498457052899\n",
      "train_loss 0.3554603548428646 train_acc 0.8450098027202548\n",
      "epoch 843 lr 0.09262954010766561\n",
      "train_loss 0.3554305198065077 train_acc 0.8450251194706531\n",
      "epoch 844 lr 0.09244446616308617\n",
      "train_loss 0.3554007813874752 train_acc 0.8450710697218479\n",
      "epoch 845 lr 0.09225976199649465\n",
      "train_loss 0.35537091836259765 train_acc 0.8450557529714495\n",
      "epoch 846 lr 0.09207542686907412\n",
      "train_loss 0.3553410214089955 train_acc 0.8450863864722461\n",
      "epoch 847 lr 0.09189146004348384\n",
      "train_loss 0.3553113201889397 train_acc 0.8451170199730426\n",
      "epoch 848 lr 0.09170786078385623\n",
      "train_loss 0.3552819795988631 train_acc 0.845147653473839\n",
      "epoch 849 lr 0.09152462835579406\n",
      "train_loss 0.3552527771369689 train_acc 0.8451782869746355\n",
      "\n",
      "val loss = 0.37261746574031757, \n",
      "val acc = 0.8301860785665058\n",
      "\n",
      "epoch 850 lr 0.09134176202636733\n",
      "train_loss 0.355223707582853 train_acc 0.845208920475432\n",
      "epoch 851 lr 0.09115926106411051\n",
      "train_loss 0.3551946361831745 train_acc 0.8451323367234408\n",
      "epoch 852 lr 0.09097712473901948\n",
      "train_loss 0.35516565687158586 train_acc 0.8451170199730426\n",
      "epoch 853 lr 0.09079535232254872\n",
      "train_loss 0.35513678818580924 train_acc 0.8451629702242373\n",
      "epoch 854 lr 0.0906139430876083\n",
      "train_loss 0.35510798154855633 train_acc 0.845147653473839\n",
      "epoch 855 lr 0.09043289630856105\n",
      "train_loss 0.3550792161623636 train_acc 0.845147653473839\n",
      "epoch 856 lr 0.09025221126121961\n",
      "train_loss 0.3550505607096565 train_acc 0.8451170199730426\n",
      "epoch 857 lr 0.09007188722284357\n",
      "train_loss 0.35502194488799277 train_acc 0.8450557529714495\n",
      "epoch 858 lr 0.0898919234721365\n",
      "train_loss 0.35499345999684334 train_acc 0.8450251194706531\n",
      "epoch 859 lr 0.08971231928924317\n",
      "train_loss 0.3549649801125676 train_acc 0.8450557529714495\n",
      "epoch 860 lr 0.08953307395574663\n",
      "train_loss 0.35493649738241717 train_acc 0.8450710697218479\n",
      "epoch 861 lr 0.08935418675466528\n",
      "train_loss 0.3549081144124442 train_acc 0.8450863864722461\n",
      "epoch 862 lr 0.08917565697045009\n",
      "train_loss 0.3548799203594431 train_acc 0.845147653473839\n",
      "epoch 863 lr 0.08899748388898167\n",
      "train_loss 0.35485174765051697 train_acc 0.8451323367234408\n",
      "epoch 864 lr 0.08881966679756749\n",
      "train_loss 0.35482366497456636 train_acc 0.8451782869746355\n",
      "epoch 865 lr 0.08864220498493891\n",
      "train_loss 0.35479559086721335 train_acc 0.8451782869746355\n",
      "epoch 866 lr 0.08846509774124847\n",
      "train_loss 0.35476760992803624 train_acc 0.8451936037250337\n",
      "epoch 867 lr 0.08828834435806693\n",
      "train_loss 0.3547396103001155 train_acc 0.8452548707266266\n",
      "epoch 868 lr 0.08811194412838055\n",
      "train_loss 0.3547116160943367 train_acc 0.8452395539762284\n",
      "epoch 869 lr 0.08793589634658817\n",
      "train_loss 0.3546838153340303 train_acc 0.8451782869746355\n",
      "epoch 870 lr 0.08776020030849843\n",
      "train_loss 0.3546559864199323 train_acc 0.8451782869746355\n",
      "epoch 871 lr 0.08758485531132694\n",
      "train_loss 0.3546281135371868 train_acc 0.845208920475432\n",
      "epoch 872 lr 0.08740986065369347\n",
      "train_loss 0.35460011326438856 train_acc 0.845208920475432\n",
      "epoch 873 lr 0.08723521563561916\n",
      "train_loss 0.35457215629200123 train_acc 0.8451936037250337\n",
      "epoch 874 lr 0.0870609195585237\n",
      "train_loss 0.3545441615159919 train_acc 0.8452395539762284\n",
      "epoch 875 lr 0.08688697172522256\n",
      "train_loss 0.3545160474288756 train_acc 0.8452395539762284\n",
      "epoch 876 lr 0.08671337143992418\n",
      "train_loss 0.3544879487950019 train_acc 0.8452701874770249\n",
      "epoch 877 lr 0.08654011800822715\n",
      "train_loss 0.35446003342325444 train_acc 0.845346771229016\n",
      "epoch 878 lr 0.08636721073711758\n",
      "train_loss 0.3544321642319655 train_acc 0.845346771229016\n",
      "epoch 879 lr 0.08619464893496608\n",
      "train_loss 0.35440441259446276 train_acc 0.8452855042274231\n",
      "epoch 880 lr 0.08602243191152525\n",
      "train_loss 0.35437674911536254 train_acc 0.8453314544786178\n",
      "epoch 881 lr 0.08585055897792677\n",
      "train_loss 0.35434910194047986 train_acc 0.8453774047298125\n",
      "epoch 882 lr 0.08567902944667868\n",
      "train_loss 0.3543214191263221 train_acc 0.8453774047298125\n",
      "epoch 883 lr 0.08550784263166261\n",
      "train_loss 0.3542938355044804 train_acc 0.8453314544786178\n",
      "epoch 884 lr 0.08533699784813108\n",
      "train_loss 0.3542662954636818 train_acc 0.8452855042274231\n",
      "epoch 885 lr 0.08516649441270471\n",
      "train_loss 0.35423887906192986 train_acc 0.8453161377282196\n",
      "epoch 886 lr 0.08499633164336956\n",
      "train_loss 0.35421157348372906 train_acc 0.8452855042274231\n",
      "epoch 887 lr 0.0848265088594743\n",
      "train_loss 0.35418443298996916 train_acc 0.8452701874770249\n",
      "epoch 888 lr 0.08465702538172759\n",
      "train_loss 0.3541573322081665 train_acc 0.8452548707266266\n",
      "epoch 889 lr 0.08448788053219529\n",
      "train_loss 0.3541302539425216 train_acc 0.8452395539762284\n",
      "epoch 890 lr 0.08431907363429776\n",
      "train_loss 0.3541033488755552 train_acc 0.8452242372258302\n",
      "epoch 891 lr 0.08415060401280719\n",
      "train_loss 0.3540766387416136 train_acc 0.8453161377282196\n",
      "epoch 892 lr 0.08398247099384487\n",
      "train_loss 0.3540500531289731 train_acc 0.8453774047298125\n",
      "epoch 893 lr 0.0838146739048785\n",
      "train_loss 0.354023509934696 train_acc 0.8453927214802107\n",
      "epoch 894 lr 0.0836472120747195\n",
      "train_loss 0.3539968493808206 train_acc 0.845469305232202\n",
      "epoch 895 lr 0.08348008483352035\n",
      "train_loss 0.35397022105173864 train_acc 0.8454539884818038\n",
      "epoch 896 lr 0.08331329151277182\n",
      "train_loss 0.3539436557589595 train_acc 0.8454233549810072\n",
      "epoch 897 lr 0.08314683144530044\n",
      "train_loss 0.3539170990408746 train_acc 0.845408038230609\n",
      "epoch 898 lr 0.08298070396526569\n",
      "train_loss 0.353890749228341 train_acc 0.8454233549810072\n",
      "epoch 899 lr 0.08281490840815746\n",
      "train_loss 0.35386452119280515 train_acc 0.8454539884818038\n",
      "\n",
      "val loss = 0.37161417028786053, \n",
      "val acc = 0.830737422467264\n",
      "\n",
      "epoch 900 lr 0.08264944411079327\n",
      "train_loss 0.35383840369842656 train_acc 0.8454233549810072\n",
      "epoch 901 lr 0.08248431041131572\n",
      "train_loss 0.35381237360091555 train_acc 0.8454386717314054\n",
      "epoch 902 lr 0.0823195066491898\n",
      "train_loss 0.35378654474947835 train_acc 0.8454539884818038\n",
      "epoch 903 lr 0.08215503216520023\n",
      "train_loss 0.35376095334996066 train_acc 0.8454846219826002\n",
      "epoch 904 lr 0.08199088630144886\n",
      "train_loss 0.3537355069780665 train_acc 0.8454999387329984\n",
      "epoch 905 lr 0.08182706840135202\n",
      "train_loss 0.3537100245318462 train_acc 0.8455152554833967\n",
      "epoch 906 lr 0.0816635778096379\n",
      "train_loss 0.3536845254525491 train_acc 0.8455152554833967\n",
      "epoch 907 lr 0.08150041387234389\n",
      "train_loss 0.353659023406995 train_acc 0.8455305722337949\n",
      "epoch 908 lr 0.08133757593681404\n",
      "train_loss 0.35363349328834826 train_acc 0.8455305722337949\n",
      "epoch 909 lr 0.08117506335169639\n",
      "train_loss 0.3536080308244718 train_acc 0.8455305722337949\n",
      "epoch 910 lr 0.08101287546694037\n",
      "train_loss 0.35358269005469867 train_acc 0.8455305722337949\n",
      "epoch 911 lr 0.08085101163379425\n",
      "train_loss 0.3535573589230341 train_acc 0.8455918392353878\n",
      "epoch 912 lr 0.08068947120480247\n",
      "train_loss 0.3535321214567329 train_acc 0.8455918392353878\n",
      "epoch 913 lr 0.08052825353380308\n",
      "train_loss 0.35350697032762335 train_acc 0.8456071559857861\n",
      "epoch 914 lr 0.08036735797592519\n",
      "train_loss 0.35348190109434086 train_acc 0.8455612057345914\n",
      "epoch 915 lr 0.08020678388758637\n",
      "train_loss 0.35345681407158774 train_acc 0.8456071559857861\n",
      "epoch 916 lr 0.08004653062649005\n",
      "train_loss 0.35343174896053 train_acc 0.8456377894865825\n",
      "epoch 917 lr 0.07988659755162296\n",
      "train_loss 0.35340679028035454 train_acc 0.8456531062369808\n",
      "epoch 918 lr 0.07972698402325258\n",
      "train_loss 0.3533819718573892 train_acc 0.845668422987379\n",
      "epoch 919 lr 0.07956768940292461\n",
      "train_loss 0.3533572535941191 train_acc 0.8456531062369808\n",
      "epoch 920 lr 0.07940871305346034\n",
      "train_loss 0.3533326157643716 train_acc 0.8456071559857861\n",
      "epoch 921 lr 0.07925005433895416\n",
      "train_loss 0.3533080886141892 train_acc 0.8456224727361843\n",
      "epoch 922 lr 0.07909171262477101\n",
      "train_loss 0.3532835988891179 train_acc 0.845668422987379\n",
      "epoch 923 lr 0.0789336872775438\n",
      "train_loss 0.3532591283658326 train_acc 0.8456990564881754\n",
      "epoch 924 lr 0.07877597766517096\n",
      "train_loss 0.353234698131712 train_acc 0.845668422987379\n",
      "epoch 925 lr 0.0786185831568138\n",
      "train_loss 0.3532102973955145 train_acc 0.8457143732385737\n",
      "epoch 926 lr 0.0784615031228941\n",
      "train_loss 0.35318594279346927 train_acc 0.8456990564881754\n",
      "epoch 927 lr 0.0783047369350915\n",
      "train_loss 0.3531615281166048 train_acc 0.8457603234897684\n",
      "epoch 928 lr 0.07814828396634106\n",
      "train_loss 0.35313711109706647 train_acc 0.8457756402401666\n",
      "epoch 929 lr 0.07799214359083068\n",
      "train_loss 0.3531127455587147 train_acc 0.8458215904913614\n",
      "epoch 930 lr 0.07783631518399864\n",
      "train_loss 0.35308842136241286 train_acc 0.8458215904913614\n",
      "epoch 931 lr 0.07768079812253113\n",
      "train_loss 0.3530641772323942 train_acc 0.8457909569905648\n",
      "epoch 932 lr 0.07752559178435968\n",
      "train_loss 0.3530400264067659 train_acc 0.8457756402401666\n",
      "epoch 933 lr 0.07737069554865875\n",
      "train_loss 0.3530160164596606 train_acc 0.8457603234897684\n",
      "epoch 934 lr 0.07721610879584316\n",
      "train_loss 0.35299217421467755 train_acc 0.8457450067393701\n",
      "epoch 935 lr 0.0770618309075657\n",
      "train_loss 0.3529684956014416 train_acc 0.8458062737409631\n",
      "epoch 936 lr 0.07690786126671463\n",
      "train_loss 0.3529447448319535 train_acc 0.8458215904913614\n",
      "epoch 937 lr 0.07675419925741117\n",
      "train_loss 0.35292107125026806 train_acc 0.8458369072417596\n",
      "epoch 938 lr 0.0766008442650071\n",
      "train_loss 0.35289749503964424 train_acc 0.8458828574929543\n",
      "epoch 939 lr 0.0764477956760822\n",
      "train_loss 0.35287403004182366 train_acc 0.845928807744149\n",
      "epoch 940 lr 0.07629505287844195\n",
      "train_loss 0.3528505022087045 train_acc 0.8459134909937508\n",
      "epoch 941 lr 0.07614261526111492\n",
      "train_loss 0.35282702670571625 train_acc 0.8459134909937508\n",
      "epoch 942 lr 0.07599048221435047\n",
      "train_loss 0.3528035960353727 train_acc 0.845928807744149\n",
      "epoch 943 lr 0.0758386531296162\n",
      "train_loss 0.3527802730097846 train_acc 0.8459441244945473\n",
      "epoch 944 lr 0.07568712739959556\n",
      "train_loss 0.3527569768682835 train_acc 0.845928807744149\n",
      "epoch 945 lr 0.07553590441818543\n",
      "train_loss 0.35273369005348226 train_acc 0.8459747579953437\n",
      "epoch 946 lr 0.0753849835804937\n",
      "train_loss 0.3527104012929505 train_acc 0.8459747579953437\n",
      "epoch 947 lr 0.0752343642828368\n",
      "train_loss 0.3526871626128625 train_acc 0.8460513417473349\n",
      "epoch 948 lr 0.07508404592273733\n",
      "train_loss 0.3526638863610566 train_acc 0.846127925499326\n",
      "epoch 949 lr 0.07493402789892167\n",
      "train_loss 0.3526406158809732 train_acc 0.846127925499326\n",
      "\n",
      "val loss = 0.37079661922711793, \n",
      "val acc = 0.8325292901447278\n",
      "\n",
      "epoch 950 lr 0.07478430961131753\n",
      "train_loss 0.35261743224677106 train_acc 0.8461126087489278\n",
      "epoch 951 lr 0.07463489046105154\n",
      "train_loss 0.35259434513225546 train_acc 0.846127925499326\n",
      "epoch 952 lr 0.07448576985044691\n",
      "train_loss 0.3525714440347226 train_acc 0.8461738757505207\n",
      "epoch 953 lr 0.07433694718302099\n",
      "train_loss 0.35254860998626036 train_acc 0.8461738757505207\n",
      "epoch 954 lr 0.07418842186348293\n",
      "train_loss 0.3525257827419392 train_acc 0.846189192500919\n",
      "epoch 955 lr 0.07404019329773123\n",
      "train_loss 0.35250291710569587 train_acc 0.8462045092513173\n",
      "epoch 956 lr 0.07389226089285145\n",
      "train_loss 0.3524801773725555 train_acc 0.8462045092513173\n",
      "epoch 957 lr 0.07374462405711375\n",
      "train_loss 0.35245753722111794 train_acc 0.8462351427521138\n",
      "epoch 958 lr 0.07359728219997062\n",
      "train_loss 0.3524349431497535 train_acc 0.8462964097537067\n",
      "epoch 959 lr 0.0734502347320544\n",
      "train_loss 0.35241245912531777 train_acc 0.8463117265041049\n",
      "epoch 960 lr 0.07330348106517506\n",
      "train_loss 0.35239002414198645 train_acc 0.8462964097537067\n",
      "epoch 961 lr 0.07315702061231773\n",
      "train_loss 0.35236758481906216 train_acc 0.8462351427521138\n",
      "epoch 962 lr 0.07301085278764037\n",
      "train_loss 0.3523451424108317 train_acc 0.8463117265041049\n",
      "epoch 963 lr 0.07286497700647152\n",
      "train_loss 0.35232260097362145 train_acc 0.8463729935056978\n",
      "epoch 964 lr 0.07271939268530785\n",
      "train_loss 0.35230004379142504 train_acc 0.8463576767552996\n",
      "epoch 965 lr 0.07257409924181187\n",
      "train_loss 0.35227750060905316 train_acc 0.8463270432545031\n",
      "epoch 966 lr 0.07242909609480962\n",
      "train_loss 0.3522549489800462 train_acc 0.8464036270064943\n",
      "epoch 967 lr 0.07228438266428833\n",
      "train_loss 0.35223245043441587 train_acc 0.8464342605072908\n",
      "epoch 968 lr 0.07213995837139407\n",
      "train_loss 0.35220995992664894 train_acc 0.8464189437568925\n",
      "epoch 969 lr 0.07199582263842949\n",
      "train_loss 0.3521875647834004 train_acc 0.8464189437568925\n",
      "epoch 970 lr 0.07185197488885146\n",
      "train_loss 0.3521651582943239 train_acc 0.8464648940080872\n",
      "epoch 971 lr 0.07170841454726878\n",
      "train_loss 0.352142842876285 train_acc 0.8466027447616714\n",
      "epoch 972 lr 0.07156514103943991\n",
      "train_loss 0.3521206081169973 train_acc 0.8466486950128661\n",
      "epoch 973 lr 0.07142215379227061\n",
      "train_loss 0.3520984610339704 train_acc 0.846709962014459\n",
      "epoch 974 lr 0.07127945223381171\n",
      "train_loss 0.3520762578131278 train_acc 0.8467252787648573\n",
      "epoch 975 lr 0.0711370357932568\n",
      "train_loss 0.35205404767415777 train_acc 0.8467405955152555\n",
      "epoch 976 lr 0.07099490390093989\n",
      "train_loss 0.3520318667620842 train_acc 0.8467252787648573\n",
      "epoch 977 lr 0.07085305598833325\n",
      "train_loss 0.3520097158297565 train_acc 0.8467405955152555\n",
      "epoch 978 lr 0.07071149148804504\n",
      "train_loss 0.35198764888189166 train_acc 0.846709962014459\n",
      "epoch 979 lr 0.07057020983381705\n",
      "train_loss 0.35196561394122217 train_acc 0.8467405955152555\n",
      "epoch 980 lr 0.0704292104605225\n",
      "train_loss 0.3519436660410194 train_acc 0.8468018625168484\n",
      "epoch 981 lr 0.0702884928041637\n",
      "train_loss 0.35192186387650437 train_acc 0.8467865457664502\n",
      "epoch 982 lr 0.07014805630186983\n",
      "train_loss 0.351900121496671 train_acc 0.8468018625168484\n",
      "epoch 983 lr 0.0700079003918947\n",
      "train_loss 0.35187847848107556 train_acc 0.8468478127680431\n",
      "epoch 984 lr 0.06986802451361449\n",
      "train_loss 0.35185673319459077 train_acc 0.8468478127680431\n",
      "epoch 985 lr 0.06972842810752547\n",
      "train_loss 0.35183489777613136 train_acc 0.8468784462688396\n",
      "epoch 986 lr 0.06958911061524187\n",
      "train_loss 0.35181318427195385 train_acc 0.8468631295184413\n",
      "epoch 987 lr 0.0694500714794935\n",
      "train_loss 0.35179150748576693 train_acc 0.846909079769636\n",
      "epoch 988 lr 0.06931131014412366\n",
      "train_loss 0.3517698457951626 train_acc 0.8469397132704325\n",
      "epoch 989 lr 0.06917282605408681\n",
      "train_loss 0.3517482673947023 train_acc 0.8469243965200343\n",
      "epoch 990 lr 0.06903461865544641\n",
      "train_loss 0.3517267716328113 train_acc 0.8470009802720255\n",
      "epoch 991 lr 0.06889668739537268\n",
      "train_loss 0.35170537476772545 train_acc 0.8470162970224238\n",
      "epoch 992 lr 0.06875903172214039\n",
      "train_loss 0.35168402430945167 train_acc 0.8470009802720255\n",
      "epoch 993 lr 0.06862165108512666\n",
      "train_loss 0.3516627200186438 train_acc 0.8470162970224238\n",
      "epoch 994 lr 0.06848454493480877\n",
      "train_loss 0.35164146078107295 train_acc 0.8470775640240167\n",
      "epoch 995 lr 0.06834771272276194\n",
      "train_loss 0.3516201620978301 train_acc 0.8470775640240167\n",
      "epoch 996 lr 0.06821115390165712\n",
      "train_loss 0.35159892560481987 train_acc 0.8471081975248131\n",
      "epoch 997 lr 0.06807486792525885\n",
      "train_loss 0.3515776166640527 train_acc 0.8471081975248131\n",
      "epoch 998 lr 0.06793885424842305\n",
      "train_loss 0.35155634980139633 train_acc 0.8471081975248131\n",
      "epoch 999 lr 0.06780311232709485\n",
      "train_loss 0.3515351560600025 train_acc 0.8472000980272025\n",
      "\n",
      "val loss = 0.36997083246799833, \n",
      "val acc = 0.8332184700206754\n",
      "\n",
      "epoch 1000 lr 0.06766764161830634\n",
      "train_loss 0.3515139569175923 train_acc 0.847230731527999\n",
      "epoch 1001 lr 0.06753244158017455\n",
      "train_loss 0.3514926603113445 train_acc 0.8472919985295919\n",
      "epoch 1002 lr 0.0673975116718991\n",
      "train_loss 0.3514714101529587 train_acc 0.8473073152799901\n",
      "epoch 1003 lr 0.06726285135376021\n",
      "train_loss 0.3514502624256038 train_acc 0.8473073152799901\n",
      "epoch 1004 lr 0.06712846008711641\n",
      "train_loss 0.35142910303595526 train_acc 0.8472460482783972\n",
      "epoch 1005 lr 0.06699433733440249\n",
      "train_loss 0.35140789935431993 train_acc 0.8472766817791937\n",
      "epoch 1006 lr 0.0668604825591272\n",
      "train_loss 0.3513866702261497 train_acc 0.8473379487807867\n",
      "epoch 1007 lr 0.06672689522587133\n",
      "train_loss 0.3513654826059918 train_acc 0.8473685822815832\n",
      "epoch 1008 lr 0.0665935748002853\n",
      "train_loss 0.35134444347093347 train_acc 0.8474145325327779\n",
      "epoch 1009 lr 0.06646052074908729\n",
      "train_loss 0.3513235514253005 train_acc 0.8474298492831761\n",
      "epoch 1010 lr 0.06632773254006086\n",
      "train_loss 0.35130271036349986 train_acc 0.8473992157823796\n",
      "epoch 1011 lr 0.06619520964205305\n",
      "train_loss 0.35128187843324526 train_acc 0.8473992157823796\n",
      "epoch 1012 lr 0.06606295152497205\n",
      "train_loss 0.35126112666448095 train_acc 0.847353265531185\n",
      "epoch 1013 lr 0.06593095765978525\n",
      "train_loss 0.35124039925346806 train_acc 0.8473226320303884\n",
      "epoch 1014 lr 0.06579922751851698\n",
      "train_loss 0.3512197351676872 train_acc 0.8473838990319814\n",
      "epoch 1015 lr 0.06566776057424654\n",
      "train_loss 0.351199129820664 train_acc 0.8474145325327779\n",
      "epoch 1016 lr 0.06553655630110594\n",
      "train_loss 0.3511785412195116 train_acc 0.8474757995343708\n",
      "epoch 1017 lr 0.06540561417427794\n",
      "train_loss 0.35115796067422567 train_acc 0.8474451660335743\n",
      "epoch 1018 lr 0.06527493366999382\n",
      "train_loss 0.35113746457032696 train_acc 0.8474757995343708\n",
      "epoch 1019 lr 0.06514451426553144\n",
      "train_loss 0.3511170207864572 train_acc 0.8474604827839726\n",
      "epoch 1020 lr 0.06501435543921295\n",
      "train_loss 0.35109658190027926 train_acc 0.8474604827839726\n",
      "epoch 1021 lr 0.06488445667040295\n",
      "train_loss 0.3510761985402054 train_acc 0.847491116284769\n",
      "epoch 1022 lr 0.06475481743950609\n",
      "train_loss 0.3510557683071352 train_acc 0.847552383286362\n",
      "epoch 1023 lr 0.06462543722796536\n",
      "train_loss 0.35103537325614487 train_acc 0.8475677000367602\n",
      "epoch 1024 lr 0.0644963155182597\n",
      "train_loss 0.3510150367837507 train_acc 0.8475830167871584\n",
      "epoch 1025 lr 0.06436745179390212\n",
      "train_loss 0.350994753671173 train_acc 0.8475983335375566\n",
      "epoch 1026 lr 0.06423884553943751\n",
      "train_loss 0.35097443952388924 train_acc 0.8476442837887513\n",
      "epoch 1027 lr 0.06411049624044075\n",
      "train_loss 0.35095407044117705 train_acc 0.847690234039946\n",
      "epoch 1028 lr 0.0639824033835144\n",
      "train_loss 0.3509336834123862 train_acc 0.847690234039946\n",
      "epoch 1029 lr 0.06385456645628691\n",
      "train_loss 0.35091326048355426 train_acc 0.8477208675407426\n",
      "epoch 1030 lr 0.06372698494741037\n",
      "train_loss 0.3508929331780304 train_acc 0.8477361842911408\n",
      "epoch 1031 lr 0.06359965834655862\n",
      "train_loss 0.35087264224484765 train_acc 0.8477361842911408\n",
      "epoch 1032 lr 0.06347258614442501\n",
      "train_loss 0.3508523748674751 train_acc 0.8477208675407426\n",
      "epoch 1033 lr 0.06334576783272065\n",
      "train_loss 0.35083205692149033 train_acc 0.8477361842911408\n",
      "epoch 1034 lr 0.06321920290417204\n",
      "train_loss 0.3508118219729617 train_acc 0.8477361842911408\n",
      "epoch 1035 lr 0.06309289085251939\n",
      "train_loss 0.3507916807629563 train_acc 0.8477361842911408\n",
      "epoch 1036 lr 0.06296683117251423\n",
      "train_loss 0.3507715210332859 train_acc 0.8477515010415391\n",
      "epoch 1037 lr 0.06284102335991774\n",
      "train_loss 0.35075135582043926 train_acc 0.8477361842911408\n",
      "epoch 1038 lr 0.06271546691149846\n",
      "train_loss 0.3507312768476459 train_acc 0.8477821345423355\n",
      "epoch 1039 lr 0.06259016132503047\n",
      "train_loss 0.35071119803121154 train_acc 0.8477974512927338\n",
      "epoch 1040 lr 0.062465106099291214\n",
      "train_loss 0.3506911034260548 train_acc 0.8478280847935302\n",
      "epoch 1041 lr 0.06234030073405966\n",
      "train_loss 0.35067098725852247 train_acc 0.8478280847935302\n",
      "epoch 1042 lr 0.06221574473011414\n",
      "train_loss 0.35065079861726384 train_acc 0.8478893517951231\n",
      "epoch 1043 lr 0.06209143758923052\n",
      "train_loss 0.3506306789336628 train_acc 0.8478893517951231\n",
      "epoch 1044 lr 0.06196737881418002\n",
      "train_loss 0.35061058019407537 train_acc 0.8478740350447249\n",
      "epoch 1045 lr 0.06184356790872742\n",
      "train_loss 0.35059043339581625 train_acc 0.8478893517951231\n",
      "epoch 1046 lr 0.06172000437762889\n",
      "train_loss 0.35057025481133935 train_acc 0.8478587182943267\n",
      "epoch 1047 lr 0.06159668772663019\n",
      "train_loss 0.35055018813376093 train_acc 0.8478740350447249\n",
      "epoch 1048 lr 0.061473617462464505\n",
      "train_loss 0.3505301428225836 train_acc 0.8478740350447249\n",
      "epoch 1049 lr 0.06135079309285066\n",
      "train_loss 0.35051022544281724 train_acc 0.8478740350447249\n",
      "\n",
      "val loss = 0.3692454850462397, \n",
      "val acc = 0.833356305995865\n",
      "\n",
      "epoch 1050 lr 0.06122821412649095\n",
      "train_loss 0.3504904541369569 train_acc 0.8478434015439285\n",
      "epoch 1051 lr 0.06110588007306942\n",
      "train_loss 0.35047080588244484 train_acc 0.8479046685455214\n",
      "epoch 1052 lr 0.06098379044324963\n",
      "train_loss 0.35045125352821294 train_acc 0.8478893517951231\n",
      "epoch 1053 lr 0.06086194474867295\n",
      "train_loss 0.35043173909692693 train_acc 0.8478740350447249\n",
      "epoch 1054 lr 0.06074034250195639\n",
      "train_loss 0.35041218939391916 train_acc 0.8479046685455214\n",
      "epoch 1055 lr 0.06061898321669085\n",
      "train_loss 0.3503926310695275 train_acc 0.8478893517951231\n",
      "epoch 1056 lr 0.06049786640743897\n",
      "train_loss 0.35037316463635265 train_acc 0.8478893517951231\n",
      "epoch 1057 lr 0.06037699158973341\n",
      "train_loss 0.35035377880805696 train_acc 0.8479199852959196\n",
      "epoch 1058 lr 0.06025635828007469\n",
      "train_loss 0.3503344269338253 train_acc 0.8479353020463178\n",
      "epoch 1059 lr 0.060135965995929457\n",
      "train_loss 0.350315139178004 train_acc 0.8479353020463178\n",
      "epoch 1060 lr 0.06001581425572836\n",
      "train_loss 0.3502958965826719 train_acc 0.8479199852959196\n",
      "epoch 1061 lr 0.05989590257886434\n",
      "train_loss 0.35027668378934884 train_acc 0.8479506187967161\n",
      "epoch 1062 lr 0.05977623048569047\n",
      "train_loss 0.3502575329089707 train_acc 0.8479506187967161\n",
      "epoch 1063 lr 0.05965679749751827\n",
      "train_loss 0.3502383646599818 train_acc 0.8479506187967161\n",
      "epoch 1064 lr 0.05953760313661557\n",
      "train_loss 0.3502192797483496 train_acc 0.8479506187967161\n",
      "epoch 1065 lr 0.05941864692620483\n",
      "train_loss 0.35020025322764836 train_acc 0.8479812522975125\n",
      "epoch 1066 lr 0.05929992839046099\n",
      "train_loss 0.3501812792596878 train_acc 0.8479965690479108\n",
      "epoch 1067 lr 0.059181447054509805\n",
      "train_loss 0.3501623244527242 train_acc 0.8479965690479108\n",
      "epoch 1068 lr 0.05906320244442573\n",
      "train_loss 0.35014348128922734 train_acc 0.8480578360495037\n",
      "epoch 1069 lr 0.0589451940872302\n",
      "train_loss 0.3501246643783488 train_acc 0.8480731527999019\n",
      "epoch 1070 lr 0.05882742151088959\n",
      "train_loss 0.35010586660623094 train_acc 0.8481037863006985\n",
      "epoch 1071 lr 0.05870988424431349\n",
      "train_loss 0.3500870559068829 train_acc 0.8481191030510967\n",
      "epoch 1072 lr 0.058592581817352614\n",
      "train_loss 0.3500681502204775 train_acc 0.8481037863006985\n",
      "epoch 1073 lr 0.05847551376079716\n",
      "train_loss 0.3500492191088685 train_acc 0.8481191030510967\n",
      "epoch 1074 lr 0.05835867960637469\n",
      "train_loss 0.35003033720230575 train_acc 0.8481037863006985\n",
      "epoch 1075 lr 0.05824207888674848\n",
      "train_loss 0.3500114949328124 train_acc 0.8481037863006985\n",
      "epoch 1076 lr 0.05812571113551546\n",
      "train_loss 0.3499927257908088 train_acc 0.8481037863006985\n",
      "epoch 1077 lr 0.05800957588720449\n",
      "train_loss 0.34997405880648896 train_acc 0.8481037863006985\n",
      "epoch 1078 lr 0.0578936726772744\n",
      "train_loss 0.3499554425497319 train_acc 0.8480578360495037\n",
      "epoch 1079 lr 0.05777800104211224\n",
      "train_loss 0.3499368088262018 train_acc 0.8480731527999019\n",
      "epoch 1080 lr 0.05766256051903125\n",
      "train_loss 0.3499181779847772 train_acc 0.8480731527999019\n",
      "epoch 1081 lr 0.05754735064626926\n",
      "train_loss 0.3498995111590364 train_acc 0.8480884695503003\n",
      "epoch 1082 lr 0.05743237096298654\n",
      "train_loss 0.34988096585813844 train_acc 0.8480731527999019\n",
      "epoch 1083 lr 0.05731762100926429\n",
      "train_loss 0.3498625042014546 train_acc 0.848011885798309\n",
      "epoch 1084 lr 0.05720310032610247\n",
      "train_loss 0.34984411525503206 train_acc 0.848011885798309\n",
      "epoch 1085 lr 0.05708880845541825\n",
      "train_loss 0.3498257834221049 train_acc 0.8480272025487072\n",
      "epoch 1086 lr 0.05697474494004394\n",
      "train_loss 0.34980747965252623 train_acc 0.8480272025487072\n",
      "epoch 1087 lr 0.05686090932372539\n",
      "train_loss 0.349789203319755 train_acc 0.8480272025487072\n",
      "epoch 1088 lr 0.056747301151119915\n",
      "train_loss 0.34977095383361756 train_acc 0.848011885798309\n",
      "epoch 1089 lr 0.05663391996779474\n",
      "train_loss 0.3497527124902138 train_acc 0.8479965690479108\n",
      "epoch 1090 lr 0.056520765320224924\n",
      "train_loss 0.34973449582867455 train_acc 0.848011885798309\n",
      "epoch 1091 lr 0.05640783675579177\n",
      "train_loss 0.34971631676461795 train_acc 0.8480425192991055\n",
      "epoch 1092 lr 0.05629513382278083\n",
      "train_loss 0.349698141730225 train_acc 0.8480731527999019\n",
      "epoch 1093 lr 0.05618265607038026\n",
      "train_loss 0.3496799310425169 train_acc 0.8480272025487072\n",
      "epoch 1094 lr 0.05607040304867886\n",
      "train_loss 0.3496617117501156 train_acc 0.8480425192991055\n",
      "epoch 1095 lr 0.05595837430866444\n",
      "train_loss 0.3496435781483225 train_acc 0.8480425192991055\n",
      "epoch 1096 lr 0.05584656940222184\n",
      "train_loss 0.34962550371621104 train_acc 0.8480272025487072\n",
      "epoch 1097 lr 0.05573498788213133\n",
      "train_loss 0.3496074591750396 train_acc 0.8480731527999019\n",
      "epoch 1098 lr 0.05562362930206665\n",
      "train_loss 0.349589408096657 train_acc 0.8480884695503003\n",
      "epoch 1099 lr 0.055512493216593364\n",
      "train_loss 0.349571402237123 train_acc 0.8480731527999019\n",
      "\n",
      "val loss = 0.36865572621917747, \n",
      "val acc = 0.8340454858718126\n",
      "\n",
      "epoch 1100 lr 0.05540157918116693\n",
      "train_loss 0.34955340327073464 train_acc 0.8480731527999019\n",
      "epoch 1101 lr 0.05529088675213112\n",
      "train_loss 0.3495353568159291 train_acc 0.8480731527999019\n",
      "epoch 1102 lr 0.05518041548671601\n",
      "train_loss 0.3495172688474405 train_acc 0.8480884695503003\n",
      "epoch 1103 lr 0.05507016494303645\n",
      "train_loss 0.3494991201079739 train_acc 0.8481191030510967\n",
      "epoch 1104 lr 0.05496013468009006\n",
      "train_loss 0.3494810563900287 train_acc 0.848134419801495\n",
      "epoch 1105 lr 0.054850324257755705\n",
      "train_loss 0.3494630068639803 train_acc 0.8481650533022914\n",
      "epoch 1106 lr 0.05474073323679148\n",
      "train_loss 0.34944502811542216 train_acc 0.8481497365518932\n",
      "epoch 1107 lr 0.054631361178833215\n",
      "train_loss 0.34942705959165976 train_acc 0.8481497365518932\n",
      "epoch 1108 lr 0.054522207646392484\n",
      "train_loss 0.3494092356198021 train_acc 0.8482263203038843\n",
      "epoch 1109 lr 0.054413272202855065\n",
      "train_loss 0.34939144550889445 train_acc 0.8481803700526896\n",
      "epoch 1110 lr 0.05430455441247898\n",
      "train_loss 0.3493736958751666 train_acc 0.8482110035534861\n",
      "epoch 1111 lr 0.05419605384039297\n",
      "train_loss 0.34935596707373245 train_acc 0.8482110035534861\n",
      "epoch 1112 lr 0.05408777005259457\n",
      "train_loss 0.34933823241002177 train_acc 0.8482416370542826\n",
      "epoch 1113 lr 0.05397970261594851\n",
      "train_loss 0.3493205219396106 train_acc 0.8482569538046808\n",
      "epoch 1114 lr 0.05387185109818487\n",
      "train_loss 0.34930285467755734 train_acc 0.8482569538046808\n",
      "epoch 1115 lr 0.053764215067897476\n",
      "train_loss 0.34928511930337935 train_acc 0.8482569538046808\n",
      "epoch 1116 lr 0.053656794094542014\n",
      "train_loss 0.3492673995071861 train_acc 0.8483182208062737\n",
      "epoch 1117 lr 0.05354958774843449\n",
      "train_loss 0.3492496782112552 train_acc 0.8483029040558755\n",
      "epoch 1118 lr 0.05344259560074934\n",
      "train_loss 0.34923205689751735 train_acc 0.8482875873054773\n",
      "epoch 1119 lr 0.05333581722351788\n",
      "train_loss 0.34921447396155525 train_acc 0.848333537556672\n",
      "epoch 1120 lr 0.053229252189626396\n",
      "train_loss 0.3491968912280331 train_acc 0.8483182208062737\n",
      "epoch 1121 lr 0.05312290007281467\n",
      "train_loss 0.3491793449908499 train_acc 0.848333537556672\n",
      "epoch 1122 lr 0.05301676044767405\n",
      "train_loss 0.34916179768393246 train_acc 0.8483488543070702\n",
      "epoch 1123 lr 0.05291083288964592\n",
      "train_loss 0.3491442091853792 train_acc 0.8483641710574684\n",
      "epoch 1124 lr 0.052805116975019877\n",
      "train_loss 0.34912662869634903 train_acc 0.8483641710574684\n",
      "epoch 1125 lr 0.052699612280932166\n",
      "train_loss 0.3491091439286468 train_acc 0.8484254380590613\n",
      "epoch 1126 lr 0.052594318385363846\n",
      "train_loss 0.349091633917179 train_acc 0.8484254380590613\n",
      "epoch 1127 lr 0.05248923486713917\n",
      "train_loss 0.34907409433422004 train_acc 0.8484560715598578\n",
      "epoch 1128 lr 0.05238436130592397\n",
      "train_loss 0.3490566257474278 train_acc 0.8484254380590613\n",
      "epoch 1129 lr 0.052279697282223814\n",
      "train_loss 0.34903912887791605 train_acc 0.8484407548094596\n",
      "epoch 1130 lr 0.05217524237738252\n",
      "train_loss 0.34902164661964435 train_acc 0.8484713883102561\n",
      "epoch 1131 lr 0.052070996173580276\n",
      "train_loss 0.3490041245485046 train_acc 0.8484407548094596\n",
      "epoch 1132 lr 0.05196695825383218\n",
      "train_loss 0.3489865587488216 train_acc 0.8484407548094596\n",
      "epoch 1133 lr 0.051863128201986367\n",
      "train_loss 0.34896904088409014 train_acc 0.8484101213086631\n",
      "epoch 1134 lr 0.05175950560272253\n",
      "train_loss 0.34895163012118074 train_acc 0.8484560715598578\n",
      "epoch 1135 lr 0.0516560900415501\n",
      "train_loss 0.348934269911756 train_acc 0.8484254380590613\n",
      "epoch 1136 lr 0.05155288110480673\n",
      "train_loss 0.3489169690648748 train_acc 0.8484407548094596\n",
      "epoch 1137 lr 0.0514498783796565\n",
      "train_loss 0.3488997179373707 train_acc 0.8485173385614508\n",
      "epoch 1138 lr 0.0513470814540884\n",
      "train_loss 0.3488825260584314 train_acc 0.8485020218110526\n",
      "epoch 1139 lr 0.05124448991691456\n",
      "train_loss 0.3488653449563492 train_acc 0.8485173385614508\n",
      "epoch 1140 lr 0.05114210335776874\n",
      "train_loss 0.3488481486140181 train_acc 0.8485173385614508\n",
      "epoch 1141 lr 0.051039921367104515\n",
      "train_loss 0.348830984303081 train_acc 0.8485020218110526\n",
      "epoch 1142 lr 0.05093794353619384\n",
      "train_loss 0.3488138539538563 train_acc 0.8485326553118491\n",
      "epoch 1143 lr 0.0508361694571252\n",
      "train_loss 0.3487967152881864 train_acc 0.8485632888126455\n",
      "epoch 1144 lr 0.05073459872280219\n",
      "train_loss 0.34877960278712794 train_acc 0.8485786055630438\n",
      "epoch 1145 lr 0.0506332309269417\n",
      "train_loss 0.3487625441644256 train_acc 0.8485786055630438\n",
      "epoch 1146 lr 0.05053206566407245\n",
      "train_loss 0.348745578645264 train_acc 0.8485786055630438\n",
      "epoch 1147 lr 0.05043110252953321\n",
      "train_loss 0.34872866101141897 train_acc 0.8486092390638402\n",
      "epoch 1148 lr 0.05033034111947135\n",
      "train_loss 0.34871172362629627 train_acc 0.8486245558142385\n",
      "epoch 1149 lr 0.05022978103084105\n",
      "train_loss 0.3486947956235759 train_acc 0.8486245558142385\n",
      "\n",
      "val loss = 0.36808013748864665, \n",
      "val acc = 0.8343211578221916\n",
      "\n",
      "epoch 1150 lr 0.050129421861401874\n",
      "train_loss 0.3486777842963008 train_acc 0.8486705060654332\n",
      "epoch 1151 lr 0.050029263209716957\n",
      "train_loss 0.34866080940027955 train_acc 0.8487011395662296\n",
      "epoch 1152 lr 0.04992930467515161\n",
      "train_loss 0.3486438855194259 train_acc 0.8487470898174243\n",
      "epoch 1153 lr 0.04982954585787151\n",
      "train_loss 0.34862700306384037 train_acc 0.8487317730670261\n",
      "epoch 1154 lr 0.04972998635884131\n",
      "train_loss 0.34861011124936864 train_acc 0.8487317730670261\n",
      "epoch 1155 lr 0.04963062577982282\n",
      "train_loss 0.3485932515464536 train_acc 0.8487470898174243\n",
      "epoch 1156 lr 0.04953146372337366\n",
      "train_loss 0.34857647739516384 train_acc 0.8487624065678225\n",
      "epoch 1157 lr 0.0494324997928454\n",
      "train_loss 0.3485597405346551 train_acc 0.8487777233182208\n",
      "epoch 1158 lr 0.049333733592382245\n",
      "train_loss 0.34854300783566355 train_acc 0.8487777233182208\n",
      "epoch 1159 lr 0.049235164726919224\n",
      "train_loss 0.34852625950747906 train_acc 0.8487777233182208\n",
      "epoch 1160 lr 0.04913679280218077\n",
      "train_loss 0.34850951321629686 train_acc 0.8487777233182208\n",
      "epoch 1161 lr 0.04903861742467903\n",
      "train_loss 0.3484928403189097 train_acc 0.8487624065678225\n",
      "epoch 1162 lr 0.048940638201712384\n",
      "train_loss 0.3484762206797656 train_acc 0.8487470898174243\n",
      "epoch 1163 lr 0.04884285474136378\n",
      "train_loss 0.34845966947323126 train_acc 0.8487624065678225\n",
      "epoch 1164 lr 0.048745266652499286\n",
      "train_loss 0.34844313283354256 train_acc 0.848793040068619\n",
      "epoch 1165 lr 0.04864787354476638\n",
      "train_loss 0.34842652771436583 train_acc 0.8488083568190172\n",
      "epoch 1166 lr 0.04855067502859253\n",
      "train_loss 0.3484098376628819 train_acc 0.8488389903198138\n",
      "epoch 1167 lr 0.048453670715183514\n",
      "train_loss 0.34839312616607887 train_acc 0.8488236735694155\n",
      "epoch 1168 lr 0.04835686021652198\n",
      "train_loss 0.3483764282327404 train_acc 0.8488389903198138\n",
      "epoch 1169 lr 0.048260243145365776\n",
      "train_loss 0.34835971029495805 train_acc 0.8488389903198138\n",
      "epoch 1170 lr 0.04816381911524652\n",
      "train_loss 0.3483429627012032 train_acc 0.8488389903198138\n",
      "epoch 1171 lr 0.04806758774046792\n",
      "train_loss 0.34832617226773865 train_acc 0.8488696238206103\n",
      "epoch 1172 lr 0.04797154863610439\n",
      "train_loss 0.3483093565036834 train_acc 0.8488389903198138\n",
      "epoch 1173 lr 0.04787570141799934\n",
      "train_loss 0.3482924999037273 train_acc 0.8488696238206103\n",
      "epoch 1174 lr 0.047780045702763826\n",
      "train_loss 0.3482756112472775 train_acc 0.8488696238206103\n",
      "epoch 1175 lr 0.04768458110777481\n",
      "train_loss 0.34825875672766193 train_acc 0.8489002573214067\n",
      "epoch 1176 lr 0.047589307251173815\n",
      "train_loss 0.3482419215804281 train_acc 0.8489615243229996\n",
      "epoch 1177 lr 0.04749422375186527\n",
      "train_loss 0.3482251663408555 train_acc 0.8489921578237961\n",
      "epoch 1178 lr 0.04739933022951507\n",
      "train_loss 0.34820839417260124 train_acc 0.8489768410733979\n",
      "epoch 1179 lr 0.047304626304548965\n",
      "train_loss 0.34819160043144143 train_acc 0.8490074745741943\n",
      "epoch 1180 lr 0.04721011159815118\n",
      "train_loss 0.3481748046530061 train_acc 0.8489768410733979\n",
      "epoch 1181 lr 0.04711578573226271\n",
      "train_loss 0.3481580191235198 train_acc 0.8490227913245926\n",
      "epoch 1182 lr 0.04702164832958001\n",
      "train_loss 0.3481412285607542 train_acc 0.8490993750765837\n",
      "epoch 1183 lr 0.0469276990135533\n",
      "train_loss 0.3481244223171615 train_acc 0.849114691826982\n",
      "epoch 1184 lr 0.046833937408385234\n",
      "train_loss 0.34810763096875 train_acc 0.8490993750765837\n",
      "epoch 1185 lr 0.04674036313902923\n",
      "train_loss 0.34809089108577873 train_acc 0.849114691826982\n",
      "epoch 1186 lr 0.046646975831188126\n",
      "train_loss 0.3480742037332977 train_acc 0.8491453253277784\n",
      "epoch 1187 lr 0.04655377511131252\n",
      "train_loss 0.34805762429390874 train_acc 0.8491606420781767\n",
      "epoch 1188 lr 0.04646076060659945\n",
      "train_loss 0.3480410417972142 train_acc 0.8491606420781767\n",
      "epoch 1189 lr 0.04636793194499073\n",
      "train_loss 0.34802441210142987 train_acc 0.8491606420781767\n",
      "epoch 1190 lr 0.046275288755171645\n",
      "train_loss 0.3480077203203888 train_acc 0.8491759588285749\n",
      "epoch 1191 lr 0.04618283066656925\n",
      "train_loss 0.3479910332618786 train_acc 0.8492065923293713\n",
      "epoch 1192 lr 0.04609055730935113\n",
      "train_loss 0.34797438261038394 train_acc 0.8491912755789731\n",
      "epoch 1193 lr 0.045998468314423675\n",
      "train_loss 0.3479576654146927 train_acc 0.8492065923293713\n",
      "epoch 1194 lr 0.04590656331343083\n",
      "train_loss 0.34794092751645334 train_acc 0.8492219090797697\n",
      "epoch 1195 lr 0.045814841938752425\n",
      "train_loss 0.34792420899991605 train_acc 0.8492372258301679\n",
      "epoch 1196 lr 0.045723303823502884\n",
      "train_loss 0.34790760951044003 train_acc 0.8492525425805661\n",
      "epoch 1197 lr 0.045631948601529575\n",
      "train_loss 0.3478910396317858 train_acc 0.8492372258301679\n",
      "epoch 1198 lr 0.04554077590741154\n",
      "train_loss 0.34787442687131037 train_acc 0.8492831760813626\n",
      "epoch 1199 lr 0.04544978537645784\n",
      "train_loss 0.34785782608478155 train_acc 0.8492678593309644\n",
      "\n",
      "val loss = 0.3675518808182071, \n",
      "val acc = 0.833631977946244\n",
      "\n",
      "epoch 1200 lr 0.04535897664470626\n",
      "train_loss 0.3478412127465964 train_acc 0.8492984928317608\n",
      "epoch 1201 lr 0.04526834934892172\n",
      "train_loss 0.3478245962301429 train_acc 0.8492831760813626\n",
      "epoch 1202 lr 0.04517790312659495\n",
      "train_loss 0.3478079682257224 train_acc 0.8492525425805661\n",
      "epoch 1203 lr 0.04508763761594091\n",
      "train_loss 0.3477913735304078 train_acc 0.8492372258301679\n",
      "epoch 1204 lr 0.04499755245589746\n",
      "train_loss 0.34777480513632625 train_acc 0.8492219090797697\n",
      "epoch 1205 lr 0.04490764728612382\n",
      "train_loss 0.3477583105823103 train_acc 0.8492372258301679\n",
      "epoch 1206 lr 0.044817921746999216\n",
      "train_loss 0.347741861682668 train_acc 0.8492525425805661\n",
      "epoch 1207 lr 0.044728375479621336\n",
      "train_loss 0.3477253748125845 train_acc 0.8492219090797697\n",
      "epoch 1208 lr 0.04463900812580504\n",
      "train_loss 0.34770883285437065 train_acc 0.8492219090797697\n",
      "epoch 1209 lr 0.04454981932808074\n",
      "train_loss 0.347692189829852 train_acc 0.8492065923293713\n",
      "epoch 1210 lr 0.04446080872969317\n",
      "train_loss 0.34767556051901294 train_acc 0.8492372258301679\n",
      "epoch 1211 lr 0.044371975974599784\n",
      "train_loss 0.34765899152957597 train_acc 0.8492219090797697\n",
      "epoch 1212 lr 0.04428332070746948\n",
      "train_loss 0.3476424462941386 train_acc 0.8492372258301679\n",
      "epoch 1213 lr 0.04419484257368103\n",
      "train_loss 0.34762591776662793 train_acc 0.8492525425805661\n",
      "epoch 1214 lr 0.04410654121932182\n",
      "train_loss 0.34760942048357146 train_acc 0.8492065923293713\n",
      "epoch 1215 lr 0.044018416291186274\n",
      "train_loss 0.34759286588993776 train_acc 0.8492219090797697\n",
      "epoch 1216 lr 0.0439304674367746\n",
      "train_loss 0.34757635280625765 train_acc 0.8492219090797697\n",
      "epoch 1217 lr 0.04384269430429123\n",
      "train_loss 0.3475599213902042 train_acc 0.8492065923293713\n",
      "epoch 1218 lr 0.04375509654264356\n",
      "train_loss 0.3475435476800758 train_acc 0.8492219090797697\n",
      "epoch 1219 lr 0.043667673801440376\n",
      "train_loss 0.34752711738517644 train_acc 0.8492525425805661\n",
      "epoch 1220 lr 0.04358042573099065\n",
      "train_loss 0.34751067875022024 train_acc 0.8492678593309644\n",
      "epoch 1221 lr 0.04349335198230193\n",
      "train_loss 0.34749422212694075 train_acc 0.8493138095821591\n",
      "epoch 1222 lr 0.043406452207079144\n",
      "train_loss 0.3474777982806312 train_acc 0.8493444430829555\n",
      "epoch 1223 lr 0.043319726057723044\n",
      "train_loss 0.34746138773324337 train_acc 0.8493597598333538\n",
      "epoch 1224 lr 0.04323317318732896\n",
      "train_loss 0.34744494566210093 train_acc 0.8493597598333538\n",
      "epoch 1225 lr 0.04314679324968525\n",
      "train_loss 0.3474285038147216 train_acc 0.8493291263325573\n",
      "epoch 1226 lr 0.04306058589927208\n",
      "train_loss 0.34741211823806367 train_acc 0.8493138095821591\n",
      "epoch 1227 lr 0.042974550791259905\n",
      "train_loss 0.3473957706922244 train_acc 0.8492678593309644\n",
      "epoch 1228 lr 0.04288868758150821\n",
      "train_loss 0.34737948082464865 train_acc 0.8492678593309644\n",
      "epoch 1229 lr 0.042802995926564016\n",
      "train_loss 0.347363199985941 train_acc 0.8492831760813626\n",
      "epoch 1230 lr 0.04271747548366061\n",
      "train_loss 0.3473468594328874 train_acc 0.8492984928317608\n",
      "epoch 1231 lr 0.042632125910716086\n",
      "train_loss 0.34733050930724263 train_acc 0.8493138095821591\n",
      "epoch 1232 lr 0.04254694686633206\n",
      "train_loss 0.34731419510003403 train_acc 0.8492831760813626\n",
      "epoch 1233 lr 0.042461938009792206\n",
      "train_loss 0.3472979506270742 train_acc 0.8492984928317608\n",
      "epoch 1234 lr 0.04237709900106103\n",
      "train_loss 0.34728174066461265 train_acc 0.8492984928317608\n",
      "epoch 1235 lr 0.042292429500782346\n",
      "train_loss 0.34726556944305076 train_acc 0.8492984928317608\n",
      "epoch 1236 lr 0.04220792917027807\n",
      "train_loss 0.3472493855944724 train_acc 0.8493291263325573\n",
      "epoch 1237 lr 0.042123597671546734\n",
      "train_loss 0.34723324420421936 train_acc 0.8493597598333538\n",
      "epoch 1238 lr 0.04203943466726227\n",
      "train_loss 0.3472171187913135 train_acc 0.849375076583752\n",
      "epoch 1239 lr 0.0419554398207725\n",
      "train_loss 0.3472009301388132 train_acc 0.849375076583752\n",
      "epoch 1240 lr 0.04187161279609798\n",
      "train_loss 0.347184728444781 train_acc 0.8494210268349467\n",
      "epoch 1241 lr 0.04178795325793045\n",
      "train_loss 0.34716853626296174 train_acc 0.8494210268349467\n",
      "epoch 1242 lr 0.041704460871631696\n",
      "train_loss 0.3471523632748619 train_acc 0.8494516603357432\n",
      "epoch 1243 lr 0.041621135303232006\n",
      "train_loss 0.3471361940445851 train_acc 0.8494057100845485\n",
      "epoch 1244 lr 0.04153797621942905\n",
      "train_loss 0.34712001426362565 train_acc 0.8494057100845485\n",
      "epoch 1245 lr 0.04145498328758633\n",
      "train_loss 0.3471038085538574 train_acc 0.8494057100845485\n",
      "epoch 1246 lr 0.04137215617573206\n",
      "train_loss 0.34708752658220926 train_acc 0.8494210268349467\n",
      "epoch 1247 lr 0.041289494552557635\n",
      "train_loss 0.34707124995949235 train_acc 0.8494669770861414\n",
      "epoch 1248 lr 0.041206998087416485\n",
      "train_loss 0.34705502575019964 train_acc 0.8494363435853449\n",
      "epoch 1249 lr 0.04112466645032262\n",
      "train_loss 0.34703881058291597 train_acc 0.8494057100845485\n",
      "\n",
      "val loss = 0.36707092770199656, \n",
      "val acc = 0.8334941419710544\n",
      "\n",
      "epoch 1250 lr 0.0410424993119494\n",
      "train_loss 0.34702266648124 train_acc 0.8494057100845485\n",
      "epoch 1251 lr 0.040960496343628146\n",
      "train_loss 0.34700658659754535 train_acc 0.8494363435853449\n",
      "epoch 1252 lr 0.040878657217346875\n",
      "train_loss 0.3469904986744935 train_acc 0.8494669770861414\n",
      "epoch 1253 lr 0.04079698160574899\n",
      "train_loss 0.34697451176945654 train_acc 0.8494976105869378\n",
      "epoch 1254 lr 0.040715469182131904\n",
      "train_loss 0.34695862642227837 train_acc 0.8495129273373361\n",
      "epoch 1255 lr 0.04063411962044585\n",
      "train_loss 0.3469427997447871 train_acc 0.8495282440877343\n",
      "epoch 1256 lr 0.04055293259529245\n",
      "train_loss 0.34692702536161485 train_acc 0.8495435608381325\n",
      "epoch 1257 lr 0.040471907781923507\n",
      "train_loss 0.3469112531113896 train_acc 0.8495588775885308\n",
      "epoch 1258 lr 0.04039104485623964\n",
      "train_loss 0.34689541200951785 train_acc 0.849574194338929\n",
      "epoch 1259 lr 0.040310343494789076\n",
      "train_loss 0.34687957311792833 train_acc 0.8496048278397256\n",
      "epoch 1260 lr 0.04022980337476621\n",
      "train_loss 0.34686372333550064 train_acc 0.8496201445901238\n",
      "epoch 1261 lr 0.04014942417401051\n",
      "train_loss 0.3468478526531496 train_acc 0.849635461340522\n",
      "epoch 1262 lr 0.04006920557100502\n",
      "train_loss 0.34683201799467733 train_acc 0.8496201445901238\n",
      "epoch 1263 lr 0.039989147244875255\n",
      "train_loss 0.3468162027824037 train_acc 0.8496814115917167\n",
      "epoch 1264 lr 0.03990924887538777\n",
      "train_loss 0.34680038791570145 train_acc 0.849635461340522\n",
      "epoch 1265 lr 0.03982951014294902\n",
      "train_loss 0.3467845866266649 train_acc 0.8496660948413185\n",
      "epoch 1266 lr 0.03974993072860393\n",
      "train_loss 0.34676884897416144 train_acc 0.8496507780909203\n",
      "epoch 1267 lr 0.03967051031403477\n",
      "train_loss 0.34675316581553944 train_acc 0.8496201445901238\n",
      "epoch 1268 lr 0.03959124858155974\n",
      "train_loss 0.34673745528761046 train_acc 0.849635461340522\n",
      "epoch 1269 lr 0.03951214521413184\n",
      "train_loss 0.3467216710490102 train_acc 0.8496660948413185\n",
      "epoch 1270 lr 0.03943319989533747\n",
      "train_loss 0.3467059227090054 train_acc 0.8496814115917167\n",
      "epoch 1271 lr 0.03935441230939527\n",
      "train_loss 0.34669018671889545 train_acc 0.849696728342115\n",
      "epoch 1272 lr 0.03927578214115477\n",
      "train_loss 0.3466744585120285 train_acc 0.8497426785933097\n",
      "epoch 1273 lr 0.03919730907609521\n",
      "train_loss 0.34665871950208127 train_acc 0.8497426785933097\n",
      "epoch 1274 lr 0.03911899280032421\n",
      "train_loss 0.3466429406818647 train_acc 0.8497579953437079\n",
      "epoch 1275 lr 0.039040833000576584\n",
      "train_loss 0.3466271016498119 train_acc 0.8497426785933097\n",
      "epoch 1276 lr 0.03896282936421299\n",
      "train_loss 0.34661126357085675 train_acc 0.8498039455949026\n",
      "epoch 1277 lr 0.03888498157921883\n",
      "train_loss 0.3465954295372563 train_acc 0.8498192623453008\n",
      "epoch 1278 lr 0.03880728933420281\n",
      "train_loss 0.3465795574275013 train_acc 0.849834579095699\n",
      "epoch 1279 lr 0.03872975231839589\n",
      "train_loss 0.3465636776058219 train_acc 0.8498805293468937\n",
      "epoch 1280 lr 0.03865237022164987\n",
      "train_loss 0.3465478512114581 train_acc 0.849895846097292\n",
      "epoch 1281 lr 0.03857514273443629\n",
      "train_loss 0.34653204644052155 train_acc 0.8498652125964955\n",
      "epoch 1282 lr 0.03849806954784506\n",
      "train_loss 0.3465163078326365 train_acc 0.8498805293468937\n",
      "epoch 1283 lr 0.038421150353583365\n",
      "train_loss 0.346500622220697 train_acc 0.8499417963484867\n",
      "epoch 1284 lr 0.0383443848439743\n",
      "train_loss 0.34648494796909063 train_acc 0.8499571130988849\n",
      "epoch 1285 lr 0.03826777271195576\n",
      "train_loss 0.34646927045293663 train_acc 0.8499571130988849\n",
      "epoch 1286 lr 0.03819131365107906\n",
      "train_loss 0.34645349626101796 train_acc 0.8499417963484867\n",
      "epoch 1287 lr 0.038115007355507914\n",
      "train_loss 0.3464376616308276 train_acc 0.8499724298492832\n",
      "epoch 1288 lr 0.03803885352001699\n",
      "train_loss 0.3464219132033121 train_acc 0.8499571130988849\n",
      "epoch 1289 lr 0.03796285183999089\n",
      "train_loss 0.3464062980787312 train_acc 0.8499877465996815\n",
      "epoch 1290 lr 0.03788700201142274\n",
      "train_loss 0.3463907023907334 train_acc 0.8500183801004779\n",
      "epoch 1291 lr 0.03781130373091317\n",
      "train_loss 0.3463751089195527 train_acc 0.8500490136012744\n",
      "epoch 1292 lr 0.03773575669566892\n",
      "train_loss 0.34635952929970215 train_acc 0.8500643303516726\n",
      "epoch 1293 lr 0.03766036060350179\n",
      "train_loss 0.3463439760610295 train_acc 0.8500490136012744\n",
      "epoch 1294 lr 0.03758511515282727\n",
      "train_loss 0.34632837143935585 train_acc 0.8500643303516726\n",
      "epoch 1295 lr 0.03751002004266348\n",
      "train_loss 0.3463127457898642 train_acc 0.8500796471020708\n",
      "epoch 1296 lr 0.03743507497262987\n",
      "train_loss 0.3462971095601965 train_acc 0.8500796471020708\n",
      "epoch 1297 lr 0.03736027964294608\n",
      "train_loss 0.3462814794511186 train_acc 0.8500796471020708\n",
      "epoch 1298 lr 0.037285633754430655\n",
      "train_loss 0.34626583192950444 train_acc 0.8500796471020708\n",
      "epoch 1299 lr 0.03721113700849998\n",
      "train_loss 0.3462501033297192 train_acc 0.8500949638524691\n",
      "\n",
      "val loss = 0.3666464917561293, \n",
      "val acc = 0.8329427980702964\n",
      "\n",
      "epoch 1300 lr 0.03713678910716693\n",
      "train_loss 0.34623430414177014 train_acc 0.8501255973532655\n",
      "epoch 1301 lr 0.03706258975303985\n",
      "train_loss 0.3462184753169504 train_acc 0.850156230854062\n",
      "epoch 1302 lr 0.03698853864932118\n",
      "train_loss 0.3462027112517817 train_acc 0.8501409141036638\n",
      "epoch 1303 lr 0.03691463549980645\n",
      "train_loss 0.346186973573146 train_acc 0.8501409141036638\n",
      "epoch 1304 lr 0.03684088000888291\n",
      "train_loss 0.3461712331541404 train_acc 0.8501715476044602\n",
      "epoch 1305 lr 0.03676727188152855\n",
      "train_loss 0.3461554821581264 train_acc 0.8501102806028673\n",
      "epoch 1306 lr 0.03669381082331072\n",
      "train_loss 0.34613972879199273 train_acc 0.8500796471020708\n",
      "epoch 1307 lr 0.03662049654038512\n",
      "train_loss 0.34612392496066546 train_acc 0.8500796471020708\n",
      "epoch 1308 lr 0.0365473287394945\n",
      "train_loss 0.34610804016398444 train_acc 0.8501409141036638\n",
      "epoch 1309 lr 0.03647430712796758\n",
      "train_loss 0.34609216680065247 train_acc 0.850156230854062\n",
      "epoch 1310 lr 0.036401431413717794\n",
      "train_loss 0.3460763856771749 train_acc 0.8501868643548585\n",
      "epoch 1311 lr 0.036328701305242204\n",
      "train_loss 0.34606059170386816 train_acc 0.8502174978556549\n",
      "epoch 1312 lr 0.036256116511620265\n",
      "train_loss 0.3460447581391671 train_acc 0.8502021811052567\n",
      "epoch 1313 lr 0.03618367674251273\n",
      "train_loss 0.3460288033406103 train_acc 0.8501868643548585\n",
      "epoch 1314 lr 0.03611138170816039\n",
      "train_loss 0.34601285192956277 train_acc 0.8502021811052567\n",
      "epoch 1315 lr 0.03603923111938305\n",
      "train_loss 0.3459970507966377 train_acc 0.8501715476044602\n",
      "epoch 1316 lr 0.03596722468757822\n",
      "train_loss 0.34598131895076767 train_acc 0.8501715476044602\n",
      "epoch 1317 lr 0.035895362124720116\n",
      "train_loss 0.34596562510416934 train_acc 0.8501868643548585\n",
      "epoch 1318 lr 0.035823643143358355\n",
      "train_loss 0.345949994497527 train_acc 0.8501715476044602\n",
      "epoch 1319 lr 0.03575206745661695\n",
      "train_loss 0.3459343854611198 train_acc 0.8501102806028673\n",
      "epoch 1320 lr 0.03568063477819302\n",
      "train_loss 0.3459187057114755 train_acc 0.8501255973532655\n",
      "epoch 1321 lr 0.035609344822355796\n",
      "train_loss 0.34590307462313286 train_acc 0.8501868643548585\n",
      "epoch 1322 lr 0.035538197303945335\n",
      "train_loss 0.34588744847459824 train_acc 0.8502021811052567\n",
      "epoch 1323 lr 0.03546719193837148\n",
      "train_loss 0.3458718215611586 train_acc 0.8502021811052567\n",
      "epoch 1324 lr 0.03539632844161265\n",
      "train_loss 0.34585627379004846 train_acc 0.8501409141036638\n",
      "epoch 1325 lr 0.0353256065302148\n",
      "train_loss 0.34584078055392475 train_acc 0.8501409141036638\n",
      "epoch 1326 lr 0.03525502592129015\n",
      "train_loss 0.34582528092890386 train_acc 0.8501868643548585\n",
      "epoch 1327 lr 0.03518458633251621\n",
      "train_loss 0.3458098658778925 train_acc 0.8501868643548585\n",
      "epoch 1328 lr 0.03511428748213451\n",
      "train_loss 0.3457944286647136 train_acc 0.8502328146060532\n",
      "epoch 1329 lr 0.035044129088949556\n",
      "train_loss 0.34577895802068354 train_acc 0.8502328146060532\n",
      "epoch 1330 lr 0.03497411087232768\n",
      "train_loss 0.34576345546227105 train_acc 0.8502481313564514\n",
      "epoch 1331 lr 0.034904232552195935\n",
      "train_loss 0.34574798561712344 train_acc 0.8503093983580443\n",
      "epoch 1332 lr 0.03483449384904092\n",
      "train_loss 0.3457325321995758 train_acc 0.8503247151084425\n",
      "epoch 1333 lr 0.034764894483907766\n",
      "train_loss 0.34571711467826766 train_acc 0.8503247151084425\n",
      "epoch 1334 lr 0.03469543417839889\n",
      "train_loss 0.3457016997951977 train_acc 0.8503247151084425\n",
      "epoch 1335 lr 0.034626112654673\n",
      "train_loss 0.3456862552740425 train_acc 0.8503706653596373\n",
      "epoch 1336 lr 0.03455692963544388\n",
      "train_loss 0.3456708331101222 train_acc 0.8503553486092391\n",
      "epoch 1337 lr 0.03448788484397939\n",
      "train_loss 0.34565541487732443 train_acc 0.8503400318588409\n",
      "epoch 1338 lr 0.034418978004100244\n",
      "train_loss 0.3456399167159868 train_acc 0.8503400318588409\n",
      "epoch 1339 lr 0.03435020884017903\n",
      "train_loss 0.34562445533633906 train_acc 0.8503706653596373\n",
      "epoch 1340 lr 0.034281577077138956\n",
      "train_loss 0.34560902524805837 train_acc 0.8504012988604338\n",
      "epoch 1341 lr 0.034213082440452916\n",
      "train_loss 0.3455936781716839 train_acc 0.8503706653596373\n",
      "epoch 1342 lr 0.03414472465614224\n",
      "train_loss 0.34557837149107407 train_acc 0.8503553486092391\n",
      "epoch 1343 lr 0.03407650345077572\n",
      "train_loss 0.34556312395238487 train_acc 0.8502940816076461\n",
      "epoch 1344 lr 0.03400841855146844\n",
      "train_loss 0.3455479355517706 train_acc 0.8503093983580443\n",
      "epoch 1345 lr 0.03394046968588072\n",
      "train_loss 0.3455327534384004 train_acc 0.8503400318588409\n",
      "epoch 1346 lr 0.03387265658221698\n",
      "train_loss 0.34551762234074135 train_acc 0.8503706653596373\n",
      "epoch 1347 lr 0.03380497896922475\n",
      "train_loss 0.34550249508735364 train_acc 0.8503706653596373\n",
      "epoch 1348 lr 0.03373743657619345\n",
      "train_loss 0.3454873490085448 train_acc 0.8503400318588409\n",
      "epoch 1349 lr 0.03367002913295346\n",
      "train_loss 0.3454721741305891 train_acc 0.8503859821100356\n",
      "\n",
      "val loss = 0.3662138064745003, \n",
      "val acc = 0.8345968297725707\n",
      "\n",
      "epoch 1350 lr 0.03360275636987487\n",
      "train_loss 0.34545705326190074 train_acc 0.8504012988604338\n",
      "epoch 1351 lr 0.033535618017866586\n",
      "train_loss 0.3454419356866731 train_acc 0.8503706653596373\n",
      "epoch 1352 lr 0.033468613808375076\n",
      "train_loss 0.3454268068953437 train_acc 0.8504012988604338\n",
      "epoch 1353 lr 0.033401743473383434\n",
      "train_loss 0.34541161923316605 train_acc 0.8504012988604338\n",
      "epoch 1354 lr 0.033335006745410206\n",
      "train_loss 0.3453964563965619 train_acc 0.850416615610832\n",
      "epoch 1355 lr 0.03326840335750843\n",
      "train_loss 0.3453813193427295 train_acc 0.8503859821100356\n",
      "epoch 1356 lr 0.033201933043264416\n",
      "train_loss 0.345366213081568 train_acc 0.8504319323612303\n",
      "epoch 1357 lr 0.03313559553679686\n",
      "train_loss 0.34535117653194775 train_acc 0.8504625658620267\n",
      "epoch 1358 lr 0.03306939057275562\n",
      "train_loss 0.3453361105281104 train_acc 0.8504931993628232\n",
      "epoch 1359 lr 0.03300331788632078\n",
      "train_loss 0.3453210297014733 train_acc 0.8504931993628232\n",
      "epoch 1360 lr 0.032937377213201474\n",
      "train_loss 0.3453059116184985 train_acc 0.8505085161132214\n",
      "epoch 1361 lr 0.03287156828963495\n",
      "train_loss 0.34529074093921086 train_acc 0.8504931993628232\n",
      "epoch 1362 lr 0.032805890852385396\n",
      "train_loss 0.34527562637578535 train_acc 0.8505085161132214\n",
      "epoch 1363 lr 0.032740344638743014\n",
      "train_loss 0.34526060806673237 train_acc 0.8505085161132214\n",
      "epoch 1364 lr 0.032674929386522826\n",
      "train_loss 0.3452455405268997 train_acc 0.8504931993628232\n",
      "epoch 1365 lr 0.03260964483406376\n",
      "train_loss 0.3452304464965806 train_acc 0.850477882612425\n",
      "epoch 1366 lr 0.032544490720227505\n",
      "train_loss 0.3452153684961161 train_acc 0.850477882612425\n",
      "epoch 1367 lr 0.032479466784397525\n",
      "train_loss 0.34520025360476875 train_acc 0.8504931993628232\n",
      "epoch 1368 lr 0.03241457276647798\n",
      "train_loss 0.3451851939943041 train_acc 0.8504472491116285\n",
      "epoch 1369 lr 0.032349808406892736\n",
      "train_loss 0.3451701738402149 train_acc 0.8504625658620267\n",
      "epoch 1370 lr 0.032285173446584235\n",
      "train_loss 0.34515516303139554 train_acc 0.8504472491116285\n",
      "epoch 1371 lr 0.03222066762701259\n",
      "train_loss 0.3451401145317447 train_acc 0.8504931993628232\n",
      "epoch 1372 lr 0.03215629069015439\n",
      "train_loss 0.34512512183121175 train_acc 0.8504625658620267\n",
      "epoch 1373 lr 0.03209204237850184\n",
      "train_loss 0.34511015101809545 train_acc 0.850477882612425\n",
      "epoch 1374 lr 0.032027922435061584\n",
      "train_loss 0.345095160001257 train_acc 0.8504472491116285\n",
      "epoch 1375 lr 0.031963930603353785\n",
      "train_loss 0.34508006413783754 train_acc 0.8505085161132214\n",
      "epoch 1376 lr 0.03190006662741102\n",
      "train_loss 0.3450649503766279 train_acc 0.8505085161132214\n",
      "epoch 1377 lr 0.03183633025177728\n",
      "train_loss 0.3450498565465143 train_acc 0.8505391496140179\n",
      "epoch 1378 lr 0.03177272122150701\n",
      "train_loss 0.34503476755410317 train_acc 0.8505391496140179\n",
      "epoch 1379 lr 0.03170923928216398\n",
      "train_loss 0.34501964440952293 train_acc 0.8505238328636197\n",
      "epoch 1380 lr 0.031645884179820366\n",
      "train_loss 0.34500457546040175 train_acc 0.8505238328636197\n",
      "epoch 1381 lr 0.031582655661055656\n",
      "train_loss 0.34498947600825236 train_acc 0.8505085161132214\n",
      "epoch 1382 lr 0.031519553472955715\n",
      "train_loss 0.34497436969015466 train_acc 0.8505085161132214\n",
      "epoch 1383 lr 0.03145657736311167\n",
      "train_loss 0.34495926707084934 train_acc 0.8504472491116285\n",
      "epoch 1384 lr 0.031393727079619044\n",
      "train_loss 0.3449441263895939 train_acc 0.8504472491116285\n",
      "epoch 1385 lr 0.031331002371076576\n",
      "train_loss 0.34492890774971263 train_acc 0.8504625658620267\n",
      "epoch 1386 lr 0.031268402986585384\n",
      "train_loss 0.3449136985791037 train_acc 0.8504625658620267\n",
      "epoch 1387 lr 0.031205928675747813\n",
      "train_loss 0.3448985030504418 train_acc 0.850477882612425\n",
      "epoch 1388 lr 0.031143579188666566\n",
      "train_loss 0.3448832605906221 train_acc 0.850477882612425\n",
      "epoch 1389 lr 0.031081354275943586\n",
      "train_loss 0.3448679950303754 train_acc 0.8504931993628232\n",
      "epoch 1390 lr 0.031019253688679162\n",
      "train_loss 0.34485268600238167 train_acc 0.8505085161132214\n",
      "epoch 1391 lr 0.03095727717847084\n",
      "train_loss 0.34483738555647125 train_acc 0.8504931993628232\n",
      "epoch 1392 lr 0.030895424497412522\n",
      "train_loss 0.34482205671388555 train_acc 0.850477882612425\n",
      "epoch 1393 lr 0.030833695398093375\n",
      "train_loss 0.34480674364341335 train_acc 0.850477882612425\n",
      "epoch 1394 lr 0.030772089633596945\n",
      "train_loss 0.34479139236552003 train_acc 0.850477882612425\n",
      "epoch 1395 lr 0.030710606957500067\n",
      "train_loss 0.3447760294190084 train_acc 0.8504931993628232\n",
      "epoch 1396 lr 0.030649247123871976\n",
      "train_loss 0.3447607403188551 train_acc 0.8505085161132214\n",
      "epoch 1397 lr 0.030588009887273237\n",
      "train_loss 0.3447455114276867 train_acc 0.8505238328636197\n",
      "epoch 1398 lr 0.03052689500275484\n",
      "train_loss 0.3447303467362624 train_acc 0.8505085161132214\n",
      "epoch 1399 lr 0.030465902225857145\n",
      "train_loss 0.3447152570212427 train_acc 0.8504931993628232\n",
      "\n",
      "val loss = 0.36570232952468423, \n",
      "val acc = 0.8340454858718126\n",
      "\n",
      "epoch 1400 lr 0.03040503131260899\n",
      "train_loss 0.3447001673244244 train_acc 0.8504931993628232\n",
      "epoch 1401 lr 0.03034428201952661\n",
      "train_loss 0.34468505509672503 train_acc 0.8505085161132214\n",
      "epoch 1402 lr 0.03028365410361278\n",
      "train_loss 0.3446699984700049 train_acc 0.8505238328636197\n",
      "epoch 1403 lr 0.03022314732235573\n",
      "train_loss 0.3446549653875548 train_acc 0.8505544663644161\n",
      "epoch 1404 lr 0.030162761433728282\n",
      "train_loss 0.34463993281549554 train_acc 0.8505391496140179\n",
      "epoch 1405 lr 0.03010249619618677\n",
      "train_loss 0.344624954392149 train_acc 0.8505697831148143\n",
      "epoch 1406 lr 0.030042351368670197\n",
      "train_loss 0.3446100070656253 train_acc 0.8505850998652126\n",
      "epoch 1407 lr 0.02998232671059914\n",
      "train_loss 0.3445950715424932 train_acc 0.8506004166156108\n",
      "epoch 1408 lr 0.02992242198187491\n",
      "train_loss 0.3445801524860196 train_acc 0.8505850998652126\n",
      "epoch 1409 lr 0.029862636942878495\n",
      "train_loss 0.34456519479395037 train_acc 0.8506310501164073\n",
      "epoch 1410 lr 0.029802971354469684\n",
      "train_loss 0.3445502046026606 train_acc 0.8506616836172037\n",
      "epoch 1411 lr 0.029743424977986013\n",
      "train_loss 0.34453521994900577 train_acc 0.8506463668668055\n",
      "epoch 1412 lr 0.029683997575241924\n",
      "train_loss 0.3445202828762346 train_acc 0.8506004166156108\n",
      "epoch 1413 lr 0.0296246889085277\n",
      "train_loss 0.3445053511405109 train_acc 0.8505850998652126\n",
      "epoch 1414 lr 0.029565498740608626\n",
      "train_loss 0.34449045850237625 train_acc 0.850615733366009\n",
      "epoch 1415 lr 0.02950642683472392\n",
      "train_loss 0.34447554661683955 train_acc 0.8506004166156108\n",
      "epoch 1416 lr 0.02944747295458591\n",
      "train_loss 0.3444606529370496 train_acc 0.8505850998652126\n",
      "epoch 1417 lr 0.029388636864378967\n",
      "train_loss 0.3444458242600075 train_acc 0.8506310501164073\n",
      "epoch 1418 lr 0.02932991832875868\n",
      "train_loss 0.344431008547604 train_acc 0.8506463668668055\n",
      "epoch 1419 lr 0.0292713171128508\n",
      "train_loss 0.34441619309650406 train_acc 0.8506310501164073\n",
      "epoch 1420 lr 0.029212832982250414\n",
      "train_loss 0.3444013405363526 train_acc 0.8506310501164073\n",
      "epoch 1421 lr 0.029154465703020896\n",
      "train_loss 0.34438646477225276 train_acc 0.8506310501164073\n",
      "epoch 1422 lr 0.029096215041693074\n",
      "train_loss 0.34437166262160135 train_acc 0.850615733366009\n",
      "epoch 1423 lr 0.0290380807652642\n",
      "train_loss 0.3443568155566923 train_acc 0.8506616836172037\n",
      "epoch 1424 lr 0.028980062641197117\n",
      "train_loss 0.3443419951814677 train_acc 0.8506616836172037\n",
      "epoch 1425 lr 0.028922160437419228\n",
      "train_loss 0.34432718533287626 train_acc 0.8506616836172037\n",
      "epoch 1426 lr 0.028864373922321666\n",
      "train_loss 0.34431240744988745 train_acc 0.8506923171180002\n",
      "epoch 1427 lr 0.02880670286475826\n",
      "train_loss 0.34429756799084105 train_acc 0.8506923171180002\n",
      "epoch 1428 lr 0.028749147034044742\n",
      "train_loss 0.3442826928964778 train_acc 0.8506923171180002\n",
      "epoch 1429 lr 0.028691706199957676\n",
      "train_loss 0.34426774842626434 train_acc 0.850677000367602\n",
      "epoch 1430 lr 0.02863438013273368\n",
      "train_loss 0.34425281239241073 train_acc 0.850738267369195\n",
      "epoch 1431 lr 0.02857716860306838\n",
      "train_loss 0.34423791609657545 train_acc 0.8507229506187968\n",
      "epoch 1432 lr 0.028520071382115608\n",
      "train_loss 0.3442230258567878 train_acc 0.850738267369195\n",
      "epoch 1433 lr 0.028463088241486377\n",
      "train_loss 0.3442080803701606 train_acc 0.8507535841195932\n",
      "epoch 1434 lr 0.028406218953248078\n",
      "train_loss 0.3441931098390086 train_acc 0.8507535841195932\n",
      "epoch 1435 lr 0.02834946328992345\n",
      "train_loss 0.3441781456285837 train_acc 0.850738267369195\n",
      "epoch 1436 lr 0.0282928210244898\n",
      "train_loss 0.3441631751734695 train_acc 0.8507535841195932\n",
      "epoch 1437 lr 0.028236291930377955\n",
      "train_loss 0.34414824105365255 train_acc 0.8507689008699915\n",
      "epoch 1438 lr 0.028179875781471495\n",
      "train_loss 0.3441333099045042 train_acc 0.850738267369195\n",
      "epoch 1439 lr 0.02812357235210572\n",
      "train_loss 0.34411842218073396 train_acc 0.8507229506187968\n",
      "epoch 1440 lr 0.028067381417066863\n",
      "train_loss 0.3441035445277642 train_acc 0.8506923171180002\n",
      "epoch 1441 lr 0.028011302751591086\n",
      "train_loss 0.34408866197747107 train_acc 0.8507535841195932\n",
      "epoch 1442 lr 0.027955336131363678\n",
      "train_loss 0.3440738735846678 train_acc 0.8507535841195932\n",
      "epoch 1443 lr 0.027899481332518055\n",
      "train_loss 0.3440591746160665 train_acc 0.8507535841195932\n",
      "epoch 1444 lr 0.027843738131634974\n",
      "train_loss 0.34404453441126703 train_acc 0.8507535841195932\n",
      "epoch 1445 lr 0.02778810630574153\n",
      "train_loss 0.34402992119177467 train_acc 0.8507842176203897\n",
      "epoch 1446 lr 0.027732585632310375\n",
      "train_loss 0.34401532195045775 train_acc 0.8508148511211862\n",
      "epoch 1447 lr 0.027677175889258714\n",
      "train_loss 0.34400074979087053 train_acc 0.8508148511211862\n",
      "epoch 1448 lr 0.027621876854947523\n",
      "train_loss 0.3439861822449892 train_acc 0.8508148511211862\n",
      "epoch 1449 lr 0.02756668830818057\n",
      "train_loss 0.3439715854787003 train_acc 0.8508761181227791\n",
      "\n",
      "val loss = 0.3653622217735058, \n",
      "val acc = 0.8334941419710544\n",
      "\n",
      "epoch 1450 lr 0.027511610028203615\n",
      "train_loss 0.3439569662437649 train_acc 0.8508761181227791\n",
      "epoch 1451 lr 0.027456641794703446\n",
      "train_loss 0.34394233281495945 train_acc 0.8509067516235755\n",
      "epoch 1452 lr 0.027401783387807077\n",
      "train_loss 0.3439277716173317 train_acc 0.8508914348731773\n",
      "epoch 1453 lr 0.02734703458808078\n",
      "train_loss 0.34391321879637515 train_acc 0.850937385124372\n",
      "epoch 1454 lr 0.027292395176529313\n",
      "train_loss 0.3438987257787012 train_acc 0.8509527018747702\n",
      "epoch 1455 lr 0.02723786493459493\n",
      "train_loss 0.3438842453339436 train_acc 0.8509680186251685\n",
      "epoch 1456 lr 0.02718344364415661\n",
      "train_loss 0.343869770527387 train_acc 0.8510139688763632\n",
      "epoch 1457 lr 0.027129131087529103\n",
      "train_loss 0.34385530856495883 train_acc 0.8509833353755667\n",
      "epoch 1458 lr 0.02707492704746213\n",
      "train_loss 0.3438409065791343 train_acc 0.8510139688763632\n",
      "epoch 1459 lr 0.027020831307139434\n",
      "train_loss 0.3438265320365819 train_acc 0.8510292856267614\n",
      "epoch 1460 lr 0.02696684365017801\n",
      "train_loss 0.3438121972215559 train_acc 0.8510292856267614\n",
      "epoch 1461 lr 0.026912963860627127\n",
      "train_loss 0.3437978904249703 train_acc 0.8510139688763632\n",
      "epoch 1462 lr 0.026859191722967583\n",
      "train_loss 0.3437835322141123 train_acc 0.8510139688763632\n",
      "epoch 1463 lr 0.02680552702211073\n",
      "train_loss 0.34376914179449725 train_acc 0.8510292856267614\n",
      "epoch 1464 lr 0.02675196954339772\n",
      "train_loss 0.34375480263281805 train_acc 0.8510292856267614\n",
      "epoch 1465 lr 0.02669851907259854\n",
      "train_loss 0.3437404912846721 train_acc 0.8510139688763632\n",
      "epoch 1466 lr 0.02664517539591126\n",
      "train_loss 0.343726144282203 train_acc 0.8510446023771596\n",
      "epoch 1467 lr 0.02659193829996108\n",
      "train_loss 0.3437117950200767 train_acc 0.8510752358779561\n",
      "epoch 1468 lr 0.026538807571799567\n",
      "train_loss 0.3436974274584415 train_acc 0.8510599191275579\n",
      "epoch 1469 lr 0.026485782998903713\n",
      "train_loss 0.343683009382433 train_acc 0.8510599191275579\n",
      "epoch 1470 lr 0.02643286436917518\n",
      "train_loss 0.34366851881482274 train_acc 0.8510905526283543\n",
      "epoch 1471 lr 0.02638005147093936\n",
      "train_loss 0.3436539941925848 train_acc 0.8510905526283543\n",
      "epoch 1472 lr 0.026327344092944606\n",
      "train_loss 0.3436395013884212 train_acc 0.8511058693787527\n",
      "epoch 1473 lr 0.02627474202436132\n",
      "train_loss 0.3436249904710487 train_acc 0.8511671363803456\n",
      "epoch 1474 lr 0.02622224505478117\n",
      "train_loss 0.34361054355658355 train_acc 0.8511518196299473\n",
      "epoch 1475 lr 0.02616985297421619\n",
      "train_loss 0.34359615025330764 train_acc 0.8511518196299473\n",
      "epoch 1476 lr 0.026117565573098016\n",
      "train_loss 0.3435817662111429 train_acc 0.8511365028795491\n",
      "epoch 1477 lr 0.026065382642276945\n",
      "train_loss 0.34356737785088787 train_acc 0.8511518196299473\n",
      "epoch 1478 lr 0.026013303973021207\n",
      "train_loss 0.3435529670520039 train_acc 0.8511518196299473\n",
      "epoch 1479 lr 0.025961329357016033\n",
      "train_loss 0.34353859117786445 train_acc 0.851197769881142\n",
      "epoch 1480 lr 0.025909458586362916\n",
      "train_loss 0.34352422532247967 train_acc 0.851197769881142\n",
      "epoch 1481 lr 0.02585769145357868\n",
      "train_loss 0.3435098418138273 train_acc 0.8511824531307438\n",
      "epoch 1482 lr 0.025806027751594744\n",
      "train_loss 0.3434954795657101 train_acc 0.8512130866315403\n",
      "epoch 1483 lr 0.025754467273756212\n",
      "train_loss 0.34348116027538733 train_acc 0.8512130866315403\n",
      "epoch 1484 lr 0.025703009813821127\n",
      "train_loss 0.34346685897764495 train_acc 0.851197769881142\n",
      "epoch 1485 lr 0.025651655165959554\n",
      "train_loss 0.34345262391549514 train_acc 0.851197769881142\n",
      "epoch 1486 lr 0.02560040312475286\n",
      "train_loss 0.3434384077956275 train_acc 0.8511824531307438\n",
      "epoch 1487 lr 0.02554925348519279\n",
      "train_loss 0.3434241784898671 train_acc 0.851197769881142\n",
      "epoch 1488 lr 0.025498206042680733\n",
      "train_loss 0.34340991351859346 train_acc 0.8512437201323367\n",
      "epoch 1489 lr 0.025447260593026835\n",
      "train_loss 0.3433957250398131 train_acc 0.8512284033819385\n",
      "epoch 1490 lr 0.02539641693244925\n",
      "train_loss 0.3433815337978882 train_acc 0.851259036882735\n",
      "epoch 1491 lr 0.025345674857573247\n",
      "train_loss 0.34336731742970317 train_acc 0.8512437201323367\n",
      "epoch 1492 lr 0.02529503416543048\n",
      "train_loss 0.34335311048594136 train_acc 0.851259036882735\n",
      "epoch 1493 lr 0.025244494653458086\n",
      "train_loss 0.3433389395256254 train_acc 0.8512743536331332\n",
      "epoch 1494 lr 0.02519405611949798\n",
      "train_loss 0.34332479804668037 train_acc 0.8512437201323367\n",
      "epoch 1495 lr 0.025143718361795932\n",
      "train_loss 0.34331059786422596 train_acc 0.8512437201323367\n",
      "epoch 1496 lr 0.025093481179000867\n",
      "train_loss 0.3432963817955195 train_acc 0.8512284033819385\n",
      "epoch 1497 lr 0.025043344370163964\n",
      "train_loss 0.3432821935477575 train_acc 0.8512437201323367\n",
      "epoch 1498 lr 0.024993307734737943\n",
      "train_loss 0.3432680269627912 train_acc 0.8512743536331332\n",
      "epoch 1499 lr 0.024943371072576177\n",
      "train_loss 0.34325389847932136 train_acc 0.8513049871339297\n",
      "\n",
      "val loss = 0.3650292473840794, \n",
      "val acc = 0.8341833218470021\n",
      "\n",
      "epoch 1500 lr 0.02489353418393197\n",
      "train_loss 0.3432397965871082 train_acc 0.8513049871339297\n",
      "epoch 1501 lr 0.02484379686945769\n",
      "train_loss 0.343225647567969 train_acc 0.8512896703835314\n",
      "epoch 1502 lr 0.024794158930204\n",
      "train_loss 0.34321147154538545 train_acc 0.8513203038843279\n",
      "epoch 1503 lr 0.024744620167619105\n",
      "train_loss 0.3431972907807575 train_acc 0.8513203038843279\n",
      "epoch 1504 lr 0.024695180383547857\n",
      "train_loss 0.3431831904969578 train_acc 0.8514122043867173\n",
      "epoch 1505 lr 0.024645839380231085\n",
      "train_loss 0.3431691559453697 train_acc 0.8514428378875137\n",
      "epoch 1506 lr 0.02459659696030468\n",
      "train_loss 0.3431551161679746 train_acc 0.8514122043867173\n",
      "epoch 1507 lr 0.024547452926798927\n",
      "train_loss 0.3431410910786187 train_acc 0.8514734713883103\n",
      "epoch 1508 lr 0.024498407083137597\n",
      "train_loss 0.34312714042102993 train_acc 0.8515041048891068\n",
      "epoch 1509 lr 0.024449459233137277\n",
      "train_loss 0.34311319758053926 train_acc 0.8515347383899032\n",
      "epoch 1510 lr 0.024400609181006477\n",
      "train_loss 0.3430992184373625 train_acc 0.8515500551403015\n",
      "epoch 1511 lr 0.024351856731344948\n",
      "train_loss 0.3430853156795185 train_acc 0.8515653718906997\n",
      "epoch 1512 lr 0.024303201689142802\n",
      "train_loss 0.3430714347810251 train_acc 0.8515806886410979\n",
      "epoch 1513 lr 0.024254643859779827\n",
      "train_loss 0.3430575827923263 train_acc 0.8515806886410979\n",
      "epoch 1514 lr 0.024206183049024617\n",
      "train_loss 0.3430437939186565 train_acc 0.8515500551403015\n",
      "epoch 1515 lr 0.02415781906303389\n",
      "train_loss 0.34303005072112486 train_acc 0.851519421639505\n",
      "epoch 1516 lr 0.02410955170835162\n",
      "train_loss 0.34301632320172637 train_acc 0.8515806886410979\n",
      "epoch 1517 lr 0.024061380791908338\n",
      "train_loss 0.34300250975960866 train_acc 0.8515347383899032\n",
      "epoch 1518 lr 0.024013306121020293\n",
      "train_loss 0.3429886525636232 train_acc 0.8515500551403015\n",
      "epoch 1519 lr 0.02396532750338876\n",
      "train_loss 0.3429748087985192 train_acc 0.8515653718906997\n",
      "epoch 1520 lr 0.023917444747099184\n",
      "train_loss 0.3429609917167871 train_acc 0.8515806886410979\n",
      "epoch 1521 lr 0.023869657660620498\n",
      "train_loss 0.3429472053354333 train_acc 0.8515653718906997\n",
      "epoch 1522 lr 0.023821966052804268\n",
      "train_loss 0.342933457500286 train_acc 0.8515653718906997\n",
      "epoch 1523 lr 0.023774369732884024\n",
      "train_loss 0.3429198068227317 train_acc 0.8515960053914962\n",
      "epoch 1524 lr 0.0237268685104744\n",
      "train_loss 0.34290618507174175 train_acc 0.8515500551403015\n",
      "epoch 1525 lr 0.023679462195570464\n",
      "train_loss 0.34289251538780835 train_acc 0.8515500551403015\n",
      "epoch 1526 lr 0.023632150598546876\n",
      "train_loss 0.34287882391445795 train_acc 0.851519421639505\n",
      "epoch 1527 lr 0.0235849335301572\n",
      "train_loss 0.3428651677540978 train_acc 0.8515500551403015\n",
      "epoch 1528 lr 0.02353781080153308\n",
      "train_loss 0.3428515155816818 train_acc 0.8515653718906997\n",
      "epoch 1529 lr 0.023490782224183555\n",
      "train_loss 0.3428378853780335 train_acc 0.8515347383899032\n",
      "epoch 1530 lr 0.023443847609994243\n",
      "train_loss 0.3428242561572851 train_acc 0.8515653718906997\n",
      "epoch 1531 lr 0.02339700677122664\n",
      "train_loss 0.3428106190868003 train_acc 0.8515806886410979\n",
      "epoch 1532 lr 0.023350259520517308\n",
      "train_loss 0.34279696176930174 train_acc 0.8515960053914962\n",
      "epoch 1533 lr 0.0233036056708772\n",
      "train_loss 0.3427832946015722 train_acc 0.8516113221418944\n",
      "epoch 1534 lr 0.023257045035690836\n",
      "train_loss 0.34276960845811555 train_acc 0.8516419556426909\n",
      "epoch 1535 lr 0.023210577428715636\n",
      "train_loss 0.3427559353989845 train_acc 0.8516419556426909\n",
      "epoch 1536 lr 0.02316420266408109\n",
      "train_loss 0.34274223208620963 train_acc 0.8516725891434873\n",
      "epoch 1537 lr 0.023117920556288092\n",
      "train_loss 0.34272857772903303 train_acc 0.8517032226442838\n",
      "epoch 1538 lr 0.023071730920208137\n",
      "train_loss 0.34271489790853704 train_acc 0.8517032226442838\n",
      "epoch 1539 lr 0.023025633571082633\n",
      "train_loss 0.34270121877259235 train_acc 0.8517032226442838\n",
      "epoch 1540 lr 0.022979628324522106\n",
      "train_loss 0.34268747039965974 train_acc 0.8517644896458767\n",
      "epoch 1541 lr 0.022933714996505525\n",
      "train_loss 0.3426736766875359 train_acc 0.8517491728954785\n",
      "epoch 1542 lr 0.022887893403379496\n",
      "train_loss 0.34265986613499383 train_acc 0.8517032226442838\n",
      "epoch 1543 lr 0.022842163361857612\n",
      "train_loss 0.3426460350293739 train_acc 0.851718539394682\n",
      "epoch 1544 lr 0.022796524689019618\n",
      "train_loss 0.34263213000983 train_acc 0.8517644896458767\n",
      "epoch 1545 lr 0.02275097720231079\n",
      "train_loss 0.3426182512625846 train_acc 0.8518257566474696\n",
      "epoch 1546 lr 0.02270552071954109\n",
      "train_loss 0.3426044070613029 train_acc 0.8517644896458767\n",
      "epoch 1547 lr 0.022660155058884555\n",
      "train_loss 0.34259056717497 train_acc 0.8517491728954785\n",
      "epoch 1548 lr 0.02261488003887846\n",
      "train_loss 0.342576696274577 train_acc 0.8517491728954785\n",
      "epoch 1549 lr 0.022569695478422684\n",
      "train_loss 0.34256280921024945 train_acc 0.8517338561450802\n",
      "\n",
      "val loss = 0.3647429527164132, \n",
      "val acc = 0.8344589937973811\n",
      "\n",
      "epoch 1550 lr 0.022524601196778904\n",
      "train_loss 0.3425489908132033 train_acc 0.8517338561450802\n",
      "epoch 1551 lr 0.02247959701356995\n",
      "train_loss 0.3425352085557705 train_acc 0.8517491728954785\n",
      "epoch 1552 lr 0.02243468274877902\n",
      "train_loss 0.34252140196627295 train_acc 0.8517798063962749\n",
      "epoch 1553 lr 0.022389858222749002\n",
      "train_loss 0.3425075771582471 train_acc 0.8517644896458767\n",
      "epoch 1554 lr 0.022345123256181723\n",
      "train_loss 0.3424937782956118 train_acc 0.8517644896458767\n",
      "epoch 1555 lr 0.022300477670137268\n",
      "train_loss 0.3424800509375652 train_acc 0.8517491728954785\n",
      "epoch 1556 lr 0.02225592128603322\n",
      "train_loss 0.3424663142420401 train_acc 0.8517644896458767\n",
      "epoch 1557 lr 0.022211453925644\n",
      "train_loss 0.3424525455597356 train_acc 0.8517951231466732\n",
      "epoch 1558 lr 0.02216707541110009\n",
      "train_loss 0.3424387708792769 train_acc 0.8518257566474696\n",
      "epoch 1559 lr 0.022122785564887386\n",
      "train_loss 0.34242501662110286 train_acc 0.8518717068986644\n",
      "epoch 1560 lr 0.02207858420984643\n",
      "train_loss 0.34241128365626355 train_acc 0.8518104398970714\n",
      "epoch 1561 lr 0.022034471169171763\n",
      "train_loss 0.3423975696971976 train_acc 0.8518563901482662\n",
      "epoch 1562 lr 0.021990446266411143\n",
      "train_loss 0.3423838484046018 train_acc 0.8518870236490627\n",
      "epoch 1563 lr 0.021946509325464915\n",
      "train_loss 0.34237006351550237 train_acc 0.8518717068986644\n",
      "epoch 1564 lr 0.021902660170585245\n",
      "train_loss 0.34235623498767204 train_acc 0.8519023403994609\n",
      "epoch 1565 lr 0.02185889862637547\n",
      "train_loss 0.34234243601675773 train_acc 0.8518717068986644\n",
      "epoch 1566 lr 0.021815224517789333\n",
      "train_loss 0.3423286297165314 train_acc 0.8518410733978679\n",
      "epoch 1567 lr 0.021771637670130368\n",
      "train_loss 0.3423148242288043 train_acc 0.8518257566474696\n",
      "epoch 1568 lr 0.021728137909051103\n",
      "train_loss 0.34230102913969396 train_acc 0.8518104398970714\n",
      "epoch 1569 lr 0.02168472506055245\n",
      "train_loss 0.3422872339858988 train_acc 0.8518257566474696\n",
      "epoch 1570 lr 0.021641398950982948\n",
      "train_loss 0.3422734559025695 train_acc 0.8518410733978679\n",
      "epoch 1571 lr 0.02159815940703811\n",
      "train_loss 0.34225970743196615 train_acc 0.8518257566474696\n",
      "epoch 1572 lr 0.021555006255759693\n",
      "train_loss 0.34224599686085316 train_acc 0.8518104398970714\n",
      "epoch 1573 lr 0.021511939324535045\n",
      "train_loss 0.3422322914146683 train_acc 0.8517951231466732\n",
      "epoch 1574 lr 0.021468958441096368\n",
      "train_loss 0.34221855299961845 train_acc 0.8517798063962749\n",
      "epoch 1575 lr 0.02142606343352009\n",
      "train_loss 0.3422047915879855 train_acc 0.8517798063962749\n",
      "epoch 1576 lr 0.021383254130226105\n",
      "train_loss 0.3421910328408857 train_acc 0.8517798063962749\n",
      "epoch 1577 lr 0.021340530359977163\n",
      "train_loss 0.3421773064644656 train_acc 0.8517798063962749\n",
      "epoch 1578 lr 0.021297891951878107\n",
      "train_loss 0.34216350647337196 train_acc 0.8517951231466732\n",
      "epoch 1579 lr 0.021255338735375263\n",
      "train_loss 0.3421497093597222 train_acc 0.8517951231466732\n",
      "epoch 1580 lr 0.02121287054025569\n",
      "train_loss 0.34213593771916084 train_acc 0.8518257566474696\n",
      "epoch 1581 lr 0.021170487196646572\n",
      "train_loss 0.34212216164471304 train_acc 0.8518257566474696\n",
      "epoch 1582 lr 0.021128188535014462\n",
      "train_loss 0.3421083242197235 train_acc 0.8518104398970714\n",
      "epoch 1583 lr 0.02108597438616467\n",
      "train_loss 0.34209446555043843 train_acc 0.8518104398970714\n",
      "epoch 1584 lr 0.021043844581240527\n",
      "train_loss 0.3420806142555286 train_acc 0.8517951231466732\n",
      "epoch 1585 lr 0.021001798951722776\n",
      "train_loss 0.34206670624135843 train_acc 0.8518104398970714\n",
      "epoch 1586 lr 0.020959837329428826\n",
      "train_loss 0.3420528540811602 train_acc 0.8518104398970714\n",
      "epoch 1587 lr 0.020917959546512148\n",
      "train_loss 0.34203898789425385 train_acc 0.8518257566474696\n",
      "epoch 1588 lr 0.02087616543546154\n",
      "train_loss 0.3420250712462235 train_acc 0.8518410733978679\n",
      "epoch 1589 lr 0.020834454829100516\n",
      "train_loss 0.3420111158131582 train_acc 0.8517951231466732\n",
      "epoch 1590 lr 0.02079282756058658\n",
      "train_loss 0.34199718266534307 train_acc 0.8517798063962749\n",
      "epoch 1591 lr 0.02075128346341062\n",
      "train_loss 0.3419833349910699 train_acc 0.8517798063962749\n",
      "epoch 1592 lr 0.020709822371396173\n",
      "train_loss 0.3419696168890071 train_acc 0.8517951231466732\n",
      "epoch 1593 lr 0.020668444118698833\n",
      "train_loss 0.34195594725757134 train_acc 0.8517951231466732\n",
      "epoch 1594 lr 0.020627148539805514\n",
      "train_loss 0.34194234598612583 train_acc 0.8518257566474696\n",
      "epoch 1595 lr 0.02058593546953387\n",
      "train_loss 0.3419288058870251 train_acc 0.8518257566474696\n",
      "epoch 1596 lr 0.02054480474303154\n",
      "train_loss 0.3419152741201633 train_acc 0.8518257566474696\n",
      "epoch 1597 lr 0.020503756195775585\n",
      "train_loss 0.3419017255989932 train_acc 0.8518717068986644\n",
      "epoch 1598 lr 0.020462789663571745\n",
      "train_loss 0.3418881310105499 train_acc 0.8519023403994609\n",
      "epoch 1599 lr 0.02042190498255385\n",
      "train_loss 0.34187450620913584 train_acc 0.8519023403994609\n",
      "\n",
      "val loss = 0.3645125590109763, \n",
      "val acc = 0.8341833218470021\n",
      "\n",
      "epoch 1600 lr 0.020381101989183102\n",
      "train_loss 0.34186087124950354 train_acc 0.8519329739002574\n",
      "epoch 1601 lr 0.0203403805202475\n",
      "train_loss 0.3418472639062658 train_acc 0.8519329739002574\n",
      "epoch 1602 lr 0.02029974041286109\n",
      "train_loss 0.34183359584832745 train_acc 0.8518870236490627\n",
      "epoch 1603 lr 0.020259181504463403\n",
      "train_loss 0.34181996915273055 train_acc 0.8519023403994609\n",
      "epoch 1604 lr 0.02021870363281874\n",
      "train_loss 0.3418063343372336 train_acc 0.8519329739002574\n",
      "epoch 1605 lr 0.020178306636015574\n",
      "train_loss 0.34179271191725163 train_acc 0.8519482906506556\n",
      "epoch 1606 lr 0.02013799035246585\n",
      "train_loss 0.34177909384960276 train_acc 0.8519023403994609\n",
      "epoch 1607 lr 0.020097754620904393\n",
      "train_loss 0.34176548517726796 train_acc 0.8519023403994609\n",
      "epoch 1608 lr 0.020057599280388208\n",
      "train_loss 0.34175187979494237 train_acc 0.8519176571498591\n",
      "epoch 1609 lr 0.020017524170295897\n",
      "train_loss 0.3417382819341201 train_acc 0.8519482906506556\n",
      "epoch 1610 lr 0.019977529130326948\n",
      "train_loss 0.34172469323267973 train_acc 0.8519636074010538\n",
      "epoch 1611 lr 0.019937614000501168\n",
      "train_loss 0.3417111156691051 train_acc 0.8519636074010538\n",
      "epoch 1612 lr 0.019897778621157963\n",
      "train_loss 0.34169753277142995 train_acc 0.8519636074010538\n",
      "epoch 1613 lr 0.019858022832955784\n",
      "train_loss 0.3416839338583819 train_acc 0.8519482906506556\n",
      "epoch 1614 lr 0.0198183464768714\n",
      "train_loss 0.34167033462289736 train_acc 0.8519636074010538\n",
      "epoch 1615 lr 0.019778749394199362\n",
      "train_loss 0.34165679163544027 train_acc 0.851978924151452\n",
      "epoch 1616 lr 0.019739231426551263\n",
      "train_loss 0.34164324597680984 train_acc 0.8519636074010538\n",
      "epoch 1617 lr 0.019699792415855195\n",
      "train_loss 0.3416297430309611 train_acc 0.8519636074010538\n",
      "epoch 1618 lr 0.019660432204355052\n",
      "train_loss 0.341616265075762 train_acc 0.8519329739002574\n",
      "epoch 1619 lr 0.019621150634609945\n",
      "train_loss 0.3416027483796609 train_acc 0.8518717068986644\n",
      "epoch 1620 lr 0.019581947549493533\n",
      "train_loss 0.34158920581135543 train_acc 0.8518717068986644\n",
      "epoch 1621 lr 0.019542822792193434\n",
      "train_loss 0.3415756234464128 train_acc 0.8519023403994609\n",
      "epoch 1622 lr 0.019503776206210553\n",
      "train_loss 0.3415620675968533 train_acc 0.8519329739002574\n",
      "epoch 1623 lr 0.019464807635358513\n",
      "train_loss 0.3415485798147651 train_acc 0.851978924151452\n",
      "epoch 1624 lr 0.019425916923762956\n",
      "train_loss 0.3415350956654363 train_acc 0.8519636074010538\n",
      "epoch 1625 lr 0.019387103915861004\n",
      "train_loss 0.3415216302480223 train_acc 0.851978924151452\n",
      "epoch 1626 lr 0.019348368456400568\n",
      "train_loss 0.3415080830184697 train_acc 0.8519482906506556\n",
      "epoch 1627 lr 0.019309710390439744\n",
      "train_loss 0.34149449400594406 train_acc 0.8519942409018503\n",
      "epoch 1628 lr 0.019271129563346236\n",
      "train_loss 0.34148088232826435 train_acc 0.8520095576522485\n",
      "epoch 1629 lr 0.01923262582079667\n",
      "train_loss 0.34146728165554857 train_acc 0.8520095576522485\n",
      "epoch 1630 lr 0.019194199008776038\n",
      "train_loss 0.34145367033775786 train_acc 0.8520248744026467\n",
      "epoch 1631 lr 0.019155848973577024\n",
      "train_loss 0.3414400330131103 train_acc 0.8520555079034432\n",
      "epoch 1632 lr 0.019117575561799455\n",
      "train_loss 0.34142639840248584 train_acc 0.8520555079034432\n",
      "epoch 1633 lr 0.019079378620349613\n",
      "train_loss 0.34141280106145594 train_acc 0.852040191153045\n",
      "epoch 1634 lr 0.019041257996439704\n",
      "train_loss 0.3413991680034157 train_acc 0.8520708246538414\n",
      "epoch 1635 lr 0.019003213537587157\n",
      "train_loss 0.34138549976997107 train_acc 0.8520555079034432\n",
      "epoch 1636 lr 0.018965245091614107\n",
      "train_loss 0.3413718750634295 train_acc 0.8520708246538414\n",
      "epoch 1637 lr 0.018927352506646705\n",
      "train_loss 0.34135824976235596 train_acc 0.8520555079034432\n",
      "epoch 1638 lr 0.01888953563111457\n",
      "train_loss 0.3413446355928531 train_acc 0.8520555079034432\n",
      "epoch 1639 lr 0.01885179431375014\n",
      "train_loss 0.34133105392817636 train_acc 0.8520248744026467\n",
      "epoch 1640 lr 0.018814128403588107\n",
      "train_loss 0.34131746236629507 train_acc 0.852040191153045\n",
      "epoch 1641 lr 0.018776537749964767\n",
      "train_loss 0.34130392537026744 train_acc 0.8520248744026467\n",
      "epoch 1642 lr 0.018739022202517473\n",
      "train_loss 0.3412903948182232 train_acc 0.852040191153045\n",
      "epoch 1643 lr 0.018701581611183963\n",
      "train_loss 0.3412768544700724 train_acc 0.8520555079034432\n",
      "epoch 1644 lr 0.01866421582620184\n",
      "train_loss 0.3412633284435682 train_acc 0.8520708246538414\n",
      "epoch 1645 lr 0.018626924698107904\n",
      "train_loss 0.3412497559840915 train_acc 0.8521014581546379\n",
      "epoch 1646 lr 0.0185897080777376\n",
      "train_loss 0.34123609894597795 train_acc 0.8521320916554344\n",
      "epoch 1647 lr 0.018552565816224387\n",
      "train_loss 0.341222507445727 train_acc 0.8521474084058326\n",
      "epoch 1648 lr 0.018515497764999184\n",
      "train_loss 0.34120892513425205 train_acc 0.8521474084058326\n",
      "epoch 1649 lr 0.01847850377578972\n",
      "train_loss 0.34119529544476856 train_acc 0.8520861414042397\n",
      "\n",
      "val loss = 0.3642752536028504, \n",
      "val acc = 0.833907649896623\n",
      "\n",
      "epoch 1650 lr 0.018441583700620004\n",
      "train_loss 0.3411816367964959 train_acc 0.8520555079034432\n",
      "epoch 1651 lr 0.018404737391809672\n",
      "train_loss 0.3411679824836143 train_acc 0.8520708246538414\n",
      "epoch 1652 lr 0.018367964701973456\n",
      "train_loss 0.3411542896374305 train_acc 0.8520861414042397\n",
      "epoch 1653 lr 0.01833126548402053\n",
      "train_loss 0.3411406236783781 train_acc 0.8520555079034432\n",
      "epoch 1654 lr 0.01829463959115399\n",
      "train_loss 0.341126959344814 train_acc 0.852040191153045\n",
      "epoch 1655 lr 0.018258086876870198\n",
      "train_loss 0.34111331789399585 train_acc 0.8520708246538414\n",
      "epoch 1656 lr 0.01822160719495827\n",
      "train_loss 0.3410996821104331 train_acc 0.8521320916554344\n",
      "epoch 1657 lr 0.018185200399499404\n",
      "train_loss 0.3410859704454182 train_acc 0.8521167749050361\n",
      "epoch 1658 lr 0.018148866344866392\n",
      "train_loss 0.34107228997807715 train_acc 0.8520861414042397\n",
      "epoch 1659 lr 0.01811260488572295\n",
      "train_loss 0.34105857259744243 train_acc 0.8521014581546379\n",
      "epoch 1660 lr 0.01807641587702321\n",
      "train_loss 0.3410448497082358 train_acc 0.8521167749050361\n",
      "epoch 1661 lr 0.018040299174011072\n",
      "train_loss 0.34103106413669154 train_acc 0.8521627251562308\n",
      "epoch 1662 lr 0.018004254632219694\n",
      "train_loss 0.3410171944870512 train_acc 0.8521474084058326\n",
      "epoch 1663 lr 0.01796828210747084\n",
      "train_loss 0.3410033163648756 train_acc 0.8521933586570273\n",
      "epoch 1664 lr 0.01793238145587438\n",
      "train_loss 0.34098945209887743 train_acc 0.8522086754074255\n",
      "epoch 1665 lr 0.01789655253382765\n",
      "train_loss 0.34097559903990393 train_acc 0.8522086754074255\n",
      "epoch 1666 lr 0.01786079519801492\n",
      "train_loss 0.34096172310139145 train_acc 0.8522086754074255\n",
      "epoch 1667 lr 0.017825109305406792\n",
      "train_loss 0.3409478663736375 train_acc 0.8522239921578239\n",
      "epoch 1668 lr 0.01778949471325966\n",
      "train_loss 0.34093412173171966 train_acc 0.8522546256586203\n",
      "epoch 1669 lr 0.017753951279115093\n",
      "train_loss 0.3409204247814573 train_acc 0.8522699424090185\n",
      "epoch 1670 lr 0.01771847886079932\n",
      "train_loss 0.34090677298850774 train_acc 0.852300575909815\n",
      "epoch 1671 lr 0.01768307731642261\n",
      "train_loss 0.3408931434762592 train_acc 0.8523158926602132\n",
      "epoch 1672 lr 0.01764774650437875\n",
      "train_loss 0.34087951576483855 train_acc 0.8522699424090185\n",
      "epoch 1673 lr 0.017612486283344428\n",
      "train_loss 0.3408658841324772 train_acc 0.852300575909815\n",
      "epoch 1674 lr 0.01757729651227873\n",
      "train_loss 0.3408522845370533 train_acc 0.8523158926602132\n",
      "epoch 1675 lr 0.017542177050422512\n",
      "train_loss 0.34083869249145543 train_acc 0.8523618429114079\n",
      "epoch 1676 lr 0.017507127757297892\n",
      "train_loss 0.3408250588898714 train_acc 0.8523312094106115\n",
      "epoch 1677 lr 0.01747214849270764\n",
      "train_loss 0.34081139812105193 train_acc 0.8523158926602132\n",
      "epoch 1678 lr 0.017437239116734657\n",
      "train_loss 0.3407977368467703 train_acc 0.8523312094106115\n",
      "epoch 1679 lr 0.017402399489741385\n",
      "train_loss 0.34078408469091614 train_acc 0.8523312094106115\n",
      "epoch 1680 lr 0.01736762947236928\n",
      "train_loss 0.34077048065823284 train_acc 0.8523465261610097\n",
      "epoch 1681 lr 0.01733292892553822\n",
      "train_loss 0.34075691575802186 train_acc 0.8523465261610097\n",
      "epoch 1682 lr 0.017298297710445977\n",
      "train_loss 0.340743406936343 train_acc 0.8523618429114079\n",
      "epoch 1683 lr 0.017263735688567632\n",
      "train_loss 0.3407298284660156 train_acc 0.8523924764122044\n",
      "epoch 1684 lr 0.017229242721655068\n",
      "train_loss 0.34071622173747257 train_acc 0.8523465261610097\n",
      "epoch 1685 lr 0.017194818671736355\n",
      "train_loss 0.3407026187473153 train_acc 0.8523312094106115\n",
      "epoch 1686 lr 0.017160463401115263\n",
      "train_loss 0.3406890332618819 train_acc 0.8523158926602132\n",
      "epoch 1687 lr 0.01712617677237065\n",
      "train_loss 0.3406754117673342 train_acc 0.8523465261610097\n",
      "epoch 1688 lr 0.017091958648355967\n",
      "train_loss 0.3406617112015737 train_acc 0.8523771596618062\n",
      "epoch 1689 lr 0.01705780889219866\n",
      "train_loss 0.34064794633119977 train_acc 0.8523924764122044\n",
      "epoch 1690 lr 0.017023727367299672\n",
      "train_loss 0.34063413747216076 train_acc 0.8524231099130009\n",
      "epoch 1691 lr 0.016989713937332847\n",
      "train_loss 0.340620335219433 train_acc 0.8524537434137973\n",
      "epoch 1692 lr 0.016955768466244428\n",
      "train_loss 0.3406064696986887 train_acc 0.8524843769145938\n",
      "epoch 1693 lr 0.016921890818252475\n",
      "train_loss 0.3405925131729374 train_acc 0.8524690601641955\n",
      "epoch 1694 lr 0.016888080857846367\n",
      "train_loss 0.34057852862606075 train_acc 0.8524690601641955\n",
      "epoch 1695 lr 0.016854338449786198\n",
      "train_loss 0.34056460665370025 train_acc 0.8524843769145938\n",
      "epoch 1696 lr 0.016820663459102308\n",
      "train_loss 0.34055064651946104 train_acc 0.8525150104153902\n",
      "epoch 1697 lr 0.016787055751094678\n",
      "train_loss 0.3405366227038356 train_acc 0.852499693664992\n",
      "epoch 1698 lr 0.01675351519133244\n",
      "train_loss 0.34052261716936266 train_acc 0.8525303271657885\n",
      "epoch 1699 lr 0.0167200416456533\n",
      "train_loss 0.3405085766657483 train_acc 0.8525456439161867\n",
      "\n",
      "val loss = 0.3640657806253046, \n",
      "val acc = 0.8343211578221916\n",
      "\n",
      "epoch 1700 lr 0.01668663498016304\n",
      "train_loss 0.3404945738292703 train_acc 0.8525150104153902\n",
      "epoch 1701 lr 0.016653295061234943\n",
      "train_loss 0.3404806124240003 train_acc 0.8525303271657885\n",
      "epoch 1702 lr 0.016620021755509303\n",
      "train_loss 0.340466672576305 train_acc 0.8525609606665849\n",
      "epoch 1703 lr 0.016586814929892838\n",
      "train_loss 0.3404526924699635 train_acc 0.8525456439161867\n",
      "epoch 1704 lr 0.01655367445155822\n",
      "train_loss 0.34043868563602225 train_acc 0.8525456439161867\n",
      "epoch 1705 lr 0.016520600187943466\n",
      "train_loss 0.3404246878487946 train_acc 0.8525456439161867\n",
      "epoch 1706 lr 0.0164875920067515\n",
      "train_loss 0.3404106918324242 train_acc 0.8525456439161867\n",
      "epoch 1707 lr 0.01645464977594954\n",
      "train_loss 0.3403967085032691 train_acc 0.8525915941673814\n",
      "epoch 1708 lr 0.016421773363768627\n",
      "train_loss 0.3403827256940457 train_acc 0.8525762774169832\n",
      "epoch 1709 lr 0.01638896263870306\n",
      "train_loss 0.34036869409442444 train_acc 0.8526528611689744\n",
      "epoch 1710 lr 0.016356217469509906\n",
      "train_loss 0.34035467959478816 train_acc 0.8526528611689744\n",
      "epoch 1711 lr 0.01632353772520843\n",
      "train_loss 0.34034070492159574 train_acc 0.8526375444185762\n",
      "epoch 1712 lr 0.01629092327507963\n",
      "train_loss 0.3403267760750604 train_acc 0.8526375444185762\n",
      "epoch 1713 lr 0.016258373988665645\n",
      "train_loss 0.34031284951369717 train_acc 0.8526528611689744\n",
      "epoch 1714 lr 0.016225889735769296\n",
      "train_loss 0.3402989838107655 train_acc 0.8526528611689744\n",
      "epoch 1715 lr 0.01619347038645352\n",
      "train_loss 0.3402851405802116 train_acc 0.852622227668178\n",
      "epoch 1716 lr 0.016161115811040884\n",
      "train_loss 0.3402712905611455 train_acc 0.8526375444185762\n",
      "epoch 1717 lr 0.016128825880113037\n",
      "train_loss 0.34025744701654004 train_acc 0.852622227668178\n",
      "epoch 1718 lr 0.01609660046451022\n",
      "train_loss 0.3402435795461768 train_acc 0.8526528611689744\n",
      "epoch 1719 lr 0.01606443943533072\n",
      "train_loss 0.3402297328386329 train_acc 0.8526834946697709\n",
      "epoch 1720 lr 0.016032342663930384\n",
      "train_loss 0.3402158670747259 train_acc 0.8526834946697709\n",
      "epoch 1721 lr 0.016000310021922075\n",
      "train_loss 0.34020200539536544 train_acc 0.8527294449209656\n",
      "epoch 1722 lr 0.015968341381175196\n",
      "train_loss 0.3401881627827472 train_acc 0.8527294449209656\n",
      "epoch 1723 lr 0.015936436613815122\n",
      "train_loss 0.34017431819548477 train_acc 0.852760078421762\n",
      "epoch 1724 lr 0.01590459559222276\n",
      "train_loss 0.3401604137898567 train_acc 0.8527447616713638\n",
      "epoch 1725 lr 0.01587281818903397\n",
      "train_loss 0.3401464759586498 train_acc 0.8527907119225585\n",
      "epoch 1726 lr 0.0158411042771391\n",
      "train_loss 0.34013246648652634 train_acc 0.8527447616713638\n",
      "epoch 1727 lr 0.015809453729682458\n",
      "train_loss 0.34011849960575463 train_acc 0.8527753951721603\n",
      "epoch 1728 lr 0.01577786642006182\n",
      "train_loss 0.34010451180702017 train_acc 0.8527447616713638\n",
      "epoch 1729 lr 0.015746342221927893\n",
      "train_loss 0.34009057226195955 train_acc 0.8527447616713638\n",
      "epoch 1730 lr 0.015714881009183855\n",
      "train_loss 0.3400767383342392 train_acc 0.8527753951721603\n",
      "epoch 1731 lr 0.0156834826559848\n",
      "train_loss 0.3400630159332855 train_acc 0.852760078421762\n",
      "epoch 1732 lr 0.01565214703673729\n",
      "train_loss 0.34004934967251405 train_acc 0.8528060286729567\n",
      "epoch 1733 lr 0.015620874026098784\n",
      "train_loss 0.3400356666290954 train_acc 0.8528366621737532\n",
      "epoch 1734 lr 0.01558966349897722\n",
      "train_loss 0.34002191422502637 train_acc 0.8528672956745497\n",
      "epoch 1735 lr 0.015558515330530431\n",
      "train_loss 0.34000810725764147 train_acc 0.852959196176939\n",
      "epoch 1736 lr 0.015527429396165715\n",
      "train_loss 0.3399942872913335 train_acc 0.852959196176939\n",
      "epoch 1737 lr 0.015496405571539282\n",
      "train_loss 0.3399804980561092 train_acc 0.8530204631785321\n",
      "epoch 1738 lr 0.015465443732555801\n",
      "train_loss 0.3399667064222071 train_acc 0.8530357799289303\n",
      "epoch 1739 lr 0.015434543755367867\n",
      "train_loss 0.33995287529697116 train_acc 0.8530204631785321\n",
      "epoch 1740 lr 0.01540370551637554\n",
      "train_loss 0.33993904576586403 train_acc 0.8530204631785321\n",
      "epoch 1741 lr 0.015372928892225808\n",
      "train_loss 0.33992518004121924 train_acc 0.8530357799289303\n",
      "epoch 1742 lr 0.015342213759812151\n",
      "train_loss 0.33991131377164313 train_acc 0.8530204631785321\n",
      "epoch 1743 lr 0.015311559996273982\n",
      "train_loss 0.33989744176513903 train_acc 0.8530204631785321\n",
      "epoch 1744 lr 0.01528096747899622\n",
      "train_loss 0.3398836256078023 train_acc 0.852959196176939\n",
      "epoch 1745 lr 0.015250436085608741\n",
      "train_loss 0.33986993820594974 train_acc 0.8530051464281339\n",
      "epoch 1746 lr 0.015219965693985947\n",
      "train_loss 0.33985626075845465 train_acc 0.8530051464281339\n",
      "epoch 1747 lr 0.015189556182246215\n",
      "train_loss 0.3398426311659584 train_acc 0.8530357799289303\n",
      "epoch 1748 lr 0.015159207428751471\n",
      "train_loss 0.3398289942217354 train_acc 0.8530510966793285\n",
      "epoch 1749 lr 0.015128919312106647\n",
      "train_loss 0.33981541268176935 train_acc 0.853081730180125\n",
      "\n",
      "val loss = 0.3637875945456426, \n",
      "val acc = 0.8341833218470021\n",
      "\n",
      "epoch 1750 lr 0.01509869171115925\n",
      "train_loss 0.339801891209449 train_acc 0.8530970469305232\n",
      "epoch 1751 lr 0.01506852450499883\n",
      "train_loss 0.33978841275009525 train_acc 0.8530970469305232\n",
      "epoch 1752 lr 0.015038417572956516\n",
      "train_loss 0.33977490595396503 train_acc 0.853081730180125\n",
      "epoch 1753 lr 0.01500837079460455\n",
      "train_loss 0.33976133831589866 train_acc 0.853081730180125\n",
      "epoch 1754 lr 0.014978384049755768\n",
      "train_loss 0.3397477888368309 train_acc 0.8530664134297268\n",
      "epoch 1755 lr 0.01494845721846316\n",
      "train_loss 0.3397342705385111 train_acc 0.8530510966793285\n",
      "epoch 1756 lr 0.014918590181019353\n",
      "train_loss 0.33972073124084434 train_acc 0.8530204631785321\n",
      "epoch 1757 lr 0.014888782817956168\n",
      "train_loss 0.3397071758231143 train_acc 0.8530051464281339\n",
      "epoch 1758 lr 0.0148590350100441\n",
      "train_loss 0.33969362285535676 train_acc 0.8530204631785321\n",
      "epoch 1759 lr 0.01482934663829189\n",
      "train_loss 0.3396800370052677 train_acc 0.8530357799289303\n",
      "epoch 1760 lr 0.014799717583946\n",
      "train_loss 0.3396664816165022 train_acc 0.8530664134297268\n",
      "epoch 1761 lr 0.014770147728490184\n",
      "train_loss 0.33965287426814333 train_acc 0.8530357799289303\n",
      "epoch 1762 lr 0.01474063695364497\n",
      "train_loss 0.3396392630110921 train_acc 0.8530510966793285\n",
      "epoch 1763 lr 0.014711185141367232\n",
      "train_loss 0.33962561234659433 train_acc 0.853081730180125\n",
      "epoch 1764 lr 0.014681792173849666\n",
      "train_loss 0.33961192215273756 train_acc 0.8530970469305232\n",
      "epoch 1765 lr 0.01465245793352038\n",
      "train_loss 0.3395982402330239 train_acc 0.8531123636809215\n",
      "epoch 1766 lr 0.014623182303042357\n",
      "train_loss 0.3395845870528805 train_acc 0.8531736306825144\n",
      "epoch 1767 lr 0.01459396516531305\n",
      "train_loss 0.3395708987501435 train_acc 0.8531889474329126\n",
      "epoch 1768 lr 0.014564806403463856\n",
      "train_loss 0.33955723400352883 train_acc 0.8532195809337091\n",
      "epoch 1769 lr 0.014535705900859702\n",
      "train_loss 0.33954358959475184 train_acc 0.8532042641833109\n",
      "epoch 1770 lr 0.014506663541098527\n",
      "train_loss 0.3395300242936833 train_acc 0.8531736306825144\n",
      "epoch 1771 lr 0.014477679208010864\n",
      "train_loss 0.33951647923814815 train_acc 0.8531736306825144\n",
      "epoch 1772 lr 0.014448752785659331\n",
      "train_loss 0.3395029434078594 train_acc 0.8532042641833109\n",
      "epoch 1773 lr 0.014419884158338211\n",
      "train_loss 0.33948945628002924 train_acc 0.8532348976841073\n",
      "epoch 1774 lr 0.014391073210572945\n",
      "train_loss 0.3394760112549468 train_acc 0.8532195809337091\n",
      "epoch 1775 lr 0.014362319827119717\n",
      "train_loss 0.3394625905111231 train_acc 0.8532502144345055\n",
      "epoch 1776 lr 0.01433362389296494\n",
      "train_loss 0.33944914374881097 train_acc 0.8532195809337091\n",
      "epoch 1777 lr 0.014304985293324853\n",
      "train_loss 0.33943564891455597 train_acc 0.8532348976841073\n",
      "epoch 1778 lr 0.014276403913645005\n",
      "train_loss 0.3394221230153811 train_acc 0.8532655311849038\n",
      "epoch 1779 lr 0.014247879639599854\n",
      "train_loss 0.3394085606977963 train_acc 0.853280847935302\n",
      "epoch 1780 lr 0.014219412357092252\n",
      "train_loss 0.3393949453669888 train_acc 0.853280847935302\n",
      "epoch 1781 lr 0.014191001952253044\n",
      "train_loss 0.3393813174562281 train_acc 0.8533421149368949\n",
      "epoch 1782 lr 0.01416264831144056\n",
      "train_loss 0.33936769062105404 train_acc 0.8533114814360985\n",
      "epoch 1783 lr 0.014134351321240213\n",
      "train_loss 0.3393540033475285 train_acc 0.8533267981864967\n",
      "epoch 1784 lr 0.01410611086846399\n",
      "train_loss 0.33934028339406497 train_acc 0.8533267981864967\n",
      "epoch 1785 lr 0.014077926840150053\n",
      "train_loss 0.3393265161949167 train_acc 0.8533574316872933\n",
      "epoch 1786 lr 0.014049799123562244\n",
      "train_loss 0.33931262973222287 train_acc 0.8533727484376915\n",
      "epoch 1787 lr 0.014021727606189666\n",
      "train_loss 0.3392986742124581 train_acc 0.8533880651880897\n",
      "epoch 1788 lr 0.013993712175746204\n",
      "train_loss 0.3392847285180685 train_acc 0.8533421149368949\n",
      "epoch 1789 lr 0.013965752720170107\n",
      "train_loss 0.33927073305924543 train_acc 0.8533574316872933\n",
      "epoch 1790 lr 0.013937849127623508\n",
      "train_loss 0.33925662985301397 train_acc 0.8533880651880897\n",
      "epoch 1791 lr 0.013910001286492009\n",
      "train_loss 0.3392424237595808 train_acc 0.853403381938488\n",
      "epoch 1792 lr 0.013882209085384196\n",
      "train_loss 0.3392281468929224 train_acc 0.8534340154392844\n",
      "epoch 1793 lr 0.01385447241313124\n",
      "train_loss 0.3392138584002703 train_acc 0.8534646489400809\n",
      "epoch 1794 lr 0.013826791158786404\n",
      "train_loss 0.3391995429718859 train_acc 0.8534646489400809\n",
      "epoch 1795 lr 0.013799165211624644\n",
      "train_loss 0.33918525058653254 train_acc 0.8534186986888862\n",
      "epoch 1796 lr 0.013771594461142124\n",
      "train_loss 0.33917090148276224 train_acc 0.8534493321896827\n",
      "epoch 1797 lr 0.013744078797055815\n",
      "train_loss 0.3391564995609488 train_acc 0.8534646489400809\n",
      "epoch 1798 lr 0.013716618109303016\n",
      "train_loss 0.33914218095146725 train_acc 0.8534799656904791\n",
      "epoch 1799 lr 0.013689212288040948\n",
      "train_loss 0.33912790876100046 train_acc 0.8534799656904791\n",
      "\n",
      "val loss = 0.3634733829418522, \n",
      "val acc = 0.8343211578221916\n",
      "\n",
      "epoch 1800 lr 0.01366186122364628\n",
      "train_loss 0.3391137042343041 train_acc 0.8534952824408774\n",
      "epoch 1801 lr 0.013634564806714726\n",
      "train_loss 0.33909945514702855 train_acc 0.8534952824408774\n",
      "epoch 1802 lr 0.013607322928060573\n",
      "train_loss 0.3390852308921622 train_acc 0.8535565494424703\n",
      "epoch 1803 lr 0.013580135478716282\n",
      "train_loss 0.3390709546116526 train_acc 0.8535718661928685\n",
      "epoch 1804 lr 0.013553002349932005\n",
      "train_loss 0.33905665701813503 train_acc 0.853541232692072\n",
      "epoch 1805 lr 0.013525923433175206\n",
      "train_loss 0.3390423440600076 train_acc 0.8535718661928685\n",
      "epoch 1806 lr 0.013498898620130168\n",
      "train_loss 0.3390280509884418 train_acc 0.8535565494424703\n",
      "epoch 1807 lr 0.013471927802697617\n",
      "train_loss 0.3390137586234402 train_acc 0.8535718661928685\n",
      "epoch 1808 lr 0.013445010872994231\n",
      "train_loss 0.33899955511617186 train_acc 0.8535871829432667\n",
      "epoch 1809 lr 0.013418147723352269\n",
      "train_loss 0.3389853973069527 train_acc 0.8535565494424703\n",
      "epoch 1810 lr 0.013391338246319088\n",
      "train_loss 0.338971293530913 train_acc 0.8535871829432667\n",
      "epoch 1811 lr 0.01336458233465675\n",
      "train_loss 0.338957159441093 train_acc 0.8535718661928685\n",
      "epoch 1812 lr 0.013337879881341566\n",
      "train_loss 0.3389430943591386 train_acc 0.8535565494424703\n",
      "epoch 1813 lr 0.013311230779563697\n",
      "train_loss 0.3389290587617312 train_acc 0.8535565494424703\n",
      "epoch 1814 lr 0.013284634922726688\n",
      "train_loss 0.3389150270160225 train_acc 0.8535259159416738\n",
      "epoch 1815 lr 0.01325809220444709\n",
      "train_loss 0.3389009414444818 train_acc 0.853541232692072\n",
      "epoch 1816 lr 0.013231602518553981\n",
      "train_loss 0.3388867855601687 train_acc 0.8535718661928685\n",
      "epoch 1817 lr 0.013205165759088594\n",
      "train_loss 0.33887260720555695 train_acc 0.8536331331944614\n",
      "epoch 1818 lr 0.013178781820303844\n",
      "train_loss 0.33885842348939715 train_acc 0.8536178164440632\n",
      "epoch 1819 lr 0.013152450596663954\n",
      "train_loss 0.3388441645153135 train_acc 0.8536178164440632\n",
      "epoch 1820 lr 0.01312617198284398\n",
      "train_loss 0.3388299410565541 train_acc 0.8536331331944614\n",
      "epoch 1821 lr 0.013099945873729446\n",
      "train_loss 0.33881577193220114 train_acc 0.8536331331944614\n",
      "epoch 1822 lr 0.013073772164415867\n",
      "train_loss 0.33880163310547534 train_acc 0.8536637666952579\n",
      "epoch 1823 lr 0.013047650750208382\n",
      "train_loss 0.3387875770052034 train_acc 0.8536790834456561\n",
      "epoch 1824 lr 0.01302158152662129\n",
      "train_loss 0.33877355327700354 train_acc 0.8536637666952579\n",
      "epoch 1825 lr 0.012995564389377674\n",
      "train_loss 0.3387594992583733 train_acc 0.8536637666952579\n",
      "epoch 1826 lr 0.012969599234408935\n",
      "train_loss 0.33874539177005575 train_acc 0.8536484499448597\n",
      "epoch 1827 lr 0.012943685957854433\n",
      "train_loss 0.33873117928355395 train_acc 0.8536484499448597\n",
      "epoch 1828 lr 0.012917824456061013\n",
      "train_loss 0.3387169678847659 train_acc 0.8536484499448597\n",
      "epoch 1829 lr 0.01289201462558265\n",
      "train_loss 0.3387028446221393 train_acc 0.8537097169464526\n",
      "epoch 1830 lr 0.012866256363179972\n",
      "train_loss 0.3386887346131131 train_acc 0.8537097169464526\n",
      "epoch 1831 lr 0.012840549565819906\n",
      "train_loss 0.33867458633327835 train_acc 0.8537250336968508\n",
      "epoch 1832 lr 0.01281489413067522\n",
      "train_loss 0.3386604512580042 train_acc 0.8537403504472492\n",
      "epoch 1833 lr 0.012789289955124147\n",
      "train_loss 0.3386463284478728 train_acc 0.8537556671976474\n",
      "epoch 1834 lr 0.012763736936749943\n",
      "train_loss 0.3386321467692691 train_acc 0.8537709839480456\n",
      "epoch 1835 lr 0.012738234973340508\n",
      "train_loss 0.33861796303615216 train_acc 0.8538169341992403\n",
      "epoch 1836 lr 0.012712783962887947\n",
      "train_loss 0.33860374701151474 train_acc 0.8538322509496385\n",
      "epoch 1837 lr 0.012687383803588193\n",
      "train_loss 0.33858962291518135 train_acc 0.8538322509496385\n",
      "epoch 1838 lr 0.012662034393840563\n",
      "train_loss 0.3385754130651263 train_acc 0.8538322509496385\n",
      "epoch 1839 lr 0.012636735632247398\n",
      "train_loss 0.3385612882205413 train_acc 0.8538016174488421\n",
      "epoch 1840 lr 0.012611487417613606\n",
      "train_loss 0.3385471482260961 train_acc 0.8538322509496385\n",
      "epoch 1841 lr 0.012586289648946303\n",
      "train_loss 0.33853305131781486 train_acc 0.8538169341992403\n",
      "epoch 1842 lr 0.012561142225454375\n",
      "train_loss 0.3385190368298466 train_acc 0.8538322509496385\n",
      "epoch 1843 lr 0.012536045046548101\n",
      "train_loss 0.3385050327731838 train_acc 0.8538475677000368\n",
      "epoch 1844 lr 0.012510998011838722\n",
      "train_loss 0.33849110512115166 train_acc 0.853862884450435\n",
      "epoch 1845 lr 0.012486001021138077\n",
      "train_loss 0.33847725141514273 train_acc 0.8538782012008332\n",
      "epoch 1846 lr 0.01246105397445816\n",
      "train_loss 0.33846338164845163 train_acc 0.8538935179512315\n",
      "epoch 1847 lr 0.012436156772010761\n",
      "train_loss 0.3384494629302366 train_acc 0.8539241514520279\n",
      "epoch 1848 lr 0.012411309314207026\n",
      "train_loss 0.3384355073824434 train_acc 0.8539241514520279\n",
      "epoch 1849 lr 0.0123865115016571\n",
      "train_loss 0.33842159178727327 train_acc 0.8539088347016297\n",
      "\n",
      "val loss = 0.36313151240536096, \n",
      "val acc = 0.8356995175740869\n",
      "\n",
      "epoch 1850 lr 0.012361763235169692\n",
      "train_loss 0.338407590412716 train_acc 0.8538782012008332\n",
      "epoch 1851 lr 0.012337064415751714\n",
      "train_loss 0.3383935282703008 train_acc 0.8539088347016297\n",
      "epoch 1852 lr 0.01231241494460784\n",
      "train_loss 0.33837952970660645 train_acc 0.853862884450435\n",
      "epoch 1853 lr 0.012287814723140169\n",
      "train_loss 0.338365485883636 train_acc 0.8538935179512315\n",
      "epoch 1854 lr 0.012263263652947769\n",
      "train_loss 0.3383514743418182 train_acc 0.8539547849528244\n",
      "epoch 1855 lr 0.012238761635826335\n",
      "train_loss 0.3383375261803187 train_acc 0.8539701017032226\n",
      "epoch 1856 lr 0.012214308573767757\n",
      "train_loss 0.33832359621849867 train_acc 0.8540160519544173\n",
      "epoch 1857 lr 0.012189904368959767\n",
      "train_loss 0.33830965391781237 train_acc 0.8540160519544173\n",
      "epoch 1858 lr 0.012165548923785501\n",
      "train_loss 0.3382958137330917 train_acc 0.8540160519544173\n",
      "epoch 1859 lr 0.012141242140823155\n",
      "train_loss 0.3382819250783113 train_acc 0.8540313687048156\n",
      "epoch 1860 lr 0.012116983922845556\n",
      "train_loss 0.33826796160994327 train_acc 0.8540007352040191\n",
      "epoch 1861 lr 0.01209277417281981\n",
      "train_loss 0.3382540004085583 train_acc 0.8540313687048156\n",
      "epoch 1862 lr 0.012068612793906872\n",
      "train_loss 0.33824012921992114 train_acc 0.8540466854552138\n",
      "epoch 1863 lr 0.012044499689461209\n",
      "train_loss 0.3382262649571364 train_acc 0.854062002205612\n",
      "epoch 1864 lr 0.012020434763030358\n",
      "train_loss 0.3382123897194261 train_acc 0.8540926357064085\n",
      "epoch 1865 lr 0.011996417918354589\n",
      "train_loss 0.3381985969729953 train_acc 0.8540773189560102\n",
      "epoch 1866 lr 0.011972449059366484\n",
      "train_loss 0.33818484373692 train_acc 0.8540773189560102\n",
      "epoch 1867 lr 0.011948528090190586\n",
      "train_loss 0.33817110061624905 train_acc 0.854123269207205\n",
      "epoch 1868 lr 0.011924654915142973\n",
      "train_loss 0.33815741243857106 train_acc 0.8541539027080015\n",
      "epoch 1869 lr 0.011900829438730927\n",
      "train_loss 0.33814378347557256 train_acc 0.8541539027080015\n",
      "epoch 1870 lr 0.011877051565652498\n",
      "train_loss 0.3381301658822337 train_acc 0.8542304864599927\n",
      "epoch 1871 lr 0.011853321200796173\n",
      "train_loss 0.33811655959802606 train_acc 0.8542151697095944\n",
      "epoch 1872 lr 0.011829638249240451\n",
      "train_loss 0.33810299040585 train_acc 0.8542304864599927\n",
      "epoch 1873 lr 0.011806002616253503\n",
      "train_loss 0.3380893829580773 train_acc 0.8542304864599927\n",
      "epoch 1874 lr 0.011782414207292757\n",
      "train_loss 0.33807577413861334 train_acc 0.8542151697095944\n",
      "epoch 1875 lr 0.011758872928004555\n",
      "train_loss 0.33806212393992 train_acc 0.8542458032103909\n",
      "epoch 1876 lr 0.011735378684223743\n",
      "train_loss 0.33804847676614636 train_acc 0.8542611199607891\n",
      "epoch 1877 lr 0.01171193138197331\n",
      "train_loss 0.3380348748952347 train_acc 0.8542764367111874\n",
      "epoch 1878 lr 0.011688530927464027\n",
      "train_loss 0.33802131124380297 train_acc 0.8542917534615856\n",
      "epoch 1879 lr 0.011665177227094032\n",
      "train_loss 0.3380077176994358 train_acc 0.8542764367111874\n",
      "epoch 1880 lr 0.011641870187448505\n",
      "train_loss 0.3379940957557583 train_acc 0.8543070702119838\n",
      "epoch 1881 lr 0.011618609715299244\n",
      "train_loss 0.3379805056102305 train_acc 0.8543530204631785\n",
      "epoch 1882 lr 0.011595395717604342\n",
      "train_loss 0.33796692464142586 train_acc 0.8542917534615856\n",
      "epoch 1883 lr 0.011572228101507766\n",
      "train_loss 0.33795341042998156 train_acc 0.854322386962382\n",
      "epoch 1884 lr 0.01154910677433903\n",
      "train_loss 0.33793991151443675 train_acc 0.854322386962382\n",
      "epoch 1885 lr 0.011526031643612785\n",
      "train_loss 0.3379263958335672 train_acc 0.854322386962382\n",
      "epoch 1886 lr 0.011503002617028489\n",
      "train_loss 0.3379128756452208 train_acc 0.8542764367111874\n",
      "epoch 1887 lr 0.011480019602469992\n",
      "train_loss 0.33789940103862565 train_acc 0.8542611199607891\n",
      "epoch 1888 lr 0.011457082508005216\n",
      "train_loss 0.33788596688331013 train_acc 0.8542764367111874\n",
      "epoch 1889 lr 0.011434191241885746\n",
      "train_loss 0.3378725518916841 train_acc 0.8542764367111874\n",
      "epoch 1890 lr 0.01141134571254649\n",
      "train_loss 0.3378591468553698 train_acc 0.8543070702119838\n",
      "epoch 1891 lr 0.011388545828605297\n",
      "train_loss 0.3378457686562325 train_acc 0.8543683372135767\n",
      "epoch 1892 lr 0.011365791498862608\n",
      "train_loss 0.3378324573974774 train_acc 0.854383653963975\n",
      "epoch 1893 lr 0.011343082632301065\n",
      "train_loss 0.33781915876334323 train_acc 0.8543530204631785\n",
      "epoch 1894 lr 0.011320419138085179\n",
      "train_loss 0.33780582835781464 train_acc 0.8543070702119838\n",
      "epoch 1895 lr 0.011297800925560934\n",
      "train_loss 0.33779249200354916 train_acc 0.8543070702119838\n",
      "epoch 1896 lr 0.01127522790425546\n",
      "train_loss 0.33777913512807045 train_acc 0.8543530204631785\n",
      "epoch 1897 lr 0.011252699983876631\n",
      "train_loss 0.33776582293175994 train_acc 0.8543377037127803\n",
      "epoch 1898 lr 0.011230217074312746\n",
      "train_loss 0.3377525497367818 train_acc 0.8543377037127803\n",
      "epoch 1899 lr 0.011207779085632127\n",
      "train_loss 0.33773922060847106 train_acc 0.8543377037127803\n",
      "\n",
      "val loss = 0.3629060874444166, \n",
      "val acc = 0.8351481736733287\n",
      "\n",
      "epoch 1900 lr 0.0111853859280828\n",
      "train_loss 0.3377258802167014 train_acc 0.8543989707143732\n",
      "epoch 1901 lr 0.011163037512092095\n",
      "train_loss 0.3377125731416072 train_acc 0.8543989707143732\n",
      "epoch 1902 lr 0.011140733748266326\n",
      "train_loss 0.3376992990964821 train_acc 0.8544449209655679\n",
      "epoch 1903 lr 0.0111184745473904\n",
      "train_loss 0.33768605341012276 train_acc 0.8544449209655679\n",
      "epoch 1904 lr 0.011096259820427494\n",
      "train_loss 0.33767280481888273 train_acc 0.8544602377159661\n",
      "epoch 1905 lr 0.011074089478518657\n",
      "train_loss 0.33765959724485956 train_acc 0.8544449209655679\n",
      "epoch 1906 lr 0.011051963432982507\n",
      "train_loss 0.33764640861091877 train_acc 0.8544602377159661\n",
      "epoch 1907 lr 0.011029881595314818\n",
      "train_loss 0.33763320322495616 train_acc 0.8544908712167627\n",
      "epoch 1908 lr 0.011007843877188223\n",
      "train_loss 0.3376199307972292 train_acc 0.8545061879671609\n",
      "epoch 1909 lr 0.010985850190451809\n",
      "train_loss 0.33760663834180393 train_acc 0.8544908712167627\n",
      "epoch 1910 lr 0.01096390044713081\n",
      "train_loss 0.337593344103348 train_acc 0.8545061879671609\n",
      "epoch 1911 lr 0.010941994559426212\n",
      "train_loss 0.33758006646908556 train_acc 0.8545368214679574\n",
      "epoch 1912 lr 0.010920132439714446\n",
      "train_loss 0.33756683651638275 train_acc 0.8545215047175592\n",
      "epoch 1913 lr 0.010898314000546996\n",
      "train_loss 0.33755359423526815 train_acc 0.8545674549687539\n",
      "epoch 1914 lr 0.010876539154650082\n",
      "train_loss 0.33754029760931326 train_acc 0.8545827717191521\n",
      "epoch 1915 lr 0.010854807814924285\n",
      "train_loss 0.3375270411850892 train_acc 0.8545674549687539\n",
      "epoch 1916 lr 0.010833119894444226\n",
      "train_loss 0.3375137885972763 train_acc 0.8545827717191521\n",
      "epoch 1917 lr 0.010811475306458183\n",
      "train_loss 0.33750050507255597 train_acc 0.8546134052199486\n",
      "epoch 1918 lr 0.010789873964387785\n",
      "train_loss 0.3374872001848391 train_acc 0.8546287219703468\n",
      "epoch 1919 lr 0.010768315781827627\n",
      "train_loss 0.33747387388679845 train_acc 0.854644038720745\n",
      "epoch 1920 lr 0.010746800672544961\n",
      "train_loss 0.33746058782361626 train_acc 0.8546593554711432\n",
      "epoch 1921 lr 0.010725328550479307\n",
      "train_loss 0.33744728377824845 train_acc 0.8546746722215415\n",
      "epoch 1922 lr 0.010703899329742162\n",
      "train_loss 0.337433954564613 train_acc 0.8546899889719397\n",
      "epoch 1923 lr 0.010682512924616602\n",
      "train_loss 0.3374206057312362 train_acc 0.8547053057223379\n",
      "epoch 1924 lr 0.010661169249556988\n",
      "train_loss 0.33740727649860536 train_acc 0.8547665727239309\n",
      "epoch 1925 lr 0.010639868219188582\n",
      "train_loss 0.33739397731673915 train_acc 0.8547665727239309\n",
      "epoch 1926 lr 0.010618609748307245\n",
      "train_loss 0.33738070992745184 train_acc 0.8547665727239309\n",
      "epoch 1927 lr 0.010597393751879056\n",
      "train_loss 0.33736742431505956 train_acc 0.8547818894743291\n",
      "epoch 1928 lr 0.010576220145040009\n",
      "train_loss 0.3373541014961537 train_acc 0.8547818894743291\n",
      "epoch 1929 lr 0.010555088843095637\n",
      "train_loss 0.3373408645369685 train_acc 0.8547818894743291\n",
      "epoch 1930 lr 0.010533999761520717\n",
      "train_loss 0.3373276832646003 train_acc 0.8547665727239309\n",
      "epoch 1931 lr 0.010512952815958883\n",
      "train_loss 0.33731459956733667 train_acc 0.8547665727239309\n",
      "epoch 1932 lr 0.010491947922222335\n",
      "train_loss 0.3373015797196948 train_acc 0.8547665727239309\n",
      "epoch 1933 lr 0.01047098499629146\n",
      "train_loss 0.3372885545933391 train_acc 0.8547512559735326\n",
      "epoch 1934 lr 0.010450063954314536\n",
      "train_loss 0.3372754774310375 train_acc 0.8547359392231344\n",
      "epoch 1935 lr 0.010429184712607358\n",
      "train_loss 0.33726237844947043 train_acc 0.8547818894743291\n",
      "epoch 1936 lr 0.010408347187652942\n",
      "train_loss 0.33724931100800615 train_acc 0.8547972062247273\n",
      "epoch 1937 lr 0.010387551296101149\n",
      "train_loss 0.33723624000820646 train_acc 0.8548584732263204\n",
      "epoch 1938 lr 0.010366796954768396\n",
      "train_loss 0.3372231802983987 train_acc 0.8548737899767186\n",
      "epoch 1939 lr 0.010346084080637278\n",
      "train_loss 0.3372101354640901 train_acc 0.8548891067271168\n",
      "epoch 1940 lr 0.010325412590856283\n",
      "train_loss 0.3371970102750093 train_acc 0.8548891067271168\n",
      "epoch 1941 lr 0.010304782402739413\n",
      "train_loss 0.33718388802411475 train_acc 0.854843156475922\n",
      "epoch 1942 lr 0.0102841934337659\n",
      "train_loss 0.33717082359865513 train_acc 0.854843156475922\n",
      "epoch 1943 lr 0.010263645601579828\n",
      "train_loss 0.3371577068375403 train_acc 0.8548278397255238\n",
      "epoch 1944 lr 0.010243138823989853\n",
      "train_loss 0.33714459623946796 train_acc 0.8548278397255238\n",
      "epoch 1945 lr 0.010222673018968826\n",
      "train_loss 0.3371314439093202 train_acc 0.8548278397255238\n",
      "epoch 1946 lr 0.01020224810465351\n",
      "train_loss 0.3371182674287083 train_acc 0.8548584732263204\n",
      "epoch 1947 lr 0.010181863999344213\n",
      "train_loss 0.3371050362619233 train_acc 0.8548891067271168\n",
      "epoch 1948 lr 0.01016152062150449\n",
      "train_loss 0.3370918313173326 train_acc 0.8549350569783115\n",
      "epoch 1949 lr 0.0101412178897608\n",
      "train_loss 0.3370786464363547 train_acc 0.8548891067271168\n",
      "\n",
      "val loss = 0.3627295391981522, \n",
      "val acc = 0.8354238456237078\n",
      "\n",
      "epoch 1950 lr 0.010120955722902196\n",
      "train_loss 0.3370654706052481 train_acc 0.8548737899767186\n",
      "epoch 1951 lr 0.010100734039879971\n",
      "train_loss 0.33705233577331173 train_acc 0.8548737899767186\n",
      "epoch 1952 lr 0.01008055275980738\n",
      "train_loss 0.3370391290694451 train_acc 0.854904423477515\n",
      "epoch 1953 lr 0.010060411801959263\n",
      "train_loss 0.3370259571409236 train_acc 0.8549197402279133\n",
      "epoch 1954 lr 0.010040311085771771\n",
      "train_loss 0.3370128454552417 train_acc 0.8548737899767186\n",
      "epoch 1955 lr 0.010020250530842007\n",
      "train_loss 0.3369997173999878 train_acc 0.854843156475922\n",
      "epoch 1956 lr 0.01000023005692773\n",
      "train_loss 0.33698662613017294 train_acc 0.8548737899767186\n",
      "epoch 1957 lr 0.00998024958394701\n",
      "train_loss 0.33697359492080736 train_acc 0.854904423477515\n",
      "epoch 1958 lr 0.009960309031977938\n",
      "train_loss 0.33696054022331035 train_acc 0.8548891067271168\n",
      "epoch 1959 lr 0.00994040832125827\n",
      "train_loss 0.33694744679096744 train_acc 0.8549197402279133\n",
      "epoch 1960 lr 0.009920547372185144\n",
      "train_loss 0.3369343763935467 train_acc 0.8549503737287097\n",
      "epoch 1961 lr 0.00990072610531473\n",
      "train_loss 0.3369213666120619 train_acc 0.854965690479108\n",
      "epoch 1962 lr 0.009880944441361943\n",
      "train_loss 0.3369083924044337 train_acc 0.8549197402279133\n",
      "epoch 1963 lr 0.009861202301200092\n",
      "train_loss 0.33689548366387057 train_acc 0.8549503737287097\n",
      "epoch 1964 lr 0.009841499605860598\n",
      "train_loss 0.33688258736085713 train_acc 0.8549350569783115\n",
      "epoch 1965 lr 0.009821836276532644\n",
      "train_loss 0.33686970213823164 train_acc 0.854965690479108\n",
      "epoch 1966 lr 0.009802212234562898\n",
      "train_loss 0.33685683096087715 train_acc 0.8549810072295062\n",
      "epoch 1967 lr 0.009782627401455156\n",
      "train_loss 0.33684396368527963 train_acc 0.8550116407303027\n",
      "epoch 1968 lr 0.009763081698870066\n",
      "train_loss 0.33683105508031647 train_acc 0.8549963239799044\n",
      "epoch 1969 lr 0.009743575048624786\n",
      "train_loss 0.33681815495198536 train_acc 0.8550422742310991\n",
      "epoch 1970 lr 0.009724107372692695\n",
      "train_loss 0.3368052232799717 train_acc 0.8550269574807009\n",
      "epoch 1971 lr 0.009704678593203057\n",
      "train_loss 0.33679226898502673 train_acc 0.8550575909814974\n",
      "epoch 1972 lr 0.009685288632440735\n",
      "train_loss 0.3367793329242585 train_acc 0.8550269574807009\n",
      "epoch 1973 lr 0.009665937412845852\n",
      "train_loss 0.3367663601446303 train_acc 0.8550729077318956\n",
      "epoch 1974 lr 0.009646624857013513\n",
      "train_loss 0.33675335787118776 train_acc 0.8550422742310991\n",
      "epoch 1975 lr 0.00962735088769346\n",
      "train_loss 0.336740335719631 train_acc 0.8550882244822938\n",
      "epoch 1976 lr 0.009608115427789799\n",
      "train_loss 0.33672727574609373 train_acc 0.8550575909814974\n",
      "epoch 1977 lr 0.009588918400360654\n",
      "train_loss 0.3367141944643335 train_acc 0.8551188579830903\n",
      "epoch 1978 lr 0.009569759728617901\n",
      "train_loss 0.3367011068551039 train_acc 0.855103541232692\n",
      "epoch 1979 lr 0.009550639335926819\n",
      "train_loss 0.3366880180031273 train_acc 0.8551188579830903\n",
      "epoch 1980 lr 0.009531557145805818\n",
      "train_loss 0.33667488155354447 train_acc 0.8551188579830903\n",
      "epoch 1981 lr 0.009512513081926105\n",
      "train_loss 0.336661738630517 train_acc 0.8550882244822938\n",
      "epoch 1982 lr 0.009493507068111407\n",
      "train_loss 0.3366486114628762 train_acc 0.8550729077318956\n",
      "epoch 1983 lr 0.009474539028337635\n",
      "train_loss 0.3366355436457458 train_acc 0.8551188579830903\n",
      "epoch 1984 lr 0.009455608886732613\n",
      "train_loss 0.33662253452763785 train_acc 0.8550882244822938\n",
      "epoch 1985 lr 0.009436716567575743\n",
      "train_loss 0.33660956302235956 train_acc 0.8551188579830903\n",
      "epoch 1986 lr 0.009417861995297728\n",
      "train_loss 0.3365966158137185 train_acc 0.855103541232692\n",
      "epoch 1987 lr 0.009399045094480248\n",
      "train_loss 0.3365836598167325 train_acc 0.8551341747334885\n",
      "epoch 1988 lr 0.009380265789855681\n",
      "train_loss 0.3365706239262548 train_acc 0.855103541232692\n",
      "epoch 1989 lr 0.009361524006306778\n",
      "train_loss 0.33655754250585135 train_acc 0.8551341747334885\n",
      "epoch 1990 lr 0.009342819668866386\n",
      "train_loss 0.3365444537823267 train_acc 0.8551341747334885\n",
      "epoch 1991 lr 0.009324152702717121\n",
      "train_loss 0.3365313281980172 train_acc 0.8551801249846832\n",
      "epoch 1992 lr 0.009305523033191106\n",
      "train_loss 0.336518206747522 train_acc 0.8551341747334885\n",
      "epoch 1993 lr 0.009286930585769624\n",
      "train_loss 0.3365051300740944 train_acc 0.8552107584854797\n",
      "epoch 1994 lr 0.009268375286082873\n",
      "train_loss 0.33649211406037843 train_acc 0.8552413919862762\n",
      "epoch 1995 lr 0.009249857059909621\n",
      "train_loss 0.3364791581260054 train_acc 0.8552567087366745\n",
      "epoch 1996 lr 0.009231375833176944\n",
      "train_loss 0.3364662304312983 train_acc 0.8552567087366745\n",
      "epoch 1997 lr 0.009212931531959906\n",
      "train_loss 0.33645330274405333 train_acc 0.8552413919862762\n",
      "epoch 1998 lr 0.009194524082481281\n",
      "train_loss 0.3364404175677657 train_acc 0.8552260752358779\n",
      "epoch 1999 lr 0.009176153411111243\n",
      "train_loss 0.33642756057681444 train_acc 0.8552873422374709\n",
      "\n",
      "val loss = 0.36257605535562776, \n",
      "val acc = 0.8354238456237078\n",
      "\n",
      "epoch 2000 lr 0.00915781944436709\n",
      "train_loss 0.33641468004754194 train_acc 0.8552413919862762\n",
      "epoch 2001 lr 0.009139522108912923\n",
      "train_loss 0.3364017461435974 train_acc 0.8552720254870727\n",
      "epoch 2002 lr 0.009121261331559377\n",
      "train_loss 0.33638879142482636 train_acc 0.8551954417350814\n",
      "epoch 2003 lr 0.009103037039263313\n",
      "train_loss 0.3363758024979591 train_acc 0.8552720254870727\n",
      "epoch 2004 lr 0.00908484915912755\n",
      "train_loss 0.3363628146313457 train_acc 0.8552567087366745\n",
      "epoch 2005 lr 0.009066697618400538\n",
      "train_loss 0.33634983870092505 train_acc 0.8552873422374709\n",
      "epoch 2006 lr 0.009048582344476088\n",
      "train_loss 0.33633684227362837 train_acc 0.8552720254870727\n",
      "epoch 2007 lr 0.009030503264893072\n",
      "train_loss 0.336323858597239 train_acc 0.8553179757382674\n",
      "epoch 2008 lr 0.009012460307335164\n",
      "train_loss 0.33631090616811793 train_acc 0.8552720254870727\n",
      "epoch 2009 lr 0.008994453399630502\n",
      "train_loss 0.33629798238767405 train_acc 0.8552873422374709\n",
      "epoch 2010 lr 0.008976482469751431\n",
      "train_loss 0.33628505356453303 train_acc 0.8552720254870727\n",
      "epoch 2011 lr 0.0089585474458142\n",
      "train_loss 0.336272103731393 train_acc 0.8553332924886656\n",
      "epoch 2012 lr 0.008940648256078706\n",
      "train_loss 0.3362591568803276 train_acc 0.8552873422374709\n",
      "epoch 2013 lr 0.008922784828948156\n",
      "train_loss 0.3362462333954512 train_acc 0.8553026589878692\n",
      "epoch 2014 lr 0.00890495709296882\n",
      "train_loss 0.336233377980528 train_acc 0.8552567087366745\n",
      "epoch 2015 lr 0.008887164976829722\n",
      "train_loss 0.336220559473303 train_acc 0.8553026589878692\n",
      "epoch 2016 lr 0.008869408409362387\n",
      "train_loss 0.3362077474171631 train_acc 0.8552873422374709\n",
      "epoch 2017 lr 0.008851687319540516\n",
      "train_loss 0.3361949669226975 train_acc 0.8552720254870727\n",
      "epoch 2018 lr 0.008834001636479724\n",
      "train_loss 0.33618227591524064 train_acc 0.8553332924886656\n",
      "epoch 2019 lr 0.00881635128943725\n",
      "train_loss 0.3361696342875993 train_acc 0.8552567087366745\n",
      "epoch 2020 lr 0.008798736207811696\n",
      "train_loss 0.3361569709369599 train_acc 0.8553792427398603\n",
      "epoch 2021 lr 0.008781156321142706\n",
      "train_loss 0.33614426259775293 train_acc 0.8553179757382674\n",
      "epoch 2022 lr 0.008763611559110708\n",
      "train_loss 0.33613154395912914 train_acc 0.8553945594902586\n",
      "epoch 2023 lr 0.008746101851536623\n",
      "train_loss 0.33611882278791955 train_acc 0.8554098762406568\n",
      "epoch 2024 lr 0.008728627128381615\n",
      "train_loss 0.33610612901056 train_acc 0.8554098762406568\n",
      "epoch 2025 lr 0.008711187319746757\n",
      "train_loss 0.3360934222335233 train_acc 0.8554558264918515\n",
      "epoch 2026 lr 0.008693782355872794\n",
      "train_loss 0.3360806860286919 train_acc 0.8554558264918515\n",
      "epoch 2027 lr 0.008676412167139838\n",
      "train_loss 0.33606785557412694 train_acc 0.8555017767430462\n",
      "epoch 2028 lr 0.008659076684067128\n",
      "train_loss 0.33605500869237276 train_acc 0.8554864599926479\n",
      "epoch 2029 lr 0.008641775837312697\n",
      "train_loss 0.33604220168574067 train_acc 0.8556089939958338\n",
      "epoch 2030 lr 0.00862450955767314\n",
      "train_loss 0.336029382413697 train_acc 0.8555170934934444\n",
      "epoch 2031 lr 0.008607277776083305\n",
      "train_loss 0.33601655131915137 train_acc 0.8555477269942409\n",
      "epoch 2032 lr 0.008590080423616057\n",
      "train_loss 0.3360036770522465 train_acc 0.8555324102438426\n",
      "epoch 2033 lr 0.008572917431481959\n",
      "train_loss 0.3359908458701199 train_acc 0.8555477269942409\n",
      "epoch 2034 lr 0.008555788731029015\n",
      "train_loss 0.3359780495718548 train_acc 0.8555630437446391\n",
      "epoch 2035 lr 0.008538694253742398\n",
      "train_loss 0.33596527654791697 train_acc 0.8555324102438426\n",
      "epoch 2036 lr 0.008521633931244187\n",
      "train_loss 0.33595249500531127 train_acc 0.8555477269942409\n",
      "epoch 2037 lr 0.008504607695293062\n",
      "train_loss 0.3359397662062482 train_acc 0.8555477269942409\n",
      "epoch 2038 lr 0.00848761547778406\n",
      "train_loss 0.335927095307053 train_acc 0.8555477269942409\n",
      "epoch 2039 lr 0.008470657210748276\n",
      "train_loss 0.3359144834132758 train_acc 0.8555936772454356\n",
      "epoch 2040 lr 0.008453732826352638\n",
      "train_loss 0.33590187609934163 train_acc 0.8555936772454356\n",
      "epoch 2041 lr 0.008436842256899576\n",
      "train_loss 0.3358892923140534 train_acc 0.8556396274966304\n",
      "epoch 2042 lr 0.008419985434826792\n",
      "train_loss 0.33587676654765747 train_acc 0.8556243107462321\n",
      "epoch 2043 lr 0.008403162292706967\n",
      "train_loss 0.33586424765808925 train_acc 0.8556702609974268\n",
      "epoch 2044 lr 0.008386372763247524\n",
      "train_loss 0.33585176360207475 train_acc 0.855685577747825\n",
      "epoch 2045 lr 0.008369616779290316\n",
      "train_loss 0.3358392999196607 train_acc 0.8557162112486215\n",
      "epoch 2046 lr 0.008352894273811385\n",
      "train_loss 0.3358268258865353 train_acc 0.855685577747825\n",
      "epoch 2047 lr 0.008336205179920677\n",
      "train_loss 0.3358143592570338 train_acc 0.855685577747825\n",
      "epoch 2048 lr 0.008319549430861812\n",
      "train_loss 0.33580179108429165 train_acc 0.8557008944982233\n",
      "epoch 2049 lr 0.008302926960011765\n",
      "train_loss 0.3357892007370235 train_acc 0.855746844749418\n",
      "\n",
      "val loss = 0.362407832294597, \n",
      "val acc = 0.8358373535492764\n",
      "\n",
      "epoch 2050 lr 0.008286337700880626\n",
      "train_loss 0.3357766414637581 train_acc 0.8557008944982233\n",
      "epoch 2051 lr 0.008269781587111332\n",
      "train_loss 0.33576412945999534 train_acc 0.8557008944982233\n",
      "epoch 2052 lr 0.008253258552479421\n",
      "train_loss 0.3357515993254299 train_acc 0.855746844749418\n",
      "epoch 2053 lr 0.008236768530892724\n",
      "train_loss 0.3357390558561096 train_acc 0.8557315279990197\n",
      "epoch 2054 lr 0.008220311456391134\n",
      "train_loss 0.33572651235139067 train_acc 0.8557774782502144\n",
      "epoch 2055 lr 0.008203887263146322\n",
      "train_loss 0.3357140229314403 train_acc 0.8557621614998162\n",
      "epoch 2056 lr 0.008187495885461507\n",
      "train_loss 0.3357015177825881 train_acc 0.8557621614998162\n",
      "epoch 2057 lr 0.008171137257771152\n",
      "train_loss 0.33568904847346914 train_acc 0.8558234285014091\n",
      "epoch 2058 lr 0.008154811314640725\n",
      "train_loss 0.3356765861577897 train_acc 0.8558540620022056\n",
      "epoch 2059 lr 0.00813851799076642\n",
      "train_loss 0.3356641032926374 train_acc 0.8558387452518074\n",
      "epoch 2060 lr 0.008122257220974935\n",
      "train_loss 0.33565162964164624 train_acc 0.8558693787526038\n",
      "epoch 2061 lr 0.008106028940223166\n",
      "train_loss 0.3356390552389 train_acc 0.8558846955030021\n",
      "epoch 2062 lr 0.008089833083597965\n",
      "train_loss 0.33562647718189276 train_acc 0.8559306457541968\n",
      "epoch 2063 lr 0.008073669586315878\n",
      "train_loss 0.33561390937442076 train_acc 0.8559306457541968\n",
      "epoch 2064 lr 0.008057538383722907\n",
      "train_loss 0.33560135293525606 train_acc 0.8559306457541968\n",
      "epoch 2065 lr 0.008041439411294217\n",
      "train_loss 0.33558885438454505 train_acc 0.8559612792549932\n",
      "epoch 2066 lr 0.008025372604633893\n",
      "train_loss 0.3355763592404332 train_acc 0.8559919127557898\n",
      "epoch 2067 lr 0.008009337899474679\n",
      "train_loss 0.3355638611060782 train_acc 0.8560225462565862\n",
      "epoch 2068 lr 0.00799333523167775\n",
      "train_loss 0.3355514248463767 train_acc 0.8559612792549932\n",
      "epoch 2069 lr 0.007977364537232407\n",
      "train_loss 0.3355390185803671 train_acc 0.8559612792549932\n",
      "epoch 2070 lr 0.007961425752255849\n",
      "train_loss 0.33552653015762207 train_acc 0.8559306457541968\n",
      "epoch 2071 lr 0.007945518812992908\n",
      "train_loss 0.3355140469732288 train_acc 0.8559306457541968\n",
      "epoch 2072 lr 0.007929643655815818\n",
      "train_loss 0.3355015428481534 train_acc 0.8559000122534003\n",
      "epoch 2073 lr 0.007913800217223927\n",
      "train_loss 0.33548903950601594 train_acc 0.8559153290037985\n",
      "epoch 2074 lr 0.007897988433843456\n",
      "train_loss 0.3354765306128348 train_acc 0.8559306457541968\n",
      "epoch 2075 lr 0.007882208242427243\n",
      "train_loss 0.33546410060828563 train_acc 0.8559612792549932\n",
      "epoch 2076 lr 0.007866459579854516\n",
      "train_loss 0.3354516228777024 train_acc 0.8559306457541968\n",
      "epoch 2077 lr 0.007850742383130598\n",
      "train_loss 0.3354391491608622 train_acc 0.8559765960053914\n",
      "epoch 2078 lr 0.00783505658938668\n",
      "train_loss 0.33542667120627706 train_acc 0.8559612792549932\n",
      "epoch 2079 lr 0.007819402135879559\n",
      "train_loss 0.3354142221125243 train_acc 0.8559765960053914\n",
      "epoch 2080 lr 0.007803778959991416\n",
      "train_loss 0.3354017802099162 train_acc 0.8559306457541968\n",
      "epoch 2081 lr 0.007788186999229517\n",
      "train_loss 0.335389242566719 train_acc 0.855945962504595\n",
      "epoch 2082 lr 0.007772626191225999\n",
      "train_loss 0.33537668913554786 train_acc 0.8559000122534003\n",
      "epoch 2083 lr 0.007757096473737602\n",
      "train_loss 0.3353642008572937 train_acc 0.8559306457541968\n",
      "epoch 2084 lr 0.0077415977846454495\n",
      "train_loss 0.33535169258898023 train_acc 0.8559000122534003\n",
      "epoch 2085 lr 0.0077261300619547585\n",
      "train_loss 0.33533922474045796 train_acc 0.855945962504595\n",
      "epoch 2086 lr 0.007710693243794617\n",
      "train_loss 0.3353268166425902 train_acc 0.8559612792549932\n",
      "epoch 2087 lr 0.007695287268417724\n",
      "train_loss 0.3353143734043725 train_acc 0.856007229506188\n",
      "epoch 2088 lr 0.007679912074200172\n",
      "train_loss 0.3353018986743085 train_acc 0.8559919127557898\n",
      "epoch 2089 lr 0.007664567599641157\n",
      "train_loss 0.33528948759935634 train_acc 0.8559919127557898\n",
      "epoch 2090 lr 0.00764925378336276\n",
      "train_loss 0.33527706419855785 train_acc 0.8559765960053914\n",
      "epoch 2091 lr 0.007633970564109688\n",
      "train_loss 0.33526461925038986 train_acc 0.8559612792549932\n",
      "epoch 2092 lr 0.007618717880749058\n",
      "train_loss 0.3352521238694105 train_acc 0.8559612792549932\n",
      "epoch 2093 lr 0.00760349567227011\n",
      "train_loss 0.3352396793636671 train_acc 0.8559765960053914\n",
      "epoch 2094 lr 0.007588303877783989\n",
      "train_loss 0.33522725205853265 train_acc 0.856007229506188\n",
      "epoch 2095 lr 0.00757314243652349\n",
      "train_loss 0.3352148484776314 train_acc 0.8559919127557898\n",
      "epoch 2096 lr 0.0075580112878428415\n",
      "train_loss 0.3352024966265761 train_acc 0.8559919127557898\n",
      "epoch 2097 lr 0.007542910371217421\n",
      "train_loss 0.3351901343144517 train_acc 0.8560378630069845\n",
      "epoch 2098 lr 0.007527839626243543\n",
      "train_loss 0.33517777416786193 train_acc 0.8560225462565862\n",
      "epoch 2099 lr 0.0075127989926382\n",
      "train_loss 0.3351653849568421 train_acc 0.8560531797573827\n",
      "\n",
      "val loss = 0.36225566433974454, \n",
      "val acc = 0.8359751895244659\n",
      "\n",
      "epoch 2100 lr 0.0074977884102388525\n",
      "train_loss 0.3351529891863021 train_acc 0.8560684965077809\n",
      "epoch 2101 lr 0.0074828078190031415\n",
      "train_loss 0.33514066332730247 train_acc 0.8560225462565862\n",
      "epoch 2102 lr 0.007467857159008684\n",
      "train_loss 0.33512835065209556 train_acc 0.8560378630069845\n",
      "epoch 2103 lr 0.007452936370452814\n",
      "train_loss 0.3351160592749561 train_acc 0.8560225462565862\n",
      "epoch 2104 lr 0.007438045393652368\n",
      "train_loss 0.3351037054074242 train_acc 0.8560225462565862\n",
      "epoch 2105 lr 0.007423184169043416\n",
      "train_loss 0.33509128777314695 train_acc 0.8560991300085774\n",
      "epoch 2106 lr 0.007408352637181036\n",
      "train_loss 0.3350788532335054 train_acc 0.8560684965077809\n",
      "epoch 2107 lr 0.007393550738739077\n",
      "train_loss 0.33506648077455464 train_acc 0.8560378630069845\n",
      "epoch 2108 lr 0.0073787784145099376\n",
      "train_loss 0.33505408368916967 train_acc 0.8559919127557898\n",
      "epoch 2109 lr 0.007364035605404294\n",
      "train_loss 0.33504173376221 train_acc 0.8560378630069845\n",
      "epoch 2110 lr 0.007349322252450892\n",
      "train_loss 0.3350294200217614 train_acc 0.8559919127557898\n",
      "epoch 2111 lr 0.007334638296796291\n",
      "train_loss 0.3350170901069116 train_acc 0.8560531797573827\n",
      "epoch 2112 lr 0.007319983679704664\n",
      "train_loss 0.3350047146743631 train_acc 0.8560838132581792\n",
      "epoch 2113 lr 0.007305358342557515\n",
      "train_loss 0.33499231298280635 train_acc 0.8561144467589756\n",
      "epoch 2114 lr 0.007290762226853477\n",
      "train_loss 0.3349799528923843 train_acc 0.8560838132581792\n",
      "epoch 2115 lr 0.007276195274208062\n",
      "train_loss 0.3349676183910393 train_acc 0.8560838132581792\n",
      "epoch 2116 lr 0.00726165742635345\n",
      "train_loss 0.3349552765094049 train_acc 0.8560838132581792\n",
      "epoch 2117 lr 0.007247148625138227\n",
      "train_loss 0.33494295789971457 train_acc 0.8560684965077809\n",
      "epoch 2118 lr 0.007232668812527167\n",
      "train_loss 0.3349306990311711 train_acc 0.8561144467589756\n",
      "epoch 2119 lr 0.0072182179306009946\n",
      "train_loss 0.33491845958113664 train_acc 0.8560991300085774\n",
      "epoch 2120 lr 0.007203795921556175\n",
      "train_loss 0.33490623154598603 train_acc 0.8561450802597721\n",
      "epoch 2121 lr 0.007189402727704647\n",
      "train_loss 0.33489404892689023 train_acc 0.8560991300085774\n",
      "epoch 2122 lr 0.007175038291473615\n",
      "train_loss 0.33488186283962096 train_acc 0.8561144467589756\n",
      "epoch 2123 lr 0.00716070255540531\n",
      "train_loss 0.33486966181014194 train_acc 0.8560991300085774\n",
      "epoch 2124 lr 0.0071463954621567806\n",
      "train_loss 0.33485748493336115 train_acc 0.8561450802597721\n",
      "epoch 2125 lr 0.007132116954499628\n",
      "train_loss 0.3348453540075095 train_acc 0.8561297635093739\n",
      "epoch 2126 lr 0.007117866975319803\n",
      "train_loss 0.334833190998179 train_acc 0.8561144467589756\n",
      "epoch 2127 lr 0.007103645467617369\n",
      "train_loss 0.33482104108376864 train_acc 0.8561450802597721\n",
      "epoch 2128 lr 0.007089452374506271\n",
      "train_loss 0.3348088743796632 train_acc 0.8561297635093739\n",
      "epoch 2129 lr 0.007075287639214131\n",
      "train_loss 0.3347966740717411 train_acc 0.8561757137605686\n",
      "epoch 2130 lr 0.007061151205081981\n",
      "train_loss 0.3347844554180501 train_acc 0.8561144467589756\n",
      "epoch 2131 lr 0.007047043015564066\n",
      "train_loss 0.3347722002027898 train_acc 0.8561910305109668\n",
      "epoch 2132 lr 0.007032963014227603\n",
      "train_loss 0.33475994261072695 train_acc 0.8561603970101703\n",
      "epoch 2133 lr 0.007018911144752581\n",
      "train_loss 0.33474770751152094 train_acc 0.8562369807621615\n",
      "epoch 2134 lr 0.007004887350931495\n",
      "train_loss 0.3347355009391008 train_acc 0.8561910305109668\n",
      "epoch 2135 lr 0.006990891576669154\n",
      "train_loss 0.33472327925870266 train_acc 0.8562982477637544\n",
      "epoch 2136 lr 0.006976923765982434\n",
      "train_loss 0.334711047294108 train_acc 0.8562522975125597\n",
      "epoch 2137 lr 0.006962983863000087\n",
      "train_loss 0.3346988279067958 train_acc 0.8563135645141526\n",
      "epoch 2138 lr 0.006949071811962477\n",
      "train_loss 0.3346866715092476 train_acc 0.8562829310133562\n",
      "epoch 2139 lr 0.006935187557221378\n",
      "train_loss 0.33467450298175255 train_acc 0.8563441980149491\n",
      "epoch 2140 lr 0.0069213310432397505\n",
      "train_loss 0.33466233888078 train_acc 0.8562982477637544\n",
      "epoch 2141 lr 0.00690750221459153\n",
      "train_loss 0.33465017945944286 train_acc 0.8562829310133562\n",
      "epoch 2142 lr 0.0068937010159613775\n",
      "train_loss 0.334638012502299 train_acc 0.8562522975125597\n",
      "epoch 2143 lr 0.006879927392144481\n",
      "train_loss 0.33462589763108097 train_acc 0.856206347261365\n",
      "epoch 2144 lr 0.00686618128804632\n",
      "train_loss 0.334613805055677 train_acc 0.8562676142629579\n",
      "epoch 2145 lr 0.0068524626486824725\n",
      "train_loss 0.3346016633222341 train_acc 0.8562369807621615\n",
      "epoch 2146 lr 0.006838771419178356\n",
      "train_loss 0.3345895900988585 train_acc 0.8562676142629579\n",
      "epoch 2147 lr 0.006825107544769034\n",
      "train_loss 0.33457752242971284 train_acc 0.8563135645141526\n",
      "epoch 2148 lr 0.006811470970798986\n",
      "train_loss 0.3345654693907102 train_acc 0.8562522975125597\n",
      "epoch 2149 lr 0.006797861642721909\n",
      "train_loss 0.3345534777378438 train_acc 0.8563441980149491\n",
      "\n",
      "val loss = 0.36218878155390166, \n",
      "val acc = 0.8354238456237078\n",
      "\n",
      "epoch 2150 lr 0.006784279506100467\n",
      "train_loss 0.33454145205839414 train_acc 0.8562676142629579\n",
      "epoch 2151 lr 0.006770724506606094\n",
      "train_loss 0.3345293311599732 train_acc 0.8563441980149491\n",
      "epoch 2152 lr 0.006757196590018771\n",
      "train_loss 0.3345172946775742 train_acc 0.8562982477637544\n",
      "epoch 2153 lr 0.006743695702226822\n",
      "train_loss 0.3345052040731362 train_acc 0.8563441980149491\n",
      "epoch 2154 lr 0.006730221789226674\n",
      "train_loss 0.3344931233550406 train_acc 0.8563288812645509\n",
      "epoch 2155 lr 0.006716774797122657\n",
      "train_loss 0.3344810578885508 train_acc 0.8563288812645509\n",
      "epoch 2156 lr 0.006703354672126778\n",
      "train_loss 0.33446894208428407 train_acc 0.8563441980149491\n",
      "epoch 2157 lr 0.00668996136055853\n",
      "train_loss 0.33445688932643874 train_acc 0.8562676142629579\n",
      "epoch 2158 lr 0.006676594808844646\n",
      "train_loss 0.33444486330068474 train_acc 0.8563288812645509\n",
      "epoch 2159 lr 0.006663254963518899\n",
      "train_loss 0.3344328515358285 train_acc 0.8562829310133562\n",
      "epoch 2160 lr 0.006649941771221884\n",
      "train_loss 0.33442086766894696 train_acc 0.8563441980149491\n",
      "epoch 2161 lr 0.006636655178700826\n",
      "train_loss 0.33440878446379135 train_acc 0.8562369807621615\n",
      "epoch 2162 lr 0.006623395132809333\n",
      "train_loss 0.33439667205085655 train_acc 0.8563595147653473\n",
      "epoch 2163 lr 0.006610161580507201\n",
      "train_loss 0.33438457730374543 train_acc 0.8562676142629579\n",
      "epoch 2164 lr 0.006596954468860199\n",
      "train_loss 0.33437243110787396 train_acc 0.8563595147653473\n",
      "epoch 2165 lr 0.0065837737450398755\n",
      "train_loss 0.33436033513772895 train_acc 0.8562982477637544\n",
      "epoch 2166 lr 0.006570619356323309\n",
      "train_loss 0.3343482525270659 train_acc 0.8563595147653473\n",
      "epoch 2167 lr 0.00655749125009293\n",
      "train_loss 0.33433625321085886 train_acc 0.8563441980149491\n",
      "epoch 2168 lr 0.006544389373836289\n",
      "train_loss 0.33432428833844263 train_acc 0.8563595147653473\n",
      "epoch 2169 lr 0.006531313675145874\n",
      "train_loss 0.3343122683059551 train_acc 0.8563595147653473\n",
      "epoch 2170 lr 0.006518264101718868\n",
      "train_loss 0.3343001638413515 train_acc 0.8563901482661439\n",
      "epoch 2171 lr 0.00650524060135696\n",
      "train_loss 0.33428794808294576 train_acc 0.8563748315157457\n",
      "epoch 2172 lr 0.0064922431219661255\n",
      "train_loss 0.3342757924471575 train_acc 0.8564360985173386\n",
      "epoch 2173 lr 0.006479271611556441\n",
      "train_loss 0.3342636552216497 train_acc 0.8563595147653473\n",
      "epoch 2174 lr 0.006466326018241842\n",
      "train_loss 0.33425150658898767 train_acc 0.8564514152677368\n",
      "epoch 2175 lr 0.006453406290239937\n",
      "train_loss 0.3342393211738594 train_acc 0.8563748315157457\n",
      "epoch 2176 lr 0.006440512375871792\n",
      "train_loss 0.3342271672978567 train_acc 0.8564820487685333\n",
      "epoch 2177 lr 0.0064276442235617435\n",
      "train_loss 0.33421504779848293 train_acc 0.8563441980149491\n",
      "epoch 2178 lr 0.00641480178183716\n",
      "train_loss 0.3342029208483172 train_acc 0.8564667320181351\n",
      "epoch 2179 lr 0.006401984999328256\n",
      "train_loss 0.3341907364636216 train_acc 0.8563288812645509\n",
      "epoch 2180 lr 0.00638919382476788\n",
      "train_loss 0.33417860678557776 train_acc 0.8564667320181351\n",
      "epoch 2181 lr 0.0063764282069913285\n",
      "train_loss 0.33416644355289965 train_acc 0.8563288812645509\n",
      "epoch 2182 lr 0.006363688094936106\n",
      "train_loss 0.33415440394239226 train_acc 0.8564667320181351\n",
      "epoch 2183 lr 0.006350973437641749\n",
      "train_loss 0.3341423117298411 train_acc 0.8563595147653473\n",
      "epoch 2184 lr 0.006338284184249604\n",
      "train_loss 0.3341303089673365 train_acc 0.8564360985173386\n",
      "epoch 2185 lr 0.006325620284002653\n",
      "train_loss 0.3341181767419501 train_acc 0.8563595147653473\n",
      "epoch 2186 lr 0.006312981686245271\n",
      "train_loss 0.33410613276713996 train_acc 0.8564054650165421\n",
      "epoch 2187 lr 0.006300368340423053\n",
      "train_loss 0.33409411421267626 train_acc 0.8563901482661439\n",
      "epoch 2188 lr 0.006287780196082591\n",
      "train_loss 0.33408215969225097 train_acc 0.8564514152677368\n",
      "epoch 2189 lr 0.006275217202871303\n",
      "train_loss 0.33407014601454615 train_acc 0.8563901482661439\n",
      "epoch 2190 lr 0.0062626793105371925\n",
      "train_loss 0.33405816972255653 train_acc 0.8564360985173386\n",
      "epoch 2191 lr 0.006250166468928675\n",
      "train_loss 0.3340462345292224 train_acc 0.8564054650165421\n",
      "epoch 2192 lr 0.006237678627994361\n",
      "train_loss 0.3340342947141804 train_acc 0.8564514152677368\n",
      "epoch 2193 lr 0.006225215737782882\n",
      "train_loss 0.334022241748491 train_acc 0.8564054650165421\n",
      "epoch 2194 lr 0.006212777748442653\n",
      "train_loss 0.3340103175521408 train_acc 0.8565126822693298\n",
      "epoch 2195 lr 0.006200364610221703\n",
      "train_loss 0.33399837351034367 train_acc 0.8564820487685333\n",
      "epoch 2196 lr 0.006187976273467455\n",
      "train_loss 0.333986470787386 train_acc 0.8565433157701262\n",
      "epoch 2197 lr 0.006175612688626557\n",
      "train_loss 0.33397475256734993 train_acc 0.8565433157701262\n",
      "epoch 2198 lr 0.006163273806244648\n",
      "train_loss 0.3339629680344988 train_acc 0.8565586325205244\n",
      "epoch 2199 lr 0.0061509595769661815\n",
      "train_loss 0.3339512770300023 train_acc 0.8565433157701262\n",
      "\n",
      "val loss = 0.36210240987353354, \n",
      "val acc = 0.8355616815988973\n",
      "\n",
      "epoch 2200 lr 0.006138669951534218\n",
      "train_loss 0.33393949264287304 train_acc 0.8566045827717191\n",
      "epoch 2201 lr 0.006126404880790252\n",
      "train_loss 0.3339277075214302 train_acc 0.8565739492709227\n",
      "epoch 2202 lr 0.006114164315673977\n",
      "train_loss 0.3339159385676832 train_acc 0.8566045827717191\n",
      "epoch 2203 lr 0.006101948207223117\n",
      "train_loss 0.33390413290309123 train_acc 0.8565892660213209\n",
      "epoch 2204 lr 0.0060897565065732165\n",
      "train_loss 0.33389215443679 train_acc 0.8566198995221174\n",
      "epoch 2205 lr 0.006077589164957467\n",
      "train_loss 0.333880224185588 train_acc 0.8565892660213209\n",
      "epoch 2206 lr 0.006065446133706482\n",
      "train_loss 0.3338682358214549 train_acc 0.8566352162725156\n",
      "epoch 2207 lr 0.006053327364248118\n",
      "train_loss 0.3338561576570666 train_acc 0.8565586325205244\n",
      "epoch 2208 lr 0.006041232808107277\n",
      "train_loss 0.33384423732298585 train_acc 0.8566505330229138\n",
      "epoch 2209 lr 0.006029162416905729\n",
      "train_loss 0.3338321971946147 train_acc 0.8565739492709227\n",
      "epoch 2210 lr 0.006017116142361887\n",
      "train_loss 0.33382013847527436 train_acc 0.8566658497733121\n",
      "epoch 2211 lr 0.006005093936290638\n",
      "train_loss 0.3338080227390941 train_acc 0.8565892660213209\n",
      "epoch 2212 lr 0.005993095750603136\n",
      "train_loss 0.3337959225105897 train_acc 0.8566198995221174\n",
      "epoch 2213 lr 0.005981121537306631\n",
      "train_loss 0.33378383752678975 train_acc 0.8565892660213209\n",
      "epoch 2214 lr 0.005969171248504251\n",
      "train_loss 0.3337718602182604 train_acc 0.8565892660213209\n",
      "epoch 2215 lr 0.005957244836394824\n",
      "train_loss 0.33375988797916106 train_acc 0.8565586325205244\n",
      "epoch 2216 lr 0.005945342253272679\n",
      "train_loss 0.3337479201230503 train_acc 0.8565739492709227\n",
      "epoch 2217 lr 0.005933463451527481\n",
      "train_loss 0.3337359266003275 train_acc 0.856527999019728\n",
      "epoch 2218 lr 0.0059216083836439995\n",
      "train_loss 0.33372398241540796 train_acc 0.8566505330229138\n",
      "epoch 2219 lr 0.005909777002201948\n",
      "train_loss 0.33371206964908845 train_acc 0.8565126822693298\n",
      "epoch 2220 lr 0.005897969259875781\n",
      "train_loss 0.3337001577947875 train_acc 0.8566658497733121\n",
      "epoch 2221 lr 0.005886185109434522\n",
      "train_loss 0.33368825145537684 train_acc 0.8564973655189315\n",
      "epoch 2222 lr 0.005874424503741549\n",
      "train_loss 0.3336764094767873 train_acc 0.8566811665237103\n",
      "epoch 2223 lr 0.005862687395754423\n",
      "train_loss 0.33366467882874573 train_acc 0.8565586325205244\n",
      "epoch 2224 lr 0.005850973738524692\n",
      "train_loss 0.3336528379033873 train_acc 0.8566964832741085\n",
      "epoch 2225 lr 0.005839283485197722\n",
      "train_loss 0.33364121308099093 train_acc 0.8566045827717191\n",
      "epoch 2226 lr 0.0058276165890124776\n",
      "train_loss 0.33362946791217485 train_acc 0.8566964832741085\n",
      "epoch 2227 lr 0.00581597300330136\n",
      "train_loss 0.33361786918770603 train_acc 0.8566352162725156\n",
      "epoch 2228 lr 0.0058043526814900055\n",
      "train_loss 0.3336061649041959 train_acc 0.8566964832741085\n",
      "epoch 2229 lr 0.005792755577097121\n",
      "train_loss 0.33359436986692 train_acc 0.8566964832741085\n",
      "epoch 2230 lr 0.005781181643734268\n",
      "train_loss 0.33358252092254265 train_acc 0.8568190172772945\n",
      "epoch 2231 lr 0.0057696308351056986\n",
      "train_loss 0.3335708355231538 train_acc 0.8566964832741085\n",
      "epoch 2232 lr 0.005758103105008158\n",
      "train_loss 0.33355891293127904 train_acc 0.8568037005268963\n",
      "epoch 2233 lr 0.00574659840733072\n",
      "train_loss 0.33354709638467583 train_acc 0.856727116774905\n",
      "epoch 2234 lr 0.005735116696054572\n",
      "train_loss 0.33353516401183303 train_acc 0.8568343340276927\n",
      "epoch 2235 lr 0.005723657925252856\n",
      "train_loss 0.33352330016935217 train_acc 0.8567424335253033\n",
      "epoch 2236 lr 0.005712222049090467\n",
      "train_loss 0.333511358722458 train_acc 0.8568037005268963\n",
      "epoch 2237 lr 0.005700809021823896\n",
      "train_loss 0.3334996448457359 train_acc 0.8567424335253033\n",
      "epoch 2238 lr 0.0056894187978010135\n",
      "train_loss 0.33348777455218553 train_acc 0.8568037005268963\n",
      "epoch 2239 lr 0.005678051331460908\n",
      "train_loss 0.333476096132358 train_acc 0.8567730670260998\n",
      "epoch 2240 lr 0.005666706577333694\n",
      "train_loss 0.33346428858689375 train_acc 0.8568496507780909\n",
      "epoch 2241 lr 0.005655384490040351\n",
      "train_loss 0.33345259337033095 train_acc 0.8568190172772945\n",
      "epoch 2242 lr 0.005644085024292507\n",
      "train_loss 0.3334407346775589 train_acc 0.8568802842788874\n",
      "epoch 2243 lr 0.005632808134892286\n",
      "train_loss 0.3334287993418936 train_acc 0.8568343340276927\n",
      "epoch 2244 lr 0.0056215537767321105\n",
      "train_loss 0.333416906155824 train_acc 0.8568956010292856\n",
      "epoch 2245 lr 0.005610321904794542\n",
      "train_loss 0.3334049820835524 train_acc 0.8568802842788874\n",
      "epoch 2246 lr 0.005599112474152073\n",
      "train_loss 0.3333931340961176 train_acc 0.8569109177796839\n",
      "epoch 2247 lr 0.005587925439966967\n",
      "train_loss 0.3333812753349124 train_acc 0.8569109177796839\n",
      "epoch 2248 lr 0.005576760757491066\n",
      "train_loss 0.3333693758328464 train_acc 0.8569568680308786\n",
      "epoch 2249 lr 0.005565618382065635\n",
      "train_loss 0.3333574286348997 train_acc 0.856987501531675\n",
      "\n",
      "val loss = 0.3620559420385, \n",
      "val acc = 0.8361130254996554\n",
      "\n",
      "epoch 2250 lr 0.005554498269121154\n",
      "train_loss 0.33334554167462443 train_acc 0.8569415512804803\n",
      "epoch 2251 lr 0.005543400374177155\n",
      "train_loss 0.3333337807658141 train_acc 0.856987501531675\n",
      "epoch 2252 lr 0.005532324652842043\n",
      "train_loss 0.3333220775382365 train_acc 0.856987501531675\n",
      "epoch 2253 lr 0.005521271060812915\n",
      "train_loss 0.3333104049314742 train_acc 0.8570181350324715\n",
      "epoch 2254 lr 0.005510239553875396\n",
      "train_loss 0.33329874924414443 train_acc 0.8570028182820733\n",
      "epoch 2255 lr 0.0054992300879034405\n",
      "train_loss 0.3332870950456862 train_acc 0.8570028182820733\n",
      "epoch 2256 lr 0.005488242618859169\n",
      "train_loss 0.3332754176264137 train_acc 0.856987501531675\n",
      "epoch 2257 lr 0.005477277102792685\n",
      "train_loss 0.33326397558577486 train_acc 0.8570181350324715\n",
      "epoch 2258 lr 0.00546633349584192\n",
      "train_loss 0.33325238752729286 train_acc 0.8570181350324715\n",
      "epoch 2259 lr 0.005455411754232427\n",
      "train_loss 0.33324099488938874 train_acc 0.8570640852836662\n",
      "epoch 2260 lr 0.005444511834277225\n",
      "train_loss 0.33322958138529124 train_acc 0.8570640852836662\n",
      "epoch 2261 lr 0.005433633692376615\n",
      "train_loss 0.33321830431461347 train_acc 0.8570794020340644\n",
      "epoch 2262 lr 0.005422777285018023\n",
      "train_loss 0.3332068570030656 train_acc 0.8570947187844626\n",
      "epoch 2263 lr 0.005411942568775803\n",
      "train_loss 0.33319546600265504 train_acc 0.8571406690356574\n",
      "epoch 2264 lr 0.005401129500311073\n",
      "train_loss 0.3331840946167181 train_acc 0.8571559857860557\n",
      "epoch 2265 lr 0.005390338036371541\n",
      "train_loss 0.3331727597376586 train_acc 0.8571866192868521\n",
      "epoch 2266 lr 0.005379568133791346\n",
      "train_loss 0.33316133053528646 train_acc 0.8570794020340644\n",
      "epoch 2267 lr 0.00536881974949086\n",
      "train_loss 0.3331501816087475 train_acc 0.8572019360372504\n",
      "epoch 2268 lr 0.0053580928404765304\n",
      "train_loss 0.3331387191871706 train_acc 0.8571713025364539\n",
      "epoch 2269 lr 0.005347387363840701\n",
      "train_loss 0.3331275683506315 train_acc 0.8572325695380468\n",
      "epoch 2270 lr 0.005336703276761463\n",
      "train_loss 0.33311601364210136 train_acc 0.8571559857860557\n",
      "epoch 2271 lr 0.005326040536502446\n",
      "train_loss 0.3331044975261502 train_acc 0.8572172527876486\n",
      "epoch 2272 lr 0.0053153991004126775\n",
      "train_loss 0.3330930073658916 train_acc 0.8571866192868521\n",
      "epoch 2273 lr 0.005304778925926392\n",
      "train_loss 0.33308149469788834 train_acc 0.8572478862884451\n",
      "epoch 2274 lr 0.005294179970562889\n",
      "train_loss 0.3330698755196105 train_acc 0.8572938365396398\n",
      "epoch 2275 lr 0.005283602191926327\n",
      "train_loss 0.3330584371248717 train_acc 0.857309153290038\n",
      "epoch 2276 lr 0.0052730455477055784\n",
      "train_loss 0.3330469021826828 train_acc 0.8572325695380468\n",
      "epoch 2277 lr 0.005262509995674045\n",
      "train_loss 0.3330354577064728 train_acc 0.8573551035412327\n",
      "epoch 2278 lr 0.005251995493689517\n",
      "train_loss 0.3330239098862209 train_acc 0.8572325695380468\n",
      "epoch 2279 lr 0.005241501999693966\n",
      "train_loss 0.3330124129968383 train_acc 0.8573551035412327\n",
      "epoch 2280 lr 0.005231029471713402\n",
      "train_loss 0.3330009684804653 train_acc 0.8572019360372504\n",
      "epoch 2281 lr 0.005220577867857695\n",
      "train_loss 0.33298946443133914 train_acc 0.8573244700404362\n",
      "epoch 2282 lr 0.005210147146320425\n",
      "train_loss 0.33297787864920475 train_acc 0.8572172527876486\n",
      "epoch 2283 lr 0.005199737265378687\n",
      "train_loss 0.3329665890061274 train_acc 0.8572938365396398\n",
      "epoch 2284 lr 0.005189348183392944\n",
      "train_loss 0.3329551249240161 train_acc 0.8572325695380468\n",
      "epoch 2285 lr 0.005178979858806848\n",
      "train_loss 0.3329437170245704 train_acc 0.8572785197892415\n",
      "epoch 2286 lr 0.005168632250147098\n",
      "train_loss 0.3329321937834738 train_acc 0.8572478862884451\n",
      "epoch 2287 lr 0.00515830531602324\n",
      "train_loss 0.3329209872751249 train_acc 0.8573397867908344\n",
      "epoch 2288 lr 0.005147999015127524\n",
      "train_loss 0.3329098375841138 train_acc 0.8572478862884451\n",
      "epoch 2289 lr 0.005137713306234727\n",
      "train_loss 0.3328986737077759 train_acc 0.8574163705428256\n",
      "epoch 2290 lr 0.005127448148202011\n",
      "train_loss 0.3328875348305716 train_acc 0.8572478862884451\n",
      "epoch 2291 lr 0.005117203499968724\n",
      "train_loss 0.33287625805104487 train_acc 0.8574163705428256\n",
      "epoch 2292 lr 0.00510697932055626\n",
      "train_loss 0.3328649084665257 train_acc 0.8572478862884451\n",
      "epoch 2293 lr 0.005096775569067883\n",
      "train_loss 0.3328536738921533 train_acc 0.8574316872932238\n",
      "epoch 2294 lr 0.005086592204688581\n",
      "train_loss 0.3328426315357914 train_acc 0.8572019360372504\n",
      "epoch 2295 lr 0.0050764291866848815\n",
      "train_loss 0.3328310768869387 train_acc 0.8574623207940203\n",
      "epoch 2296 lr 0.005066286474404697\n",
      "train_loss 0.3328202828022044 train_acc 0.8572019360372504\n",
      "epoch 2297 lr 0.005056164027277161\n",
      "train_loss 0.3328088609363227 train_acc 0.8574163705428256\n",
      "epoch 2298 lr 0.00504606180481248\n",
      "train_loss 0.33279798816391254 train_acc 0.8572785197892415\n",
      "epoch 2299 lr 0.005035979766601745\n",
      "train_loss 0.3327870956799926 train_acc 0.8574163705428256\n",
      "\n",
      "val loss = 0.36206934442724403, \n",
      "val acc = 0.8355616815988973\n",
      "\n",
      "epoch 2300 lr 0.005025917872316792\n",
      "train_loss 0.3327761303874449 train_acc 0.8572632030388433\n",
      "epoch 2301 lr 0.005015876081710026\n",
      "train_loss 0.33276552853897273 train_acc 0.8574623207940203\n",
      "epoch 2302 lr 0.005005854354614278\n",
      "train_loss 0.3327549285268509 train_acc 0.8572172527876486\n",
      "epoch 2303 lr 0.004995852650942623\n",
      "train_loss 0.33274475094207784 train_acc 0.8575235877956133\n",
      "epoch 2304 lr 0.004985870930688233\n",
      "train_loss 0.33273422324660257 train_acc 0.8571559857860557\n",
      "epoch 2305 lr 0.00497590915392421\n",
      "train_loss 0.3327239987335789 train_acc 0.8575082710452151\n",
      "epoch 2306 lr 0.00496596728080344\n",
      "train_loss 0.3327128365438309 train_acc 0.8571253522852592\n",
      "epoch 2307 lr 0.004956045271558416\n",
      "train_loss 0.3327023860460454 train_acc 0.8574929542948169\n",
      "epoch 2308 lr 0.004946143086501086\n",
      "train_loss 0.3326909156401593 train_acc 0.8570794020340644\n",
      "epoch 2309 lr 0.004936260686022691\n",
      "train_loss 0.33268030453156056 train_acc 0.8575082710452151\n",
      "epoch 2310 lr 0.004926398030593628\n",
      "train_loss 0.3326686555122722 train_acc 0.8570794020340644\n",
      "epoch 2311 lr 0.004916555080763255\n",
      "train_loss 0.33265786309836554 train_acc 0.8575235877956133\n",
      "epoch 2312 lr 0.004906731797159761\n",
      "train_loss 0.3326458379403546 train_acc 0.8571253522852592\n",
      "epoch 2313 lr 0.004896928140489993\n",
      "train_loss 0.3326344357997271 train_acc 0.857569538046808\n",
      "epoch 2314 lr 0.004887144071539321\n",
      "train_loss 0.33262247773329134 train_acc 0.8571253522852592\n",
      "epoch 2315 lr 0.004877379551171452\n",
      "train_loss 0.33261132664026977 train_acc 0.857569538046808\n",
      "epoch 2316 lr 0.004867634540328289\n",
      "train_loss 0.3325998472737385 train_acc 0.8572019360372504\n",
      "epoch 2317 lr 0.0048579090000297745\n",
      "train_loss 0.33258849809674124 train_acc 0.8575389045460116\n",
      "epoch 2318 lr 0.0048482028913737416\n",
      "train_loss 0.3325770264197282 train_acc 0.8572325695380468\n",
      "epoch 2319 lr 0.004838516175535739\n",
      "train_loss 0.33256543942149763 train_acc 0.8575235877956133\n",
      "epoch 2320 lr 0.004828848813768888\n",
      "train_loss 0.33255372990375004 train_acc 0.8572478862884451\n",
      "epoch 2321 lr 0.004819200767403728\n",
      "train_loss 0.33254232573395004 train_acc 0.8575848547972063\n",
      "epoch 2322 lr 0.004809571997848067\n",
      "train_loss 0.3325310271689414 train_acc 0.8572632030388433\n",
      "epoch 2323 lr 0.00479996246658681\n",
      "train_loss 0.33251914783694736 train_acc 0.8575082710452151\n",
      "epoch 2324 lr 0.004790372135181819\n",
      "train_loss 0.33250802061623963 train_acc 0.8572785197892415\n",
      "epoch 2325 lr 0.004780800965271752\n",
      "train_loss 0.33249611498291215 train_acc 0.8574776375444185\n",
      "epoch 2326 lr 0.004771248918571925\n",
      "train_loss 0.3324847566540574 train_acc 0.8573244700404362\n",
      "epoch 2327 lr 0.0047617159568741334\n",
      "train_loss 0.3324729154798611 train_acc 0.8574623207940203\n",
      "epoch 2328 lr 0.004752202042046519\n",
      "train_loss 0.33246166928119497 train_acc 0.8573551035412327\n",
      "epoch 2329 lr 0.004742707136033404\n",
      "train_loss 0.332449952633362 train_acc 0.8574929542948169\n",
      "epoch 2330 lr 0.0047332312008551616\n",
      "train_loss 0.33243846400759797 train_acc 0.8573857370420291\n",
      "epoch 2331 lr 0.004723774198608033\n",
      "train_loss 0.33242688201527587 train_acc 0.8575542212964098\n",
      "epoch 2332 lr 0.004714336091463997\n",
      "train_loss 0.332415354210656 train_acc 0.8574163705428256\n",
      "epoch 2333 lr 0.00470491684167061\n",
      "train_loss 0.3324041519320324 train_acc 0.8575235877956133\n",
      "epoch 2334 lr 0.004695516411550866\n",
      "train_loss 0.3323923602681804 train_acc 0.8574470040436221\n",
      "epoch 2335 lr 0.004686134763503029\n",
      "train_loss 0.3323813838024626 train_acc 0.8576001715476045\n",
      "epoch 2336 lr 0.004676771860000493\n",
      "train_loss 0.33236936862932853 train_acc 0.8574776375444185\n",
      "epoch 2337 lr 0.0046674276635916305\n",
      "train_loss 0.33235812116980773 train_acc 0.8576461217987992\n",
      "epoch 2338 lr 0.004658102136899649\n",
      "train_loss 0.33234602577977856 train_acc 0.8574470040436221\n",
      "epoch 2339 lr 0.0046487952426224255\n",
      "train_loss 0.3323348266170623 train_acc 0.8577227055507903\n",
      "epoch 2340 lr 0.004639506943532371\n",
      "train_loss 0.33232316013961355 train_acc 0.8574776375444185\n",
      "epoch 2341 lr 0.004630237202476273\n",
      "train_loss 0.3323123033264875 train_acc 0.8577073888003921\n",
      "epoch 2342 lr 0.004620985982375162\n",
      "train_loss 0.33230102662606165 train_acc 0.8575389045460116\n",
      "epoch 2343 lr 0.004611753246224142\n",
      "train_loss 0.33229034961144605 train_acc 0.8577533390515868\n",
      "epoch 2344 lr 0.004602538957092257\n",
      "train_loss 0.3322792551853357 train_acc 0.8574776375444185\n",
      "epoch 2345 lr 0.004593343078122332\n",
      "train_loss 0.33226908814048267 train_acc 0.8577227055507903\n",
      "epoch 2346 lr 0.004584165572530848\n",
      "train_loss 0.33225842925092763 train_acc 0.8575389045460116\n",
      "epoch 2347 lr 0.0045750064036077665\n",
      "train_loss 0.33224837131393264 train_acc 0.8577380223011886\n",
      "epoch 2348 lr 0.004565865534716399\n",
      "train_loss 0.3322380184496591 train_acc 0.857569538046808\n",
      "epoch 2349 lr 0.004556742929293255\n",
      "train_loss 0.3322291727546073 train_acc 0.8577227055507903\n",
      "\n",
      "val loss = 0.36209696007562997, \n",
      "val acc = 0.8354238456237078\n",
      "\n",
      "epoch 2350 lr 0.004547638550847908\n",
      "train_loss 0.33221975906051643 train_acc 0.8576614385491974\n",
      "epoch 2351 lr 0.004538552362962827\n",
      "train_loss 0.33221181506528 train_acc 0.8577839725523833\n",
      "epoch 2352 lr 0.004529484329293249\n",
      "train_loss 0.33220300109111284 train_acc 0.8575848547972063\n",
      "epoch 2353 lr 0.004520434413567025\n",
      "train_loss 0.3321943693321312 train_acc 0.8577227055507903\n",
      "epoch 2354 lr 0.004511402579584485\n",
      "train_loss 0.33218547873912085 train_acc 0.8575542212964098\n",
      "epoch 2355 lr 0.004502388791218279\n",
      "train_loss 0.3321772788279683 train_acc 0.8576461217987992\n",
      "epoch 2356 lr 0.0044933930124132415\n",
      "train_loss 0.33216909255410637 train_acc 0.8575235877956133\n",
      "epoch 2357 lr 0.004484415207186241\n",
      "train_loss 0.3321618036613571 train_acc 0.8575389045460116\n",
      "epoch 2358 lr 0.004475455339626052\n",
      "train_loss 0.33215386747224224 train_acc 0.8575082710452151\n",
      "epoch 2359 lr 0.004466513373893188\n",
      "train_loss 0.3321459647189139 train_acc 0.8574776375444185\n",
      "epoch 2360 lr 0.004457589274219776\n",
      "train_loss 0.3321380009626474 train_acc 0.8574623207940203\n",
      "epoch 2361 lr 0.0044486830049094\n",
      "train_loss 0.33213093819740325 train_acc 0.8575235877956133\n",
      "epoch 2362 lr 0.0044397945303369804\n",
      "train_loss 0.3321236196061746 train_acc 0.8574470040436221\n",
      "epoch 2363 lr 0.004430923814948601\n",
      "train_loss 0.3321176297502728 train_acc 0.857630805048401\n",
      "epoch 2364 lr 0.004422070823261388\n",
      "train_loss 0.3321116781984502 train_acc 0.8574163705428256\n",
      "epoch 2365 lr 0.004413235519863361\n",
      "train_loss 0.3321062838302505 train_acc 0.8576001715476045\n",
      "epoch 2366 lr 0.0044044178694133025\n",
      "train_loss 0.3321002737015722 train_acc 0.8574470040436221\n",
      "epoch 2367 lr 0.004395617836640594\n",
      "train_loss 0.33209434358463297 train_acc 0.8576461217987992\n",
      "epoch 2368 lr 0.004386835386345092\n",
      "train_loss 0.33208809810749496 train_acc 0.8575082710452151\n",
      "epoch 2369 lr 0.004378070483396981\n",
      "train_loss 0.3320820734741017 train_acc 0.8575542212964098\n",
      "epoch 2370 lr 0.004369323092736645\n",
      "train_loss 0.33207561615763276 train_acc 0.8574929542948169\n",
      "epoch 2371 lr 0.004360593179374506\n",
      "train_loss 0.3320686792747689 train_acc 0.8574929542948169\n",
      "epoch 2372 lr 0.004351880708390899\n",
      "train_loss 0.33206114064513387 train_acc 0.8575848547972063\n",
      "epoch 2373 lr 0.004343185644935923\n",
      "train_loss 0.3320524778404523 train_acc 0.8574929542948169\n",
      "epoch 2374 lr 0.004334507954229322\n",
      "train_loss 0.3320447789218448 train_acc 0.857569538046808\n",
      "epoch 2375 lr 0.004325847601560317\n",
      "train_loss 0.33203485443333136 train_acc 0.8574776375444185\n",
      "epoch 2376 lr 0.004317204552287486\n",
      "train_loss 0.33202784905730365 train_acc 0.857569538046808\n",
      "epoch 2377 lr 0.004308578771838621\n",
      "train_loss 0.3320180514099411 train_acc 0.8575848547972063\n",
      "epoch 2378 lr 0.004299970225710584\n",
      "train_loss 0.3320113417702963 train_acc 0.8575542212964098\n",
      "epoch 2379 lr 0.004291378879469188\n",
      "train_loss 0.33200009644860257 train_acc 0.8575848547972063\n",
      "epoch 2380 lr 0.00428280469874903\n",
      "train_loss 0.3319929416609857 train_acc 0.857569538046808\n",
      "epoch 2381 lr 0.004274247649253379\n",
      "train_loss 0.3319820509795375 train_acc 0.8575542212964098\n",
      "epoch 2382 lr 0.004265707696754019\n",
      "train_loss 0.33197592793877345 train_acc 0.8575848547972063\n",
      "epoch 2383 lr 0.004257184807091138\n",
      "train_loss 0.33196370802150493 train_acc 0.857569538046808\n",
      "epoch 2384 lr 0.004248678946173161\n",
      "train_loss 0.33195699258460887 train_acc 0.8576461217987992\n",
      "epoch 2385 lr 0.004240190079976634\n",
      "train_loss 0.331947663682759 train_acc 0.8576001715476045\n",
      "epoch 2386 lr 0.004231718174546076\n",
      "train_loss 0.331943254203524 train_acc 0.8576461217987992\n",
      "epoch 2387 lr 0.004223263195993863\n",
      "train_loss 0.3319341872038387 train_acc 0.8575542212964098\n",
      "epoch 2388 lr 0.004214825110500065\n",
      "train_loss 0.33193068095945505 train_acc 0.8576461217987992\n",
      "epoch 2389 lr 0.004206403884312329\n",
      "train_loss 0.3319224507565596 train_acc 0.8576154882980027\n",
      "epoch 2390 lr 0.004197999483745735\n",
      "train_loss 0.3319188988130996 train_acc 0.8576767552995956\n",
      "epoch 2391 lr 0.0041896118751826765\n",
      "train_loss 0.3319133810738281 train_acc 0.8575542212964098\n",
      "epoch 2392 lr 0.004181241025072706\n",
      "train_loss 0.3319124320099618 train_acc 0.8576614385491974\n",
      "epoch 2393 lr 0.00417288689993241\n",
      "train_loss 0.33190808662790694 train_acc 0.8576767552995956\n",
      "epoch 2394 lr 0.004164549466345273\n",
      "train_loss 0.3319030408106395 train_acc 0.8576767552995956\n",
      "epoch 2395 lr 0.004156228690961559\n",
      "train_loss 0.33189833940119734 train_acc 0.857630805048401\n",
      "epoch 2396 lr 0.0041479245404981505\n",
      "train_loss 0.3318940283784145 train_acc 0.8577073888003921\n",
      "epoch 2397 lr 0.004139636981738434\n",
      "train_loss 0.33188985083812617 train_acc 0.8576767552995956\n",
      "epoch 2398 lr 0.004131365981532161\n",
      "train_loss 0.33188339321482613 train_acc 0.8576767552995956\n",
      "epoch 2399 lr 0.004123111506795325\n",
      "train_loss 0.3318792490066183 train_acc 0.8576461217987992\n",
      "\n",
      "val loss = 0.3624684636935114, \n",
      "val acc = 0.8343211578221916\n",
      "\n",
      "epoch 2400 lr 0.004114873524510015\n",
      "train_loss 0.33187286842448316 train_acc 0.8576461217987992\n",
      "epoch 2401 lr 0.004106652001724289\n",
      "train_loss 0.3318712129559292 train_acc 0.8576920720499939\n",
      "epoch 2402 lr 0.004098446905552042\n",
      "train_loss 0.3318659793163575 train_acc 0.8576001715476045\n",
      "epoch 2403 lr 0.004090258203172885\n",
      "train_loss 0.33186667586801777 train_acc 0.8578146060531797\n",
      "epoch 2404 lr 0.004082085861831995\n",
      "train_loss 0.3318636150542297 train_acc 0.8575542212964098\n",
      "epoch 2405 lr 0.004073929848839994\n",
      "train_loss 0.33186822034487495 train_acc 0.857891189805171\n",
      "epoch 2406 lr 0.004065790131572818\n",
      "train_loss 0.33186675737632204 train_acc 0.8575389045460116\n",
      "epoch 2407 lr 0.004057666677471592\n",
      "train_loss 0.3318739296619028 train_acc 0.857891189805171\n",
      "epoch 2408 lr 0.004049559454042487\n",
      "train_loss 0.33187895584846283 train_acc 0.8574929542948169\n",
      "epoch 2409 lr 0.004041468428856596\n",
      "train_loss 0.33189661318574004 train_acc 0.857768655801985\n",
      "epoch 2410 lr 0.004033393569549807\n",
      "train_loss 0.33190474289802036 train_acc 0.8574316872932238\n",
      "epoch 2411 lr 0.004025334843822678\n",
      "train_loss 0.3319240224849541 train_acc 0.8578758730547728\n",
      "epoch 2412 lr 0.00401729221944029\n",
      "train_loss 0.33193032329226596 train_acc 0.8574010537924274\n",
      "epoch 2413 lr 0.004009265664232137\n",
      "train_loss 0.33195630436783635 train_acc 0.857829922803578\n",
      "epoch 2414 lr 0.004001255146091983\n",
      "train_loss 0.3319667002065202 train_acc 0.857309153290038\n",
      "epoch 2415 lr 0.003993260632977751\n",
      "train_loss 0.33199661468463465 train_acc 0.8579371400563657\n",
      "epoch 2416 lr 0.003985282092911376\n",
      "train_loss 0.33201145188408704 train_acc 0.8571559857860557\n",
      "epoch 2417 lr 0.003977319493978686\n",
      "train_loss 0.3320536430504309 train_acc 0.8576920720499939\n",
      "epoch 2418 lr 0.003969372804329272\n",
      "train_loss 0.33207318804729125 train_acc 0.8571406690356574\n",
      "epoch 2419 lr 0.003961441992176371\n",
      "train_loss 0.33212832782363827 train_acc 0.8577227055507903\n",
      "epoch 2420 lr 0.003953527025796721\n",
      "train_loss 0.3321491733136267 train_acc 0.8570640852836662\n",
      "epoch 2421 lr 0.003945627873530445\n",
      "train_loss 0.33221178509544913 train_acc 0.8576461217987992\n",
      "epoch 2422 lr 0.003937744503780921\n",
      "train_loss 0.3322314465267306 train_acc 0.856987501531675\n",
      "epoch 2423 lr 0.003929876885014665\n",
      "train_loss 0.33229693078388867 train_acc 0.8576001715476045\n",
      "epoch 2424 lr 0.00392202498576119\n",
      "train_loss 0.33233428003546117 train_acc 0.8569109177796839\n",
      "epoch 2425 lr 0.003914188774612887\n",
      "train_loss 0.3324070759640596 train_acc 0.8572938365396398\n",
      "epoch 2426 lr 0.003906368220224898\n",
      "train_loss 0.3324445346472022 train_acc 0.8568037005268963\n",
      "epoch 2427 lr 0.0038985632913150024\n",
      "train_loss 0.33252114563870305 train_acc 0.8572325695380468\n",
      "epoch 2428 lr 0.003890773956663469\n",
      "train_loss 0.33255969592471296 train_acc 0.8568956010292856\n",
      "epoch 2429 lr 0.0038830001851129507\n",
      "train_loss 0.33263572961164506 train_acc 0.8569568680308786\n",
      "epoch 2430 lr 0.0038752419455683465\n",
      "train_loss 0.3326657669271534 train_acc 0.8568649675284892\n",
      "epoch 2431 lr 0.003867499206996695\n",
      "train_loss 0.3327534454089136 train_acc 0.8567577502757016\n",
      "epoch 2432 lr 0.003859771938427028\n",
      "train_loss 0.33277824290876223 train_acc 0.8567577502757016\n",
      "epoch 2433 lr 0.003852060108950261\n",
      "train_loss 0.3328744053101512 train_acc 0.8566658497733121\n",
      "epoch 2434 lr 0.003844363687719063\n",
      "train_loss 0.3328983036417231 train_acc 0.8565892660213209\n",
      "epoch 2435 lr 0.0038366826439477446\n",
      "train_loss 0.3330069614269563 train_acc 0.8563135645141526\n",
      "epoch 2436 lr 0.003829016946912118\n",
      "train_loss 0.3330418661412452 train_acc 0.8564054650165421\n",
      "epoch 2437 lr 0.0038213665659493842\n",
      "train_loss 0.33315862072227215 train_acc 0.8561603970101703\n",
      "epoch 2438 lr 0.0038137314704580058\n",
      "train_loss 0.33319325793554927 train_acc 0.8564514152677368\n",
      "epoch 2439 lr 0.0038061116298975977\n",
      "train_loss 0.3333068610447925 train_acc 0.8558081117510109\n",
      "epoch 2440 lr 0.003798507013788784\n",
      "train_loss 0.3333224175503616 train_acc 0.8561910305109668\n",
      "epoch 2441 lr 0.00379091759171309\n",
      "train_loss 0.3334521055538444 train_acc 0.8555630437446391\n",
      "epoch 2442 lr 0.003783343333312814\n",
      "train_loss 0.33346726389343334 train_acc 0.8560531797573827\n",
      "epoch 2443 lr 0.0037757842082909196\n",
      "train_loss 0.33362239702028074 train_acc 0.855425192991055\n",
      "epoch 2444 lr 0.0037682401864108923\n",
      "train_loss 0.33360237047234237 train_acc 0.8559612792549932\n",
      "epoch 2445 lr 0.003760711237496635\n",
      "train_loss 0.33374961819889465 train_acc 0.8553792427398603\n",
      "epoch 2446 lr 0.003753197331432339\n",
      "train_loss 0.33369789003735106 train_acc 0.8559612792549932\n",
      "epoch 2447 lr 0.0037456984381623757\n",
      "train_loss 0.3338349649050162 train_acc 0.8553945594902586\n",
      "epoch 2448 lr 0.0037382145276911596\n",
      "train_loss 0.3337595616918017 train_acc 0.8559306457541968\n",
      "epoch 2449 lr 0.0037307455700830387\n",
      "train_loss 0.3339016244086903 train_acc 0.8554405097414532\n",
      "\n",
      "val loss = 0.3651696529661427, \n",
      "val acc = 0.8312887663680221\n",
      "\n",
      "epoch 2450 lr 0.003723291535462169\n",
      "train_loss 0.3338195707394575 train_acc 0.8558693787526038\n",
      "epoch 2451 lr 0.003715852394012409\n",
      "train_loss 0.33394962143136064 train_acc 0.8554558264918515\n",
      "epoch 2452 lr 0.0037084281159771794\n",
      "train_loss 0.33385968976737995 train_acc 0.855746844749418\n",
      "epoch 2453 lr 0.0037010186716593583\n",
      "train_loss 0.3339775255534284 train_acc 0.8554405097414532\n",
      "epoch 2454 lr 0.003693624031421155\n",
      "train_loss 0.33387424436909824 train_acc 0.8557621614998162\n",
      "epoch 2455 lr 0.0036862441656840056\n",
      "train_loss 0.333977740726152 train_acc 0.8554711432422497\n",
      "epoch 2456 lr 0.003678879044928434\n",
      "train_loss 0.3338598929061847 train_acc 0.8557774782502144\n",
      "epoch 2457 lr 0.003671528639693948\n",
      "train_loss 0.33394389834939286 train_acc 0.8554864599926479\n",
      "epoch 2458 lr 0.003664192920578912\n",
      "train_loss 0.33381661101709953 train_acc 0.8557315279990197\n",
      "epoch 2459 lr 0.0036568718582404474\n",
      "train_loss 0.33388057666963555 train_acc 0.8554711432422497\n",
      "epoch 2460 lr 0.0036495654233942914\n",
      "train_loss 0.3337422426213053 train_acc 0.8557621614998162\n",
      "epoch 2461 lr 0.003642273586814695\n",
      "train_loss 0.33380288139112646 train_acc 0.855425192991055\n",
      "epoch 2462 lr 0.0036349963193342996\n",
      "train_loss 0.3336595831167812 train_acc 0.8558846955030021\n",
      "epoch 2463 lr 0.003627733591844031\n",
      "train_loss 0.3337094744391082 train_acc 0.8554864599926479\n",
      "epoch 2464 lr 0.0036204853752929665\n",
      "train_loss 0.33355746993739993 train_acc 0.8559153290037985\n",
      "epoch 2465 lr 0.0036132516406882313\n",
      "train_loss 0.33358444573583534 train_acc 0.8554405097414532\n",
      "epoch 2466 lr 0.0036060323590948727\n",
      "train_loss 0.3334254508063677 train_acc 0.8560225462565862\n",
      "epoch 2467 lr 0.0035988275016357618\n",
      "train_loss 0.33344469617021455 train_acc 0.8555017767430462\n",
      "epoch 2468 lr 0.0035916370394914556\n",
      "train_loss 0.3332914475346248 train_acc 0.8562676142629579\n",
      "epoch 2469 lr 0.003584460943900097\n",
      "train_loss 0.33330689357470983 train_acc 0.8555324102438426\n",
      "epoch 2470 lr 0.0035772991861572896\n",
      "train_loss 0.33315878188142345 train_acc 0.8563901482661439\n",
      "epoch 2471 lr 0.0035701517376159997\n",
      "train_loss 0.3331732539363736 train_acc 0.8556702609974268\n",
      "epoch 2472 lr 0.0035630185696864207\n",
      "train_loss 0.33303108520944025 train_acc 0.8565433157701262\n",
      "epoch 2473 lr 0.003555899653835871\n",
      "train_loss 0.3330396515014892 train_acc 0.8557621614998162\n",
      "epoch 2474 lr 0.0035487949615886742\n",
      "train_loss 0.3328933966356467 train_acc 0.8566352162725156\n",
      "epoch 2475 lr 0.0035417044645260592\n",
      "train_loss 0.3328884575591938 train_acc 0.8560225462565862\n",
      "epoch 2476 lr 0.0035346281342860247\n",
      "train_loss 0.3327595682290226 train_acc 0.8567730670260998\n",
      "epoch 2477 lr 0.00352756594256324\n",
      "train_loss 0.3327497428846475 train_acc 0.8561603970101703\n",
      "epoch 2478 lr 0.003520517861108926\n",
      "train_loss 0.33263466187921104 train_acc 0.8568802842788874\n",
      "epoch 2479 lr 0.003513483861730753\n",
      "train_loss 0.3326208367493527 train_acc 0.8563288812645509\n",
      "epoch 2480 lr 0.0035064639162927123\n",
      "train_loss 0.33252605232183097 train_acc 0.8568956010292856\n",
      "epoch 2481 lr 0.0034994579967150114\n",
      "train_loss 0.33251905188891856 train_acc 0.856527999019728\n",
      "epoch 2482 lr 0.0034924660749739607\n",
      "train_loss 0.3324295203687992 train_acc 0.8569721847812768\n",
      "epoch 2483 lr 0.0034854881231018695\n",
      "train_loss 0.33242676436197716 train_acc 0.856788383776498\n",
      "epoch 2484 lr 0.003478524113186918\n",
      "train_loss 0.3323505440684872 train_acc 0.8570028182820733\n",
      "epoch 2485 lr 0.003471574017373057\n",
      "train_loss 0.33234761046105554 train_acc 0.8568190172772945\n",
      "epoch 2486 lr 0.0034646378078598914\n",
      "train_loss 0.332294812646723 train_acc 0.8570947187844626\n",
      "epoch 2487 lr 0.00345771545690258\n",
      "train_loss 0.33229713786174575 train_acc 0.8568190172772945\n",
      "epoch 2488 lr 0.003450806936811706\n",
      "train_loss 0.3322513830609084 train_acc 0.8571100355348609\n",
      "epoch 2489 lr 0.003443912219953181\n",
      "train_loss 0.3322554794419728 train_acc 0.8568343340276927\n",
      "epoch 2490 lr 0.003437031278748124\n",
      "train_loss 0.3322121303102321 train_acc 0.8571100355348609\n",
      "epoch 2491 lr 0.0034301640856727682\n",
      "train_loss 0.3322147967396077 train_acc 0.8568802842788874\n",
      "epoch 2492 lr 0.003423310613258329\n",
      "train_loss 0.332175229203302 train_acc 0.8571559857860557\n",
      "epoch 2493 lr 0.0034164708340909066\n",
      "train_loss 0.33219006637822623 train_acc 0.8568802842788874\n",
      "epoch 2494 lr 0.0034096447208113727\n",
      "train_loss 0.33215605864141795 train_acc 0.8571713025364539\n",
      "epoch 2495 lr 0.0034028322461152716\n",
      "train_loss 0.3321739279231269 train_acc 0.8568802842788874\n",
      "epoch 2496 lr 0.003396033382752692\n",
      "train_loss 0.33214332805454916 train_acc 0.8571559857860557\n",
      "epoch 2497 lr 0.0033892481035281714\n",
      "train_loss 0.3321673070917537 train_acc 0.8569262345300821\n",
      "epoch 2498 lr 0.003382476381300581\n",
      "train_loss 0.332143242904975 train_acc 0.8571713025364539\n",
      "epoch 2499 lr 0.0033757181889830287\n",
      "train_loss 0.3321726490585139 train_acc 0.8569415512804803\n",
      "\n",
      "val loss = 0.36385005858200303, \n",
      "val acc = 0.8323914541695383\n",
      "\n",
      "epoch 2500 lr 0.0033689734995427335\n",
      "train_loss 0.33215400681545887 train_acc 0.8571866192868521\n",
      "epoch 2501 lr 0.0033622422860009283\n",
      "train_loss 0.33220339694853324 train_acc 0.8569415512804803\n",
      "epoch 2502 lr 0.00335552452143275\n",
      "train_loss 0.3321831669766807 train_acc 0.8571100355348609\n",
      "epoch 2503 lr 0.0033488201789671286\n",
      "train_loss 0.332241768185317 train_acc 0.8567730670260998\n",
      "epoch 2504 lr 0.003342129231786691\n",
      "train_loss 0.33223647242760046 train_acc 0.8570181350324715\n",
      "epoch 2505 lr 0.0033354516531276367\n",
      "train_loss 0.33230599527884175 train_acc 0.8564514152677368\n",
      "epoch 2506 lr 0.0033287874162796424\n",
      "train_loss 0.3323126708402632 train_acc 0.8570794020340644\n",
      "epoch 2507 lr 0.0033221364945857485\n",
      "train_loss 0.33239680994547965 train_acc 0.8563288812645509\n",
      "epoch 2508 lr 0.0033154988614422657\n",
      "train_loss 0.33240850677996187 train_acc 0.8568190172772945\n",
      "epoch 2509 lr 0.0033088744902986487\n",
      "train_loss 0.3325124546739955 train_acc 0.856206347261365\n",
      "epoch 2510 lr 0.003302263354657405\n",
      "train_loss 0.33251990979114077 train_acc 0.8568343340276927\n",
      "epoch 2511 lr 0.0032956654280739805\n",
      "train_loss 0.33262544638065905 train_acc 0.8559153290037985\n",
      "epoch 2512 lr 0.003289080684156665\n",
      "train_loss 0.3326131106408929 train_acc 0.8566505330229138\n",
      "epoch 2513 lr 0.0032825090965664717\n",
      "train_loss 0.33272808653355157 train_acc 0.8558693787526038\n",
      "epoch 2514 lr 0.0032759506390170412\n",
      "train_loss 0.3326989784237307 train_acc 0.8565892660213209\n",
      "epoch 2515 lr 0.0032694052852745323\n",
      "train_loss 0.33281783606215987 train_acc 0.8558234285014091\n",
      "epoch 2516 lr 0.0032628730091575258\n",
      "train_loss 0.3327919855494191 train_acc 0.8566045827717191\n",
      "epoch 2517 lr 0.003256353784536907\n",
      "train_loss 0.33290926611212646 train_acc 0.8557774782502144\n",
      "epoch 2518 lr 0.003249847585335768\n",
      "train_loss 0.33287380701481495 train_acc 0.8566045827717191\n",
      "epoch 2519 lr 0.0032433543855293003\n",
      "train_loss 0.3330028075304811 train_acc 0.8557008944982233\n",
      "epoch 2520 lr 0.0032368741591447025\n",
      "train_loss 0.33296767633896834 train_acc 0.856527999019728\n",
      "epoch 2521 lr 0.003230406880261057\n",
      "train_loss 0.33310987211271303 train_acc 0.8556549442470286\n",
      "epoch 2522 lr 0.0032239525230092396\n",
      "train_loss 0.33307480119338734 train_acc 0.8565126822693298\n",
      "epoch 2523 lr 0.0032175110615718103\n",
      "train_loss 0.3332083637500039 train_acc 0.8557162112486215\n",
      "epoch 2524 lr 0.0032110824701829196\n",
      "train_loss 0.3331798091496098 train_acc 0.8563135645141526\n",
      "epoch 2525 lr 0.0032046667231281916\n",
      "train_loss 0.3332907823509134 train_acc 0.8555783604950373\n",
      "epoch 2526 lr 0.003198263794744629\n",
      "train_loss 0.3332574296817303 train_acc 0.8562829310133562\n",
      "epoch 2527 lr 0.0031918736594205065\n",
      "train_loss 0.3333593573314829 train_acc 0.8555783604950373\n",
      "epoch 2528 lr 0.0031854962915952804\n",
      "train_loss 0.3333132435833378 train_acc 0.8561910305109668\n",
      "epoch 2529 lr 0.0031791316657594684\n",
      "train_loss 0.33341000257287895 train_acc 0.8554864599926479\n",
      "epoch 2530 lr 0.003172779756454558\n",
      "train_loss 0.33334907485786003 train_acc 0.8561450802597721\n",
      "epoch 2531 lr 0.0031664405382729006\n",
      "train_loss 0.33344238863187836 train_acc 0.8554711432422497\n",
      "epoch 2532 lr 0.0031601139858576217\n",
      "train_loss 0.3333663978769655 train_acc 0.8560838132581792\n",
      "epoch 2533 lr 0.0031538000739024996\n",
      "train_loss 0.33344611223985055 train_acc 0.8555017767430462\n",
      "epoch 2534 lr 0.003147498777151878\n",
      "train_loss 0.33334874909236545 train_acc 0.8561144467589756\n",
      "epoch 2535 lr 0.003141210070400559\n",
      "train_loss 0.3334140079365854 train_acc 0.8555170934934444\n",
      "epoch 2536 lr 0.0031349339284937124\n",
      "train_loss 0.333306334476184 train_acc 0.8561144467589756\n",
      "epoch 2537 lr 0.00312867032632676\n",
      "train_loss 0.3333528935345715 train_acc 0.8555936772454356\n",
      "epoch 2538 lr 0.0031224192388452842\n",
      "train_loss 0.33323450119349995 train_acc 0.8561910305109668\n",
      "epoch 2539 lr 0.0031161806410449243\n",
      "train_loss 0.3332499753104385 train_acc 0.8557315279990197\n",
      "epoch 2540 lr 0.0031099545079712864\n",
      "train_loss 0.33313014850036876 train_acc 0.8562676142629579\n",
      "epoch 2541 lr 0.0031037408147198266\n",
      "train_loss 0.33314846384505625 train_acc 0.8557162112486215\n",
      "epoch 2542 lr 0.0030975395364357646\n",
      "train_loss 0.33302426201408103 train_acc 0.8563135645141526\n",
      "epoch 2543 lr 0.003091350648313975\n",
      "train_loss 0.33304094693727015 train_acc 0.8557621614998162\n",
      "epoch 2544 lr 0.0030851741255989037\n",
      "train_loss 0.3329155053535008 train_acc 0.8564820487685333\n",
      "epoch 2545 lr 0.003079009943584448\n",
      "train_loss 0.3329223995627688 train_acc 0.8558540620022056\n",
      "epoch 2546 lr 0.0030728580776138727\n",
      "train_loss 0.33279573165663506 train_acc 0.8565433157701262\n",
      "epoch 2547 lr 0.0030667185030797016\n",
      "train_loss 0.3328039039120512 train_acc 0.8560225462565862\n",
      "epoch 2548 lr 0.003060591195423635\n",
      "train_loss 0.33267328611315766 train_acc 0.8566811665237103\n",
      "epoch 2549 lr 0.0030544761301364303\n",
      "train_loss 0.3326766176437175 train_acc 0.8560531797573827\n",
      "\n",
      "val loss = 0.3646914732841483, \n",
      "val acc = 0.8325292901447278\n",
      "\n",
      "epoch 2550 lr 0.003048373282757819\n",
      "train_loss 0.3325523346235061 train_acc 0.8566505330229138\n",
      "epoch 2551 lr 0.0030422826288764005\n",
      "train_loss 0.3325589713148302 train_acc 0.8559612792549932\n",
      "epoch 2552 lr 0.0030362041441295566\n",
      "train_loss 0.33243557029818466 train_acc 0.8568190172772945\n",
      "epoch 2553 lr 0.0030301378042033376\n",
      "train_loss 0.3324521444108421 train_acc 0.8561297635093739\n",
      "epoch 2554 lr 0.0030240835848323756\n",
      "train_loss 0.3323342080214997 train_acc 0.8568956010292856\n",
      "epoch 2555 lr 0.0030180414617997824\n",
      "train_loss 0.33236012421296107 train_acc 0.8561603970101703\n",
      "epoch 2556 lr 0.0030120114109370632\n",
      "train_loss 0.3322503579567196 train_acc 0.8569262345300821\n",
      "epoch 2557 lr 0.0030059934081240035\n",
      "train_loss 0.33228053031519944 train_acc 0.8562676142629579\n",
      "epoch 2558 lr 0.0029999874292885847\n",
      "train_loss 0.3321709145001484 train_acc 0.8570794020340644\n",
      "epoch 2559 lr 0.00299399345040688\n",
      "train_loss 0.33220421423893665 train_acc 0.8563288812645509\n",
      "epoch 2560 lr 0.0029880114475029714\n",
      "train_loss 0.332096856782383 train_acc 0.8570947187844626\n",
      "epoch 2561 lr 0.002982041396648837\n",
      "train_loss 0.3321336957495309 train_acc 0.8564514152677368\n",
      "epoch 2562 lr 0.0029760832739642654\n",
      "train_loss 0.33203987237143484 train_acc 0.8572172527876486\n",
      "epoch 2563 lr 0.002970137055616755\n",
      "train_loss 0.3320785421740509 train_acc 0.8566198995221174\n",
      "epoch 2564 lr 0.00296420271782143\n",
      "train_loss 0.33198740817729216 train_acc 0.8572785197892415\n",
      "epoch 2565 lr 0.0029582802368409286\n",
      "train_loss 0.3320411895737909 train_acc 0.8566811665237103\n",
      "epoch 2566 lr 0.0029523695889853187\n",
      "train_loss 0.33195709891984937 train_acc 0.8572632030388433\n",
      "epoch 2567 lr 0.002946470750611999\n",
      "train_loss 0.33201576199671895 train_acc 0.856727116774905\n",
      "epoch 2568 lr 0.0029405836981256125\n",
      "train_loss 0.3319354476001892 train_acc 0.8572478862884451\n",
      "epoch 2569 lr 0.0029347084079779395\n",
      "train_loss 0.33200105794603346 train_acc 0.8567424335253033\n",
      "epoch 2570 lr 0.0029288448566678112\n",
      "train_loss 0.3319298043982602 train_acc 0.8572632030388433\n",
      "epoch 2571 lr 0.0029229930207410127\n",
      "train_loss 0.33199896660513284 train_acc 0.8566505330229138\n",
      "epoch 2572 lr 0.0029171528767901965\n",
      "train_loss 0.33193710569657364 train_acc 0.8572325695380468\n",
      "epoch 2573 lr 0.0029113244014547773\n",
      "train_loss 0.3320193120315823 train_acc 0.8565433157701262\n",
      "epoch 2574 lr 0.0029055075714208454\n",
      "train_loss 0.33197001790622827 train_acc 0.8572478862884451\n",
      "epoch 2575 lr 0.0028997023634210707\n",
      "train_loss 0.33205732520325304 train_acc 0.8564360985173386\n",
      "epoch 2576 lr 0.0028939087542346185\n",
      "train_loss 0.33201780272300835 train_acc 0.8572632030388433\n",
      "epoch 2577 lr 0.0028881267206870417\n",
      "train_loss 0.3321160665442279 train_acc 0.8564054650165421\n",
      "epoch 2578 lr 0.002882356239650199\n",
      "train_loss 0.33208455575809215 train_acc 0.8572785197892415\n",
      "epoch 2579 lr 0.002876597288042155\n",
      "train_loss 0.3321897394495414 train_acc 0.8563595147653473\n",
      "epoch 2580 lr 0.0028708498428271015\n",
      "train_loss 0.33215408180693623 train_acc 0.8571866192868521\n",
      "epoch 2581 lr 0.0028651138810152467\n",
      "train_loss 0.3322548660914478 train_acc 0.8562676142629579\n",
      "epoch 2582 lr 0.0028593893796627365\n",
      "train_loss 0.33222110166795016 train_acc 0.8570640852836662\n",
      "epoch 2583 lr 0.002853676315871555\n",
      "train_loss 0.33233597637778023 train_acc 0.8561757137605686\n",
      "epoch 2584 lr 0.002847974666789444\n",
      "train_loss 0.3323050765776253 train_acc 0.8570334517828697\n",
      "epoch 2585 lr 0.0028422844096097975\n",
      "train_loss 0.3324288353439499 train_acc 0.8560991300085774\n",
      "epoch 2586 lr 0.0028366055215715796\n",
      "train_loss 0.33238306691656233 train_acc 0.8568649675284892\n",
      "epoch 2587 lr 0.002830937979959227\n",
      "train_loss 0.3325006671857736 train_acc 0.8560531797573827\n",
      "epoch 2588 lr 0.002825281762102572\n",
      "train_loss 0.3324461335407064 train_acc 0.8567118000245068\n",
      "epoch 2589 lr 0.002819636845376732\n",
      "train_loss 0.3325744424332289 train_acc 0.8561144467589756\n",
      "epoch 2590 lr 0.002814003207202033\n",
      "train_loss 0.33251186530666454 train_acc 0.8566811665237103\n",
      "epoch 2591 lr 0.0028083808250439126\n",
      "train_loss 0.33263891741427626 train_acc 0.8560838132581792\n",
      "epoch 2592 lr 0.002802769676412839\n",
      "train_loss 0.3325639259965169 train_acc 0.8566198995221174\n",
      "epoch 2593 lr 0.0027971697388642085\n",
      "train_loss 0.33268914372395625 train_acc 0.855945962504595\n",
      "epoch 2594 lr 0.0027915809899982627\n",
      "train_loss 0.3326040305387694 train_acc 0.8565433157701262\n",
      "epoch 2595 lr 0.0027860034074599967\n",
      "train_loss 0.3327361335810329 train_acc 0.8559306457541968\n",
      "epoch 2596 lr 0.0027804369689390777\n",
      "train_loss 0.3326587142729743 train_acc 0.8563748315157457\n",
      "epoch 2597 lr 0.0027748816521697413\n",
      "train_loss 0.3327933013517068 train_acc 0.8558234285014091\n",
      "epoch 2598 lr 0.002769337434930714\n",
      "train_loss 0.33272132465157855 train_acc 0.8562982477637544\n",
      "epoch 2599 lr 0.002763804295045116\n",
      "train_loss 0.33285407833992425 train_acc 0.855746844749418\n",
      "\n",
      "val loss = 0.36538103055481974, \n",
      "val acc = 0.8312887663680221\n",
      "\n",
      "epoch 2600 lr 0.0027582822103803858\n",
      "train_loss 0.3327705597554863 train_acc 0.8563288812645509\n",
      "epoch 2601 lr 0.002752771158848175\n",
      "train_loss 0.33290204893679526 train_acc 0.8557774782502144\n",
      "epoch 2602 lr 0.00274727111840427\n",
      "train_loss 0.33281115075324347 train_acc 0.8562676142629579\n",
      "epoch 2603 lr 0.0027417820670484986\n",
      "train_loss 0.33291972230916006 train_acc 0.8558234285014091\n",
      "epoch 2604 lr 0.002736303982824654\n",
      "train_loss 0.33281260429438564 train_acc 0.8562829310133562\n",
      "epoch 2605 lr 0.002730836843820389\n",
      "train_loss 0.3329189168527706 train_acc 0.8558234285014091\n",
      "epoch 2606 lr 0.0027253806281671406\n",
      "train_loss 0.33279971875146336 train_acc 0.8563288812645509\n",
      "epoch 2607 lr 0.0027199353140400363\n",
      "train_loss 0.3329017073588773 train_acc 0.8558081117510109\n",
      "epoch 2608 lr 0.002714500879657817\n",
      "train_loss 0.33277368795063517 train_acc 0.8563748315157457\n",
      "epoch 2609 lr 0.0027090773032827356\n",
      "train_loss 0.3328661957358732 train_acc 0.8558693787526038\n",
      "epoch 2610 lr 0.0027036645632204795\n",
      "train_loss 0.33272462747741166 train_acc 0.8563595147653473\n",
      "epoch 2611 lr 0.002698262637820079\n",
      "train_loss 0.33280717835660606 train_acc 0.8558693787526038\n",
      "epoch 2612 lr 0.00269287150547383\n",
      "train_loss 0.33265397819308995 train_acc 0.8563288812645509\n",
      "epoch 2613 lr 0.0026874911446171925\n",
      "train_loss 0.33271711408623245 train_acc 0.8559612792549932\n",
      "epoch 2614 lr 0.0026821215337287175\n",
      "train_loss 0.3325521333447342 train_acc 0.8564973655189315\n",
      "epoch 2615 lr 0.002676762651329951\n",
      "train_loss 0.33262022659900714 train_acc 0.8561297635093739\n",
      "epoch 2616 lr 0.0026714144759853614\n",
      "train_loss 0.33245452381411905 train_acc 0.8565586325205244\n",
      "epoch 2617 lr 0.0026660769863022377\n",
      "train_loss 0.3325085844492594 train_acc 0.8562676142629579\n",
      "epoch 2618 lr 0.0026607501609306134\n",
      "train_loss 0.3323394526526081 train_acc 0.8566198995221174\n",
      "epoch 2619 lr 0.002655433978563179\n",
      "train_loss 0.3323851030415114 train_acc 0.8563748315157457\n",
      "epoch 2620 lr 0.002650128417935201\n",
      "train_loss 0.3322013518929214 train_acc 0.8566658497733121\n",
      "epoch 2621 lr 0.0026448334578244286\n",
      "train_loss 0.33224145230084673 train_acc 0.8563288812645509\n",
      "epoch 2622 lr 0.002639549077051014\n",
      "train_loss 0.3320543317201448 train_acc 0.8567730670260998\n",
      "epoch 2623 lr 0.0026342752544774245\n",
      "train_loss 0.3320846331539976 train_acc 0.856206347261365\n",
      "epoch 2624 lr 0.0026290119690083676\n",
      "train_loss 0.3319024369443382 train_acc 0.8570181350324715\n",
      "epoch 2625 lr 0.0026237591995906923\n",
      "train_loss 0.3319316201453509 train_acc 0.8563595147653473\n",
      "epoch 2626 lr 0.0026185169252133135\n",
      "train_loss 0.33175702272025137 train_acc 0.8573244700404362\n",
      "epoch 2627 lr 0.0026132851249071267\n",
      "train_loss 0.3317872722362154 train_acc 0.8564820487685333\n",
      "epoch 2628 lr 0.002608063777744922\n",
      "train_loss 0.3316319583795546 train_acc 0.8574316872932238\n",
      "epoch 2629 lr 0.0026028528628413076\n",
      "train_loss 0.3316556149247953 train_acc 0.8566352162725156\n",
      "epoch 2630 lr 0.0025976523593526156\n",
      "train_loss 0.3315153257575565 train_acc 0.8573857370420291\n",
      "epoch 2631 lr 0.002592462246476824\n",
      "train_loss 0.3315268546488433 train_acc 0.8566964832741085\n",
      "epoch 2632 lr 0.002587282503453473\n",
      "train_loss 0.33139457017777707 train_acc 0.8574470040436221\n",
      "epoch 2633 lr 0.002582113109563588\n",
      "train_loss 0.33140579181539986 train_acc 0.8567424335253033\n",
      "epoch 2634 lr 0.0025769540441295835\n",
      "train_loss 0.3312939678098515 train_acc 0.8575082710452151\n",
      "epoch 2635 lr 0.0025718052865151917\n",
      "train_loss 0.33130807032920595 train_acc 0.8568956010292856\n",
      "epoch 2636 lr 0.0025666668161253726\n",
      "train_loss 0.3312092881096988 train_acc 0.8574776375444185\n",
      "epoch 2637 lr 0.002561538612406243\n",
      "train_loss 0.3312366350623457 train_acc 0.8569721847812768\n",
      "epoch 2638 lr 0.002556420654844978\n",
      "train_loss 0.33114030182598436 train_acc 0.8575235877956133\n",
      "epoch 2639 lr 0.002551312922969741\n",
      "train_loss 0.33117199879850845 train_acc 0.857048768533268\n",
      "epoch 2640 lr 0.002546215396349595\n",
      "train_loss 0.33108056815055126 train_acc 0.8575848547972063\n",
      "epoch 2641 lr 0.0025411280545944324\n",
      "train_loss 0.3311192385222007 train_acc 0.8570794020340644\n",
      "epoch 2642 lr 0.002536050877354876\n",
      "train_loss 0.3310258379274476 train_acc 0.857569538046808\n",
      "epoch 2643 lr 0.0025309838443222103\n",
      "train_loss 0.33107298868800894 train_acc 0.8571713025364539\n",
      "epoch 2644 lr 0.0025259269352282945\n",
      "train_loss 0.33098760880383227 train_acc 0.857630805048401\n",
      "epoch 2645 lr 0.0025208801298454895\n",
      "train_loss 0.3310434383241056 train_acc 0.8571406690356574\n",
      "epoch 2646 lr 0.002515843407986565\n",
      "train_loss 0.33095912566592944 train_acc 0.8576614385491974\n",
      "epoch 2647 lr 0.002510816749504627\n",
      "train_loss 0.3310234866027956 train_acc 0.8571406690356574\n",
      "epoch 2648 lr 0.0025058001342930327\n",
      "train_loss 0.33094711378803215 train_acc 0.8576920720499939\n",
      "epoch 2649 lr 0.002500793542285319\n",
      "train_loss 0.33102153601943174 train_acc 0.8571406690356574\n",
      "\n",
      "val loss = 0.36387585410265605, \n",
      "val acc = 0.833631977946244\n",
      "\n",
      "epoch 2650 lr 0.0024957969534551085\n",
      "train_loss 0.33095073478831705 train_acc 0.8576920720499939\n",
      "epoch 2651 lr 0.00249081034781604\n",
      "train_loss 0.3310371398375623 train_acc 0.8570794020340644\n",
      "epoch 2652 lr 0.002485833705421681\n",
      "train_loss 0.33097168437526064 train_acc 0.8576154882980027\n",
      "epoch 2653 lr 0.0024808670063654606\n",
      "train_loss 0.33106083660617186 train_acc 0.8570947187844626\n",
      "epoch 2654 lr 0.0024759102307805735\n",
      "train_loss 0.33101157339052256 train_acc 0.8576614385491974\n",
      "epoch 2655 lr 0.002470963358839911\n",
      "train_loss 0.3311107765706337 train_acc 0.856987501531675\n",
      "epoch 2656 lr 0.002466026370755976\n",
      "train_loss 0.33107352852173677 train_acc 0.8574776375444185\n",
      "epoch 2657 lr 0.002461099246780814\n",
      "train_loss 0.33119420228829966 train_acc 0.8569721847812768\n",
      "epoch 2658 lr 0.002456181967205921\n",
      "train_loss 0.3311726877417873 train_acc 0.8573551035412327\n",
      "epoch 2659 lr 0.0024512745123621716\n",
      "train_loss 0.3313102168533076 train_acc 0.8568956010292856\n",
      "epoch 2660 lr 0.002446376862619738\n",
      "train_loss 0.3313029411730553 train_acc 0.8572938365396398\n",
      "epoch 2661 lr 0.002441488998388019\n",
      "train_loss 0.3314769723793368 train_acc 0.8568190172772945\n",
      "epoch 2662 lr 0.002436610900115548\n",
      "train_loss 0.331467043251045 train_acc 0.857309153290038\n",
      "epoch 2663 lr 0.002431742548289927\n",
      "train_loss 0.33164028954073294 train_acc 0.8566045827717191\n",
      "epoch 2664 lr 0.0024268839234377394\n",
      "train_loss 0.3316337161569303 train_acc 0.8571559857860557\n",
      "epoch 2665 lr 0.0024220350061244836\n",
      "train_loss 0.33182339686902546 train_acc 0.8564820487685333\n",
      "epoch 2666 lr 0.0024171957769544812\n",
      "train_loss 0.3318133017113301 train_acc 0.8570334517828697\n",
      "epoch 2667 lr 0.00241236621657081\n",
      "train_loss 0.33200654002451874 train_acc 0.8564514152677368\n",
      "epoch 2668 lr 0.002407546305655219\n",
      "train_loss 0.3319918031335345 train_acc 0.8569568680308786\n",
      "epoch 2669 lr 0.002402736024928063\n",
      "train_loss 0.33217220582919865 train_acc 0.8564820487685333\n",
      "epoch 2670 lr 0.0023979353551482107\n",
      "train_loss 0.33212962362144666 train_acc 0.8568190172772945\n",
      "epoch 2671 lr 0.0023931442771129756\n",
      "train_loss 0.3323153280919682 train_acc 0.8563748315157457\n",
      "epoch 2672 lr 0.002388362771658038\n",
      "train_loss 0.3322863027844686 train_acc 0.8566198995221174\n",
      "epoch 2673 lr 0.0023835908196573738\n",
      "train_loss 0.33250050353593585 train_acc 0.8561297635093739\n",
      "epoch 2674 lr 0.0023788284020231664\n",
      "train_loss 0.33244863924979284 train_acc 0.8565126822693298\n",
      "epoch 2675 lr 0.002374075499705739\n",
      "train_loss 0.3326588031958999 train_acc 0.856007229506188\n",
      "epoch 2676 lr 0.002369332093693473\n",
      "train_loss 0.3325855668020387 train_acc 0.8563748315157457\n",
      "epoch 2677 lr 0.0023645981650127434\n",
      "train_loss 0.3327756776567409 train_acc 0.8558081117510109\n",
      "epoch 2678 lr 0.0023598736947278267\n",
      "train_loss 0.33267477978816695 train_acc 0.856206347261365\n",
      "epoch 2679 lr 0.0023551586639408355\n",
      "train_loss 0.33285872937258426 train_acc 0.8557927950006127\n",
      "epoch 2680 lr 0.002350453053791638\n",
      "train_loss 0.3327342467027512 train_acc 0.8561910305109668\n",
      "epoch 2681 lr 0.0023457568454577915\n",
      "train_loss 0.3329171680891487 train_acc 0.8558234285014091\n",
      "epoch 2682 lr 0.002341070020154455\n",
      "train_loss 0.33277382301986635 train_acc 0.8562216640117633\n",
      "epoch 2683 lr 0.00233639255913432\n",
      "train_loss 0.3329243564344448 train_acc 0.8558387452518074\n",
      "epoch 2684 lr 0.0023317244436875354\n",
      "train_loss 0.33276541497216044 train_acc 0.8562216640117633\n",
      "epoch 2685 lr 0.002327065655141636\n",
      "train_loss 0.332887699212279 train_acc 0.8558693787526038\n",
      "epoch 2686 lr 0.00232241617486146\n",
      "train_loss 0.3326999488586971 train_acc 0.8562216640117633\n",
      "epoch 2687 lr 0.00231777598424908\n",
      "train_loss 0.3327919498792809 train_acc 0.8558846955030021\n",
      "epoch 2688 lr 0.0023131450647437255\n",
      "train_loss 0.33258071916055937 train_acc 0.8563135645141526\n",
      "epoch 2689 lr 0.002308523397821716\n",
      "train_loss 0.3326386211594597 train_acc 0.8558846955030021\n",
      "epoch 2690 lr 0.002303910964996376\n",
      "train_loss 0.33241556587639953 train_acc 0.8564514152677368\n",
      "epoch 2691 lr 0.0022993077478179677\n",
      "train_loss 0.33246048691248054 train_acc 0.8560991300085774\n",
      "epoch 2692 lr 0.0022947137278736146\n",
      "train_loss 0.33223924267831784 train_acc 0.8566964832741085\n",
      "epoch 2693 lr 0.0022901288867872346\n",
      "train_loss 0.33226256379232044 train_acc 0.8562982477637544\n",
      "epoch 2694 lr 0.002285553206219455\n",
      "train_loss 0.33203090475401137 train_acc 0.8568956010292856\n",
      "epoch 2695 lr 0.0022809866678675478\n",
      "train_loss 0.33204763686658834 train_acc 0.8564360985173386\n",
      "epoch 2696 lr 0.0022764292534653515\n",
      "train_loss 0.33181424353250727 train_acc 0.8571253522852592\n",
      "epoch 2697 lr 0.002271880944783206\n",
      "train_loss 0.33180610149342066 train_acc 0.8565739492709227\n",
      "epoch 2698 lr 0.0022673417236278694\n",
      "train_loss 0.3315836903059001 train_acc 0.8571866192868521\n",
      "epoch 2699 lr 0.00226281157184245\n",
      "train_loss 0.33157278082840635 train_acc 0.856788383776498\n",
      "\n",
      "val loss = 0.36465948971540146, \n",
      "val acc = 0.8314266023432115\n",
      "\n",
      "epoch 2700 lr 0.002258290471306333\n",
      "train_loss 0.331355814733906 train_acc 0.8572478862884451\n",
      "epoch 2701 lr 0.002253778403935114\n",
      "train_loss 0.33134106235153854 train_acc 0.8568496507780909\n",
      "epoch 2702 lr 0.0022492753516805165\n",
      "train_loss 0.3311569301648763 train_acc 0.8574010537924274\n",
      "epoch 2703 lr 0.0022447812965303245\n",
      "train_loss 0.33114715517043325 train_acc 0.8570640852836662\n",
      "epoch 2704 lr 0.0022402962205083097\n",
      "train_loss 0.3309818329745123 train_acc 0.8574929542948169\n",
      "epoch 2705 lr 0.002235820105674166\n",
      "train_loss 0.3309824310465386 train_acc 0.8572172527876486\n",
      "epoch 2706 lr 0.002231352934123426\n",
      "train_loss 0.33084648858782284 train_acc 0.8574776375444185\n",
      "epoch 2707 lr 0.0022268946879873976\n",
      "train_loss 0.33084483122785663 train_acc 0.8573551035412327\n",
      "epoch 2708 lr 0.0022224453494330883\n",
      "train_loss 0.3307215255834618 train_acc 0.8574929542948169\n",
      "epoch 2709 lr 0.002218004900663142\n",
      "train_loss 0.3307248964630717 train_acc 0.8573551035412327\n",
      "epoch 2710 lr 0.002213573323915756\n",
      "train_loss 0.3306022235369119 train_acc 0.8574776375444185\n",
      "epoch 2711 lr 0.002209150601464617\n",
      "train_loss 0.3306049773879586 train_acc 0.8575082710452151\n",
      "epoch 2712 lr 0.002204736715618827\n",
      "train_loss 0.33048161977464824 train_acc 0.8576154882980027\n",
      "epoch 2713 lr 0.0022003316487228413\n",
      "train_loss 0.33049340851106795 train_acc 0.8575389045460116\n",
      "epoch 2714 lr 0.002195935383156384\n",
      "train_loss 0.3303844961329535 train_acc 0.8576154882980027\n",
      "epoch 2715 lr 0.002191547901334388\n",
      "train_loss 0.33039988420407124 train_acc 0.857569538046808\n",
      "epoch 2716 lr 0.002187169185706917\n",
      "train_loss 0.3303109807332031 train_acc 0.8576767552995956\n",
      "epoch 2717 lr 0.002182799218759107\n",
      "train_loss 0.3303289993262488 train_acc 0.8575235877956133\n",
      "epoch 2718 lr 0.0021784379830110823\n",
      "train_loss 0.3302543766623802 train_acc 0.8576614385491974\n",
      "epoch 2719 lr 0.0021740854610178945\n",
      "train_loss 0.33027888020892465 train_acc 0.8575389045460116\n",
      "epoch 2720 lr 0.0021697416353694474\n",
      "train_loss 0.330209632204117 train_acc 0.8577533390515868\n",
      "epoch 2721 lr 0.002165406488690437\n",
      "train_loss 0.33024300388883254 train_acc 0.8575542212964098\n",
      "epoch 2722 lr 0.0021610800036402683\n",
      "train_loss 0.3301864406671786 train_acc 0.8577533390515868\n",
      "epoch 2723 lr 0.0021567621629129956\n",
      "train_loss 0.3302315099496285 train_acc 0.857569538046808\n",
      "epoch 2724 lr 0.0021524529492372483\n",
      "train_loss 0.33018435736625856 train_acc 0.8577380223011886\n",
      "epoch 2725 lr 0.00214815234537617\n",
      "train_loss 0.3302377385500894 train_acc 0.8575848547972063\n",
      "epoch 2726 lr 0.0021438603341273374\n",
      "train_loss 0.33019968582753045 train_acc 0.8576767552995956\n",
      "epoch 2727 lr 0.0021395768983226995\n",
      "train_loss 0.3302645756071276 train_acc 0.8575235877956133\n",
      "epoch 2728 lr 0.002135302020828506\n",
      "train_loss 0.33023846417314995 train_acc 0.8575848547972063\n",
      "epoch 2729 lr 0.0021310356845452446\n",
      "train_loss 0.3303287051434988 train_acc 0.8575848547972063\n",
      "epoch 2730 lr 0.0021267778724075627\n",
      "train_loss 0.3303129590606651 train_acc 0.8576154882980027\n",
      "epoch 2731 lr 0.0021225285673842063\n",
      "train_loss 0.3304222446623185 train_acc 0.8574010537924274\n",
      "epoch 2732 lr 0.0021182877524779475\n",
      "train_loss 0.3304140733508463 train_acc 0.8576154882980027\n",
      "epoch 2733 lr 0.0021140554107255253\n",
      "train_loss 0.3305336615765946 train_acc 0.8572325695380468\n",
      "epoch 2734 lr 0.002109831525197564\n",
      "train_loss 0.330523639149569 train_acc 0.8576461217987992\n",
      "epoch 2735 lr 0.002105616078998517\n",
      "train_loss 0.3306657264331758 train_acc 0.8572478862884451\n",
      "epoch 2736 lr 0.002101409055266592\n",
      "train_loss 0.3306784633521208 train_acc 0.8574623207940203\n",
      "epoch 2737 lr 0.0020972104371736913\n",
      "train_loss 0.3308504110904018 train_acc 0.8570794020340644\n",
      "epoch 2738 lr 0.002093020207925336\n",
      "train_loss 0.3308672036555164 train_acc 0.8574776375444185\n",
      "epoch 2739 lr 0.002088838350760603\n",
      "train_loss 0.33106759266781527 train_acc 0.8569568680308786\n",
      "epoch 2740 lr 0.0020846648489520558\n",
      "train_loss 0.3310982450973639 train_acc 0.8574470040436221\n",
      "epoch 2741 lr 0.002080499685805686\n",
      "train_loss 0.33132912162276695 train_acc 0.8568037005268963\n",
      "epoch 2742 lr 0.0020763428446608336\n",
      "train_loss 0.3313576295116403 train_acc 0.8571713025364539\n",
      "epoch 2743 lr 0.002072194308890128\n",
      "train_loss 0.3315964844793768 train_acc 0.8565126822693298\n",
      "epoch 2744 lr 0.0020680540618994198\n",
      "train_loss 0.33160721205843796 train_acc 0.8569262345300821\n",
      "epoch 2745 lr 0.002063922087127718\n",
      "train_loss 0.33187067281896987 train_acc 0.8562522975125597\n",
      "epoch 2746 lr 0.0020597983680471165\n",
      "train_loss 0.33183946416662896 train_acc 0.856727116774905\n",
      "epoch 2747 lr 0.0020556828881627335\n",
      "train_loss 0.3321142273412313 train_acc 0.8560991300085774\n",
      "epoch 2748 lr 0.0020515756310126422\n",
      "train_loss 0.33205646063700567 train_acc 0.8565739492709227\n",
      "epoch 2749 lr 0.0020474765801678126\n",
      "train_loss 0.3323236118628394 train_acc 0.8560684965077809\n",
      "\n",
      "val loss = 0.36612541993148146, \n",
      "val acc = 0.8312887663680221\n",
      "\n",
      "epoch 2750 lr 0.0020433857192320333\n",
      "train_loss 0.3322662977674875 train_acc 0.8563748315157457\n",
      "\n",
      "-----training done-----\n",
      "\n",
      "model2 training took 34.86 minutes\n",
      "training of all models took 111.27 minutes\n"
     ]
    }
   ],
   "source": [
    "#Training of the models using selected the number of epochs maximizing the validation loss and exponential learning rate decay. \n",
    "\n",
    "N_epochs = [3001, 1501, 1501]\n",
    "dec_speed = 500\n",
    "\n",
    "t0 = time.time()\n",
    "model0 = NN(nn_architecture0)\n",
    "model0.init_weights()\n",
    "print('-----model0 training-----\\n')\n",
    "train_l0, train_a0, val_l0, val_a0 = model0.train(train_data0,train_y0,val_data0,val_y0,max_epochs=N_epochs[0],dec_speed=dec_speed)\n",
    "t1 = time.time()\n",
    "print(f'model0 training took {((t1-t0)/60):.2f} minutes')\n",
    "\n",
    "model1 = NN(nn_architecture1)\n",
    "model1.init_weights()\n",
    "print('\\n-----model1 training-----\\n')\n",
    "train_l1, train_a1, val_l1, val_a1 = model1.train(train_data1,train_y1,val_data1,val_y1,max_epochs=N_epochs[1],dec_speed=dec_speed,)\n",
    "t2 = time.time()\n",
    "print(f'model1 training took {((t2-t1)/60):.2f} minutes')\n",
    "\n",
    "model2 = NN(nn_architecture2)\n",
    "model2.init_weights()\n",
    "print('-----model2 training-----\\n')\n",
    "train_l2, train_a2, val_l2, val_a2 = model2.train(train_data2,train_y2,val_data2,val_y2,max_epochs=N_epochs[2],dec_speed=dec_speed)\n",
    "t3 = time.time()\n",
    "print(f'model2 training took {((t3-t2)/60):.2f} minutes')\n",
    "print(f'training of all models took {((t3-t0)/60):.2f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the models weights\n",
    "models_params = (model0.params, model1.params, model2.params)\n",
    "\n",
    "for i, model_params in enumerate(models_params):\n",
    "    f = open(f'models/model{i}_{N_epochs[i]}_ep.pkl', 'wb')\n",
    "    pickle.dump(model_params,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1266/2745508655.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  pickle.dump(np.array([train_losses,train_accuracies,val_losses,val_accuracies]),open('training_logs.pkl','wb'))\n"
     ]
    }
   ],
   "source": [
    "#saving the training logs\n",
    "pickle.dump(np.array([train_losses,train_accuracies,val_losses,val_accuracies]),open('training_logs.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the train and validation losses and accuracies\n",
    "train_logs = pickle.load(open(\"training_logs.pkl\",'rb'))\n",
    "train_losses = train_logs[0,:]\n",
    "train_accuracies = train_logs[1,:]\n",
    "val_losses = train_logs[2,:]\n",
    "val_accuracies = train_logs[3,:]\n",
    "\n",
    "f, axs = plt.subplots(2,2,figsize=(12,12))\n",
    "axs[0,0].set_title('training losses')\n",
    "for i,train_loss in enumerate(train_losses):\n",
    "    axs[0,0].plot(range(len(train_loss)),train_loss,label=f'model{i}')\n",
    "axs[0,0].set_xlabel('epochs')\n",
    "axs[0,0].set_ylabel('loss')\n",
    "\n",
    "axs[0,1].set_title('training accuracies')\n",
    "for train_acc in train_accuracies:\n",
    "    axs[0,1].plot(range(len(train_acc)),train_acc)\n",
    "axs[0,1].set_xlabel('epochs')\n",
    "axs[0,1].set_ylabel('accuracy')\n",
    "\n",
    "axs[1,0].set_title('validation losses')\n",
    "for i, val_loss in enumerate(val_losses):\n",
    "    x = np.linspace(0,len(train_losses[i]),len(val_loss))\n",
    "    axs[1,0].plot(x,val_loss)\n",
    "axs[1,0].set_xlabel('epochs')\n",
    "axs[1,0].set_ylabel('loss')\n",
    "\n",
    "axs[1,1].set_title('validation accuracies')\n",
    "for i, val_acc in enumerate(val_accuracies):\n",
    "    x = np.linspace(0,len(train_losses[i]),len(val_acc))\n",
    "    axs[1,1].plot(x,val_acc)\n",
    "axs[1,1].set_xlabel('epochs')\n",
    "axs[1,1].set_ylabel('accuracy')\n",
    "f.legend(ncol=3,bbox_to_anchor=(0.65, 0.05))\n",
    "plt.savefig('training_logs.png',dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c2cef518e44103d2e87bbc7bdbad3c849c59c4ad82abf34e0b5c0b1400204ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
